{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SOvAezRZMlB",
    "outputId": "48e98430-74cb-4ffc-db14-9441cf2f39b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=3a3304f0d393800295e864a34dd422910c180126d6f502d6f99bf069659a0055\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, rouge_score, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate, accelerate\n",
      "Successfully installed accelerate-0.29.2 datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 responses-0.18.0 rouge_score-0.1.2 xxhash-3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate rouge_score accelerate -U # accelerate -U is needed for seq2seq training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6nuZnGVtZxDQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Mvf_wW5ta8YJ"
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    {\n",
    "        # https://github.com/pydantic/pydantic/pull/9111\n",
    "        \"code\": \"\"\"\n",
    "Pull Request Diff:\n",
    "```\n",
    "diff --git a/pydantic/_internal/_fields.py b/pydantic/_internal/_fields.py\n",
    "index 3f78a920d5..6e5e933061 100644\n",
    "--- a/pydantic/_internal/_fields.py\n",
    "+++ b/pydantic/_internal/_fields.py\n",
    "@@ -177,7 +177,7 @@ def collect_model_fields(  # noqa: C901\n",
    "             )\n",
    "\n",
    "         # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n",
    "-        # \"... shadows an attribute\" errors\n",
    "+        # \"... shadows an attribute\" warnings\n",
    "         generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n",
    "         for base in bases:\n",
    "             dataclass_fields = {\n",
    "#  Do not warn about shadowed fields if they are not redefined in a child class\n",
    "```\n",
    "\"\"\",\n",
    "        \"description\": \"\"\"\n",
    "        # Change Summary\n",
    "\n",
    "        Adds another early exit condition when evaluating whether to log a warning message during detection for shadowed fields.\n",
    "\n",
    "In the case where a field is defined in a parent class, but it has not been defined at all in a child class, it is technically not a shadowed field, and so shouldn't be warned as such.\n",
    "\n",
    "Note this is very different from the case where a child class does redefine a field but with a narrower type or even defined as the same type but with a different default. Conceptually this is probably ok, but checking for that is quite complex and this PR does not attempt to try. So this is about checking if a field is defined or not defined - if it is, regardless of type or default value, the warning message is still logged.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        # https://github.com/pydantic/pydantic/pull/9144\n",
    "        \"code\": \"\"\"\n",
    "        --- a/pydantic/main.py\n",
    "+++ b/pydantic/main.py\n",
    "@@ -222,9 +222,12 @@ def model_construct(cls: type[Model], _fields_set: set[str] | None = None, **val\n",
    "         fields_set = set()\n",
    "\n",
    "         for name, field in cls.model_fields.items():\n",
    "-            if field.alias and field.alias in values:\n",
    "+            if field.alias is not None and field.alias in values:\n",
    "                 fields_values[name] = values.pop(field.alias)\n",
    "                 fields_set.add(name)\n",
    "+            elif field.validation_alias is not None and field.validation_alias in values:\n",
    "+                fields_values[name] = values.pop(field.validation_alias)\n",
    "+                fields_set.add(name)\n",
    "             elif name in values:\n",
    "                 fields_values[name] = values.pop(name)\n",
    "                 fields_set.add(name)\n",
    "        \"\"\",\n",
    "        \"description\": \"\"\"\n",
    "        # Change Summary\n",
    "\n",
    "        just like you can construct a model using a field alias, this PR fixes constructing a model using validation_alias.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"\"\"\n",
    "        diff --git a/pydantic/json_schema.py b/pydantic/json_schema.py\n",
    "index 9f0ceb3e36..3e63ecc08d 100644\n",
    "--- a/pydantic/json_schema.py\n",
    "+++ b/pydantic/json_schema.py\n",
    "@@ -751,6 +751,8 @@ def literal_schema(self, schema: core_schema.LiteralSchema) -> JsonSchemaValue:\n",
    "             result['type'] = 'boolean'\n",
    "         elif types == {list}:\n",
    "             result['type'] = 'array'\n",
    "+        elif types == {type(None)}:\n",
    "+            result['type'] = 'null'\n",
    "         return result\n",
    "\n",
    "     def enum_schema(self, schema: core_schema.EnumSchema) -> JsonSchemaValue:\n",
    "        \"\"\",\n",
    "        \"description\": \"\"\"\n",
    "        # Change Summary\n",
    "\n",
    "        This PR aims to complete #8944 and #8905 by also handling null types when generating a json-schema from a pydantic model.\n",
    "\n",
    "For instance, the following model:\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class Foo(BaseModel):\n",
    "    bar: Literal[\"Bar\"] = 'Bar'\n",
    "    baz: Literal[None] = None\n",
    "    foo: str = 'Foo'\n",
    "```\n",
    "leads to:\n",
    "```\n",
    "{'properties': {'bar': {'const': 'Bar', 'default': 'Bar', 'enum': ['Bar'], 'title': 'Bar', 'type': 'string'}, 'baz': {'const': None, 'default': None, 'enum': [None], 'title': 'Baz', 'type': 'null'}, 'foo': {'default': 'Foo', 'title': 'Foo', 'type': 'string'}}, 'title': 'Foo', 'type': 'object'}\n",
    "```\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "6ER75xDGZywH"
   },
   "outputs": [],
   "source": [
    "class CodeDescriptionDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Prepare the dataset\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        for entry in texts:\n",
    "            # Tokenize input and target texts\n",
    "            input_encodings = tokenizer(entry[\"code\"], truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            target_encodings = tokenizer(\n",
    "                entry[\"description\"], truncation=True, max_length=max_length, padding=\"max_length\"\n",
    "            )\n",
    "\n",
    "            self.inputs.append(torch.tensor(input_encodings[\"input_ids\"]))\n",
    "            self.targets.append(torch.tensor(target_encodings[\"input_ids\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.inputs[idx]\n",
    "        target_ids = self.targets[idx]\n",
    "\n",
    "        # We can create a mask for the targets with -100 (ignored by loss functions in HuggingFace) where the input is padding\n",
    "        target_mask = (target_ids != self.tokenizer.pad_token_id).long()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": target_ids * target_mask\n",
    "            + (tokenizer.pad_token_id * (1 - target_mask)),  # Mask out pad tokens in labels\n",
    "        }  # 50257 -- [PAD] token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTKQue0Wa_BR",
    "outputId": "bfb127cc-8427-48ab-8b55-31e8d203bc2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "_u9h9L95bA6e"
   },
   "outputs": [],
   "source": [
    "# tokenizer(\"[PAD]\")[\"input_ids\"][0] # 50257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "seRPrtuSbcW2"
   },
   "outputs": [],
   "source": [
    "# dataset = CodeDescriptionDataset(texts, tokenizer)\n",
    "# train_dataset, val_dataset = random_split(dataset, [2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "-k5YeWPybjNS"
   },
   "outputs": [],
   "source": [
    "train_dataset = CodeDescriptionDataset(texts, tokenizer)\n",
    "eval_dataset = CodeDescriptionDataset(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "COXh4SR2b3lA"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metrics_name = [\"bleu\", \"rouge\", \"exact_match\"]\n",
    "for name in metrics_name:\n",
    "    evaluate.load(name)\n",
    "metrics = evaluate.combine(metrics_name)\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, label_ids = eval_pred.predictions, eval_pred.label_ids\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    decoded_preds = [\n",
    "        tokenizer.decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=True) for pred in predictions\n",
    "    ]\n",
    "    decoded_labels = [\n",
    "        tokenizer.decode(label, skip_special_tokens=True, clean_up_tokenization_spaces=True) for label in label_ids\n",
    "    ]\n",
    "\n",
    "    # Prepare data for BLEU\n",
    "    # formatted_predictions = [pred.strip() for pred in decoded_preds]\n",
    "    # formatted_references = [ref.strip() for ref in decoded_labels]  # BLEU expects list of list of references for each prediction\n",
    "\n",
    "    return metrics.compute(predictions=decoded_preds, references=decoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-vikF23ubxDD",
    "outputId": "8c86635e-b445-4882-e476-78a350287aad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # output directory\n",
    "    num_train_epochs=5,  # total number of training epochs\n",
    "    # warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    # weight_decay=0.01,               # strength of weight decay\n",
    "    # logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"epoch\",  # perform evaluation each epoch\n",
    "    # eval_steps=2000,\n",
    "    # # per_device_train_batch_size=8,\n",
    "    # # per_device_eval_batch_size=64,\n",
    "    # auto_find_batch_size=True,\n",
    "    # save_strategy=\"epoch\",\n",
    "    # lr_scheduler_type=SchedulerType.COSINE_WITH_RESTARTS,\n",
    "    # predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "TZGclZpcb_gL",
    "outputId": "7237a8d8-b3cf-44f6-eb95-8be651e7b699"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Precisions</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27.274300</td>\n",
       "      <td>60.178959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>0.234104</td>\n",
       "      <td>81</td>\n",
       "      <td>346</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28.927500</td>\n",
       "      <td>60.178959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>0.234104</td>\n",
       "      <td>81</td>\n",
       "      <td>346</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28.128000</td>\n",
       "      <td>60.178959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>0.234104</td>\n",
       "      <td>81</td>\n",
       "      <td>346</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>26.431000</td>\n",
       "      <td>60.178959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>0.234104</td>\n",
       "      <td>81</td>\n",
       "      <td>346</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>27.533300</td>\n",
       "      <td>60.178959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>0.234104</td>\n",
       "      <td>81</td>\n",
       "      <td>346</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.25925925925925924, 0.07692307692307693, 0.0, 0.0]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=27.658814239501954, metrics={'train_runtime': 5.4833, 'train_samples_per_second': 2.736, 'train_steps_per_second': 0.912, 'total_flos': 3919380480000.0, 'train_loss': 27.658814239501954, 'epoch': 5.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "tmDRXEZOhJ_w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
