Unnamed: 0,target,generated_val
0,"Fix bug related to CPU training
Resolves #389
Encoder training works on CPU with this fix.", # Remove torch.cpu.synchronize
1,"Improved docs of ImageDataGenerator
Shown default values of arguments in ImageDataGenerator docs
", # Update image.md
2,"mexc networks updated to working values
fixes: #15251

```
% mexc withdraw USDT 11 '""0xa4d50e44877cbf7fe983420967d27a783807a79f""' '{""network"": ""BEP20""}'
2022-10-12T01:35:32.374Z
Node.js: v18.4.0
CCXT v1.95.35
(node:7423) ExperimentalWarning: The Fetch API is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
mexc.withdraw (USDT, 11, 0xa4d50e44877cbf7fe983420967d27a783807a79f, [object Object])
2022-10-12T01:35:34.921Z iteration 0 passed in 379 ms

{
  info: { withdrawId: 'fe2a535f5cf6427aa470690b5def4f12' },
  id: 'fe2a535f5cf6427aa470690b5def4f12'
}
2022-10-12T01:35:34.921Z iteration 1 passed in 379 ms
```

```
% mexc withdraw USDT 10 TEY6qjnKDyyq5jDc3DJizWLCdUySrpQ4yp '{""network"": ""trc20""}'
2022-10-12T01:48:47.684Z
Node.js: v18.4.0
CCXT v1.95.35
(node:7980) ExperimentalWarning: The Fetch API is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
mexc.withdraw (USDT, 10, TEY6qjnKDyyq5jDc3DJizWLCdUySrpQ4yp, [object Object])
2022-10-12T01:48:50.053Z iteration 0 passed in 374 ms

{
  info: { withdrawId: '8fea1067efd94e87bc0dba3baadbecfd' },
  id: '8fea1067efd94e87bc0dba3baadbecfd'
}
2022-10-12T01:48:50.053Z iteration 1 passed in 374 ms
```", # fix: fix ETH > ERC-20 alias
3,"Remove another reference to simplehttp
Since the command `a2enconf letsencrypt` is listed on this page, make sure the config file is named accordingly.
", # Fix typo in webroot plugin
4,"client: allow callers to add information to the user agent
This change introduces a new flag to allow callers to add information to the user agent without replacing it entirely.

This allows people re-packaging or wrapping Certbot to influence its user agent string. They may which to do this so that stats/metrics related to their distribution are available to boulder.

This is beneficial for both the Certbot team and the party re-packaging Certbot as it allows the custom user agent to match the Certbot user agent as closely as possible, allowing data about use of the re-packaged version to be collected along side or separately from vanilla certbot.

Resolves #4682", # Add --user-agent-comment flagAdd a flag to allow users to add a comment to the default user agent string. This is useful for repackaging Certbot or calling it from another tool to allow additional statistical data to be collected.
5,"ref(py): Sort imports in projectoptions module (1 files)
", # [3.1] Add project options to manage.py
6,"Fix global_steps checkpoint loading.
", # [DeepSpeed] Fix checkpointing testFixes #1000.
7,"Primer: pyramid and sqlalchemy are now formatted with latest Black
* https://github.com/Pylons/pyramid/pull/3616
* https://github.com/sqlalchemy/sqlalchemy/commit/c3f102c9fe9811fd5286628cc6aafa5fbc324621

Turns Primer CI back green.

", # Remove expect_formatting_changes from primer.jsonThis is a simple change to remove the `expect_formatting_changes` key from the primer.json file. This key is no longer needed and is not used by the primer.
8,"Add Open Brewery DB
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added Open Brewery DB
9,"Bump prisma from 4.11.0 to 4.13.0 in /website
Bumps [prisma](https://github.com/prisma/prisma/tree/HEAD/packages/cli) from 4.11.0 to 4.13.0.

Release notes
Sourced from prisma's releases.

4.13.0
üåü Help us spread the word about Prisma by starring the repo or tweeting about the release. üåü
Highlights
Introspection stopgaps
The Prisma Schema Language (PSL) currently doesn't support all database features and functionality of our target databases. The PSL is an abstraction over SQL and will keep evolving to address gaps in our database feature matrix.
Before this release, prisma db pull did not pick up the unsupported features in a database. It was easy to lose them when running prisma migrate dev based on an existing Prisma schema if not included in a migration file using custom migrations.
To avoid this, we added Introspection Stopgaps that surface the existence of these features in your database and link to our documentation on how to manually work around the Prisma Schema with unsupported database features (‚ÄùStopgaps‚Äù as we will remove them as soon as we implement full support for these features).
In this release, we added stopgaps for the following features:

Partitioned tables
PostgreSQL Row Level Security
Index sort order, NULLS FIRST / NULLS LAST
CockroachDB row-level TTL
Comments
PostgreSQL deferred constraints

Prisma CLI will output warnings on introspection (prisma db pull) and add comments to your Prisma schema. In the coming releases, we will expand this to many more features labeled with topic: database-functionality on GitHub.
Improved support for Netlify and Vercel build process
Netlify and Vercel cache project dependencies during the build process and reuse that cache until dependencies change. While this helps speed up the build process, any postinstall scripts of these dependencies will not be executed.
Prisma uses a postinstall script in its package to automatically trigger the customized generation of Prisma Client for your Prisma Schema. When a dependency cache is used, that generation process is not triggered, and an outdated Prisma Client may be used in your application.
When you update your Prisma Schema but not your dependencies, Prisma Client will not be generated for the new schema. For example, columns you added recently to one of your models will not be present in the Prisma Client API - causing errors.
This problem can be avoided by:

Adding a custom postinstall script in your package.json file
Manually adding a prisma generate step to the ‚ÄúBuild‚Äù scripts of Vercel and Netlify.

We now added detection of this scenario and will prevent a build without an additional prisma generate. This will ensure you're aware of the problem early and get guidance on how to fix this problem. You can read more on how to do this in our docs ‚Äî Vercel caching troubleshooting, Netlify caching troubleshooting.
Better support for pnpm as a package manager
Before this release, Prisma only used npm scripts which would lead to undesirable behavior for a project using a different package manager such as pnpm and yarn. This release improves the detection of the package managers in your project by using ni. If you're still running into this problem, let us know by creating a GitHub issue.
Segmentation fault and TLS connection error fix
In this release, we've fixed a TLS connection error segmentation fault. This mostly affected users running on Node.js 17 or later with OpenSSL 1.1 when using TLS to connect to their database.
JSON protocol Preview feature feedback
We have fixed multiple bugs for the jsonProtocol Preview feature and are close to making it Generally Available. We are still looking for feedback about its usage to ensure it is ready and works as expected for everyone.


... (truncated)


Commits

d29c126 docs(cli): add --generator option to the help hint (#18592)
e50b0e2 chore(deps): update studio to v0.484.0 (#18636)
047fda8 chore(deps): update engines to 4.13.0-15.f8f78f335fd86dea323d7fbc581fdf500d74...
906d265 chore: Remove unused variables and enable no-unused-vars rule (#18584)
5acfc52 fix(client): throw error on caching platforms (#18437)
efab78e fix(cli): Exclude source maps from bundled client (#18571)
12af01f refactor: remove unused imports from Generate.ts (#18486)
fb51d43 refactor: rename variants of BinaryType enum (#18455)
92d87a6 chore(deps): update jest to v29.4.3 (#17802)
See full diff in compare view





[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=prisma&package-manager=npm_and_yarn&previous-version=4.11.0&new-version=4.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


", # Update prisma to 4.13.0
10,"Add `requests-async` link to ""non-blocking"" docs.
Links to https://github.com/encode/requests-async for an asyncio non-blocking option.", # Add requests-async to docs
11,"Bump tough-cookie from 4.1.2 to 4.1.3 in /component-lib
Bumps [tough-cookie](https://github.com/salesforce/tough-cookie) from 4.1.2 to 4.1.3.

Release notes
Sourced from tough-cookie's releases.

4.1.3
Security fix for Prototype Pollution discovery in #282. This is a minor release, although output from the inspect utility is affected by this change, we felt this change was important enough to be pushed into the next patch.



Commits

4ff4d29 4.1.3 release preparation, update the package and lib/version to 4.1.3. (#284)
12d4747 Prevent prototype pollution in cookie memstore (#283)
f06b72d Fix documentation for store.findCookies, missing allowSpecialUseDomain proper...
See full diff in compare view





[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tough-cookie&package-manager=npm_and_yarn&previous-version=4.1.2&new-version=4.1.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/streamlit/streamlit/network/alerts).

", # bump tough-cookie to 4.1.3
12,"[letstest] create and reuse a persistent boulder AMI
Closes #2017 
"," # Boulder server: killboulder, boulderonly, fast"
13,"remove Animelab extractor
<!--
# Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)
- I trust Github actions to take care of Flake8. The AnimeLabIE test fails (as expected). I did not check that the AnimeLabShowsIE test fails, because I don't have an AnimeLab account

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

---

### Description of your *pull request* and other information

This removes the Animelab extractor, because Animelab has been [shut down](https://www.animelab.com/sunset)
Please note: animelab.py currently includes a line `# TODO implement myqueue`. I don't know what myqueue is, nor could I find an explanation in the commit history. However, I am guessing that it's similar to Youtube's ""watch later"" feature, especially because of all the results that `animelab ""my queue""` returns on Google. If any maintainers want to be extra sure that it isn't anything that could still be useful, I'd suggest pinging mariuszskon

<!--
copilot:emoji
-->

:recycle::truck::scissors:

<!--
1.  :recycle: This emoji can be used to indicate a refactoring process that aims to improve the code structure, readability, or maintainability without changing its functionality or behavior.
2. :truck: This emoji can be used to indicate a file or code movement from one location to another, such as moving extractors to a separate module or renaming a file or directory.
3. :scissors: This emoji can be used to indicate a code removal or deletion, such as removing unused imports or redundant code.
-->",
14,"fix: dark theme background to 404 && 500 pages
Before: 
![image](https://user-images.githubusercontent.com/65485999/216893439-a0a137ac-62c3-4628-a609-6f4e3e519dd1.png)
Now:
![image](https://user-images.githubusercontent.com/65485999/216893490-7fb7cf70-b0e3-40e5-9bf6-09b13ae50f71.png)
", # Add color mode to 404 and 500 pages
15,"Skip tests if redbaron is not installed
This will make sure these tests will be skipped if you don't have redbaron installed.
", # [3.1] Fix test_import_migration.py
16,"[polskieradio] category fixes, tag support
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

add support for 2 other pagination methods, categories with direct audio (instead of links to articles with audio), tag pages on legacy frontends


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


",
17,"Merge dev branch
", # Add some options to the Model tab
18,"set_time: use python library
", # Fix panda time setting
19,"Add correlation metrics for Reward Modeling
The earlier version of this has some alignment issues which are now resolved. 

[Comparison](https://wandb.ai/open-assistant/reward-model?workspace=user-shahules786) of `main` and new PR runs 

", # Add reward metrics to RM trainingAdd reward metrics to RM training.
20,"[`bnb`] Add simple check for bnb import
# What does this PR do?

as discussed internally @sgugger let's add a GPU check inside `is_bnb_available` 

", # Fix bitsandbytes importFixes #10000
21,"[dependencies] Handle deprecation of `sqlite3.version`
Refs:
https://github.com/python/cpython/issues/93370
https://github.com/python/cpython/pull/93482
https://github.com/python/cpython/commit/ffc58a9710172b2d716a810a9f303828f3ebf108

Closes #8152


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [x] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at e19a282

### Summary
üõ†Ô∏èüö´üóÉÔ∏è

<!--
1.  üõ†Ô∏è - This emoji represents the modification of the `get_package_info` function to check for a custom attribute, which is a kind of fix or improvement to the existing code.
2.  üö´ - This emoji represents the suppression of the deprecation warning that is raised by accessing the `sqlite3.version` attribute, which is a kind of prevention or avoidance of a potential problem or annoyance for the users.
3.  üóÉÔ∏è - This emoji represents the setting of the custom attribute `_yt_dlp__version` for the sqlite3 module, which is a kind of data or information management or storage.
-->
Modify `get_package_info` to support custom version attributes for dependencies and set `_yt_dlp__version` for `sqlite3` to avoid deprecation warning and improve version output.

> _`yt_dlp` updates_
> _version info of modules_
> _autumn leaves fall_

### Walkthrough
*  Add custom attribute `_yt_dlp__version` to sqlite3 module to override its version information ([link](https://github.com/yt-dlp/yt-dlp/pull/8167/files?diff=unified&w=0#diff-de7a33dfc7bfbde1984024aefea7058b51f5de324d4460efdee999bf798ebd01R46-R50))
*  Modify `get_package_info` function to check for `_yt_dlp__version` attribute in imported modules before standard attributes ([link](https://github.com/yt-dlp/yt-dlp/pull/8167/files?diff=unified&w=0#diff-3a91d23c8ecd4737ba2b42ca27465fed4d85c2b53e4e7c6632bf2b1dfefcd99fL18-R18))




", # [compat] Fix #8152
22,"Update builder.py


## üìå Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## üö® Issue number

Not involved


## üìù What does this PR do?

Optimization Code
The source code has not been modified, only a few spelling errors in the comments have been changed


## üí• Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [x] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [x] I have added thorough tests.
- [x] I have added docstrings for all the functions/methods I implemented

## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?

- [x] üåù Yes, I do.
- [ ] üåö No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
", # Fix typos
23,"Add update pip and setuptools section
## Following workflow in `CONTRIBUTING.rst`

```pwsh
> python -m venv env
> .\env\Scripts\activate
> pip --version
pip 19.2.3 from d:\python\flask\env\lib\site-packages\pip (python 3.8)
```

```pwsh
> pip install -r .\requirements\dev.txt
> pip install -e .
Obtaining file:///D:/PYTHON/flask
    ERROR: Command errored out with exit status 1:
     command: 'd:\python\flask\env\scripts\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'D:\\PYTHON\\flask\\setup.py'""'""'; __file__='""'""'D:\\PYTHON\\flask\\setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base 'C:\Users\oleksis\AppData\Local\Temp\pip-pip-egg-info-6n77jjdo'
         cwd: D:\PYTHON\flask\
    Complete output (33 lines):
    Traceback (most recent call last):
      File """", line 1, in 
      File ""D:\PYTHON\flask\setup.py"", line 4, in 
        setup(
      File ""d:\python\flask\env\lib\site-packages\setuptools\__init__.py"", line 145, in setup
        return distutils.core.setup(**attrs)
      File ""D:\Anaconda3\lib\distutils\core.py"", line 121, in setup
        dist.parse_config_files()
      File ""d:\python\flask\env\lib\site-packages\setuptools\dist.py"", line 699, in parse_config_files
        parse_configuration(self, self.command_options,
      File ""d:\python\flask\env\lib\site-packages\setuptools\config.py"", line 120, in parse_configuration
        meta.parse()
      File ""d:\python\flask\env\lib\site-packages\setuptools\config.py"", line 425, in parse
        section_parser_method(section_options)
      File ""d:\python\flask\env\lib\site-packages\setuptools\config.py"", line 398, in parse_section
        self[name] = value
      File ""d:\python\flask\env\lib\site-packages\setuptools\config.py"", line 183, in __setitem__
        value = parser(value)
      File ""d:\python\flask\env\lib\site-packages\setuptools\config.py"", line 513, in _parse_version
        version = self._parse_attr(value, self.package_dir)
      File ""d:\python\flask\env\lib\site-packages\setuptools\config.py"", line 348, in _parse_attr
        module = import_module(module_name)
      File ""D:\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File """", line 1014, in _gcd_import
      File """", line 991, in _find_and_load
      File """", line 975, in _find_and_load_unlocked
      File """", line 671, in _load_unlocked
      File """", line 783, in exec_module
      File """", line 219, in _call_with_frames_removed
      File ""D:\PYTHON\flask\src\flask\__init__.py"", line 3, in 
        from werkzeug.exceptions import abort as abort
    ModuleNotFoundError: No module named 'werkzeug'
    ----------------------------------------
WARNING: Discarding file:///D:/PYTHON/flask. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
```

## Fix the issue
Requirement pip>=20.3 (from pip-tools==6.1.0->-r .\requirements\dev.txt (line 67))

```pwsh
> python -m pip install -U pip setuptools
> pip install -r .\requirements\dev.txt && pip install -e .
```

Checklist:

- [ ] Add tests that demonstrate the correct behavior of the change. Tests should fail without the change.
- [x] Add or update relevant docs, in the docs folder and in code.
- [ ] Add an entry in `CHANGES.rst` summarizing the change and linking to the issue.
- [ ] Add `.. versionchanged::` entries in any relevant code docs.
- [ ] Run `pre-commit` hooks and fix any issues.
- [ ] Run `pytest` and `tox`, no tests failed.
", # Add instructions to upgrade pip and setuptools
24,"Update requirements.txt
"," # [MRG+1] Remove test extras from requirements.txt### Describe your change:* [ ] Add an algorithm?* [ ] Fix a bug or typo in an existing algorithm?* [ ] Documentation change?### Checklist:* [x] I have read [CONTRIBUTING.md](https://github.com/oobabooga/text-generation-webui/blob/master/CONTRIBUTING.md).* [x] This pull request is all my own work -- I have not plagiarized.* [x] I know that pull requests will not be merged if they fail the automated tests.* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.* [x] All new Python files are placed inside an existing directory.* [x] All filenames are in all lowercase characters with no spaces or dashes.* [x] All functions and variable names follow Python naming conventions.* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
25,"bpo-40222: Mark exception table function in the dis module as private
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y]  (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->
", # Fixes #26222
26,"[rllib] Better document APIs to access policy state
https://github.com/ray-project/ray/issues/2930
", # [rllib] Update doc/source/rllib-training.rst
27,"docs: move extraction up
", # Update sidebar position for Extraction use case
28,"Fixed warnings produced by test_record_video.py and test_video_recorder.py
With https://github.com/openai/gym/pull/2654, test_record_video.py and test_video_recorder.py were throwing new warnings
This was caused by the new render_fps value being different from the default backward compatible value. 

Updated the default backward compatible values to be the up to date parameters", # [gym] Fix video recorder backward compatibility
29,"Manifest subtitles V
  Boilerplate (own code, improvement/feature/fix) 

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)

### What is the purpose of your *pull request*?
- Improvement
- New feature
- Bug fix



Previously in this series: #247, #515, #948, #2686.

The Go case was caught, again, on issue tracker: , . This PR is *not* expected to resolve the overall tickets, though.

The fix for viu is speculative, as the reporter in the upstream ticket (ytdl-org/youtube-dl#30779) used the direct stream URL instead of the player frontend URL. It is not certain if this will work, as I have no means to test it.

As a side note, the viu extractor contains a somewhat curious FIXME comment, which I did not address here, but I think is worth paying some attention to:

https://github.com/yt-dlp/yt-dlp/blob/4628a3aa751ac0b2161b216662f0e959eb9bd206/yt_dlp/extractor/viu.py#L79-L82
", # [go] extract subtitles
30,"added Kairos to Development section
", # Added Kairos API
31,"Simplified Options._get_fields() a bit.
", # Remove chain from fields()
32,"Find max function in python
", # Add FindMax.py
33,"Remove permissions to read Configurations for User and Viewer roles
Only `Admin` or `Op` roles should have permissions to view Configurations.

Previously, Users with `User` or `Viewer` role were able to get/view configurations using
the REST API or in the Webserver. From Airflow 2.0.1, only users with `Admin` or `Op` role would be able
to get/view Configurations.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
", # Remove can_read permission on config resource for User and Viewer roleThis PR removes the can_read permission on config resource for User and Viewer role. This is because the config resource is not meant to be accessed by these roles.
34,"Update wording and formatting
Minor changes to https://github.com/psf/black/pull/1294.", # Fixes #1002
35,"DOC Update maintainers' guide to use new wheel builder system
#### Reference Issues/PRs

Closes #18776.

#### What does this implement/fix? Explain your changes.

This PR updates the maintainers' guide to use the `Wheel builder` workflow.

#### Any other comments?

CC @ogrisel.",
36,"optimize parameters for mobile network
", # fix: auto range
37,"Fix typo in 'Strings can be tricky sometimes'
Hi üëã ,
thanks for this awesome work. I gave it a partial read and found a typo.
Best"," # [3.7] Explain why `a, b = ""wtf!""` and `a = ""wtf!""; b = ""wtf!""` have different identities"
38,"bump pyparsing
", # bump pyparsing to 2.1.3
39,"[pre-commit.ci] pre-commit autoupdate

updates:
- [github.com/codespell-project/codespell: v2.2.4 ‚Üí v2.2.5](https://github.com/codespell-project/codespell/compare/v2.2.4...v2.2.5)
- [github.com/tox-dev/pyproject-fmt: 0.11.2 ‚Üí 0.12.0](https://github.com/tox-dev/pyproject-fmt/compare/0.11.2...0.12.0)
", # Add linear programming testsAdded linear programming tests.
40,"add Sakura CardCaptor API


- [X] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [X] My addition is ordered alphabetically
- [X] My submission has a useful description
- [X] The description does not have more than 100 characters
- [X] The description does not end with punctuation
- [X] Each table column is padded with one space on either side
- [X] I have searched the repository for any relevant issues or pull requests
- [X] Any category I am creating has the minimum requirement of 3 items
- [X] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added Sakura CardCaptor API
41,"Add skip_special_tokens checkbox for Dolly model
It is disabled by default for Dolly, GALACTICA, and Open Assistant.

For #1161",
42,"Remove Climacell.
Climacell no longer offers a free API.

https://www.climacell.co/weather-api/pricing/

===

Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Remove ClimaCell Micro Weather APIClimaCell Micro Weather API is no longer available.
43,"add: some more feature packed applications.
Add and update more feature packed applications.
Cleaning the duplicates.
Add environment.yml file for dependencies of the repository.", # Determine sign of a number
44,"new command line argument --cert-passphrase added.
For decrypting the private key that is provided with the --certs command

#### Description

New command line argument added ""--cert-passphrase"", OpenSSL.crypto.load_privatekey already supports the passphrase, and it was only missing the arguments to pass the passphrase.

#### Checklist

 - [x] I have updated tests where applicable.
 - [x] I have added an entry to the CHANGELOG.
",
45,"Update play.py
resolve KeyError from missing key in action dict. use `(dict).get` with a default value of NOP (0).", # [gym] Fix for when no keys are pressed
46,"BUG: Categorical.remove_categories(np.nan) fails when underlying dtype is float
Fixes GH #10156. This also makes different null values indistinguishable inside of remove_categories, but they're already indistinguishable in most other contexts:

``` .python
>>> pd.Categorical([], categories=[np.nan, None])
Traceback (most recent call last):
  File """", line 1, in 
  File ""pandas/core/categorical.py"", line 289, in __init__
    categories = self._validate_categories(categories)
  File ""pandas/core/categorical.py"", line 447, in _validate_categories
    raise ValueError('Categorical categories must be unique')
ValueError: Categorical categories must be unique
```
", # [MRG] Fix Categorical.remove_categoriesFixes #10156
47,"[Workflow] dedupe download on recovery




## Why are these changes needed?



## Related issue number



## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",
48,"Fix URL parsing bug
Fixes an error where pathlib incorrectly detects the name for some URLs. Used when passing an authenticated url as the data argument

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Improvement in file name parsing for remote file downloading.

### üìä Key Changes
- Simplified the parsing of file names from URLs by changing the order of operations‚Äîfirst stripping the query parameters and then extracting the name.

### üéØ Purpose & Impact
- **Enhances File Handling**: This tweak ensures that file names are extracted correctly, without any appended URL parameters that could cause errors.
- **Improves Robustness**: The update strengthens the download process, preventing potential file naming issues and ensuring successful downloads for users.
- **User Experience**: Users dealing with remote files can expect a more seamless experience with less risk of encountering file-related errors while using the code.", # Fix bug in general.py
49,"Added 500px
The API is free to use.
", # Add 500px APIAdded 500px API to the list of APIs.
50,"[Windows] Working unit tests for certbot-nginx
This PR fixes certbot-nginx and relevant tests to make them succeed on Windows.

Next step will be to enable integration tests through certbot-ci in a future PR.
",
51,"Add CSS for lists
The added styles should improve how HTML lists look in chat and instruct mode, for comparison:

  Old chat CSS on PC
  
  ![1-chat](https://user-images.githubusercontent.com/31524206/230454316-c4940a2c-3bb4-4db4-bcd0-727a68af4f3a.png)
  


  New chat CSS on PC
  
  ![2-chat](https://user-images.githubusercontent.com/31524206/230454893-a56b8280-c6fb-406d-a8ae-4f1bbdf68557.png)




  Old instruct CSS on PC
  
  ![1-instruct](https://user-images.githubusercontent.com/31524206/230455038-465db73f-b727-4b55-8ab3-269dedb0b7ee.png)
  


  New instruct CSS on PC
  
  ![2-instruct](https://user-images.githubusercontent.com/31524206/230455133-9f56c25f-f003-4116-9226-d9b4c1267272.png)
  



  Old chat CSS on mobile
  
  ![1-chat-mobile](https://user-images.githubusercontent.com/31524206/230455450-6195d9d2-370d-44cb-be1a-c274e06d0c16.png)
  


  New chat CSS on mobile
  
  ![2-chat-mobile](https://user-images.githubusercontent.com/31524206/230455550-e2347d41-73ef-41f1-89c2-f72305208159.png)
  



  Old instruct CSS on mobile
  
  ![1-instruct-phone](https://user-images.githubusercontent.com/31524206/230455789-268ab636-0e81-481a-a60c-2db0b65893cf.png)
  


  New instruct CSS on mobile
  
  ![2-instruct-phone](https://user-images.githubusercontent.com/31524206/230455806-9e355d50-558a-4cd8-8cf0-3a15140600b2.png)
  




", # Fixes #1006
52,"Keep blank query values for flow hashing
I've found that some websites use query values that are blank, e.g. foobar.com/index?thing.
The current master branch would hash '/index?thing' and '/index?other' as the same flow for server replay, which is undesirable. This patch causes these blank query values to be preserved and included when hashing.
", # [MRG] Fix hash for blank values
53,"Adds NSFW content filter option
This is to fix issue #285 by adding it as an option configurable under settings. I have it disabled by default as that seems to be what the general population likes, but I could see reasons to enable by default.", # Add filter_nsfw optionAdd filter_nsfw option to remove NSFW content from the output.
54,"Use self._trial  to generate trial_name for Trainer.
# What does this PR do?

Generate trial name unless the trial is not None, and use `(self._trial or trial)` to generate trial name. 
Because [currently the `optuna` backend give a None trial when using DDP and rank != 0](https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/integrations.py#L193)

Related code:
https://github.com/huggingface/transformers/blob/bd469c40659ce76c81f69c7726759d249b4aef49/src/transformers/integrations.py#L160-L208


Or maybe the documentation should be changed.

https://github.com/huggingface/transformers/blob/bd469c40659ce76c81f69c7726759d249b4aef49/src/transformers/trainer.py#L2318-L2319

Who can review: 

* Trainer: @sgugger  
* optuna HPO: @sywangyi
", # Fix hp_name in trainer.pyFix hp_name in trainer.py.
55,"[3.6] Install dependencies in Travis OSX build (GH-1952)
(cherry picked from commit 167e0fc211c06df)", # Travis: Install openssl and set flagsTravis will install openssl and set the flags for the compiler.
56,"üìù Add OpenAPI warning to ""Body - Fields"" docs with extra schema extensions
This PR adds a warning in the docs about generating invalid OpenAPI schemas (see #3745) when using additional keys in pydantic `Field` specifications. This warning only effects versions `fastapi>=0.66`, which could be added to the note if helpful.

I would have liked to include a workaround for those who want to keep generating valid schemas, but is currently non-trivial and either involves overriding a whole chain of field info classes, or writing a custom OpenAPI schema method, to undo the effect of `extra = ""allow""` in the `fastapi.openapi.models.Schema` class.
It is a bit of a shame this hasn't been acknowledged as an issue in #3745 but I hope that this warning will be helpful for those who are trying to use generic OpenAPI tools with FastAPI.", # Add warning about extra keys in `Field`Add warning about extra keys in `Field`
57,"ref(ts): Migrate projectContext test from .jsx to .tsx
", # Remove routes and router props from ProjectContext
58,"Add update template_body



## Motivation
CFn get-template after change-set execution is not showing the right template.


## Changes
- Update template-body when change-set is applied
- Added aws validated test cases.

<!-- The following sections are optional, but can be useful! 

## Testing

Description of how to test the changes

## TODO

What's left to do:

- [ ] ...
- [ ] ...

-->

"," # [cloudformation] Update stack after template update### Describe the changes you have made:* [ ] Add an API?* [ ] Add a feature to an existing API?* [ ] Fix a bug or typo in an existing API?* [ ] Documentation change?### Checklist:* [x] I have read [CONTRIBUTING.md](https://github.com/boto/boto3/blob/master/CONTRIBUTING.md).* [x] This pull request is all my own work -- I have not plagiarized.* [x] I know that pull requests will not be merged if they fail the automated tests.* [x] This PR only changes one API, and only tests are added, not removed.* [x] All new Python files are placed inside an existing directory.* [x] All filenames are in all lowercase characters with no spaces or dashes.* [x] All functions and variable names follow Python naming conventions.* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.* [x] All new algorithms have a corresponding [perfplot](https://perfplot.run).* [x] All new AWS services are added to [AWS Services Dependencies](https://github.com/boto/boto3/blob/master/AWS_SERVICES_DEPENDENCIES.md).* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
59,"Bump idna from 3.6 to 3.7 in /llama-index-integrations/storage/docstore/llama-index-storage-docstore-elasticsearch
Bumps [idna](https://github.com/kjd/idna) from 3.6 to 3.7.

Release notes
Sourced from idna's releases.

v3.7
What's Changed

Fix issue where specially crafted inputs to encode() could take exceptionally long amount of time to process. [CVE-2024-3651]

Thanks to Guido Vranken for reporting the issue.
Full Changelog: https://github.com/kjd/idna/compare/v3.6...v3.7



Changelog
Sourced from idna's changelog.

3.7 (2024-04-11)
++++++++++++++++

Fix issue where specially crafted inputs to encode() could
take exceptionally long amount of time to process. [CVE-2024-3651]

Thanks to Guido Vranken for reporting the issue.



Commits

1d365e1 Release v3.7
c1b3154 Merge pull request #172 from kjd/optimize-contextj
0394ec7 Merge branch 'master' into optimize-contextj
cd58a23 Merge pull request #152 from elliotwutingfeng/dev
5beb28b More efficient resolution of joiner contexts
1b12148 Update ossf/scorecard-action to v2.3.1
d516b87 Update Github actions/checkout to v4
c095c75 Merge branch 'master' into dev
60a0a4c Fix typo in GitHub Actions workflow key
5918a0e Merge branch 'master' into dev
Additional commits viewable in compare view





[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=idna&package-manager=pip&previous-version=3.6&new-version=3.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/run-llama/llama_index/network/alerts).

", # bump idna to 3.7
60,"[fp16/doc] correct initial_scale_power default value
This is a follow up to https://github.com/microsoft/DeepSpeed/pull/2663, fixing the doc's default from 32 to 16.

@tjruwase ", # Update docs
61,"Fix space characters problem of Text
Related issue #1017

Code to reproduce the problem
1. character `'\n'`
```py
from manimlib.imports import *

class Test(Scene):
    def construct(self):
        t1 = Text('a\nb').move_to(UP)
        t2 = Text('123').move_to(DOWN)
        self.play(Transform(t1, t2))
        self.wait()
```
![enter](https://user-images.githubusercontent.com/47266984/81162376-ac45c300-8fbf-11ea-97bf-96c3a18eab17.gif)

2. character `'\t'`
```py
from manimlib.imports import *

class Test(Scene):
    def construct(self):
        t1 = Text('a\tb').move_to(UP)
        t2 = Text('123').move_to(DOWN)
        self.play(Transform(t1, t2))
        self.wait()
```
![tab](https://user-images.githubusercontent.com/47266984/81162609-0d6d9680-8fc0-11ea-81a2-348fe0d7a918.gif)

3. character `' '`
```py
from manimlib.imports import *

class Test(Scene):
    def construct(self):
        t1 = Text('a b').move_to(UP)
        t2 = Text('123').move_to(DOWN)
        self.play(Transform(t1, t2))
        self.wait()
```
![space](https://user-images.githubusercontent.com/47266984/81162581-00e93e00-8fc0-11ea-91bf-83b2431ad2f9.gif)
", # Fix SVG text mobject
62,"Add button to manually create dataset events
Use the new create dataset rest api endpoint to add a ""Manually create dataset event"" button in the UI:








---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",
63,"Added Eliot logging system.
A logging library for distributed systems: https://github.com/ClusterHQ/eliot
", # Add EliotAdded Eliot to the list of awesome Python logging frameworks.
64,"feat: use jpeg instead of jpg, use enums instead of strings
Reasoning: 
1. we're already using jpeg to save a jpg file and should sync the filetype accordingly to support more features.
.jpg is just a compatible form for older OS which only support 3 characters for file extensions.
2. enums allow for less typos in strings and allow the actual value behind the enum option to be changed if needed.

- https://www.adobe.com/creativecloud/file-types/image/raster/jpeg-file.html
- https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#jpeg
- https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#jpeg-2000", # Update flags
65,"Add Cors support column for EVA
This is my first contribution for an open source project, so I'm trying to keep things as simple as possible.

I've tested this EVA API for validating emails and changed the value on the table for CORS support.
Tested on the browser and using this test cors website. 

Here is a [link for the test ](https://www.test-cors.org/#?client_method=GET&client_credentials=false&server_url=https%3A%2F%2Fapi.eva.pingutil.com%2Femail%3Femail%3Dkibutzzz%40gmail.com&server_enable=true&server_status=200&server_credentials=false&server_tabs=remote)



- [x] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] [N/A] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit


[squash-link]: 
", # Update EVA API
66,"Document that blackd ignores pyproject.toml
", # Add note about blackd not using pyproject.toml
67,"fix openai agent infinite loop
# Description

Fixes issue where we were using continue instead of breaking from function call

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [x] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
", # [OpenAI] Add max_function_calls to OpenAIAgentAdd max_function_calls to OpenAIAgent.
68,"fix(fly): Turn links blue
Legal didn't like the links being grey so I'm removing the styling to turn them back to blue.


", # Remove hover effect from auth-terms
69,"[recurbate.com] Add recurbate extractor
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

This is a new extractor to support the NSFW website Recurbate.com, by default the website support 1 free download, so a premium subscription is required

Fixes #


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [x] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


",
70,"Update
Added another type , `tvshort` to the `movie_types`", # Added tvshort
71,"fix: Don't remove comments along with parens
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

Resolves #3815

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [y] Add an entry in `CHANGES.md` if necessary?
- [y] Add / update tests if necessary?
- [-] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
", # Preserve comments before and after parenthesesFixes #4218
72,"Docs: Add more section labels for referencing
Allows for sections to be linked from other projects using Intersphinx.
", # Add a few more sections to the advanced docs
73,"3.10 support
", # Add Python 3.10 support
74,"[FIX] elasticsearch vector_store: add await for self.client.indices.exist
# Description

- Since client is `AsyncElasticsearchClient` we need to have `await` on `self.client.indices.exist` otherwise it returns a `Coroutine` object

Fixes #11417

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [x] Ran the script provided by the issue author and it works
- [x] I stared at the code and made sure it makes sense
", # Fixes #10064
75,"Update pip official website url
", # Update links
76,"[Classifier]: TensorBoard logging epoch fix
Fixes TB logging for classification training. @AyushExel 

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Improved logging of training metrics with epoch information in Ultralytics YOLOv5.

### üìä Key Changes
- `classifier.py`: Added epoch number to the `logger.log_metrics` function call.
- `utils/loggers/__init__.py`: Updated the `log_metrics` method to accept an additional `epoch` parameter.

### üéØ Purpose & Impact
- **Purpose**: To enhance the logging functionality by including epoch information, enabling better tracking and visualization of training progress over time.
- **Impact**: Users will now see metrics logged with corresponding epoch numbers, improving the interpretability of training logs in tools like TensorBoard and Weights & Biases. üìà This change enhances debugging and analysis for developers, researchers, and practitioners working with the YOLOv5 model.", # Add epoch to wandb and tb logging
77,"Add Kerberos CVE-2022-33679 (RC4 Is Still Considered Harmful)
", # Added CVE-2022-33679
78,"Cleans all DBs on ./breeze stop
When ./breeze stop is run, we run docker-compose down under the
hood - by default with --volumes flag which also removes the
volumes. But the volumes were only defined when you
selected the database.

We want to clean up all the volumes on breeze stop
in order to avoid surprizes when you switch the DB and find
the DB is there.

Otherwise when you switch databases while they are running
stop will delete volumes for only the most recently used
database.

The fix makes sure that all the db
volumes are defined always so they are always all deleted on stop

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
", # Remove unused volumes
79,"Use print() function in both Python 2 and Python 3
Legacy __print__ statements are syntax errors in Python 3 but __print()__ function works as expected in both Python 2 and Python 3.",
80,"Small PEP8 corrections
", # Fixing the traceback in memento.py
81,"fix typo
", # Fix typo in README.md
82,"urllib2 is not available on Python 3.
## Pull Request Checklist

- [x] If the change being made is to a [distributed component](https://certbot.eff.org/docs/contributing.html#code-components-and-layout), edit the `master` section of `certbot/CHANGELOG.md` to include a description of the change being made.
- [x] Add or update any documentation as needed to support the changes in this PR.
- [x] Include your name in `AUTHORS.md` if you like.
", # Fixes #1000
83,"therock.has futures methods, fetchMarkets ordering, string math, leverage, margin
```
2022-01-24T12:19:20.304Z
Node.js: v14.17.0
CCXT v1.69.20
therock.fetchMarkets ()
1145 ms
     id |   symbol | base | quote | settle | baseId | quoteId | settleId | type | spot | margin | future |  swap | option | contract | linear | inverse | taker | maker | contractSize | active | expiry | expiryDatetime | strike | optionType |              precision |                                                                        limits
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 BTCEUR |  BTC/EUR |  BTC |   EUR |        |    BTC |     EUR |          | spot | true |  false |  false | false |  false |    false |        |         | 0.002 | 0.002 |              |   true |        |                |        |            | {""amount"":4,""price"":2} | {""leverage"":{""min"":1},""amount"":{""min"":0.0005},""price"":{""min"":0.01},""cost"":{}}
...
LINKETH | LINK/ETH | LINK |   ETH |        |   LINK |     ETH |          | spot | true |  false |  false | false |  false |    false |        |         | 0.002 | 0.002 |              |   true |        |                |        |            | {""amount"":4,""price"":9} |   {""leverage"":{""min"":1},""amount"":{""min"":0.01},""price"":{""min"":1e-9},""cost"":{}}
 UNIETH |  UNI/ETH |  UNI |   ETH |        |    UNI |     ETH |          | spot | true |  false |  false | false |  false |    false |        |         | 0.002 | 0.002 |              |   true |        |                |        |            | {""amount"":4,""price"":9} |   {""leverage"":{""min"":1},""amount"":{""min"":0.01},""price"":{""min"":1e-9},""cost"":{}}
26 objects
```", # therock: add spot market info
84,"Implement support for AutoGPTQ for loading GPTQ quantized models.
This is a quick implementation of PanQiWei /[AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) for inference.

This is an alternative to the current GPTQ-for-LLaMA hopefully offering a more universally supported option which is not limited to one platform like linux.

AutoGPTQ supports cuda, triton(on linux) and ~cpu~. Splitting using pre_layer is not supported.

#1263 implements another alternative for GPTQ, but due to relying on triton it is not universal. This pr should be compatible with it though as an option.

Right now requires newer than 0.0.5 version of AutoGPTQ in pypi, so build from source is required at the time of writing.

From my testing appears to be slightly slower than GPTQ-for-LLaMA triton branch and slower still with cuda. I have not compared against cuda versions of GPTQ-for-LLaMA. Probably slower than #1263

But AutoGPTQ is seeing rapid development and likely will have better performance while maintaining compatibility and I think this is the main benefit of this implementation.

Please give feedback and testing is appreciated.

", # AutoGPTQ: add --desc_act option
85,"Upgrade hatch to fix installing extras bug
### Description

Fix #4107 by updating hatchling  ~~in a fairly hacky way though.~~

Hatch ~~will~~ used to strip out parenthesis in the extras if it thinks it doesn't need them and wouldn't add them back in. ~~:( We can, however, add a meaningless restriction like `and python_version >= '1'` to force hatch to use our parenthesis. Extremely hacky, and I would understand if we don't want this to be merged until a cleaner hatch fix is upstream. Also happy to come up with another way of essentially just having `true` in the spec, but I couldn't find one with a quick reading of https://peps.python.org/pep-0508/.~~

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [x] Add an entry in `CHANGES.md` if necessary?
- [x] Add / update tests if necessary?   I'm not sure it's a great idea to add a test to see that dependency was avoided, happy to add one if desired though!
      I did manually test this by installing my local checkout of the project, confirming that the dependencies for the `d` extra aren't installed:
      
```logs
$ pip install .
Processing /home/brycew/Developer/black
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Requirement already satisfied: typing-extensions>=4.0.1 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (4.9.0)
Requirement already satisfied: tomli>=1.1.0 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (2.0.1)
Requirement already satisfied: mypy-extensions>=0.4.3 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (1.0.0)
Requirement already satisfied: pathspec>=0.9.0 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (0.12.1)
Requirement already satisfied: platformdirs>=2 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (4.1.0)
Requirement already satisfied: click>=8.0.0 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (8.1.7)
Requirement already satisfied: packaging>=22.0 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1763+gdad9f79.d20231212) (23.2)
Building wheels for collected packages: black
  Building wheel for black (pyproject.toml) ... done
  Created wheel for black: filename=black-0.1.dev1763+gdad9f79.d20231212-py3-none-any.whl size=194930 sha256=a511959e5af87f2bc5623744f13eba2bd3c406fd9b522e8a537c8f3d341b1a18
  Stored in directory: /tmp/pip-ephem-wheel-cache-o2gmqktu/wheels/92/d6/de/b610e33302c2b433609d1ae2283761d3ff26bd0fb805d38fe1
Successfully built black
Installing collected packages: black
  Attempting uninstall: black
    Found existing installation: black 0.1.dev1763+gdad9f79
    Uninstalling black-0.1.dev1763+gdad9f79:
      Successfully uninstalled black-0.1.dev1763+gdad9f79
Successfully installed black-0.1.dev1763+gdad9f79.d20231212
```

When run on main, this output includes `Requirement already satisfied: aiohttp>=3.7.4 in /home/brycew/Developer/.venv/lib/python3.10/site-packages (from black==0.1.dev1762+g35ce37d) (3.9.1)`, and all of it's dependencies.

- [x] Add new / update outdated documentation? (nothing changed here)

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
", # Fix hatch-vcs dependencyFixes #4108
86,"Adding Prompt lookup decoding
# What does this PR do?

Adds the prompt lookup decoding method from https://github.com/apoorvumang/prompt-lookup-decoding , issue #27722 


## Before submitting
- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).
- [x] Did you write any new necessary tests?


## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors who may be interested in your PR.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

Models:

- text models: @ArthurZucker and @younesbelkada
- vision models: @amyeroberts
- speech models: @sanchit-gandhi
- graph models: @clefourrier

Library:

- flax: @sanchit-gandhi
- generate: @gante
- pipelines: @Narsil
- tensorflow: @gante and @Rocketknight1
- tokenizers: @ArthurZucker
- trainer: @muellerzr and @pacman100

Integrations:

- deepspeed: HF Trainer/Accelerate: @pacman100
- ray/raytune: @richardliaw, @amogkam
- Big Model Inference: @SunMarc
- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada

Documentation: @stevhliu and @MKhalusova

HF projects:

- accelerate: [different repo](https://github.com/huggingface/accelerate)
- datasets: [different repo](https://github.com/huggingface/datasets)
- diffusers: [different repo](https://github.com/huggingface/diffusers)
- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)

Maintained examples (not research project or legacy):

- Flax: @sanchit-gandhi
- PyTorch: See Models above and tag the person corresponding to the modality of the example.
- TensorFlow: @Rocketknight1

 -->
",
87,"changing describe_parameters call to use paginator
##### SUMMARY
updated create_update_parameter() to use a paginator for the describe_parameter method when updating an existing parameter.  I ran into an issue where the parameter I needed to update was not in the first result set of items returned by: client.get_parameter(Name=args['Name'], WithDecryption=True)

See ADDITIONAL INFORMATION for details

##### ISSUE TYPE
- Bugfix Pull Request
##### COMPONENT NAME
aws_ssm_parameter_store

##### ANSIBLE VERSION

```
ansible 2.6.4
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python2.7/site-packages/ansible
  executable location = /bin/ansible
  python version = 2.7.5 (default, Aug  4 2017, 00:39:18) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]

```

##### ADDITIONAL INFORMATION

I ran into an issue where the parameter I needed to update was not in the first result set of items returned by: client.get_parameter(Name=args['Name'], WithDecryption=True)
I got this error when running my playbook:
```

Result:
 ESTABLISH LOCAL CONNECTION FOR USER: root
 EXEC /bin/sh -c 'echo ~root && sleep 0'
 EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239 `"" && echo ansible-tmp-1536863695.84-147938161401239=""` echo /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239 `"" ) && sleep 0'
Using module file /usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/aws_ssm_parameter_store.py
 PUT /root/.ansible/tmp/ansible-local-30457dmHRd8/tmp_9kYoS TO /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239/aws_ssm_parameter_store.py
 EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239/ /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239/aws_ssm_parameter_store.py && sleep 0'
 EXEC /bin/sh -c '/usr/bin/python2 /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239/aws_ssm_parameter_store.py && sleep 0'
 EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1536863695.84-147938161401239/ > /dev/null 2>&1 && sleep 0'
The full traceback is:
Traceback (most recent call last):
  File ""/tmp/ansible_0pStDP/ansible_module_aws_ssm_parameter_store.py"", line 253, in 
    main()
  File ""/tmp/ansible_0pStDP/ansible_module_aws_ssm_parameter_store.py"", line 248, in main
    (changed, response) = invocations[state](client, module)
  File ""/tmp/ansible_0pStDP/ansible_module_aws_ssm_parameter_store.py"", line 192, in create_update_parameter
    if describe_existing_parameter['Parameters'][0]['Description'] != args['Description']:
IndexError: list index out of range

fatal: [localhost]: FAILED! => {
    ""changed"": false,
    ""module_stderr"": ""Traceback (most recent call last):\n  File \""/tmp/ansible_0pStDP/ansible_module_aws_ssm_parameter_store.py\"", line 253, in \n    main()\n  File \""/tmp/ansible_0pStDP/ansible_module_aws_ssm_parameter_store.py\"", line 248, in main\n    (changed, response) = invocations[state](client, module)\n  File \""/tmp/ansible_0pStDP/ansible_module_aws_ssm_parameter_store.py\"", line 192, in create_update_parameter\n    if describe_existing_parameter['Parameters'][0]['Description'] != args['Description']:\nIndexError: list index out of range\n"",
    ""module_stdout"": """",
    ""msg"": ""MODULE FAILURE"",
    ""rc"": 1
}
```
The call to client.get_parameter(Name=args['Name'], WithDecryption=True) was actually returning this:

```
 {u'NextToken': u'AAEAAYo5rAFED3zqXPRdM2barhRoPEy7XKiKyQseIg/NfpRoAAAAAFuai7PyhJdo0bspyIm/QCuI/KQWErCGt+O7i4bwVHyJXsX+Z0jYMdddl9TpkJwG+vxArVfXLlu+0rfdy14DbLbK8audCg4cJiThDTRdFhQLCHWptaOTIiblxoJnJfd5KT8yfXsFig/dVTcx9T8oYOFXKF6SdlJ4hlvDmzA/cdGUxTuLGqCXAj0OBmDXsH3jVRm57qEVqkWeTbXzWpZNJvQ6rsAK+UQQKJG4UlgNu3j/0iIlWjgRWr4fd3LaNjTmadFPXUW6sWw8o+tLR0j324YmVCg0s/rSo+2iXnSdh0GgPOAZfmVaBUvH2VkmYe+7yESYlUsYc7Bgzhd+BhE0Cj5h5atle5ipSiJa2/mdtwBJigg7lQiQg2tOfsCvzf9gyvpdqrNvdND37xktB6dOxu+tpUeaJDZ+joqGqdEWLTKE1jfA1ajLCjKXiP/gkUMNrZnXXx/++nmL3ohaWXdV0OfXDgzR2YxQSLTFCPhTm6TcPlK5ibhFYeaC8IX+TtsRTxJD8LMDB5lhbxwXNJO0gLm7LkSFsrTKbaiJhELgChQZBx20zX7t8XCm8pn/Zq23L7wigvnl4Ce0dIKMCqiNk7Vqls2U+90QnHK+X08ulPOS2tF4nzJ0MlTaLyYypWDlr0/Ktn/rp+kCHl1vrYOiwRJuqt8t2zrK+J5faOkleVV0Fx3g5Z4XPrpvYmt8ZlNPGE2zXQjk5insxzLFt+C7vj14xcvql4O2iAK5duFoTQE/L4/ZCw==', 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'XXXXXXX', 'HTTPHeaders': {'x-amzn-requestid': 'XXXXXXX', 'date': 'Thu, 13 Sep 2018 16:09:22 GMT', 'content-length': '840', 'content-type': 'application/x-amz-json-1.1'}}, u'Parameters': []})

```
", # Fix pagination for describe_parametersFixes #10064
88,"build(python): Add autoreload functionality for workers
This adds autoreload functionality for [celery] workers. Uses `django.util.autoreload`.", # [3.1] Run worker with autoreload
89,"Fix False Positive On 500px
Fix false positive for 500px. The site changed their error text, so Sherlock started reporting false positives.", # Update Sherlock: Find Usernames Across Social Networks
90,"Allows applying dilation by passing negative erosion kernel values. If value is negative, ‚Ä¶
‚Ä¶it turns it into a dilation kernel, which allows facehullandrect to cover more space. Can help to cover double eyebrows. Also could be useful with Masked converter for GAN in @oatssss PR.", # Add erosion/dilation kernel size to masked converter
91,"Create decimal to binary
it will convert all decimal numbers to binary", # decimal to binary
92,"[doc] Fix typo in asyncio-eventloop documentation
Hi. This proposal is for a change that the python-doc-es team noticed during the translation to Spanish. 

Thanks and regards.", # Fix typo in asyncio-eventloop.rst
93,"onExecutionStart
On execution start, call onExecutionStart on all nodes which have it.

Allows a custom node to initialize itself - for instance, to clear any UI output from the previous run.", # [web] Call onExecutionStart on all nodes
94,"[WrzutaIE] Add extractor for wrzuta.pl (fixes #3072)
", # [wrzuta] Add extractor
95,"Fix installtion script for OpenSSL in Linux.
Ëøô‰∏™ÈóÆÈ¢òÊàëÂ∑≤ÁªèÂøç‰∫ÜÂ•Ω‰πÖ‰∫Ü, ‰∏ªË¶ÅÁöÑ‰øÆÊîπÊúâ2‰∏™:

1. Fix ArchLinux‰∏ãÁöÑOpenSSLÊòØÂê¶ÂÆâË£ÖÁöÑÂà§Êñ≠, ‰πãÂâçÁöÑËÑöÊú¨‰ºöÈªòËÆ§‰ΩøÁî®Python 3.
2. Âà†Èô§‰∫ÜInteractive ShellÁöÑÂà§Êñ≠, ÊÑüËßâ‰πãÂâçÁöÑÈÇ£‰∏™Âà§Êñ≠‰ºöÂΩ±ÂìçOpenSSLÊ≠£Â∏∏ÁöÑÂÆâË£Ö.

ÊàëÂêØÂä®XX-NetÁöÑÊñπÂºèÊòØ`./start`, ÊØèÊ¨°ÈÉΩ‰∏ç‰ºöÊâßË°åÂÆâË£ÖËÑöÊú¨. ÈÉΩÊèêÁ§∫Êàë`Please install pyOpenSSL`.", # Fixes #1002
96,"Fix error in user stats when loading
there was no check for waiting the data to be fetched, worked locally, not when deployed.", # Fixes #1006
97,"Allow you to pass in arbitrary rsync options
", # Add support for passing in rsync options
98,"Dev
", # Fix CUDA kernel error
99,"Dont require typing-extensions in 3.10
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

<!-- Good things to put here include: reasoning for the change (please link
     any relevant issues!), any noteworthy (or hacky) choices to be aware of,
     or what the problem resolved here looked like ... we won't mind a ranty
     story :) -->

As noted on Discord by @ichard26 

My bad for bumping typing-extensions in the Jupyter PR without making it conditional on the Python version, so here's a PR to rectify

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [ ] Add a CHANGELOG entry if necessary?
- [ ] Add / update tests if necessary?
- [ ] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
", # Remove `typing-extensions` from `setup.py``typing-extensions` is no longer a required dependency in Python 3.10+.
100,"Ensure that manually creating a DAG run doesn't ""block"" the scheduler
It was possible to ""block"" the scheduler such that it would not schedule or queue tasks for a dag if you triggered a DAG run when the DAG was already at the max active runs.

This approach works around the problem for now, but a better longer term fix for this would be to introduce a ""queued"" state for DagRuns, and then when manually creating dag runs (or clearing) set it to queued, and only have the scheduler set DagRuns to running, nothing else -- this would mean we wouldn't need to examine active runs in the TI part of the scheduler loop, only in DagRun creation part.

Fixes #11582.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).",
101,"Added support for filter out AWS Kendra search by score confidence
 **Description:** It will add support for filter out kendra search by score confidence which will make result more accurate.
    For example
   ```
retriever = AmazonKendraRetriever(
        index_id=kendra_index_id, top_k=5, region_name=region,
        score_confidence=""HIGH""
    )
```
Result will not include the records which has score confidence ""LOW"" or ""MEDIUM"". 
Relevant docs 
https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/kendra/client/query.html
https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/kendra/client/retrieve.html

 **Issue:** the issue # it resolve #11801 
**twitter:** [@SmitCode](https://twitter.com/SmitCode)

", # Add score confidence to Kendra retrieverAdd score confidence to Kendra retriever.
102,"[tests] make it easier to run tests
Currently to run tests against the local branch and not mistakenly against the preinstalled deepspeed one has to remember to add: `PYTHONPATH=. ` as in:
```
PYTHONPATH=. pytest tests
```
this PR automates this.

Now you just need to run:
```
pytest tests
```
and it'll always test this checkout/branch and not the installed one if any.", # Add conftest.pyAdded conftest.py to allow for multiple repository checkouts and not needing to remember to rerun tests.
103,"Improve `--help` output
Fixes #1072

- [x] replace `main()` docstring in `--help` output with a more descriptive description of the application
- [x] correct `--clarify` and `--self-heal` option descriptions (from @hmasdev in #1024)
- [x] unify `--improve`, `--clarify` and `--self-heal` help text formats (from @hmasdev in #1024)", # Update CLI help text
104,"Add Chinese translation for help-fastapi.md
@Dustyposa @RunningIkkyu @phy25 Please take a look.", # Add Chinese translation for help-fastapi.md
105,"Fixed anchors of computer vision sections
If you click on the Python computer vision link, it falsely jumps to the .NET section.", # Update README.md
106,"Con.1 Issue #1905 Return local const
Update for Issue #1905", # [MRG] Fix #10064
107,"remove tiktoken pin
As suggested in #1713", # Fix tokenizer tests
108,"Version 0.57.3
Just up version to 0.57.3 without any other changes. That's because 0.57.3 was just released consisting of 0.57.2, which is already merged into develop, plus a cherrypick that is also already merged into develop.", # bump version to 0.57.3
109,"fix(alerts): Send null for all environments
Using `''` sets to the default no environment, using null will be more
explicit about no environment", # Fix #10000: Allow null environmentFixes #10000
110,"Updated Azure Readme, What is an N-tier architecture
", # Add N-tier architecture to Azure topicAdd N-tier architecture to Azure topic.
111,"Fix error when there are no docker volumes present yet
##### SUMMARY


The existing code will attempt to iterate over `None`. A quick `if` statement protects the `for` loop and returns `None`. Return of `None` because there are no volumes.



<!---
If you are fixing an existing issue, please include ""Fixes #nnn"" in your
commit message and your description; but you should still explain what
the change does.
-->

##### ISSUE TYPE
 - Bugfix Pull Request


##### COMPONENT NAME
In the cloud module, in the docker module,  the `docker_volume` command


##### ANSIBLE VERSION

```
ansible 2.4.0 (devel cd32ed1929) last updated 2017/08/14 04:01:47 (GMT +000)
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/home/underway/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /home/underway/underway-server/ansible-fork/lib/ansible
  executable location = /home/underway/underway-server/ansible-fork/bin/ansible
  python version = 2.7.13 (default, Jan 19 2017, 14:48:08) [GCC 6.3.0 20170118]
```


##### ADDITIONAL INFORMATION
<!---
Include additional information to help people understand the change here.
For bugs that don't have a linked bug report, a step-by-step reproduction
of the problem is helpful.
  -->

Attempt to create a volume, where there isn't one on the server yet. Manually do `docker volume ls -q | xargs docker volume rm` if needed

```
- name: Install pip
   easy_install:
    name: pip
    ", # docker_volume: return None if no volumes
112,"Add vector make tests
Currently `gym.vector.make` does not have any tests
This PR adds a number of tests for the function parameters", # [core] Add tests for vector env
113,"Add SSL MITM using OpenSSL
", # Add SSL MITM with OpenSSL
114,"[cherry-pick] #2038
", # [paddleocr] fix unclip ratio
115,"Fix bug in renegotiating a nonce with the server
If a session runs long enough (without constant activity) then the server can
expire the nonce the session has negotiated. If that happens the session will
get a new 401 response which we were immediately returning to the user. A user
would then have to essentially reinitialize session.auth each time they get an
unexpected 401.

Also, there's no need for setattr calls when we can simply assign the
attribute on the instance.
", # Fix digest authFixes #1002.
116,"Typo fix
", # Fixes #1006
117,"Fix Liabots session
", # Fix Liaobots
118,"Add manifest includes for reuse licenses
##### SUMMARY
Add manifest includes for reuse licenses. Fixes #79368 

##### ISSUE TYPE
- Feature Pull Request

##### COMPONENT NAME
```
lib/ansible/galaxy/collection/__init__.py
```

##### ADDITIONAL INFORMATION




```paste below

```"," # [galaxy] Add license files to ignore list### DescriptionAdd license files to ignore list### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/ansible/ansible/blob/master/CONTRIBUTING.rst#L106-L110) - [x] I have performed a self-review of my own code- [x] My code follows the [style guidelines](https://github.com/ansible/ansible/blob/master/CONTRIBUTING.rst#L111-L113)- [x] My code passes [tests](https://github.com/ansible/ansible/blob/master/CONTRIBUTING.rst#L114-L116)- [x] My code is covered with [tests](https://github.com/ansible/ansible/blob/master/CONTRIBUTING.rst#L117-L120)- [x] I have commented my code, particularly in hard-to-understand areas- [x] I have made corresponding changes to the relevant documentation"
119,"Add `distributed_port` for `deepspeed.initialize`
`deepspeed.initialize` does not involve the `distributed_port` argument, and always uses `TORCH_DISTRIBUTED_DEFAULT_PORT` to initialize the dist env", # [deepspeed] Add distributed_port to initializeAdd distributed_port to initialize.
120,"DOC Update `validate_parameter_constraints()` docstring.
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->


#### What does this implement/fix? Explain your changes.
The docstring for `validate_parameter_constraints()` listing the options available isn't up to date. This add options that were currently missing.

#### Any other comments?


<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",
121,"Try to fix Captcha Issue
", # fix: highlight code in conversation
122,"refine parse_outputs in ExecuteNbCode.
ÈáçÊûÑExecuteNbCode‰∏≠ËæìÂá∫Ëß£ÊûêÈÉ®ÂàÜ‰ª£Á†Å„ÄÇÂÆûÁé∞ÂêåÊó∂ËæìÂá∫‰ª£Á†ÅÁâáÊÆµ‰∏≠ÁöÑÊ≠£Â∏∏ÊâìÂç∞ÂÜÖÂÆπÂíåÂºÇÂ∏∏ÂÜÖÂÆπÔºåÁ§∫‰æãÂ¶Ç‰∏ãÔºö
```python
executor = ExecuteNbCode()
code = """"""
import pandas as pd
df = pd.DataFrame({'ID': [1,2,3], 'NAME': ['a', 'b', 'c']})
print(df.columns)  # ÈúÄË¶ÅÊ≠£Â∏∏ËæìÂá∫ÁöÑÂÜÖÂÆπ
print(df['DUMMPY_ID'])  # ‰ºöÂèëÁîüÂºÇÂ∏∏ÁöÑ‰ª£Á†Å
""""""
output, is_success = await executor.run(code)
assert not is_success                 # -> True
assert ""Index(['ID', 'NAME'], dtype='object')"" in output  # -> True
assert ""Executed code failed,"" in output  # -> True
assert ""KeyError: 'DUMMPY_ID'"" in output # -> True
print(output)
#  Index(['ID', 'NAME'], dtype='object')    # ËøôÊòØÈúÄË¶ÅÊ≠£Â∏∏ËæìÂá∫ÁöÑÂÜÖÂÆπÔºåÂâ©‰∏ãÁöÑÊòØÈúÄË¶ÅËæìÂá∫ÁöÑÂºÇÂ∏∏‰ø°ÊÅØ
#, Executed code failed, please reflect the cause of bug and then debug. Truncated to show only last 2000 characters
#-----------------------------------------------------------------
# KeyError                                  Traceback (most recent call last)
# File ~/opt/anaconda3/envs/metagpt/lib/python3.9/site-packages/pandas/core/indexes/base.py:3653, in 
# Index.get_loc(self, key)
# 3652 try:
# -> 3653     return self._engine.get_loc(casted_key)
# 3654 except KeyError as err:
# ....
```", # fix: parse outputs
123,"Update builder.py
NotImplemented --> NotImplementedError

Re: https://github.com/faif/python-patterns/pull/112#discussion_r51224284
", # Fix typo in Builder.py
124,"Catch error if multiprocessing is not available or is unable to determine the number of CPUs
resolves #4113 ", # Fix multiprocessing testsFixes #10064
125,"ENH Use OpenMP effective nthreads helper in sparse manhattan‚Ä¶
Follow up on #14196 "," # [MRG] Use num_threads in pairwise_fast### DescriptionThis PR uses the number of threads in the current process to parallelize the pairwise_fast function. This is a simple change that should improve the performance of the function.### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#developer-instructions).- [x] This pull request is all my own work -- I have not plagiarized.- [x] I know that pull requests will not be merged if they fail the automated tests.- [x] This PR only changes one or two files.  If it's a big change, please split it into multiple PRs.- [x] All new Python files are placed inside an existing directory.- [x] All filenames are in all lowercase characters with no spaces or dashes.- [x] All functions and variable names follow Python naming conventions.- [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).- [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.- [x] All new algorithms have a URL in its comments that links to Wikipedia or other similar explanation.- [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
126,"[MRG+1] add Lasagna to related projects docs
add Lasagne to related projects in docs
", # Add Lasagne to related projectsAdd Lasagne to related projects.
127,"ref(backup): Lazily load expensive maps
Previously, we were always doing the relatively involved calculations for `get_default_comparators()`, `dependencies()`, and `sorted_dependencies()` at init time. This is wasteful, and slows down the test of anyone who imports these modules. A better solution is to resolve this information lazily when needed, and to cache that result going forward. This ensures that we still only do the work once, but now only when it is actually needed, rather than as soon as possible.",
128,"More robustly stop patches
Inspired by Joona's work at https://github.com/certbot/certbot/pull/7744#discussion_r376559363 and the pattern in [Python docs](https://docs.python.org/3/library/unittest.mock.html#patch-methods-start-and-stop), this PR more robustly stops the `mock.patch` objects that were started during `setUp`.", # Fix tearDown for patchesFixes #1006.
129,"DOCS: fix core api ref build
", # Fix docs/api_reference/create_api_rst.py
130,"Bump httpcore to 1.0.5
## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Fixes missing handling of EndOfStream errors
https://github.com/encode/httpcore/pull/899

changelog: https://github.com/encode/httpcore/compare/1.0.4...1.0.5

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [x] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: #92734 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] I have followed the [perfect PR recommendations][perfect-pr]
- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
", # bump httpcore to 1.0.5Bumps httpcore to 1.0.5.
131,"Typo in History
", # Fix typo in HISTORY.rst
132,"[YouTube] Fix not finding videos listed under a channel's ""shorts"" subpage. 
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Fixed a bug related to youtube-dl not being able to find and download videos listed under a channel's ""shorts"" subpage with help and guidance from @dirkf. Also tried to improve upon the solution by having the playlist data allow a title to be proposed in the list of playlist items. When running youtube-dl with the --flat-playlist and --dump-json option, the returned JSON data now has the title for each video. 
", # [youtube] Fix extractor for shortsFix extractor for shorts.
133,"Added VisPy
This is a pure Python library for high-performance scientific visualization. Based on OpenGL, it is GPU-accelerated.
", # Add VisPyAdded VisPy to the list of awesome Python libraries.
134,"Added pacman invalid option rule
Changes lowercase options to uppercase for pacman", # Add pacman_invalid_option rule
135,"Prefer more equal signs before a break when splitting chained assignments
### Description

This PR makes rhs processing prefer more equal signs before breaking the line.

Fixes #4007 

### Checklist - did you ...

- [X] Add an entry in `CHANGES.md` if necessary?
- [X] Add / update tests if necessary?"," # Prefer splitting rhs of chained assignments### Describe your change:This PR prefers splitting rhs of chained assignments. This is a preview feature, so it's not enabled by default."
136,"Corrected 2D relicts in 3D function comments
In Cropping3D and ZeroPadding3D, the comments referred to ""two"" values, which for 3D functions must be ""three"".
### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
", # Fix typo in Convolutional layer docstring
137,"Update model_adapter.py




## Why are these changes needed?
The function `.lower()` makes everything lowercase which makes the comparison to 'TinyLlama' always false.



## Related issue number (if applicable)



## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).
", # Fix TinyLlama adapter
138,"fix issue 868
fix issue https://github.com/geekan/MetaGPT/issues/868;
according to https://github.com/pandas-dev/pandas/pull/55008, pd.DataFrame.copy() leaks has been fixed by pandas 2.1.1", # Update pandas
139,"Add NoPhishy to Anti-Malware


- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not have more than 100 characters
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [ ] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add NoPhishy APIAdded NoPhishy API to the list of APIs.
140,"Implemented breadth first search for shortest graph path in graph_search.py
Added `find_shortest_path_bfs` to GraphSearch class which uses breadth first search with linear time complexity.  
Updated other method names to show that they are depth first search (for example: `find_path` to `find_path_dfs`).
Included an example for the new method.", # Add BFS and DFS to graph search
141,"Fix saving of UI defaults to settings.yaml - Fixes #5592
## Checklist:

- [X] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
", # Fix UI save_settingsFixes #1006
142,"Adding AnimeNewsNetwork API
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [X] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [X] Your additions are ordered alphabetically
- [X] Your submission has a useful description
- [X] The description does not end with punctuation
- [X] Each table column should be padded with one space on either side
- [X] You have searched the repository for any relevant issues or pull requests
- [ ] Any category you are creating has the minimum requirement of 3 items
- [X] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add AnimeNewsNetwork APIAdded AnimeNewsNetwork API to the list of APIs.
143,"unset torch arch list for JIT mode
PyTorch will add `-gencode` args for whatever CCs are in the `TORCH_CUDA_ARCH_LIST` at compile time, this makes sense when pre-compiling but does not make sense in JIT compile mode since we know at runtime what the targets need to be. Our op-builder has already set the intended targets that are needed at runtime. We need to unset the arch list before JIT compiling to avoid CC collisions such as multiple __half  implementations. This PR simply stashes the arch list before JIT compiling and resets it after build.", # Fix TORCH_CUDA_ARCH_LIST collisionsThis PR fixes collisions between TORCH_CUDA_ARCH_LIST and the arch list that is set in the op_builder.py file. This is a known issue that can cause multiple __half implementations to be generated.
144,"fix token counting for new openai client
# Description

The new openai client changed where to find token counts, causing the token counter to be very bad for OpenAI function calling.

Fixes https://github.com/run-llama/llama_index/issues/8978

## Type of Change

- [x] Bug fix (non-breaking change which fixes an issue)

", # Fix token counting for new openai clientFixes #8981
145,"added sources check to not repeat identical sources
Original PR: https://github.com/imartinez/privateGPT/pull/1679
Recreating as the branch I was working on was closed.

I found that after increasing
similarity_top_k: int in vector_store_component.py to something higher, like 10, I would getting some duplicate hits in the sources used.

Instead of just outputting the sources, as you loop through these, inject them into an array. If the item already exists in the array, don't re-add this to the sources_text.


This only affects ""Query Docs""", # Fix UI sources
146,"Added tests for check command
Added tests for the check command to increase coverage.", # [MRG+1] Add tests for run with opts list
147,"Skip ipv6 tests on sudo-enabled travis builds
Travis tests are currently failing because travis migrated their precise builds [1] from their container-based infrastructure to full virtual machines, which apparently don't support IPv6. This PR skips the IPv6 tests on systems where no IPv6 support is present.

[1] We use those so that our PyInstaller inaries are compiled with an old glibc version. Otherwise, they do not work on old systems (and AWS Lambda).", # [net] skip tests if no IPv6 support
148,"gh-103879: Fix refleak in super specialization



* Issue: gh-103879

", # Fix specialize.c
149,"[extractor/facebook] Fix Reels Format
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

Get video format for facebook reels

Fixes #


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at 615f799

### Summary
üé•üõ†Ô∏èüîó

<!--
1.  üé• - This emoji represents the video content and the extractor that is being improved.
2.  üõ†Ô∏è - This emoji represents the fix or the workaround that is applied to the missing playable_url issue.
3.  üîó - This emoji represents the alternative source of the playable_url from the creation_story field.
-->
Improve Facebook extractor by adding a fallback for playable_url. Use the `creation_story` field of the video object to get the `playable_url` if the original field is missing. This fixes some videos not being downloadable.

> _Some videos fail_
> _`playable_url` missing_
> _Fall back to `story`_

### Walkthrough
* Add support for more video types, such as live videos, premiere videos, and videos from groups or pages ([link](https://github.com/yt-dlp/yt-dlp/pull/7564/files?diff=unified&w=0#diff-ca6052d2c84eb4ac45aaf04463a4eaecdc75fb3ae4766e234917d8ab131b60ecL504-R504),                            F0




",
150,"[pre-commit.ci] pre-commit autoupdate

updates:
- [github.com/astral-sh/ruff-pre-commit: v0.3.3 ‚Üí v0.3.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.3...v0.3.4)
", # Update ruff pre-commit to v0.3.4
151,"load: Optionally disable reading secrets from env
Thank you for contributing to LangChain!

- [ ] **PR title**: ""package: description""
  - Where ""package"" is whichever of langchain, community, core, experimental, etc. is being modified. Use ""docs: ..."" for purely docs changes, ""templates: ..."" for template changes, ""infra: ..."" for CI changes.
  - Example: ""community: add foobar LLM""


- [ ] **PR message**: ***Delete this entire checklist*** and replace with
    - **Description:** a description of the change
    - **Issue:** the issue # it fixes, if applicable
    - **Dependencies:** any dependencies required for this change
    - **Twitter handle:** if your PR gets announced, and you'd like a mention, we'll gladly shout you out!


- [ ] **Add tests and docs**: If you're adding a new integration, please include
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use. It lives in `docs/docs/integrations` directory.


- [ ] **Lint and test**: Run `make format`, `make lint` and `make test` from the root of the package(s) you've modified. See contribution guidelines for more: https://python.langchain.com/docs/contributing/

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in langchain.

If no one reviews your PR within a few days, please @-mention one of baskaryan, efriis, eyurtsev, hwchase17.
", # [core] Add support for secrets_from_envAdd support for secrets_from_env in load() and load()
152,"user: Remove superfluous user not found warning
##### SUMMARY

Removes the warning, when `local: true` and the user could not be found.

A note about this warning already exists in the documentation.

Fixes #80267

##### ISSUE TYPE

- Bugfix Pull Request

##### COMPONENT NAME

ansible.builtin.user

##### ADDITIONAL INFORMATION

See #80267."," # Remove user not found warningThis PR removes the warning that is displayed when a user is not found. This is a minor change, but it is a nice one."
153,"Mark blackd tests with the `blackd` optional marker
This is a follow-up of #2203 that uses a pytest marker instead of a bunch of `skipUnless`.  Similarly to the Python 2 tests, they are running by default and will crash on an unsuspecting contributor with missing dependencies.  This is by design, we WANT contributors to test everything.  Unless we actually don't
and then we can run:

```
pytest --run-optional=no_blackd
```

Relatedly, bump required aiohttp to 3.6.0 at least to get rid of expected failures on Python 3.8 (see 6b5eb7d4651c7333cc3f5df4bf7aa7a1f1ffb45b).",
154,"Fix help typo
", # Remove --non-interactive implication from --quiet
155,"Removed unneeded list() calls in sorted() argument.
",
156,"add prob for ra
att", # [imaug] add prob to RandAugment
157,"[Core] ensure uniqueness in spilled file name




## Why are these changes needed?

There are cases that same object is being spilled twice due to failures. This made two spill worker overwrites the same file and causing corruption. The fix is as simple as ensure the uniqueness of the file.

close #26395

## Related issue number



## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
"," # [MRUI] Fix spill file name uniquenessFixes #10000## Why are these changes needed?## Related issue number## Checks- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.- [ ] I've run `scripts/format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.    - [ ] I've added any new APIs to the API Reference. For example, if I added a      method in Tune, I've added it in `docs/source/tune/api.rst`.    - [ ] I've made sure the tests are passing. Note that there might be a few      flaky tests, see the recent failures at https://flakey-tests.ray.io/## Suggested checklist:- [ ] I've run `scripts/format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.    - [ ] I've added any new APIs to the API Reference. For example, if I added a      method in Tune, I've added it in `docs/source/tune/api.rst`.- [ ] I've made sure the tests are passing. Note that there might be a few  flaky tests, see the recent failures at https://flakey-tests.ray.io/- [ ] I've added an entry in `docs/source/README.md` that describes how to  run the relevant integration tests.- [ ] If fixing an open issue, I've linked the PR to the issue with `sourcing`  (see https://docs.ray.io/en/master/contributing/integration.html#sourcing-pull-requests)."
158,"Fixed typo
Changed config-changes in the short help (wrong) to config_changes (right)
", # Fix typo in CLI
159,"docs: extract_info(process=False)


### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [ ] Covered the code with tests (note that PRs without tests will be REJECTED)
- [ ] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

`process` must be True for `download` to work, right? maybe we could make that more clear somehow", # [youtube-dl] Fix docstring
160,"[extensions/openai] use instruction templates with chat_completions
The ChatCompletions endpoint is much more reliable when you can instruct the model using the right format, this change loads the correct instruction template for the model if it exists, otherwise falls back to the previous behavior.

It also includes a dummy billing endpoint and some improvements for handling max_new_tokens & length when a large (4k+) context is assumed. ",
161,"remove superfluous code
this looks like stray code
get_merged_array is computed recursively on line 701 and appended to the result
the value computed on line 704 is discarded", # Remove redundant call to get_merged_array
162,"Fix broken links
### Description

There are multiple broken links in this project. Here is what I have fixed:

https://github.com/rlaphoenix/VSGAN/blob/master/vsgan/archs/ESRGAN.py --> https://github.com/rlaphoenix/VSGAN/blob/master/vsgan/archs/esrgan.py

https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/drop.py --> https://github.com/huggingface/pytorch-image-models/blob/main/timm/layers/drop.py

https://kornia-tutorials.readthedocs.io/en/latest/ --> https://kornia.readthedocs.io/en/latest/

This is an updated PR of #1007

### Support my work

These links where found with [link-inspector](https://github.com/justindhillon/link-inspector). If you find this PR useful, give the repo a ‚≠ê", # Fix typo in LDM patched
163,"Add Timestamp to SNS messages
This seems to be an official field on SNS messages

See https://docs.aws.amazon.com/en_pv/sns/latest/dg/sns-message-and-json-formats.html", # Add timestamp to SNS message bodyAdd timestamp to SNS message body.
164,"removed InsaneJournal
Removed InsaneJournal as it returns false positives when giving a it a
username with a period. I was not able to find what the criterias were
for a valid username on InsaneJournal, so the best thing to do is to
remove it

----

Dont mind the branch name. I accidentally committed to the old branch which was used to fix the the IFTTT false positive and dont know how to revert that."," # Remove InsaneJournalAs of 2020-02-23, InsaneJournal returns false positive, when providing a username which contains a period. Since we were not able to find the critera for a valid username, the best thing to do now is to remove it."
165,"Initial mobile support
- Added correct meta tags to index.html - head
- Changed litegraph.core.js - pointerevents_method: ""pointer""  
  This should not negatively affect desktop browsers, since pointer events are supported in most modern browsers. https://caniuse.com/pointer
- Litegraph's double click events are handled even using non-primary pointer.
- Changed setting to not close dialogs on mouseleave.

Current state:

- Can move around canvas
- Right click by tapping with two fingers  
  (Hint: can tap with the second finger later.)
- Can type in conditions
- Double tap to bring search box up  
  (Hint: tap somewhere around top-right on the screen so it will be shown while typing.)
- Tapping input fields opens them like normal, can type in them.

Further work:

- Zooming is not implemented yet, maybe some touch gesture would work...  
  (Zoom by mousewheel still works as usual.)
- Menu is not collapsible, might be in the way", # Fixes #1002
166,"Small typo in README.
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [x] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [ ] I've run the latest [black](https://github.com/ambv/black) with default args on new code.
- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Typo fix in README.
", # Fix typo in README.md
167,"feat: add performance sdxl lightning
closes #2382, links to discussion https://github.com/lllyasviel/Fooocus/discussions/2318 & https://github.com/lllyasviel/Fooocus/discussions/2416

Based on https://huggingface.co/ByteDance/SDXL-Lightning/blob/main/sdxl_lightning_4step_lora.safetensors
Also read https://www.felixsanz.dev/articles/sdxl-lightning-quick-look-and-comparison#checkpoint-comparison (https://github.com/lllyasviel/Fooocus/discussions/2318#discussioncomment-8634972 @felixsanz).

Disables negative prompt for even faster generation with cfg = 1, even though it's capable of handling negative prompts with cfg > 1.", # Lightning mode
168,"Bump tox from 3.20.1 to 3.21.3
Bumps [tox](https://github.com/tox-dev/tox) from 3.20.1 to 3.21.3.

Changelog
Sourced from tox's changelog.

v3.21.3 (2021-01-28)
Bugfixes

Fix a killed tox (via SIGTERM) leaving the commands subprocesses running by handling it as if it were a KeyboardInterrupt - by dajose #1772

v3.21.2 (2021-01-19)
Bugfixes

Newer coverage tools update the COV_CORE_CONTEXT environment variable, add it to the list of environment variables that can change in our pytest plugin - by gaborbernat. #1854

v3.21.1 (2021-01-13)
Bugfixes

Fix regression that broke using install_command in config replacements - by jayvdb #1777
Fix regression parsing posargs default containing colon. - by jayvdb #1785

Features

Prevent .tox in envlist - by jayvdb #1684

Miscellaneous

Enable building tox with setuptools_scm 4 and 5 by hroncok #1799

v3.21.0 (2021-01-08)
Bugfixes

Fix the false congratulations message that appears when a KeyboardInterrupt occurs during package installation. - by gnikonorov #1453
Fix platform support for install_command. - by jayvdb #1464
Fixed regression in v3.20.0 that caused escaped curly braces in setenv to break usage of the variable elsewhere in tox.ini. - by jayvdb #1690
Prevent {} and require {: is only followed by }. - by jayvdb #1711
Raise MissingSubstitution on access of broken ini setting. - by jayvdb #1716

Features


... (truncated)


Commits

7dbed25 release 3.21.3
15533dd [pre-commit.ci] pre-commit autoupdate (#1872)
8a2bb56 Format markdown
6725807 tox use discord
833b33f Handle sigterm by killing the commands subprocess (#1860)
3d80588 Merge pull request #1858 from tox-dev/release-3.21.2
4116e90 release 3.21.2
1d23293 Newer coverage plugin updates env-vars, ignore in pytest plugin (#1854)
6624a8c Add missing backticks to my username (#1851)
51cd5fd Update README.md
Additional commits viewable in compare view





[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=tox&package-manager=pip&previous-version=3.20.1&new-version=3.21.3)](https://dependabot.com/compatibility-score/?dependency-name=tox&package-manager=pip&previous-version=3.20.1&new-version=3.21.3)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
If all status checks pass Dependabot will automatically merge this pull request.

[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



", # Update requirements.dev
169,"fix lite demo readme
", # ‰øÆÂ§çÊé®ÁêÜÂ∫ìÁöÑ‰∏ãËΩΩÈìæÊé•‰øÆÂ§çÊé®ÁêÜÂ∫ìÁöÑ‰∏ãËΩΩÈìæÊé•Ôºå‰ª•ÈÅøÂÖç‰∏ãËΩΩÁöÑÈìæÊé•‰∏çÂ≠òÂú®„ÄÇ
170,"Droplistmenu
The code is to show using tkinter GUI to creat droplist and calender, and using .place() to manage the positions.", # Droplistmenu: GUI to create droplist and calender
171,"Refactor a small function
", # Fix datetime_safe.py
172,"Fix issue #2077
* Update delete_keys_response_template (jinja2 template)
* Patch _bucket_response_delete_keys from moto
* Add test case for bugfix

", # [s3] fix delete_keys responseFixes #2077
173,"CLN: redundant function in `Styler`
simplifies code by removing unnecessary function def.", # Fix #10064
174,"New GCP Module: gcp_compute_target_http_proxy_facts
##### SUMMARY

New GCP Module: gcp_compute_target_http_proxy_facts
##### ISSUE TYPE
- New Module Pull Request

##### COMPONENT NAME
gcp_compute_target_http_proxy_facts

##### ANSIBLE VERSION
```
2.7
```

##### ADDITIONAL INFORMATION
```
This was generated by [Magic Modules](https://github.com/googlecloudplatform/magic-modules)
```
", # Add GCP TargetHttpProxy factsAdd GCP TargetHttpProxy facts
175,"Broaden GPTQ-for-LLaMA branch support
Conditionalized the keyword arguments passed to GPTQ-for-LLaMA's `quant.make_quant()` so we can support more branches simultaneously. Pretty simple, we just test which kwargs `quant.make_quant()` currently has available and don't try to send any invalid ones.

Tested (with varying launch.py arguments) on:
* Oobabooga's old CUDA fork: [9659310499cc7a0ea5498c1beb47bb228d65d178](https://github.com/oobabooga/GPTQ-for-LLaMa/tree/9659310499cc7a0ea5498c1beb47bb228d65d178)
* Current CUDA branch: [610fdae6588c2b17bcf2726cacaaf795cd45077e](https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/610fdae6588c2b17bcf2726cacaaf795cd45077e)
* Current triton branch: [6800a08c7a3d8d682499df5d6d96666253af8ed1](https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/6800a08c7a3d8d682499df5d6d96666253af8ed1)

I suspect it would also work with the older non-groupsize versions too, but I don't think I have any old quantizations lying around to test it.

Following up #785

Just to be clear, this still won't make a model quantized by an excessively different version of GPTQ-for-LLaMA load, so e.g. you still need the old CUDA GPTQ-for-LLaMA in your repositories directory to use the 2-week-oldish quantizations most users probably have at this point. Likewise, if you want to try the new triton branch, you'll need to grab some fresh requantizations.
This PR is just so you can use different GPTQ-for-LLaMA versions without having to _also_ fiddle with text-generation-webui code to get things cooperating.", # Fix GPTQ_loader.py
176,"[MRG+1] Raise warning in scikit-learn/sklearn/linear_model/cd_fast.pyx for cases when the main loop exits without reaching the desired tolerance
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->
Fixes #10813.

#### What does this implement/fix? Explain your changes.
This pull request adds `ConvergenceWarnings` to the `enet_coordinate_descent*` solvers found in scikit-learn/sklearn/linear_model/cd_fast.pyx for cases when the main loop exits without reaching the desired tolerance.

#### Any other comments?
Tests have been included in both sklearn/linear_model/tests/test_coordinate_descent.py and sklearn/linear_model/tests/test_sparse_coordinate_descent.py

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
", # Add ConvergenceWarning to coordinate_descentAdd ConvergenceWarning to coordinate_descent.
177,"[hotfix]fixed p2p process send stuck
", # [colossalai] fix p2p.py
178,"Fixing parameter type for obtain_certificate's domains parameter
", # fix: let'sencrypt client.py
179,"fixed tests
We had removed the username_unclaimed from data.json but forgotten to remove it from the tests", # Remove unneeded parentheses in coverage_total_check
180,"update minimum requirements
Set minimum requirements to latest versions. In particular Werkzeug 2.3.", # Update minimum requirements
181,"manacher's algorithm to find palindromic string
manacher's algorithm to find palindromic string in linear time complexity",
182,"[DigitalConcertHall] Support for Films
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

The PR adds support for films to an existing extractor that previously only supported concerts.

Fixes #7184


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at 33df3da

### Summary
üé•üéºüõ†Ô∏è

<!--
1.  üé• - This emoji represents the addition of support for `film` videos, which are a different type of content from `concert` videos and may have different formats and metadata.
2.  üéº - This emoji represents the extraction of `chapters` for `concert` videos, which are a useful feature for navigating and identifying the different musical pieces and performers in a concert.
3.  üõ†Ô∏è - This emoji represents the update of the extractor code and the addition of a new test case, which are both necessary tasks for implementing and verifying the changes.
-->
Improve the Digital Concert Hall extractor by adding support for different video types and more metadata. Update tests accordingly.

> _`film` or `concert`, we don't care, we just want to rock_
> _We scrape the hall for every bit of metadata we can unlock_
> _We split the `concert` into `chapters`, we don't miss a note_
> _We test our code with `film` videos, we make the extractor float_

### Walkthrough
*  Update `_VALID_URL` regex to support `film` and `concert` types of videos ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL14-R14))
*  Add a new test case for a `film` type video with expected metadata ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcR43-R55))
   * Extract `type_` group from URL and use it to request appropriate JSON data from API ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL106-R123))
   * Handle different structures of `videos` list for `film` and `concert` videos ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL106-R123))
   * Pass `type_` parameter to `_entries` method ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL123-R141))
   * Accept `type_` parameter and use it to conditionally extract `chapters` field from `cuepoints` key of each video item ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL78-R91), [link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL133-R147))
   * Return a list of entries with video metadata and formats ([link](https://github.com/yt-dlp/yt-dlp/pull/7202/files?diff=unified&w=0#diff-ec781d6032769743854814b17eb49f18a75456f429a07ff12bb2dcf494bd20bcL78-R91))




", # [digitalconcerthall] Add type_ param to extractor
183,"Emergency Fix: SyntaxError: invalid syntax - ÊúçÂä°Âô®Á´Ø Python ËØ≠Ê≥ï BUG Á¥ßÊÄ•‰øÆÂ§çÔºÅ
This will cause Fatal problem in GAE server !!! Result in GAE_Exception 605 'status:500'


Google Log Report:


11:33:20.864
 (/base/data/home/runtimes/python27_experiment/python27_lib/versions/1/google/appengine/runtime/wsgi.py:263)
Traceback (most recent call last):
  File ""/base/data/home/runtimes/python27_experiment/python27_lib/versions/1/google/appengine/runtime/wsgi.py"", line 240, in Handle
    handler = _config_handle.add_wsgi_middleware(self._LoadHandler())
  File ""/base/data/home/runtimes/python27_experiment/python27_lib/versions/1/google/appengine/runtime/wsgi.py"", line 299, in _LoadHandler
    handler, path, err = LoadObject(self._handler)
  File ""/base/data/home/runtimes/python27_experiment/python27_lib/versions/1/google/appengine/runtime/wsgi.py"", line 85, in LoadObject
    obj = __import__(path[0])
  File ""/base/data/home/apps/s~radar1-179201/1.403929351434169704/gae.py"", line 124
    data = 'HTTP/1.1 %d %s\r\n%s\r\n\r\n%s' %
                                             ^
SyntaxError: invalid syntax", # [GAE] Fix GAE response format
184,"Add pikaur AUR manager to Arch Linux's commands
See [pikaur repo](https://github.com/actionless/pikaur) and [AUR package](https://aur.archlinux.org/packages/pikaur)
", # Add pikaur to pacman_not_found
185,"Create model card for asafaya/bert-large-arabic
", # Add Arabic BERT Large ModelAdd Arabic BERT Large Model
186,"bitmart error mapping
", # Add 51011 error code
187,"[xattrs] '--xattrs' option that writes metadata to extended attributes (implemented as a postprocessor)
I think you guys are going to like this final version of my xattr writer.

I listened to your previous objections, and rewrote most of it. It's now a postprocessor (`XAttrMetadataPP`), and it will only load the python `pyxattr` module (or search the path for `setfattr`) if the postprocessor is enabled.

Plus, it can be enabled with the `--xattrs` option.
",
188,"add /path/to to gen_label doc
",
189,"Make yalexs_ble matcher more specific


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Related issue #78051 (will not solve it since that seems to be a driver problem)


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] ü•à Silver
- [ ] ü•á Gold
- [ ] üèÜ Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
", # Add service_uuid to yalexs_bleAdd service_uuid to yalexs_ble.
190,"Fixed #35091 -- Allowed GeoIP2 querying using IPv4Address/IPv6Address.
ticket-35091.", # Allow GeoIP2 queries using IPv4Address or IPv6Address objectsThis PR allows GeoIP2 queries using IPv4Address or IPv6Address objects.
191,"Fix duplicate code on linear_model.rst
#### Reference Issues/PRs

No PR found with this search keyword

```
is:open label:module:linear_model label:Documentation 
```

#### What does this implement/fix? Explain your changes.

Remove `.fit()` function called twice in example code in ""Ordinary Least Squares"" section", # Fix doc/modules/linear_model.rst
192,"[MRG+1] Fixed SelectKBest corner case: k=0
Without this fix k = 0 will have the same behavior as k = 'all' based on how
the array indexing was written.

I've included a test that demonstrates proper behaviour.
", # Add test for SelectKBest with k=0
193,"feat: rebase to geekan:main
feat: rebase to geekan:main",
194,"Use Weverse preview endpoint if no auth provided
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

Change Weverse extractor to try and download videos using the preview endpoint if no credentials are provided.

Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at 302a6c7

### Summary
üîíüåêüõ†Ô∏è

<!--
1.  üîí - This emoji represents the improved handling of authentication and access rights, as the extractor now checks for the presence and validity of an access token before making requests to the API, and gracefully handles errors related to expired or revoked tokens, insufficient permissions, or missing content.
2.  üåê - This emoji represents the added support for alternative endpoints that provide previews of the posts for anonymous or unauthorized users, as the extractor now falls back to these endpoints when the access token is missing or invalid, or when the post is not accessible to the authenticated user. These endpoints are also used to extract some metadata that is not available from the main API, such as the number of comments and likes on a post.
3.  üõ†Ô∏è - This emoji represents the general refactoring and improvement of the code quality and readability, as the extractor now uses more consistent and descriptive variable names, follows the PEP 8 style guide, and uses helper functions and classes to avoid repetition and complexity.
-->
Refactor `weverse` extractor to improve authentication and access handling, and add preview support.

> _The `weverse` extractor was due_
> _For a refactor to make it more true_
> _To the access rights logic_
> _And the endpoints biologic_
> _That provide previews for me and for you_

### Walkthrough
* Move token check and login error to `_call_api` and `_call_post_api` functions ([link](https://github.com/yt-dlp/yt-dlp/pull/7924/files?diff=unified&w=0#diff-267a5b7aa508e0099ef609aad0ce38e0371f77515bdf56f4ad244143aaf59d60L73-R75))
* Use alternative endpoints for previews without authentication or access rights ([link](https://github.com/yt-dlp/yt-dlp/pull/7924/files?diff=unified&w=0#diff-267a5b7aa508e0099ef609aad0ce38e0371f77515bdf56f4ad244143aaf59d60L104-R112))




", # [WEVERSE] Fix #10064
195,"Exclude broken typing-extensions version + fix import
### Description

re. import, the ipynb code was assuming that typing-extensions would always be available, but that's not the case! There's an environment marker on the requirement meaning it won't get installed on 3.10 or higher. The test suite didn't catch this issue since aiohttp pulls in typing-extensions unconditionally.

### Checklist - did you ...

- [x] Add a CHANGELOG entry if necessary?
- [x] Add / update tests if necessary?
- [x] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
"," # Fix #2460: exclude typing-extensions 3.10.0.1 due to it being broken on Python 3.10### Describe your change:* [ ] Add an algorithm?* [ ] Fix a bug or typo in an existing algorithm?* [x] Documentation change?### Checklist:* [x] I have read [CONTRIBUTING.md](https://github.com/psf/black/blob/master/CONTRIBUTING.md).* [x] This pull request is all my own work -- I have not plagiarized.* [x] I know that pull requests will not be merged if they fail the automated tests.* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.* [x] All new Python files are placed inside an existing directory.* [x] All filenames are in all lowercase characters with no spaces or dashes.* [x] All functions and variable names follow Python naming conventions.* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.* [x] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
196,"Backport PR #43597 on branch 1.3.x (BUG: .cat changing dtype inplace)
Backport PR #43597: BUG: .cat changing dtype inplace", # Fix reorder_categories and set_categoriesFixes #43232 and #43334
197,"Capitalization and test to see if Travis CI is turned on
 #313 has prepared this repo for free, automated flake8 testing on each pull request but it must be enabled by @3b1b logging into https://travis-ci.com/profile via GitHub id and flipping the repository switch on.", # Fixed typo in README.md
198,"Add reminder to local-oldest-requirements.txt.
We've updated the local-oldest-requirements files a couple times now to get ""oldest"" tests to pass but forgot to update the corresponding setup.py files. This adds a reminder for us to do that.",
199,"[fix] Set default json dumps setting to ensure_ascii=False
# Description

Set json dumps setting to ensure_ascii=False in metadata_extractors. If not, the content that goes into openai would be wrong.

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [ ] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [x] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
", # fix encoding issue
200,"Bug fix for `asyncio_mod` in `LabelledRagDataset`
# Description

Quick fix on a bug when `show_progress` is `False` and `asyncio_mod`'s `gather` method doesn't have the `desc` param.

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [x] I stared at the code and made sure it makes sense", # [base] Fix for show_progress=False
201,"Print which directory gpt-engineer is using
Makes it clearer where we are actually running, especially if we're run without an explicit path as it defaults to `projects/example`", # Print project path
202,"update py inference to 2.0 and delete fluid
",
203,"Fixed #29017 -- Updated BaseCommand.leave_locale_alone doc per refs #24073.
https://code.djangoproject.com/ticket/29017", # Fix typo in docs
204,"Victoria open data


- [X] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [X] My addition is ordered alphabetically
- [X] My submission has a useful description
- [X] The description does not have more than 100 characters
- [X] The description does not end with punctuation
- [X] Each table column is padded with one space on either side
- [X] I have searched the repository for any relevant issues or pull requests
- [X] Any category I am creating has the minimum requirement of 3 items
- [X] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add Victoria State Government Open DataAdded Victoria State Government Open Data to the list of open government APIs.
205,"pivoting: add english version of the article
", # Update Network Pivoting Techniques.md
206,"Add renew_hook to options stored in the renewal config, #3394
renew_hook are called for each lineage, so it makes sense to store it and run it for each. Discussion on the issue probably still applies for pre/post hooks though. Discussion was in  #3394", # Remove standalone_supported_challenges from renewal.pyThis is a no-op change. The renewal.py file is not used by the renewal plugin.
207,"Fixing Tinder false positive
changed tinder URL to one that accurately gives results", # Update gotinder.com to tinder.com
208,"Update thirdparty.md
", # ‰øÆÊîπdoc/doc_ch/thirdparty.md‰øÆÊîπ‰∫Üthirdparty.md‰∏≠ÁöÑ‰∏Ä‰∏™È°πÁõÆÔºåÂûÇÁ±ªÂú∫ÊôØË∞É‰ºòÈ°πÁõÆÁöÑÂêçÁß∞„ÄÇ
209,"Add option to set notification sound volume
## Description

* a simple description of what you're trying to accomplish
  * This PR adds the option to the settings for changing the volume of the optional notification sound that can be played after image generation. This can be useful if the volume of the used notification sound should be lowered without the need to modify the sound file self.

* a summary of changes in code
  * The option for changing the volume value was added to the shared options in percent
  * Before playing the notification sound, the volume will be adjusted based on the set value in the options

## Screenshots/videos:
![grafik](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/118578287/82b79dbd-e131-4b44-9c0a-ead230c3e7d0)


## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Add notification volume optionAdd notification volume option.
210,"[OK.RU] Raise error in case of paid videos.
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [ ] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [x] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information
In case of paid video raise proper error.

", # [odnoklassniki] Add paid video detection
211,"Update README.md
added a missing key ingredient: SICP", # Add SICP to recommended booksAdded SICP to the list of recommended books.
212,"feat: add Fastly CDN.
", # Add Fastly to Saas Cdn
213,"Sort by confidence and remove excess boxes without explicit if
It is related to #10502.
Signed-off-by: Yonghye Kwon 

<!--
Thank you for submitting a YOLOv5 üöÄ Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ‚úÖ [Contributing Guide](https://github.com/ultralytics/yolov5/blob/master/CONTRIBUTING.md) for more details.
-->


## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Optimization of Non-Max Suppression (NMS) in YOLOv5 object detection.

### üìä Key Changes
- Simplified the sorting of detection boxes based on confidence score.
- Removed excess boxes beyond a maximum threshold (`max_nms`) in one line of code.

### üéØ Purpose & Impact
- **Purpose:** To streamline the box sorting process within NMS and improve code readability.
- **Impact:** This change can potentially speed up the NMS step in object detection, leading to faster inference times. It also makes the codebase easier to understand and maintain for developers. Users can expect slightly quicker results without compromising accuracy when detecting objects in images. üöÄ", # [MRG] Fix NMS
214,"CVE-2007-4559 Patch
# Patching CVE-2007-4559

Hi, we are security researchers from the Advanced Research Center at [Trellix](https://www.trellix.com). We have began a campaign to patch a widespread bug named CVE-2007-4559. CVE-2007-4559 is a 15 year old bug in the Python tarfile package. By using extract() or extractall() on a tarfile object without sanitizing input, a maliciously crafted .tar file could perform a directory path traversal attack. We found at least one unsantized extractall() in your codebase and are providing a patch for you via pull request. The patch essentially checks to see if all tarfile members will be extracted safely and throws an exception otherwise. We encourage you to use this patch or your own solution to secure against CVE-2007-4559. Further technical information about the vulnerability can be found in this [blog](https://www.trellix.com/en-us/about/newsroom/stories/research/tarfile-exploiting-the-world.html).

If you have further questions you may contact us through this projects lead researcher [Kasimir Schulz](mailto:kasimir.schulz@trellix.com).
", # Tarfile: Prevent Path Traversal
215,"raw now returns changed: true
##### ISSUE TYPE
- Feature Pull Request
##### COMPONENT NAME

plugins/action/raw.py
##### SUMMARY

raw now returns `changed: true` for consistency w/ shell/command/script ""non-idempotent"" modules.

Updated tests, changelog.
"," # [2.2] Raw module changed: true by defaultAs of 2.2, raw module changed: true by default. This PR adds a few tests to ensure that this is working as expected."
216,"Fix syntax error in lock action
I missed this in the last review üòî Looks like the job is failing with a syntax error because of the missing `with` clause.", # Fix lock-issues.yml
217,"Deploy Windows wheels to Amazon S3
## Why are these changes needed?

We need to upload Windows wheels.

## Related issue number

#631

## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/latest/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failure rates at https://ray-travis-tracker.herokuapp.com/.
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested (please justify below)
", # [ci] upload wheels to s3
218,"CLN: Remove redundant mixin to TimedeltaIndex
we already pass-through the relevant attributes", # Remove TimelikeOps from TimedeltaIndex
219,"fix(hybrid-cloud): Properly generate discord_request in Discord request parser
Fixes [HC-TEST-CONTROL-M7](https://sentry-st.sentry.io/issues/4681906125/?project=4505211735834624).

I've adjusted the tests to assert on `parser.get_integration_from_request()` after `parser.get_response()` to properly reflect the actual state that the parser will run with.", # [discord] fix discord integration parserFixes #10021
220,"[runtime env] Parse local conda/pip requirements files before sending runtime env to Ray Client Server




## Why are these changes needed?
Validate the runtime env before sending it to the Ray Client Server.  Validation rewrites the `pip` or `conda` field if it contains a local path to a requirements file, replacing it with a Python object containing the file contents (List in the case of a pip requirements.txt, dict in the case of a conda environment.yml). This prevents errors when the validation is run again on the remote nodes.  

In the future we should refactor jobconfig.py so a validated runtime env is passed in once at the beginning, instead of running validation every time we serialize the JobConfig.



## Related issue number


Closes #20876 
## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [x] Unit tests
   - [ ] Release tests (Will add release test once this is merged.  Can't do it beforehand because `conda` runtime_env requires the Ray wheel to exist on AWS, so I can't manually run the release test using Ray built from source.)
   - [ ] This PR is not tested :(
",
221,"fix erroneous failures in docker_compose due to deprecation warnings ‚Ä¶
‚Ä¶from docker (#60961)

##### SUMMARY

Consistently capture stdout and stderr to prevent any output from causing erroneous failures

fixes #60961
##### ISSUE TYPE

- Bugfix Pull Request

##### COMPONENT NAME

docker_compose
##### ADDITIONAL INFORMATION




",
222,"REF: avoid unnecessary raise in DataFrameGroupBy._cython_agg_general
Untangling these layered try/excepts is turning out to be an exceptional PITA, so splitting it into extra-small pieces.", # [MRG] Fix #10066
223,"Update autogen.py
fix duplicate module name for callbacks module

Callback() should be 
`keras.callbacks.Callback()`
but autogen.py generated
`keras.callbacks.callbacks.Callback()`

Classes in callbacks module had the same issue.
Added callback in `post_process_signature` method in autogen.py

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
", # Add autogen.py for callbacks
224,"fix obj insert_nodes
insert_nodes would raise errors about unserializable objects", # [core] fix for index nodes
225,"Add loss scale guard to avoid inf loop
@jeffra @sdtblck 

Brings https://github.com/EleutherAI/DeeperSpeed/commit/a6748a420be10240ff86baa65b0e6ab5fcbddf03 into upstream DeepSpeed. 

If the loss scale reaches the minimum value and we attempt to decrease it again, raise an error to avoid infinite loop.", # [deepspeed] add raise error at min scale
226,"Made observation spaces Dict iterable
So far, the Dict in gym.spaces was crashing when one tries to iterate through it. This happened because it had a __getitem__() method defined, but no __iter__(). Hence:
```
for key in Dict():
```
lead to 
```
for key in Dict():
  File ""/opt/anaconda/lib/python3.7/site-packages/gym/spaces/dict.py"", line 64, in __getitem__
    return self.spaces[key]
KeyError: 0
```

I fixed this by adding a __iter__ method to Dict. Now it is iterable.", # Add __iter__ to Dict
227,"Address #2786 - Fix code style in Project Euler Problem 76 
Signed-off-by: joan.rosellr 

### **Describe your change:**



* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
", # Fixes #76: https://projecteuler.net/problem=76
228,"Fix notebook that 'cannot convert' via nbdoc_build
", # Update Python REPL integration
229,"Check if we need to upgrade deps before rebuilding everything
Due to the order of checkes in selective_ci_checks.sh, we were never
eagerly upgrading deps on a Pull Reuqest, because we exited before
getting to `check_if_setup_files_changed`.

Previoulsy the output was this

```
Get changed files
Check if everything should be run

  Changed files matching the ^.github/workflows/|^Dockerfile|^scripts|^setup.py|^setup.cfg pattern:

  Dockerfile
  Dockerfile.ci
  setup.py

  Important environment files changed. Running everything
  ...
  image-build=true
  upgrade-to-newer-dependencies=false
```

And then it exited. By simply changing the order we set the right flag
_first_ and then exit.
", # Update selective_ci_checks.sh
230,"Fix typo in tutorial
", # Fix typo in introduction.rst
231,"Update 4 Digit Number Combinations.py
 Updated the code and appended the strings to the list, if the user needs to access it.", # Fixed the code for 4 digit number combinations
232,"Skip async tests on old python versions
This should fix the tests! :)", # [MRG] Add skipif for Python 3.7### Describe your change:Add skipif for Python 3.7### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/mitmproxy/mitmproxy/blob/master/CONTRIBUTING.md#start-contributing).- [x] This pull request is all my own work -- I have not plagiarized.- [x] I know that pull requests will not be merged if they fail the automated tests.- [x] This PR only changes one file.  All changes should be made in that one file.- [x] All new Python files are placed inside an existing directory.- [x] All filenames are in all lowercase characters with no spaces or dashes.- [x] All functions and variable names follow Python naming conventions.- [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).- [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.- [x] All new algorithms include a Wikipedia explanation of how they work.- [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
233,"Support inference with OFT networks
## Description

This PR adds support for inference of OFT networks trained with kohya-ss [sd-scripts](https://github.com/kohya-ss/sd-scripts). The implementation is based on kohya's implementation here: https://github.com/kohya-ss/sd-scripts/blob/main/networks/oft.py

~~This is a draft PR because of these major issues:~~
* ~~The network remains affects all generations after loading even when supposed to be unloaded~~
* ~~It noticeably slows down inference~~

~~The current implementation replaces sd_module's forward method with a custom forward method, which I believe is the cause of the network continuing to affect future generations and the speed of inference.~~

### ~~Any suggestions on how to fix these issues is greatly appreciated!~~

Related links:
OFT project page: https://oft.wyliu.com
OFT official repository: https://github.com/Zeju1997/oft

## Screenshots/videos:


## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",
234,"Fix incorrect statement id in Lambda add-permission API
Fixed random statement id in order to use the provided by the requests #1788.

Updated tests and responses when the policies don't exists anymore.
", # [localstack/services/awslambda] Fix Lambda APIFixes #1002
235,"Update quickstart doc and set version in pyproject.toml to 0.2.0
", # Update version
236,"Remove extra asterisk in example in C.60
See #1429", # Fix typo in C++ Core Guidelines
237,"Allow _acme-challenge as a zone
Like described here:
https://github.com/lukas2511/dehydrated/wiki/example-dns-01-nsupdate-script

Not using this patch may be an issue if the parent zone has been (where a wildcard certificate has been requested.) signed by DNSSEC.

Please consider this also for inclusion before dns-01 will be allowed for wildcards.",
238,"fixed broken badge link
", # Update badge in README
239,"Update Breadth_First_Search.py
Fixed the fact that all nodes except source are marked as visited twice", # BFS: Fix visited
240,"Update docs/cli-help.txt -- typo and formatting
'areusing' -> 'are using'", # Fix typo in --dns-dnsmadeeasy help text
241,"fix concurrency issues of cfn and sns tests
This PR introduces concurrency control for two tests that [started failing/flaking](https://app.circleci.com/pipelines/github/localstack/localstack/5973/workflows/ddd64c56-1f61-4bfe-900a-b069bf9a28bf/jobs/33718/tests#failed-test-0) after the ASF migration.
", # [integration] fix test_deploy_stack_with_iam_role
242,"binance.createOrder market buy string math
```
% binance createOrder ADA/USDT market buy 23 0.45
2022-09-07T01:56:25.564Z
Node.js: v18.4.0
CCXT v1.93.9
(node:9030) ExperimentalWarning: The Fetch API is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
binance.createOrder (ADA/USDT, market, buy, 23, 0.45)
2022-09-07T01:56:27.681Z iteration 0 passed in 676 ms

{
  info: {
    symbol: 'ADAUSDT',
    orderId: '3621981315',
    orderListId: '-1',
    clientOrderId: 'x-R4BD3S82d99ffb7e94d1468ca53816',
    transactTime: '1662515787820',
    price: '0.00000000',
    origQty: '22.50000000',
    executedQty: '22.50000000',
    cummulativeQuoteQty: '10.33650000',
    status: 'FILLED',
    timeInForce: 'GTC',
    type: 'MARKET',
    side: 'BUY',
    fills: [
      {
        price: '0.45940000',
        qty: '22.50000000',
        commission: '0.02250000',
        commissionAsset: 'ADA',
        tradeId: '406917760'
      }
    ]
  },
  id: '3621981315',
  clientOrderId: 'x-R4BD3S82d99ffb7e94d1468ca53816',
  timestamp: 1662515787820,
  datetime: '2022-09-07T01:56:27.820Z',
  lastTradeTimestamp: undefined,
  symbol: 'ADA/USDT',
  type: 'market',
  timeInForce: 'GTC',
  postOnly: false,
  reduceOnly: undefined,
  side: 'buy',
  price: 0.4594,
  stopPrice: undefined,
  amount: 22.5,
  cost: 10.3365,
  average: 0.4594,
  filled: 22.5,
  remaining: 0,
  status: 'closed',
  fee: { currency: 'ADA', cost: 0.0225 },
  trades: [
    {
      info: {
        price: '0.45940000',
        qty: '22.50000000',
        commission: '0.02250000',
        commissionAsset: 'ADA',
        tradeId: '406917760'
      },
      timestamp: undefined,
      datetime: undefined,
      symbol: 'ADA/USDT',
      id: '406917760',
      order: '3621981315',
      type: 'market',
      side: 'buy',
      takerOrMaker: undefined,
      price: 0.4594,
      amount: 22.5,
      cost: 10.3365,
      fee: { cost: 0.0225, currency: 'ADA' },
      fees: [ { currency: 'ADA', cost: '0.02250000' } ]
    }
  ],
  fees: [ { currency: 'ADA', cost: 0.0225 } ]
}
2022-09-07T01:56:27.681Z iteration 1 passed in 676 ms
```", # binance: fix precision
243,"Fix typo discovered by codespell
___codespell --quiet-level=2___
```
./python-patterns/patterns/behavioral/publish_subscribe.py:68: subscirbed ==> subscribed
./python-patterns/patterns/structural/front_controller.py:30: cant ==> can't
./python-patterns/patterns/structural/front_controller.py:72: cant ==> can't
```", # Fix typos in patterns
244,"[highlighter] Add complex numbers pattern to our highlighter's `number` matching
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

closes #2214 

The fix in action:

#### In IPython:
![Screenshot from 2022-04-25 12-24-00](https://user-images.githubusercontent.com/722388/165079687-6e497cb1-91ad-48e1-868f-f0deb7f0c5d5.png)

#### In a Jupyter notebook:
![Screenshot from 2022-04-25 12-28-04](https://user-images.githubusercontent.com/722388/165080326-d576b0be-5b2e-4a8b-b6a1-52c1fa1a71f6.png)

#### In plain Python 
![Screenshot from 2022-04-25 12-29-03](https://user-images.githubusercontent.com/722388/165080507-08913ca4-b8d4-483c-b8af-31b53a93f33c.png)

", # Add support for complex numbers
245,"[youku] Update cccode
Update cccode to 0510 for youku.py

Get from:

http://g.alicdn.com/player/ykplayer/0.5.28/youku-player.min.js

{""0505"":""interior"",""050F"":""interior"",""0501"":""interior"",""0502"":""interior"",""0503"":""interior"",""0510"":""adshow"",""0512"":""BDskin"",""0590"":""BDskin""}

Before the fix:
```
you-get --debug http://v.youku.com/v_show/id_XMzU5NjkxNTM1Ng==.html?spm=a2h0z.8244218.2371631.5
[DEBUG] get_content: https://ups.youku.com/ups/get.json?vid=XMzU5NjkxNTM1Ng==&ccode=0502&client_ip=192.168.1.1&utid=%2BoR%2BE7ve%2BDsCARi5QmohYOQw&client_ts=1526175486&ckey=DIl58SLFxFNndSV1GFNnMQVYkx1PP5tKe1siZu/86PR1u/Wh1Ptd%2BWOZsHHWxysSfAOhNJpdVWsdVJNsfJ8Sxd8WKVvNfAS8aS8fAOzYARzPyPc3JvtnPHjTdKfESTdnuTW6ZPvk2pNDh4uFzotgdMEFkzQ5wZVXl2Pf1/Y6hLK0OnCNxBj3%2Bnb0v72gZ6b0td%2BWOZsHHWxysSo/0y9D2K42SaB8Y/%2BaD2K42SaB8Y/%2BahU%2BWOZsHcrxysooUeND
you-get: Áî®Êà∑Ë¥¶Êà∑ÂºÇÂ∏∏„ÄÅËØ∑ÈáçÊñ∞ÁôªÂΩï
```

After the fix:

```
you-get --debug http://v.youku.com/v_show/id_XMzU5NjkxNTM1Ng==.html?spm=a2h0z.8244218.2371631.5
[DEBUG] get_content: https://ups.youku.com/ups/get.json?vid=XMzU5NjkxNTM1Ng==&ccode=0510&client_ip=192.168.1.1&utid=IYV%2BE0QbrVcCARi5Qmqd6hjL&client_ts=1526175525&ckey=DIl58SLFxFNndSV1GFNnMQVYkx1PP5tKe1siZu/86PR1u/Wh1Ptd%2BWOZsHHWxysSfAOhNJpdVWsdVJNsfJ8Sxd8WKVvNfAS8aS8fAOzYARzPyPc3JvtnPHjTdKfESTdnuTW6ZPvk2pNDh4uFzotgdMEFkzQ5wZVXl2Pf1/Y6hLK0OnCNxBj3%2Bnb0v72gZ6b0td%2BWOZsHHWxysSo/0y9D2K42SaB8Y/%2BaD2K42SaB8Y/%2BahU%2BWOZsHcrxysooUeND
site:                ‰ºòÈÖ∑ (Youku)
title:               Ë¥ßÂ∏ÅÊàò‰∫âÔºà‰∏ãÔºâÔºöÂ§¥Âè∑Áé©ÂÆ∂
stream:
    - format:        mp4hd3v2
      container:     mp4
      video-profile: 1080P
      size:          567.0 MiB (594580265 bytes)
      m3u8_url:      http://pl-ali.youku.com/playlist/m3u8?vid=XMzU5NjkxNTM1Ng%3D%3D&type=hd3&ups_client_netip=18b9426a&utid=IYV%2BE0QbrVcCARi5Qmqd6hjL&ccode=0510&psid=b336626aa0973701c5248c01cfa2f3f8&duration=3071&expire=18000&drm_type=1&drm_device=7&ups_ts=1526175526&onOff=0&encr=0&ups_key=bcfaf87bad590f7a77bfa4ac5ffc8793
    # download-with: you-get --format=mp4hd3v2 [URL]
```", # [youku] update ccode
246,"bpo-37759:  Significant edits to Whatsnew 3.8
Work in progress.  Please add suggestions here as you find them.


https://bugs.python.org/issue37759

",
247,"Updated with virtualenv for Atom.io
"," # Add virtualenv-apiAdded virtualenv-api to the list of awesome Python frameworks, libraries and software."
248,"Fix mypy error in web_programming/reddit.py
### Describe your change:

In recent PRs such as #9160, mypy is failing in the pre-commit check because of the following error:
```
web_programming/reddit.py:36: error: Missing named argument ""response"" for ""HTTPError""  [call-arg]
```
This happens even though contributors aren't modifying `web_programming/reddit.py`. I'm not sure why this mypy error is appearing now, but this appears to fix it.

* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [ ] All new Python files are placed inside an existing directory.
* [ ] All filenames are in all lowercase characters with no spaces or dashes.
* [ ] All functions and variable names follow Python naming conventions.
* [ ] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [ ] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [ ] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [ ] If this pull request resolves one or more open issues then the description above includes the issue number(s) with a [closing keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue): ""Fixes #ISSUE-NUMBER"".
", # Added Smith WatermanAdded Smith Waterman to the list of dynamic programming algorithms.
249,"Fix various typos
Fixes #169.

Note that one of the corrections was incorrect: ""ue""->""due"". I opened [codespell#1413](https://github.com/codespell-project/codespell/issues/1413) to track that issue.",
250,"Fix command-line formatting
Fix formatting for a bash command in ``docs/patterns/packages.rst``.", # Add code block example for running Flask app
251,"Fix-up standalone binary docs.
", # Fix typo in docs
252,"More doc updates
", # Fix docs for Requests
253,"Fix AutoModel tests
Auto model tests were not kept up to date. This patches the following two tests:
```
FAILED tests/test_modeling_auto.py::AutoModelTest::test_model_from_pretrained
FAILED tests/test_modeling_common.py::ModelUtilsTest::test_model_from_pretrained
```", # [MRG] Fix test for loading model from pretrained
254,"Fix llama2 provider, Update TOC in readme
", # Update README.md
255,"Allow disabling docs UIs by disabling OpenAPI
:sparkles: Allow disabling docs UIs by disabling OpenAPI and add docs and tests for it.", # Add conditional OpenAPI docs
256,"fix(suspect-spans): All columns must be explicitly specified
Previously, some columns were still being added automatically with a default of
adding every column. This change ensures that all the desired columns must be
explicitly specified or it won't be returned.",
257,"Extract port number from authority before IDNA decode 
#### Description

Before calling `.decode(""idna"")` first extract the port number. Attempt to fix issue #4409

If the port is present it can lead to a UnicodeError exception causing net.http.url.parse_authority to incorrectly return False.

The existing test passes because `.decode(""idna"")` accepts a port number some of the time:

```
>>> b""xn--aaa-pla.example:80"".decode(""idna"")
'√§aaa.example:80'
```

However this results in a UnicodeError exception:

```
>>> b""xn--r8jz45g.xn--zckzah:80"".decode(""idna"")
Traceback (most recent call last):
  File ""/usr/lib/python3.6/encodings/punycode.py"", line 207, in decode
    res = punycode_decode(input, errors)
  File ""/usr/lib/python3.6/encodings/punycode.py"", line 194, in punycode_decode
    return insertion_sort(base, extended, errors)
  File ""/usr/lib/python3.6/encodings/punycode.py"", line 165, in insertion_sort
    bias, errors)
  File ""/usr/lib/python3.6/encodings/punycode.py"", line 146, in decode_generalized_number
    % extended[extpos])
UnicodeError: Invalid extended code point '8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/encodings/idna.py"", line 214, in decode
    result.append(ToUnicode(label))
  File ""/usr/lib/python3.6/encodings/idna.py"", line 131, in ToUnicode
    result = label1.decode(""punycode"")
UnicodeError: decoding with 'punycode' codec failed (UnicodeError: Invalid extended code point '8')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File """", line 1, in 
UnicodeError: decoding with 'idna' codec failed (UnicodeError: decoding with 'punycode' codec failed (UnicodeError: Invalid extended code point '8'))
```

#### Checklist

 - [x] I have updated tests where applicable.
 - [x] I have added an entry to the CHANGELOG.
", # Fix IDNA host 'Bad HTTP request line' errorFixes #1000
258,"Small styling tweaks
Originally from #513

- button hover style
- ensure context menu is always above everything
", # Fix drag-handle
259,"properly handling stop value when it can be a list or a str




## Why are these changes needed?

The OpenAI `stop` parameter can be either a string or a list of strings.  Right now the vllm worker assumes its always a string and causes some fatal error deep in the vllm engine when a list is passed.  This properly handles both str and list cases.

## Related issue number (if applicable)



## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).

Manually testing this and comparing against vllm's openai api server.  With this fix I now see comparable speeds.", # Fix vllm_worker.py
260,"Fixed `from utils import create_email, check_email` in `gpt4free/uses‚Ä¶
‚Ä¶less/__init__.py`

### **Before**:
```
from utils import create_email, check_email
```


### **Now**:
```
from .utils import create_email, check_email
```


### **Change**:
`Added dot before module name`", # fix import error
261,"Count the tokens/second when using --debug 
## Why are these changes needed?
We would like to count the tokens/second when debugging a served model on the cli.
Result using `llama-7b`:



## Related issue number (if applicable)
Closes #1268 

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [ ] I've made sure the relevant tests are passing (if applicable).
", # Add token count per secondAdds a token count per second to the inference loop.
262,"Invalud argument format
Other functions other than that function have spaces between argument", # Fix pendulum.py
263,"primer: Add `--no-diff` option
- Allow runs with no code diff output
- This is handy for reducing output to see which file is erroring

Test:
- Edit config for 'channels' to expect no changes and run with `--no-diff` and see no diff output
- Fix unittests to handle new argument", # Add `--no-diff` to black-primerAdd `--no-diff` to black-primer to suppress formatting changes.
264,"Add fail2ban filter.
A simple filter for fail2ban, which is a powerful log monitoring tool.

Please put the shadowsocks.conf into your filter.d directory, and
using `filter = shadowsocks` to use the filter.
", # Add fail2ban shadowsocks config
265,"Api Key Leaks: Add Trivy to tools section
This will add [Trivy](https://github.com/aquasecurity/trivy) to the tools section of the topic `Api Key Leaks`. This is currently my go-to tool to scan docker images or repositories for secrets and therefore should be mentioned. As I could not see it mentioned somewhere, I picked this topic as it seemed to fit best. But it might also fit for other topics such as scanning for vulnerable dependencies (CVE) used in a projects or weaknesses in regards of SBOM/IaC. If you see a better fit for Trivy at other topics or might want to add it redundantly multiple times I guess we could add it to this MR.
Let me know what you think. :)

(Also changed the phrasing for two other tools as their main repository uses the upper/lowecase as changed which should not require a separate MR)", # Update README.md
266,"Revert/Fix vicuna prompt




## Why are these changes needed?

Fixing the vicuna prompt after the airoboros model PR changed the prompt



## Related issue number (if applicable)

https://github.com/lm-sys/FastChat/pull/1877


## Checks

- [ ] I've run `format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed.
- [ ] I've made sure the relevant tests are passing (if applicable).
", # fix typo
267,"New `LetterBox(size)` `CenterCrop(size)`, `ToTensor()` transforms (#9213)
YOLOv5 LetterBox class for image preprocessing, i.e. T.Compose([T.ToTensor(), LetterBox(size)])

Signed-off-by: Glenn Jocher 

@AyushExel 


## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Enhancements to image preprocessing in YOLOv5 with new transformation classes and modified dataloader behavior.

### üìä Key Changes
- üìù Introduced `LetterBox`, `CenterCrop`, and `ToTensor` custom preprocessing classes in `augmentations.py`.
- üëÅÔ∏è‚Äçüó®Ô∏è Modified the behavior of default transformations to use new custom classes instead of torchvision transforms.
- üîÑ Updated `dataloaders.py` to incorporate the new transformation classes and streamlined image color conversion when transforms are applied.
- üóÇÔ∏è Cache improvements for storing and retrieving processed images, reducing I/O operations and potentially speeding up training.

### üéØ Purpose & Impact
- üí° **Purpose**: To provide YOLOv5 with more flexible image preprocessing options, specifically tailored to the YOLO architecture, and improve performance through better caching mechanisms.
- üöÄ **Impact**: Expect increased efficiency in data loading, a potential boost in training speed, and easier customization of image preprocessing steps for YOLOv5 users.", # [utils] YOLOv5 image preprocessing
268,"F.2 corrected auto to void
Corrected an auto return type to void", # Fix #2000: Remove auto from print()
269,"[youku] Fix list extraction.(close #15065)
### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---", # [youku] Add missing entries
270,"Add support for Flickr
Sample videos:
- https://www.flickr.com/photos/brianpittman/22076440276/in/pool-timelapsevideos/
- https://www.flickr.com/photos/130585389@N04/21085642933/in/pool-timelapsevideos/



[](https://reviewable.io/reviews/soimort/you-get/697)


", # Add Flickr support
271,"Add IP Fast API to Development


- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not have more than 100 characters
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added IP Fast APIAdded IP Fast API
272,"PERF: Check identity first before comparing the objects
 - [ ] tests added / passed
- [ ] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them

This is a regeression in #41952. Checking the identity first avoids long comparison of e.g. tuples - checking the id first is also how `PyObject_RichCompareBool(a, b, Py_EQ)` works.

Here are results from asv:

```
       before           after         ratio
     [1ff6970c]       [b8285515]
-      11.0¬±0.1ms      7.09¬±0.06ms     0.64  algos.isin.IsInWithLongTupples.time_isin

SOME BENCHMARKS HAVE CHANGED SIGNIFICANTLY.
PERFORMANCE INCREASED.

```
", # [asv] Fix isin benchmarkFixes #1000.
273,"Gracefully handle user does not exist in Inference
Much less hacky hack than the one we had before, the inference log should also be much cleaner now.", # Fix 404 error when creating chat
274,"update deepspeed to run with the most recent triton 2.1.0
fixes to make deeepspeed to run with the most recent triton, [2.1.0](https://pypi.org/project/triton/2.1.0/)
Specifically, the changes are to reflect change in triton 2.1 that tl.libdevice and triton.testing.allclose are no longer available.", # Fix triton testsFixes #1000## Why are these changes needed?Fixes #1000## Related issue numberFixes #1000## Checks- [ ] I've run `format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed.- [ ] I've made sure the relevant tests are passing (if applicable).
275,"‚¨ÜÔ∏è Upgrade version of Starlette to `>= 0.36.3`
‚¨ÜÔ∏è Upgrade version of Starlette to `>= 0.36.3`", # bump starlette to 0.36.3
276,"Fix S3 S3_SKIP_SIGNATURE_VALIDATION
Due to changes in https://github.com/localstack/localstack/commit/3fe01cf6699a4fb71153b582715b4ec21560e4e1 `S3_SKIP_SIGNATURE_VALIDATION` flag is not working anymore, here is the proposed fix

**Please refer to the contribution guidelines in the README when submitting PRs.**
", # Fix S3 presign url validationFixes #1002
277,"[AIP-49] Completes the Breeze OTel integration and adds a banner to the UI 
Completes the Breeze OpenTelemetry integration and adds a banner to the UI indicating it is currently experimental.

(Final?) PR to add some groundwork to allow OTel support.  Follow-up to https://github.com/apache/airflow/pull/29521 

After getting a working working PoC, the Breeze integration needed a tweak to work correctly.  Changes have been tested against a working* proof-of-concept which can be found [here](https://github.com/ferruzzi/airflow/tree/ferruzzi/otel/poc) for now if anyone wants to try them out.

*So far only a subset of metrics are working in that POC, but the ones that ARE working are working end to end.

Major changes:
- Corrects the OpenTelemetry Collector port to 8889 instead of 8888
- Adds OTel values to the Airflow Config 
- Adds the required new Environment Variables tot he integration's docker-compose file to set those config values 
- If Otel is enabled, adds a banner to the UI showing that OTel support is currently experimental 
- Edits to scripts/ci/docker-compose/otel-collector-config.yml to get it working as expected and trim some fat

Minor Changes:
- Rephrasing some docs
- Cleans up some unnecessary port forwarding in the integration's docker-compose file
- Cleans up some extensions in the OTel collector config file that ended up being unnecessary",
278,"MAINT: Remove combineAdd and combineMult
Deprecated in 0.17.0.

xref #10735"," # [MRG] Remove combineAdd and combineMult methods- [x] closes #10735- [x] tests added / passed- [x] passes `black pandas`- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`- [x] whatsnew entry"
279,"Pass frameskip and repeat_action_probability to AtariEnv EzPickle
AtariEnv currently does not pass `frameskip` or `repeat_action_probability` to the EzPickle constructor. This leads to environments restored from pickle not being initialised correctly:

```
import gym, pickle
env = gym.make('PongNoFrameskip-v4')
print(env.unwrapped.frameskip)
```
```
1
```
```
env2 = pickle.loads(pickle.dumps(env))
print(env2.unwrapped.frameskip)
```
```
(2, 5)
```

This pull request fixes it.", # [gym] Add frameskip and repeat_action_probability to AtariEnv.__init__
280,"Skoda: add FW versions for Karoq 2021
route: 2c4292a5cd10536c|2022-07-24--09-44-25
", # Update VW Karoq info
281,"Update profile image on login
Fixes #2196 (not only for discord, but all providers)

Instead of doing the big mess of having to refresh images in the background, we update the images when the user signs in, from the profile we get from the provider.

This has the side effect that if you have 2 different images on 2 different login providers, your image will always change depending on the last provider you logged in with, but I think this is ok.

Also, consolidate all of the updates that are applied to the user to one database call.


",
282,"[MRG+1] Disable SpiderState extension if no JOBDIR set
", # [MRG] Fix spiderstate.py
283,"Add Blitapp


- [ ] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [ ] My addition is ordered alphabetically
- [ ] My submission has a useful description
- [ ] The description does not end with punctuation
- [ ] Each table column is padded with one space on either side
- [ ] I have searched the repository for any relevant issues or pull requests
- [ ] Any category I am creating has the minimum requirement of 3 items
- [ ] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add Blitapp APIAdded Blitapp API to the list of APIs.
284,"add lang filter option to message endpoints
# add lang filter option to message endpoints
Fixes issues #896

As descriped in the issues, I added a lang filter option to:
- `api/v1/messages`
- `api/v1/messages/cursor`
- `api/v1/users/{user-id}/messages`
- `api/v1/users/{user-id}/messages/cursor`

I saw that `query_messages_ordered_by_created_date()` is also used in `/api/v1/frontend_users/{auth_method}/{username}/messages` and ``/api/v1/frontend_users/{auth_method}/{username}/messages/cursor`. However, I did not add the lang filter to this endpoint since the issues did not specify this endpoint. So, I was unsure if this was desired or not. Let me know if you also want it there, it is an easy fix.", # Add lang filter to query messages
285,"Keep image extension for xkcd comics
It might be best to just keep the file extension, to prevent confusion. Especially on Windows where how the file is opened depends on the file extension. ", # Remove unnecessary slicing
286,"Fix: --sd_model in ""Prompts from file or textbox"" script is not working
## Description
Fixes bug #8079 
The Features page lists ""sd_model"" as a valid parameter for the ""Prompts from file or textbox"" script, but the implementation was never finished.
This patch enables the use of the ""sd_model"" parameter as originally intended.

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] All tests passed, but my code was not included in the [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
- [x] The code has been manually tested, both for valid and invalid input. No issues were observed.", # Add sd_model tag to prompts_from_file.py
287,"add discord reader
",
288,"Bypass shape inference in deconv2d and use the output shape provided by the user
Following the discussions in #3540 and #3824 this pull request removes the shape inference part of the `Deconv2d` layer and use the output shape provided by the user.

Because the user must specify an output shape and the shape inference introduced does not work in all cases, the code is more concise and works in cases where the user wants to introduce operations where a precise output shape is needed.

@yaringal is this reasonnable?
",
289,"fix #12492
", # [xlog] Fix #10064
290,"COMPAT: Support fastparquet 0.7.1
- [ ] closes #42588
- [ ] tests added / passed
- [ ] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them
- [ ] whatsnew entry

Also adds support for ``use_nullable_dtypes`` keyword. Technically, its not our enhancement its fastparquet's, so I think can backport. IMO, users shouldn't have to wait 6 months for 1.4 to get this new feature.
",
291,"Fix issue #3766.
‰πãÂâçÁöÑ‰∏§‰∏™Ê£ÄÊµãIPv6ÁöÑÁΩëÂùÄÊó†Ê≥ïÊ≠£Â∏∏ÊâìÂºÄÔºåÈÅÇÊõøÊç¢‰∏∫Ôºö

- ÂÖ≠Áª¥Á©∫Èó¥: `bt.neu6.edu.cn`
- DragonLabÂÆûÈ™åÂÆ§: `www.cernet2.net`

ÊõøÊç¢ÁöÑÁΩëÂùÄÊª°Ë∂≥Êù°‰ª∂: DNSËß£ÊûêÂêé‰ªÖËøîÂõûIPv6Âú∞ÂùÄ.", # Update check_local_network.py
292,"chore: update aifs
### Describe the changes you have made:

aifs APIs had changes and added capabilities, so bumping to latest: `poetry add aifs@latest`

### Reference any relevant issues (e.g. ""Fixes #000""):

### Pre-Submission Checklist (optional but appreciated):

- [ ] I have included relevant documentation updates (stored in /docs)
- [x] I have read `docs/CONTRIBUTING.md`
- [x] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [x] Tested on MacOS
- [ ] Tested on Linux
", # aifs: bump to 0.0.7
293,"[CI/cleanup/restrict_strip_Marks] 

Boilerplate: own code/#36238, bug fix/improvement
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/) except for code from PR #32638 for which this or the below was already asserted 
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature



---

### Description of your *pull request* and other information

1. Resubmit youtube consent fix with better log message
2. Ensure _apt_ is updated for Ubuntu runners
3. Fix CI not selecting correct default settings for `push` and `pull_request` events
4. Add 3.12 to standard CPythons and generalise pre-release build steps for a future beta (3.next)
5. Improve filename handling for `--restrict-filenames`: ignore any character in Unicode categories Mark and Other instead of mapping it to `_`.", # [ci] Add support for Python 3.next### Describe your changes:Add support for Python 3.next### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) and [Contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)- [x] This pull request is all my own work -- I have not plagiarized.- [x] I know that pull requests will not be merged if they fail the automated tests.- [x] This PR only changes one file.  All changes must be made in that one file.- [x] All new Python files are placed inside an existing directory.- [x] All filenames are in all lowercase characters with no spaces or dashes.- [x] All functions and variable names follow Python naming conventions.- [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).- [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.- [x] All new algorithms or data structures are [stored in a separate file](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions).- [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
294,"Fixes #31441 -- Fixed admin TabularInline problems
Fixes the first two issues of [Ticket 31441](https://code.djangoproject.com/ticket/31441#comment:3).",
295,"Update README.md
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x ] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x ] Your additions are ordered alphabetically
- [ x] Your submission has a useful description
- [ x] The description does not end with punctuation
- [ x] Each table column should be padded with one space on either side
- [x ] You have searched the repository for any relevant issues or pull requests
- [x ] Any category you are creating has the minimum requirement of 3 items
- [x ] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added Financial Modeling PrepAdded Financial Modeling Prep to the list of APIs.
296,"session_data.get_url -> server_util.get_url
`session_data.py` contains a function, `get_url()`, that has nothing to do with the SessionData class. This PR moves it to `server_util.py`.", # Fix session_data.pyFixes #1000
297,"Format azure_rm_snapshot document
##### SUMMARY

Format azure_rm_snapshot document.


##### ISSUE TYPE

- Docs Pull Request

##### COMPONENT NAME

azure_rm_snapshot
##### ADDITIONAL INFORMATION




```paste below

```
", # Update azure_rm_snapshot.py
298,"[chatgpt] fix lora save bug
## üìå Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [ ] I have added relevant tags if possible for us to better distinguish different PRs


## üö® Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`



## üìù What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.
fix the bug that we do not merge lora weight before save ckpt;
fix the bug that lora_eval has conflict with gemini 


## üí• Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?

- [ ] üåù Yes, I do.
- [ ] üåö No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
"," # [ChatGPT] Remove LoraLinear from DDP## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`- [ ] I have added relevant tags if possible for us to better distinguish different PRs## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?- [ ] üåù Yes, I do.- [ ] üåö No, I don't.Tell us more if you don't enjoy contributing to Colossal-AI."
299,"Bump the github-actions group with 2 updates
Bumps the github-actions group with 2 updates: [install-pinned/ruff](https://github.com/install-pinned/ruff) and [actions/cache](https://github.com/actions/cache).

Updates `install-pinned/ruff` from 4ec70113ad8b512f13948b8d9855ac59675535d2 to fe472defb50a6a2c00ea3a3982534e86e69991e8

Commits

fe472de update README.md (ruff 0.1.15)
cf75457 update pins (ruff 0.1.15)
a5367ea update README.md (ruff 0.1.14)
38ee0f4 update pins (ruff 0.1.14)
a8e213b update README.md (ruff 0.1.13)
21180b3 update pins (ruff 0.1.13)
58b3f74 update README.md (ruff 0.1.12)
4234903 update pins (ruff 0.1.12)
8c12fc8 update README.md (ruff 0.1.11)
dbde053 update pins (ruff 0.1.11)
See full diff in compare view




Updates `actions/cache` from 3 to 4

Release notes
Sourced from actions/cache's releases.

v4.0.0
What's Changed

Update action to node20 by @‚Äãtakost in actions/cache#1284
feat: save-always flag by @‚Äãto-s in actions/cache#1242

New Contributors

@‚Äãtakost made their first contribution in actions/cache#1284
@‚Äãto-s made their first contribution in actions/cache#1242

Full Changelog: https://github.com/actions/cache/compare/v3...v4.0.0
v3.3.3
What's Changed

Cache v3.3.3 by @‚Äãrobherley in actions/cache#1302

New Contributors

@‚Äãrobherley made their first contribution in actions/cache#1302

Full Changelog: https://github.com/actions/cache/compare/v3...v3.3.3
v3.3.2
What's Changed

Fixed readme with new segment timeout values by @‚Äãkotewar in actions/cache#1133
Readme fixes by @‚Äãkotewar in actions/cache#1134
Updated description of the lookup-only input for main action by @‚Äãkotewar in actions/cache#1130
Change two new actions mention as quoted text by @‚Äãbishal-pdMSFT in actions/cache#1131
Update Cross-OS Caching tips by @‚Äãpdotl in actions/cache#1122
Bazel example (Take #2Ô∏è‚É£) by @‚Äãvorburger in actions/cache#1132
Remove actions to add new PRs and issues to a project board by @‚Äãjorendorff in actions/cache#1187
Consume latest toolkit and fix dangling promise bug by @‚Äãchkimes in actions/cache#1217
Bump action version to 3.3.2 by @‚Äãbethanyj28 in actions/cache#1236

New Contributors

@‚Äãvorburger made their first contribution in actions/cache#1132
@‚Äãjorendorff made their first contribution in actions/cache#1187
@‚Äãchkimes made their first contribution in actions/cache#1217
@‚Äãbethanyj28 made their first contribution in actions/cache#1236

Full Changelog: https://github.com/actions/cache/compare/v3...v3.3.2
v3.3.1
What's Changed

Reduced download segment size to 128 MB and timeout to 10 minutes by @‚Äãkotewar in actions/cache#1129

Full Changelog: https://github.com/actions/cache/compare/v3...v3.3.1
v3.3.0
What's Changed

Bug: Permission is missing in cache delete example by @‚Äãkotokaze in actions/cache#1123



... (truncated)


Changelog
Sourced from actions/cache's changelog.

Releases
3.0.0

Updated minimum runner version support from node 12 -&gt; node 16

3.0.1

Added support for caching from GHES 3.5.
Fixed download issue for files &gt; 2GB during restore.

3.0.2

Added support for dynamic cache size cap on GHES.

3.0.3

Fixed avoiding empty cache save when no files are available for caching. (issue)

3.0.4

Fixed tar creation error while trying to create tar with path as ~/ home folder on ubuntu-latest. (issue)

3.0.5

Removed error handling by consuming actions/cache 3.0 toolkit, Now cache server error handling will be done by toolkit. (PR)

3.0.6

Fixed #809 - zstd -d: no such file or directory error
Fixed #833 - cache doesn't work with github workspace directory

3.0.7

Fixed #810 - download stuck issue. A new timeout is introduced in the download process to abort the download if it gets stuck and doesn't finish within an hour.

3.0.8

Fix zstd not working for windows on gnu tar in issues #888 and #891.
Allowing users to provide a custom timeout as input for aborting download of a cache segment using an environment variable SEGMENT_DOWNLOAD_TIMEOUT_MINS. Default is 60 minutes.

3.0.9

Enhanced the warning message for cache unavailablity in case of GHES.

3.0.10

Fix a bug with sorting inputs.
Update definition for restore-keys in README.md



... (truncated)


Commits

13aacd8 Merge pull request #1242 from to-s/main
53b35c5 Merge branch 'main' into main
65b8989 Merge pull request #1284 from takost/update-to-node-20
d0be34d Fix dist
66cf064 Merge branch 'main' into update-to-node-20
1326563 Merge branch 'main' into main
e718767 Fix format
0122982 Apply workaround for earlyExit
3185ecf Update &quot;only-&quot; actions to node20
25618a0 Bump version
Additional commits viewable in compare view





Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore  major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)
- `@dependabot ignore  minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)
- `@dependabot ignore ` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)
- `@dependabot unignore ` will remove all of the ignore conditions of the specified dependency
- `@dependabot unignore  ` will remove the ignore condition of the specified dependency and ignore conditions


", # Update workflows to use latest versions of actions
300,"add workflow to execute unit tests
", # Add Pytest ActionAdds a GitHub Actions workflow for running tests with pytest.
301,"üåê Add Chinese translation for Tutorial - Security - OAuth2 with Password (and hashing), Bearer with JWT tokens
@maoyibo @yanever @RunningIkkyu Please take a look.",
302,"Adding Tellonym.me
Fully tested and working", # Add Tellonym.meAdd Tellonym.me to the list of supported services.
303,"[CGTN] Add new extractor
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Explanation of your *pull request* in arbitrary form goes here. Please make sure the description explains the purpose and effect of your *pull request* and is worded well enough to be understood. Provide as much context and examples as possible.
", # [cgtn] Add extractor
304,"[parallelism docs] Megatron-Deepspeed info
This PR adds:
- BigScience fork of Megatron-Deepspeed
- Super important paper on Megatron-Deepspeed

@sgugger ", # Update docs/source/parallelism.mdx
305,"Update install readme


<!--- ***** Template: Car bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

**Route**
Route: [a route with the bug fix]

-->

<!--- ***** Template: Bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

-->

<!--- ***** Template: Car port *****

**Checklist**
- [ ] added to README
- [ ] test route added to [test_routes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/test/test_routes.py)
- [ ] route with openpilot:
- [ ] route with stock system:

-->

<!--- ***** Template: Refactor *****

**Description** [](A description of the refactor, including the goals it accomplishes.)

**Verification** [](Explain how you tested the refactor for regressions.)

-->
", # Update README.md
306,"Remove ancient .gitignores
I found these files while working on other stuff. `certbot/.gitignore` comes from [a commit from 2012](https://github.com/certbot/certbot/commit/d18c7f6eee94b1d5288140e22166a740bd9514cd) and there are no `.crt` files under `certbot/`. `certbot-dns-route53/.gitignore` comes from https://github.com/certbot/certbot/pull/4692 when we took over this plugin and it was also not ignoring any files.", # Remove unused files
307,"Add new option to generate subtitles by a specific number of words
*Updated according jonwook code review

Added a new word option called **--max_words_per_line** that will generate subtitles setting a maximum limit of words per segment. This could sound similar to **--max_line_width** option, but the results are more pleasent for readers IMHO. Here a couple of comparisons using .SRT files:

![max_word_per_line](https://github.com/openai/whisper/assets/8297398/3ccd320f-8a4d-4502-ba05-4553125d0f71)
Notice that **--max_words_per_line** works as an upper bound of words, but still it will respect the segments in the way that end of sentences can have less words if the remaining number of words in a segment is lower than the **max_words_per_line** value.
i.e. _Segment = [word1, word2, word3, word4, word5] and max_words_per_line = 3
=>Result = [word1, word2, word3] and [word4, word5]_
This is not the behaviour we can see using **--max_line_width** that can leave bigger gaps of time when joining end and beginning of segments:

![comparison](https://github.com/openai/whisper/assets/8297398/bdd209c0-42bd-4dda-b136-487cde31b76e)

Subtitles generated with **--max_words_per_line** look similar of what we can see in Shorts, Reels and other short duration videos.

This is my first contribution, so feel free of changing/comment/improve anything.

### Additional notes

- The use  of **--max_line_width** will disable the effects of **--max_words_per_line**.
- Manually tested using Python and cli and checked results in .srt and .vtt files (.txt. and .tsv files won't be affected).
",
308,"CP.44 improve example and add more accurate discussion
", # Fix #10064
309,"Up version to 1.20.0
", # [MRG+1] Fix #10069Fixes #10069.
310,"BUG: Fix aligning a DataFrame with a Series with MultiIndex #46001
When aligning a DataFrame to a Series we are using Series.reindex() to
broadcast the Series data to the new index.  That introduces NaNs when the new
index rows are not identical to the existing ones, which is not the case when
we introduce a new MultiIndex level.

In this patch we use the same approach as for aligning a Series to another
Series. That means that we have to replicate a part of Series._reindex_indexer
as DataFrame does not have it.

- [x] closes #46001 
  and #43321
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added an entry in the latest `doc/source/whatsnew/v1.5.0.rst`.
",
311,"Add validation for header name
Following up on #6083, this refactors our header validation function from 2.11.0 to consider the header name. We'd originally avoided adding header name validation because we wanted to limit the change scope to header splitting with new lines. Since then the standard library has made similar changes to ours and now raises a ValueError in `http.client`. This gives us inconsistent errors depending on which portion of the header you provide a bad value.

```python
>>> requests.get(""https://httpbin.org/get"", headers={"":bad"": ""header""})
Traceback (most recent call last):
  File """", line 1, in 
  File ""/Users/nateprewitt/Work/OpenSource/requests/requests/api.py"", line 73, in get
    return request(""get"", url, params=params, **kwargs)
  File ""/Users/nateprewitt/Work/OpenSource/requests/requests/api.py"", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File ""/Users/nateprewitt/Work/OpenSource/requests/requests/sessions.py"", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File ""/Users/nateprewitt/Work/OpenSource/requests/requests/sessions.py"", line 701, in send
    r = adapter.send(request, **kwargs)
  File ""/Users/nateprewitt/Work/OpenSource/requests/requests/adapters.py"", line 489, in send
    resp = conn.urlopen(
  File ""/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connectionpool.py"", line 727, in urlopen
    httplib_response = self._make_request(
  File ""/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connectionpool.py"", line 433, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connection.py"", line 309, in request
    super().request(method, url, body=body, headers=headers)
  File ""/Users/nateprewitt/.pyenv/versions/3.10.4/lib/python3.10/http/client.py"", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/Users/nateprewitt/.pyenv/versions/3.10.4/lib/python3.10/http/client.py"", line 1323, in _send_request
    self.putheader(hdr, value)
  File ""/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connection.py"", line 274, in putheader
    super().putheader(header, *values)
  File ""/Users/nateprewitt/.pyenv/versions/3.10.4/lib/python3.10/http/client.py"", line 1250, in putheader
    raise ValueError('Invalid header name %r' % (header,))
ValueError: Invalid header name b':bad'
```

This PR ports the [validation scheme](https://github.com/python/cpython/blob/6b9122483f1f26afb0c41bd676f9754ffe726e18/Lib/http/client.py#L139) from http.client for header names and ensures we raise an `InvalidHeader` error consistently in all supported versions."," # Validate header partsThis PR validates header parts before sending them. This is a small change, but it will help prevent some of the more common header errors."
312,"Restructure for text parsing. Faster, more stable, more maintainable
#187 ",
313,"fix sqs message group visibility when sending messages



## Motivation

Even after the initial implementation of FIFO message groups in #8238, users have reported odd behavior when using SQS FIFO queues related to message group visibility specifically that consumers are triggered although the message group is expected to be invisible #8724. This also affected lambdas triggered with fifo queues #7036.

This PR fixes the mechanism we were using to reset message group visibility, which was too general. It assumed that every message put into the message group reset its visibility, when really it should just be messages that were previously invisible, not new ones.


## Changes

* message group visibility is no longer reset when new messages are sent to the queue

Fixes
* #8724
* #7036 (tested with #7037)

<!-- The following sections are optional, but can be useful! 

## Testing

Description of how to test the changes

## TODO

What's left to do:

- [ ] ...
- [ ] ...

-->

"," # [sqs] Fix visibility of message groups when a message becomes visible againFixes #4287## Why are these changes needed?## Related issue number## Checks- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.- [ ] I've run `scripts/format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed for https://docs.github.com/en/github/writing-on-github/about-code-documentation- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.herokuapp.com/- Testing Strategy   - [ ] Unit tests   - [ ] Release tests   - [ ] This PR is not tested :("
314,"bpo-33944: note about the intended use of code in .pth files



https://bugs.python.org/issue33944



Automerge-Triggered-By: @matrixise",
315,"TST: nose.SkipTest on RemoteDataErrors in tests for io.data.Options
Prevents tests from failing if data isn't able to be downloaded from Yahoo Finance.
", # [MRG] Fix tests for get_options_dataFixes #7034
316,"pencil2: Fix awkward pronoun usage
", # Fix typo in docs
317,"bpo-35059: Enhance _PyObject_AssertFailed()
_PyObject_AssertFailed():

* exchange expr and msg arguments
* expr and func arguments can now be NULL


https://bugs.python.org/issue35059

", # Fix PyObject_AssertFailed()Fixes #20022.
318,"Restructure for text parsing. Faster, more stable, more maintainable
#187 ",
319,"Future proof octal number: 0755 --> 0o755
", # Fix #10064
320,"Bisenet-FP - Improved weights for masker
The following pull-request allows for the use of custom trained weights for the Bisenet-FP Mask.

The dataset of 40k faces has been built from a wide variety of posed and in the wild images. These have been manually annotated over several months to handle:
- many varieties of real obstructions
- difficult/varied conditions + poses
- glasses (mask out frames, keep lenses)
- dark sunglasses (mask out frames + lenses)
- multiple targets within a single extracted image.

This dataset will continue to be grown over time and will be used to create new and more improved maskers. Whilst this solution is by no means perfect, it is vastly improved over any existing masking solutions.

NB: This Pull Request does not include the actual weights file. This will be going to Patreons first for a timed exclusive, but the weights will eventually be made available for use in the main code.

### Glasses + Sunglasses:
![gls](https://user-images.githubusercontent.com/36920800/160387537-1ce15fda-4da8-41c8-9d74-57249b756d4c.gif)

### Ignoring the non-target face: 
![fac](https://user-images.githubusercontent.com/36920800/160387642-6bdd4caa-c7bb-4f4d-860a-8d987498830a.gif)

### Multiple obstruction types:
![obs](https://user-images.githubusercontent.com/36920800/160387649-0ad78edb-4dc0-42c2-b455-68ee8a5322a3.gif)

", # Update BiSeNet Mask to use faceswap weights
321,"use asf gateway as default
Disables the edge proxy by default in favor of #5243 ", # Fix typo in config.py
322,"Mark config schema as removed in Verisure
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->

The Verisure configuration schema is not deprecated, it is actually removed.
This adjusts the marker for it.

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [x] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [x] No score or internal
- [ ] ü•à Silver
- [ ] ü•á Gold
- [ ] üèÜ Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [x] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
", # Remove deprecated verisure componentRemoved the deprecated verisure component.
323,"ReplicaSets Information
Kubernetes ReplicaSets", # Add some explanations to README.md
324,"Fix MPD BaseURL handling when root-relative URL
### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [X] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Hi,

I have come across an MPD manifest that includes a BaseURL attribute set to a root-relative URL. For example:
```
/x/y/
```

The current processing of BaseURL assumes the URL is either absolute (e.g. http://example.com/x/y/z) or relative (x/y/z). Root-relative URLs end up generating an incorrect fragment_base_url, failing to download content.", # [extractor] Fix mpd base url
325,"revert instructor code and fix a bug in anthropic ds parsing
", # Fix AnthropicRLHF dataset
326,"PEP8
",
327,"[Core] Fix test_logging_to_driver


## Why are these changes needed?

Fixes test_logging_to_driver

## Related issue number



## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/latest/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failure rates at https://ray-travis-tracker.herokuapp.com/.
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested (please justify below)
", # [MRG] Remove duplicate logging tests
328,"[Gemini] hotfix the unittest bugs
We have to use the original logic to search the chunk size. Otherwise, the unittest will hang.", # [gemini] fix memory tracer
329,"Add runtime requirements
Simply copies `kornia`, `streamlit-drawable-canvas`, and `invisible-watermark` from the conda-style `environment.yaml` to the pip-style `requirements.txt`.

Tested with the following:

```
    git clone https://github.com/Stability-AI/stablediffusion/
    cd stablediffusion
    python -m venv venv
    source venv/bin/activate
    pip install -U pip
    pip install -r requirements.txt
    python scripts/txt2img.py --prompt ""our galaxy itself contains a hundred billion stars"" --ckpt ../768-v-ema.ckpt --config configs/stable-diffusion/v2-inference-v.yaml --H 768 --W 768  --n_samples 1
```
on Ubuntu 22 with Python 3.8, or similar, on a machine with CUDA already installed.
"," # Add kornia, invisible-watermark, and streamlit-drawable-canvasAdd kornia, invisible-watermark, and streamlit-drawable-canvas to requirements.txt."
330,"Backport PR #43166 on branch 1.3.x (Pin aiobotocore to get ci passing)
Backport PR #43166: Pin aiobotocore to get ci passing", # Remove aiobotocore dependency from dev requirementsThis PR removes the aiobotocore dependency from the dev requirements. This is because s3fs is already using aiobotocore internally.
331,"Detect downstream deps in tests
This is meant to detect issues such as #919. It makes sure we run tests without any downstream dependencies installed, e.g. `letsencrypt_apache` is not installed when `letsencrypt` is being tested.

It also improves verbosity of the tests, so it's a lot easier to detect problems (especially busy waiting loops) when investigating Travis build logs output.
"," # [tox] Add verbose output for nosetests### Describe your change:Add verbose output for nosetests. This is useful for detecting busy waiting, especially on Travis.### Reference any relevant issues (e.g. ""Fixes #000""):### Pre-Submission Checklist (optional but appreciated):- [ ] I have included relevant documentation updates (stored in /docs)- [ ] I have read `docs/CONTRIBUTING.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/ROADMAP.rst`- [ ] I have read `docs/CHANGELOG.md`- [ ] I have read `docs/COPYRIGHT.md`"
332,"Fixed error handling in train.py
Fixed the error handling in train.py so it doesn't swallow tracelogs.

This is an improvement to follow Python best practices of raising any exceptions that aren't handled so that tracelogs don't get lost.", # raise exception instead of print
333,"Added `--nsfw` flag in documentation
Added `--nsfw` tag in `Usage` prompt with the description matching the `help` prompt of the parser's --nsfw flag", # Add --nsfw flag
334,"Fix `pretty` cyclic reference handling
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Previously cyclic references were only handled for container and dataclass types, but not namedtuple, attrs, or custom types. This fixes that, and expands the tests to cover these cases.
",
335,"Added certbot-dns-rfc2136 to list of changed modules in CHANGELOG
Added certbot-dns-rfc2136 to list of changed modules in CHANGELOG
", # Update changelog
336,"[NFC] update news link
", # Update README.md
337,"Added Wayfair to the list of companies using Apache Airflow
Added Wayfair to INTHEWILD.md
", # Added Wayfair
338,"Add webview docs and examples, Set webview as default
",
339,"[core] Deflake test_object_manager::test_object_transfer_during_oom




## Why are these changes needed?

This flaky test checks that it isn't possible to store more objects than the available object store memory, but it looks like it may have been written before object spilling was enabled. Now with spilling and fallback to object allocation on disk, the test should be modified.

## Related issue number

Closes #40446.

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
    - [ ] I've added any new APIs to the API Reference. For example, if I added a 
           method in Tune, I've added it in `doc/source/tune/api/` under the 
           corresponding `.rst` file.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
", # [core] Remove test_object_managerThis test is flaky and not useful.
340,"TST: Added test to check that the freqstr attribute of the index is p‚Ä¶
‚Ä¶reserved after a shift operation. Run black and flake8.

- [x] closes #21275
- [x] tests added / passed
- [x] passes `black pandas`
- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [x] whatsnew entry (omitted, test only)
", # [MRG] Add test for shift with freqstr
341,"Fix code typos for C.145
Also added the ""extends B"" to D
", # [MRG] Fix example for virtual functions
342,"[openload] Fix extraction.
### Before submitting a _pull request_ make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)
### What is the purpose of your _pull request_?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

They changed ""decryption"" code a little. Here is current one. 

``` js
var y = $(""#yJ7n4OuuU7"").text();
var magic = y.slice(-1).charCodeAt(0);
y = y.split(String.fromCharCode(magic - 1)).join(""  "");
y = y.split(y.slice(-1)).join(String.fromCharCode(magic - 1));
y = y.split(""   "").join(String.fromCharCode(magic));
var s = [];
for (var i = 0; i < y.length; i++) {
  var j = y.charCodeAt(i);
  if ((j >= 33) && (j <= 126)) {
    s[i] = String.fromCharCode(33 + ((j + 14) % 94));
  } else {
    s[i] = String.fromCharCode(j);
  }
}
var tmp = s.join("""");
var str = tmp.substring(0, tmp.length - 1) + String.fromCharCode(tmp.slice(-1).charCodeAt(0) + 2);
```

They've added (funny code if you ask me) 

``` js
var magic = y.slice(-1).charCodeAt(0);
y = y.split(String.fromCharCode(magic - 1)).join(""  "");
y = y.split(y.slice(-1)).join(String.fromCharCode(magic - 1));
y = y.split(""   "").join(String.fromCharCode(magic));
```

I wonder what they are trying to achieve by doing such stupid obfuscation. 

I adopted those changes, let's see how long it will be working this time :)

Fixes #10408
", # [openload] Fix encrypted dataFixes #10064
343,"Add LEXUS_ESH_TSS2 to improved longitudinal tune
2021 Lexus ES 300h.  Tested improved longitudinal tune parameters on master-ci for better following, stopping and resuming behind lead vehicles.

Route:  3a5c5101bd71ad5d|2021-05-24--15-05-04

Examples around timestamps 15:06:45 and 15:14:00", # Toyota: Add LEXUS_ESH_TSS2
344,"fix path to script with nginx prerequisites
The path is copied from `.. include` directive below.
", # Update docs/contributing.rst
345,"Single quotes are messing with the command.
", # Fix SQLite Injection
346,"Fix typo: unoffical -> unofficial
", # Fix typo in README.md
347,"fix some typo
att", # fix #1000
348,"eos_interfaces: Added unit testcases for eos_interfaces
##### SUMMARY
Added unit testcases for the resource module eos_interfaces


##### ISSUE TYPE

- Feature Pull Request

##### COMPONENT NAME
/home/gosriniv/ansible/test/units/modules/network/eos/test_eos_interfaces.py



",
349,"Set lora target modules via command line arguments
Now it possible to set the modules directly from the command line

for example
`--lora_target_modules ""q_proj"", ""k_proj"", ""v_proj"", ""down_proj"", ""gate_proj"", ""up_proj""`", # fix lora_target_modules
350,"Update reference to SF.7 to match text
Looks like the rule was changed in 768e4620 and most references were updated but this one was missed. Since the meaning is quite different I've updated this text to match the rule.

Note #1667 in its current form does correctly update this text so supersedes this change when merged.", # Fix typo in C++ Core Guidelines
351,"Implement simplified Box representation
This pull request aims to simplify the string representation of Box spaces. 
If the lower (or analogously upper) limit is a multiple of the all-ones vector, we only print the multiplicand, instead of the entire vector. This was discussed in issue #2497.

The method `_short_repr` will return a possibly shortened string representation of an array, as outlined above. I will add a short comment to the method later.

Best,
Markus", # [gym] Add short representation of box spaceAdds a short representation of the box space. This is useful for debugging and logging.
352,"HTTPAdapter.send() timeout defaults
This PR allows to use urllib3 ``Timeout`` objects as ``timeout`` argument in ``HTTPAdapter.send()``.

Besides it omits the ``timeout`` argument when calling ``conn.urlopen()`` if ``HTTPAdapter.send()`` is called without a timeout. This allows setting a default timeout at connection pool level:
`adapter.poolmanager.connection_pool_kw['timeout'] = urllib3.Timeout(...)`", # [MRG+1] Add support for TimeoutSauce objects
353,"Add myself to CONTRIBUTORS.md
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [x] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [ ] I've run the latest [black](https://github.com/ambv/black) with default args on new code.
- [X] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [X] I accept that @willmcgugan may be pedantic in the code review.

## Description

Ref to: [this](https://github.com/willmcgugan/rich/pull/207#issuecomment-674491635)

I have put it in alphabetical order by surname as you requested in the file, even though I think putting the owner at the top should make more sense", # Add Hedy LiAdded Hedy Li to the contributors list.
354,"Model card: T5-base fine-tuned on QuaRTz
# What does this PR do?

<!--
Congratulations! You've made it this far! You're not quite done yet though.

Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.

Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.

Once you're done, someone will review your PR shortly (see the section ""Who can review?"" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.
-->



Fixes # (issue)


## Before submitting
- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to the it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors which may be interested in your PR.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

 albert, bert, XLM: @LysandreJik
 GPT2: @LysandreJik, @patrickvonplaten
 tokenizers: @mfuntowicz
 Trainer: @sgugger
 Benchmarks: @patrickvonplaten
 Model Cards: @julien-c
 Translation: @sshleifer
 Summarization: @sshleifer
 examples/distillation: @VictorSanh
 nlp datasets: [different repo](https://github.com/huggingface/nlp)
 rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)
 Text Generation: @patrickvonplaten, @TevenLeScao
 Blenderbot, Bart, Marian, Pegasus: @sshleifer
 T5: @patrickvonplaten
 Rag: @patrickvonplaten, @lhoestq
 EncoderDecoder: @patrickvonplaten
 Longformer, Reformer: @patrickvonplaten
 TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten
 examples/seq2seq: @sshleifer
 examples/bert-loses-patience: @JetRunner
 tensorflow: @jplu
 examples/token-classification: @stefan-it
 documentation: @sgugger
 FSTM: @stas00
 -->
", # Add T5-base fine-tuned on QuaRTz### SummaryAdd T5-base fine-tuned on QuaRTz### DescriptionAdd T5-base fine-tuned on QuaRTz### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).- [x] This pull request is all my own work -- I have not plagiarized.- [x] I know that pull requests will not be merged if they fail the automated tests.- [x] This PR only changes one file.  All changes should be made in that one file.- [x] All new Python files are placed inside an existing directory.- [x] All filenames are in all lowercase characters with no spaces or dashes.- [x] All functions and variable names follow Python naming conventions.- [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).- [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.- [x] All new or modified algorithms include at least one URL that points to Wikipedia or another similar explanation.- [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
355,"Match the HTTPbis on HTTP 301.
See the discussion on issue #1704.
", # Fix redirect handlingFixes #1704.
356,"fixbug: role init with is_human=True was not work
bugfix:  role init with is_human=True was not work", # Add HumanProvider to Role
357,"Fix #6628 - JSONDecodeError are not deserializable
See issue #6628 for full bug-report

-----

requests.exceptions.JSONDecodeError are not deserializable: calling `pickle.dumps` followed by `pickle.loads` will trigger an error.

This is particularly a problem in a process pool, as an attempt to decode json on an invalid json document will result in the entire process pool crashing.

This is due to the MRO of the `requests.exceptions.JSONDecodeError` class: the `__reduce__` method called when pickling an instance is not the one from the JSON library parent: two out of three args expected for instantiation will be dropped, and the instance can't be deserialised.

By specifying in the class which parent `__reduce__` method should be called, the bug is fixed as all args are carried over in the resulting pickled bytes.", # Fix pickling of JSONDecodeError#10000### Describe your change:Fix pickling of JSONDecodeError### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/kennethreitz/requests/blob/master/CONTRIBUTING.md#developer-instructions) and accepted the [Contributor License Agreement](https://github.com/kennethreitz/requests/blob/master/CONTRIBUTING.md#before-creating-the-pull-request) - [x] This pull request is all my own work -- I have not plagiarized.- [x] I know that pull requests will not be merged if they fail the automated tests.- [x] This PR only changes one thing. Please open separate PRs for separate changes.- [x] All new Python files are placed inside an existing directory.- [x] All filenames are in all lowercase characters with no spaces or dashes.- [x] All functions and variable names follow Python naming conventions.- [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).- [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.- [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.- [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
358,"langchain-community: Dappier chat model integration
**Description:** 

This PR adds [Dappier](https://dappier.com/) for the chat model. It supports generate, async generate, and batch functionalities. We added unit and integration tests as well as a notebook with more details about our chat model.


**Dependencies:** 
    No extra dependencies are needed.",
359,"Adds shrug to the category ""Japanese Emoticons""
¬Ø\\\_(„ÉÑ)_/¬Ø this guy", # Add emoji
360,"Adds wemake-python-styleguide
`wemake-python-styleguide` is the strictest python linter out there.
It was partially inspired by this project. And we have implemented almost rules as automatic checks from the examples. References: https://github.com/wemake-services/wemake-python-styleguide/search?q=wtfpython&type=Issues

It is a `flake8` plugin with some extra goodies, it can be used as `flake8 .` or like so:
![Github Action](https://raw.githubusercontent.com/wemake-services/wemake-python-styleguide/master/docs/_static/reviewdog.png)

Link: https://github.com/wemake-services/wemake-python-styleguide
Docs: https://wemake-python-stylegui.de/en/latest/", # Add wemake-python-styleguideAdd wemake-python-styleguide to the list of resources.
361,"üåê Add Japanese translation for Tutorial - Cookie Parameters
This PR translates the tutorial/cookie-params.md to Japanese.
Please review tutorial/cookie-params.md.

~~Issue #1571 generates a new directory to support Japanese.
PR #1656 generates a new directory for tutorial.
I will fix dependency after #1571 & #1656 are merged.~~", # „Éâ„Ç≠„É•„É°„É≥„Éà„Å´Cookie„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíËøΩÂä†Cookie„ÅÆ„Éë„É©„É°„Éº„Çø„Çí„Éâ„Ç≠„É•„É°„É≥„Éà„Å´ËøΩÂä†„Åó„Åæ„Åó„Åü„ÄÇ
362,"Add teddy-bear class back to first 1000 classes of imagenet22k_ms_synsets (line 851, index 850)
Working on fix for #2140 

Need to investigate further.... look at 12k & 22k map files too.", # Add n04399382Add n04399382
363,"turn 2 prints to py2/py3 compatible syntax
as my very modest contribution towards python3
", # Flask tester: fix print formatting
364,"Update utils/datasets.py to support .webp files
Simply added 'webp' as an image format to the img_formats array so that webp image files can be used as training data.

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Support for WEBP image format added to YOLOv5.

### üìä Key Changes
- The list of acceptable image formats/suffixes now includes 'webp'.

### üéØ Purpose & Impact
- **Purpose**: To allow YOLOv5 to utilize WEBP images, which are popular due to their efficient compression.
- **Impact**: Users can now train YOLOv5 models with '.webp' images, potentially reducing disk usage and improving load times. üöÄ", # Add webp to img_formatsAdd webp to img_formats
365,"Added HAR generation as inline script
As promised yesterday, this one goes open source ;)
",
366,"Don't block users with the warning thread.
Resolves #1349 "," # Fix blocking warning thread on some use cases### Describe your change:Fixes #1349### Checklist:- [x] I have read [contributing wiki page](https://github.com/httpie/httpie/wiki/Contributing)- [x] This pull request is all my own work -- I have not plagiarized- [x] I know that pull requests will not be merged if they fail the automated tests- [x] This PR only changes one file, and only adds documentation comments above new API functions/variables/enums- [x] All new Python files are placed inside an existing directory- [x] All filenames are in all lowercase characters with no spaces or dashes- [x] All functions/methods are separated by a blank line- [x] All function parameters and return values are *italicized*- [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html)- [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing- [x] All new algorithms or complex logic are accompanied by a UML diagram- [x] All UML diagrams are placed inside an existing directory- [x] All UML diagrams are named in all lowercase characters with no spaces or dashes- [x] All UML diagrams are placed at the end of the PR and include a table of contents- [x] All UML diagrams are formatted per the [PEP 8 guidelines](https://www.python.org/dev/peps/pep-0008/#imports)- [x] All imports are placed at the top of the file they are used in- [x] All imports are grouped together and alphabetically ordered- [x] All imports from the standard library are made into an alias- [x] All imports from third-party packages are placed in their own folder- [x] All third-party imports have [version annotations](https://github.com/python/typeshed/blob/master/LICENSE.txt)- [x] All third-party imports have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing- [x] All dependencies have a URL in its description in `requirements.txt` that points to the latest commit in the repository- [x] New dependencies are added to `requirements.txt` only after the code has been tested and passed [pre-commit checks](https://pre-commit.com/).- [x] All changes have been [squashed][squash-link] into a single commit[squash-link]: "
367,"Array Equilibrium-Index
", # Python-Array-Equilibrium-Index
368,"Correct some type annotations
<!--
Before contributing (PLEASE READ!)

‚ö†Ô∏è If your contribution is more than a few lines of code, then prior to starting to code on it please post in the issue saying you want to volunteer, then wait for a positive response. And if there is no issue for it yet, create it first.

This helps make sure:

  1. Two people aren't working on the same thing
  2. This is something Streamlit's maintainers believe should be implemented/fixed
  3. Any API, UI, or deeper architectural changes that need to be implemented have been fully thought through by Streamlit's maintainers
  4. Your time is well spent!

More information in our wiki: https://github.com/streamlit/streamlit/wiki/Contributing
-->

## üìö Context

Corrects type annotations and adds some missing annotations.

- What kind of change does this PR introduce?

  - [X] Bugfix
  - [ ] Feature
  - [ ] Refactoring
  - [ ] Other, please describe:

## üß† Description of Changes

- Replace `str` with `Any` where appropriate in input widgets
- Add missing annotations (e.g. `format_func : Callable[[Any], str] = str`)

  - [ ] This is a breaking API change
  - [X] This is a visible (user-facing) change

NOTE: These changes could break user's mypy tests if they rely on the existing annotations (e.g. by using `--strict` and `# type: ignore`).  This is true for basically any changes to type annotations, so IDK if this counts as a ""breaking API change"".

No behavior changes.

## üß™ Testing Done

- [ ] Screenshots included
- [ ] Added/Updated unit tests
- [ ] Added/Updated e2e tests

## üåê References

_Does this depend on other work, documents, or tickets?_

- **Issue**: Closes #XXXX

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
"," # Fix typing for multiselect, radio, select_slider, and selectboxFixes #1006"
369,"Improve docstring re-indentation handling
This addresses a few crashers, namely:

* producing non-equivalent code due to mangling escaped newlines,

* invalid hugging quote characters in the docstring body to the docstring outer triple quotes (causing a quadruple quote which is a syntax error),

* lack of handling for docstrings that start on the same line as the `def`, and

* invalid stripping of outer triple quotes when the docstring contained a string prefix.

As a bonus, tests now also run when string normalization is disabled.", # Fix docstring re-indentationFixes #1000.
370,"Added some doctests in binary_tree_traversal.py
### Describe your change:

Added doctests for the functions: level_order, get_nodes_from_left_to_right, get_nodes_from_right_to_left, and zigzag.

* [ ] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [x] Add or change doctests? -- Note: Please avoid changing both code and tests in a single pull request.
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [x] If this pull request resolves one or more open issues then the description above includes the issue number(s) with a [closing keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue): ""Fixes #ISSUE-NUMBER"".
", # Added test cases for binary tree traversals
371,"Add docker info for ClearML remote execution
<!--
Thank you for submitting a YOLOv5 üöÄ Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ‚úÖ [Contributing Guide](https://github.com/ultralytics/yolov5/blob/master/CONTRIBUTING.md) for more details.
-->


# Adding a default docker image to ClearML

This PR simply adds some information to the ClearML Task: the default docker image to use. When the task is later cloned and remotely executed, the remote worker (ClearML agent) will use the default YOLOv5 docker image to run the code inside of, which enhanced the out-of-the-box experience of new users.

## Open Question
Currently, I've added `latest` as the docker tag, which is already much better than the nothing we have now, but is there a way we can specifiy the exact correct docker image version tag? Or are you planning on making `latest` always backwards compatible? 

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Improved integration with ClearML by ensuring remote experiments are runnable using a predefined Docker image.

### üìä Key Changes
- Added code to specify a base Docker image (`ultralytics/yolov5:latest`) for remote ClearML tasks.
- Included additional Docker arguments (`--ipc=host -e=""CLEARML_AGENT_SKIP_PYTHON_ENV_INSTALL=1""`) to the task configuration.
- Inserted a script (`pip install clearml`) to set up the Docker environment for ClearML.

### üéØ Purpose & Impact
- üõ† **Enhanced Reproducibility**: Ensures remote tasks run in a consistent environment, reducing discrepancies between local and remote runs.
- üöÄ **Streamlined Set-Up**: Automates the environment setup for ClearML, making it simpler to start remote experiments.
- üìà **Potential Impact**: Benefits users leveraging ClearML for distributed experiments, potentially leading to wider adoption and a smoother experience.", # [clearml] Set base docker image for remote agent
372,"[youtube] Add support for downloading top lists (fixes #1868)
It needs to know the channel and the title of the list, because the ids change every time you browse the channels and are attached to a 'VISITOR_INFO1_LIVE' cookie.

It's not the ideal approach, but it's the only method I've found. If anyone has a better idea, please share it.
",
373,"Add back crutch of incorrect responses to ChatBase
70% of responses content order to contact support instead of answer. It must not be treated as normal answer and raise ValueError.", # [ChatBase] Add check for incorrect responses
374,"Updates starlette dependency to 0.13.6 due to vulnerability in 0.13.4
The project has Starlett dependency of version 0.13.4 which has a directory traversal vulnerability for windows machines. I was made aware of this through: https://snyk.io/vuln/SNYK-PYTHON-STARLETTE-573266

This upgrade would mostly be for the fix to this vulnerability that was introduced in Starlette 0.13.5. This upgrade would be to version 0.13.6 because version 0.13.6 fixes a breaking change related to how 0.13.5 was initially implemented.

Here is a link to the Starlett issue that was fixed for more details: https://github.com/encode/starlette/issues/981", # bump starlette to 0.13.6
375,"[netease] Add warnings for users outside of China
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Add warnings for users outside of China, add more diagnostic information, and give suggested advice.", # [neteasemusic] Fix geo restriction
376,"Added_Comments
I've Added Some Comment Lines To Make Sure That Beginner Python Developers Understand How Everything Is Working!
Hope You Like It!üòÑ", # RandomDice.py
377,"Update path name on xpu-max1100.yml, add badge in README
- Fixes xpu-max1100 not running on PR because of incorrect yml name.", # Add XPU max1100 workflowAdds a new workflow for Intel XPU Max1100.
378,"langchain-mistralai: add missing _combine_llm_outputs implementation in ChatMistralAI
# Description
Implementing `_combine_llm_outputs` to `ChatMistralAI` to override the default implementation in `BaseChatModel` returning `{}`. The implementation is inspired by the one in `ChatOpenAI` from package `langchain-openai`.
# Issue
None
# Dependencies
None
# Twitter handle
None", # Add token usage to llm_outputAdd token usage to llm_output.
379,"Flip conditional in session.send()
Previously we checked that the `request` being sent was an instance of a
PreparedRequest. If a user somehow created a PreparedRequest using a different
Requests library instance, this check makes the request un-sendable.

(This happened recently - unbeknownst to me, my server was running an outdated
version of pip, vulnerable to this issue - pypa/pip#1489, which creates
multiple subdirectories (src/requests, src/requests/requests) when you rerun
pip install --target. So the PreparedRequest was being created in one version
of the library and compared against the other version of the library, and
throwing this exception, even though they were both PreparedRequest instances!)

It would probably be preferable to check the object's behavior (instead of
its type), but a PreparedRequest has a lot of behavior, and it wouldn't be
really feasible or allow us to provide a helpful error message to check all
of it here. Instead flip the conditional to guard against the user sending an
unprepared Request, which should still give us most of the benefits of the
better error message.

Fixes #3102
", # [MRG+1] Fix #10064
380,"[docs] batch prediction guide, strict mode
",
381,"Changed sticky bit string from 'sS' to 'tT'
", # chmod.sh: fix for 's' and 't'
382,"Magical fix for #152 (M2Crypto install dependency order)
", # M2Crypto should be last in install_requires#152
383,"Adding Not So Standard Deviations blog post by Roger D. Peng and Hilary Parker
", # Add Not So Standard Deviations podcastAdded Not So Standard Deviations podcast to the blogs.md.
384,"Better cookie docs on sessions.
Suggested as part of #1488.
", # [MRG+1] Fix #10064
385,"Fix ""RuntimeError: dictionary changed size during iteration"" in the ""expire"" function of ""mitmproxy/certs.py""
Fix #4057 

I changed iteration to list comprehension in order to prevent ""RuntimeError: dictionary changed size during iteration"" in the ""expire"" function of ""mitmproxy/certs.py""

", # Fix certificate runtime error during expire cleanup
386,"[ie/nintendo] Fix Nintendo Direct extraction
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

This rewrite redirects Nintendo Direct extraction to the GraphQL-API endpoint.


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


", # [nintendo] Fix Nintendo Direct extractor
387,"Add AdamW to the supported optimizers
As a follow up to https://github.com/microsoft/DeepSpeed/pull/670 this PR documents that AdamW is natively supported.
", # Update docs/config-json.md
388,"Document and initialise Response.request
In response to #2066. Weirdly, we weren't initialising the `.request` property in the constructor. Nothing terrible there, but we need to do it to get it documented, so let's do it.
", # Add request to ResponseAdds a reference to the request to the response.
389,"[RLlib] Trajectory view API: enable by default for ES and ARS


This PR is based on #11747 (which needs to be merged first!)

It enables the trajectory view API by default for: ES and ARS (on tf, tfe, tf2, and torch).



## Why are these changes needed?



## Related issue number



## Checks

- [x] I've run `scripts/format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [x] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [x] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
"," # [rllib] Use TrajectoryView API to collect samples and produce model- and policy inputs## Why are these changes needed?The TrajectoryView API is a new API introduced in [rllib v1.1](https://github.com/ray-project/ray/pull/10098) that allows users to collect samples and produce model- and policy inputs. This PR uses the TrajectoryView API to collect samples and produce model- and policy inputs in the ARS and ES agents.## Related issue number (if applicable)## Checks- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.- [ ] I've run `scripts/format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.    - [ ] I've added any new APIs to the API Reference. For example, if I added a new class, e.g., `MyAgent`, I've added it to `ray/rllib/agents/my_agent.py`    - [ ] I've added any new parameters to the parameters reference. For example, if I added a new parameter, e.g., `my_param`, to `MyAgent`, I've added it to `ray/rllib/agents/my_agent.py`    - [ ] I've added any new return types to the return types reference. For example, if I added a new return type, e.g., `MyReturnType`, to `MyAgent`, I've added it to `ray/rllib/agents/my_agent.py`- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/- Testing Strategy   - [ ] Unit tests   - [ ] Release tests   - [ ] This PR is not tested :("
390,"Fix 2 typos
In manim cairo-backend, line 127 and 131,
Fixing typo: ""ipmlemented"" to ""implemented"" ; ""understanable"" to ""understandable""", # Fixes #1006
391,"Fix awkward wording.
", # Fix typo in C.30
392,"Correct order of overflowing_tokens for slow tokenizer
# What does this PR do?
 When using a slow tokenizer (LayoutLM, Bert, Alberta, etc.), the `overflowing_tokens` were obtained in the wrong order. I have made the necessary changes that will produce the `overflowing_tokens` in the correct order.
## Tasks summary - 
- [x] making sure overflowing tokens are returned in the correct order for all `truncation_strategy` for a sequences of input ids.
- [x] if a pair of sequences of input ids (or batch of pairs) is provided, an error should be raised for the `truncation_strategy=True` or `longest_first` stating _""Not possible to return overflowing tokens for pair of sequences with the `longest_first`.Please select another truncation strategy than `longest_first`, for instance `only_second` or `only_first`.""_
- [x] Replaced the deprecated method `encode_plus` to regular `__call__` method in `test\test_tokenization_common.py`.

<!--
Congratulations! You've made it this far! You're not quite done yet though.

Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.

Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.

Once you're done, someone will review your PR shortly (see the section ""Who can review?"" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.
-->



This PR fixes the issue [ huggingface/transformers#13148 ](https://github.com/huggingface/transformers/issues/13148 ) 
Fixes huggingface#13148



## Before submitting
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),Pull Request section? Yes üëçüèª
- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Yes, [ huggingface/transformers#13148 ](https://github.com/huggingface/transformers/issues/13148 ) 
- [x] Did you write any new necessary tests?Yes üëçüèª  , Required tests are added in `tests/test_tokenization_common.py`
- [x] Did you make sure to update the documentation with your changes? 


Anyone in the community is free to review the PR once the tests have passed.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

Models:

- albert, bert, xlm: @LysandreJik
- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj
- longformer, reformer, transfoxl, xlnet: @patrickvonplaten
- fsmt: @stas00
- funnel: @sgugger
- gpt2: @patrickvonplaten, @LysandreJik
- rag: @patrickvonplaten, @lhoestq
- tensorflow: @LysandreJik

Library:

- benchmarks: @patrickvonplaten
- deepspeed: @stas00
- ray/raytune: @richardliaw, @amogkam
- text generation: @patrickvonplaten
- tokenizers: @n1t0, @LysandreJik
- trainer: @sgugger
- pipelines: @LysandreJik

Documentation: @sgugger

HF projects:

- datasets: [different repo](https://github.com/huggingface/datasets)
- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)

Examples:

- maintained examples (not research project or legacy): @sgugger, @patil-suraj
- research_projects/bert-loses-patience: @JetRunner
- research_projects/distillation: @VictorSanh

 -->
@patrickvonplaten  @NielsRogge @LysandreJik @n1t0 @SaulLu ",
393,"Use internal imports in Bluetooth update coordinator to avoid future circular imports

## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
We should not import from the top level / public api here, instead we should import the internal path since future refactoring will create circular imports otherwise


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] I have followed the [perfect PR recommendations][perfect-pr]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
", # Update Bluetooth coordinator## Type of changes- [ ] Bug fix- [ ] New feature- [ ] Documentation / docstrings- [ ] Tests- [ ] Other## Checklist- [ ] I've run the latest [black](https://github.com/psf/black) with default args on new code.- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.- [ ] I've added tests for new code.- [ ] I accept that @willmcgugan may be pedantic in the code review.## DescriptionMove Bluetooth related imports to `api.py` to avoid circular imports.## Checklist- [ ] I've added an entry in `CHANGES.md` that describes this change.- [ ] The description above contains no more than 100 characters.- [ ] I've added tests that prove this change is effective.- [ ] New and existing unit tests pass locally with my changes.- [ ] I've added new code to the [linter tests](https://github.com/home-assistant/core/blob/master/tests/lint/README.md#adding-new-tests).- [ ] I've added new code to the [coverage tests](https://github.com/home-assistant/core/blob/master/tests/coverage/README.md#adding-new-code).- [ ] New and existing code has been formatted with `black`.- [ ] I've updated tests and documentation where appropriate.
394,"fix
", # [fooocus] fix #1000
395,"a+=b vs a=a+b : clarify the difference is not universal
Made the text say it depends on class, and rest of explanation talk of lists, not objects.", # Update README.md
396,"[downloader/http] Make retrying more lenient
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [X] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [X] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [X] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [X] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [X] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Makes the http downloader much more lenient on what it retries on, to survive any sort of brief network interruption etc. (given enough retries for such). 

We are thinking it is better to retry on more even though some may be unrecoverable, vs retrying on few, known and likely to be recoverable errors but missing many other cases.

Resolves https://github.com/yt-dlp/yt-dlp/issues/3056, https://github.com/yt-dlp/yt-dlp/issues/2071, https://github.com/yt-dlp/yt-dlp/issues/3034, https://github.com/yt-dlp/yt-dlp/issues/2969 and prob many upstream

Might also help sorting exceptions in #2861 simpler.
", # [downloader] Fix SSL errorsFixes #1006
397,"0.107.3
- Fix netatmo webhook registration issue ([@cgtobi] - [#32994]) ([netatmo docs])
- Fix discovery issue with netatmo climate devices ([@cgtobi] - [#33040]) ([netatmo docs])
- Fix packages for schemas without a default ([@frenck] - [#33045]) ([person docs])

[#32994]: https://github.com/home-assistant/core/pull/32994
[#33040]: https://github.com/home-assistant/core/pull/33040
[#33045]: https://github.com/home-assistant/core/pull/33045
[@cgtobi]: https://github.com/cgtobi
[@frenck]: https://github.com/frenck
[netatmo docs]: https://www.home-assistant.io/integrations/netatmo/
[person docs]: https://www.home-assistant.io/integrations/person/",
398,"Typo in a comment
", # Fix typo in autoblack.yml
399,"Fix requests.packages not having package attributes
Fixes #4104", # Fixes #1006
400,"Add a reference paper for Adagrad
Add the reference paper for the Adagrad optimizer: [Adaptive Subgradient Methods for
Online Learning and Stochastic Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf).
", # Add reference to Adagrad paperAdd reference to Adagrad paper
401,"Flag that DNS plugins are distributed separately from Certbot
#8470 


",
402,"Remove unneeded mypy dependencies
Black no longer uses typed-ast or the dataclasses backport, so these should both be unnecessary now!", # Remove types-typed-astThis PR removes `types-typed-ast` from the list of dependencies. This is because `types-typed-ast` is no longer maintained and is not compatible with Python 3.10.
403,"Connect AppVeyor to the certbot git repository
Hello !

Since my first PR for cerbot windows compatibility has been merged (see #6296), it is time to industrialize a continuous integration process for windows.

**Principle**

The goal here is to do the same than Travis, but on Windows: to execute all regression tests on various Windows plateform at each push on master, and each push on a PR for master.

This PR and the next are focusing on this:
1) Create a connection to AppVeyor (this PR)
2) Launch as much as possible existing tests on AppVeyor (see adferrand/certbot#8 for a preview).

**About AppVeyor**

First, why AppVeyor ? AppVeyor is really similar to Travis in its approach: it connects to GitHub nicely, configure the build pipeline through a yaml file, allows execution matrix against several environment descriptors (plateform, python version and so on). It is free for GitHub projects, like Travis.

But AppVeyor is built on top of Windows VM clusters, so the build environment is Windows Server 2012 R2, or Windows Server 2016. So to sum up, it is the Travis for Windows.

Furthermore, the VMs offers a complete Visual Studio environment, so it is the royal path to build MSI installers of Certbot on Windows platforms.

**About this PR**

Now, this PR does not a lot of things: it declares a ""dummy"" `appveyor.yml` at the root of certbot repository: the built declared cannot fail, it just prints ""Hello World"" before marking the build as succeeded.

What really matters here, is to connect AppVeyor to the certbot github repository, and it is the real work of this PR, that I cannot do obsiously ... 

**The process to connect AppVeyor to GitHub**

The process is really similar to Travis. **It must be done after the current PR is merged to master!** (Otherwise unexpected behavior will occur due to the lack of `appveyor.yml` file on the master branch).

A developper with access to the certbot account need to go to https://www.appveyor.com/, click Sign-In, then select GitHub as the provider to create the account. Once the OAuth authentication is established, AppVeyor will scan for public repositories hold by the certbot GitHub account. From AppVeyor administration page, you will need to go to `Projects`, `New Project`, and select `certbot` in the drop-down list of GitHub category.

Once done, AppVeyor is connected to the certbot project repository. Any PR on master will need by default to pass both Travis CI pipelines and AppVeyor pipelines. As said before, and until my next PR, this will have no impact as the integrated dummy `appveyor.yml` cannot fail.

**Next step**

When this PR is merged and AppVeyor is connected to GitHub, I will create the next PR, that will then toggle the real CI pipeline for Windows that I prepared here: adferrand/certbot#8

**Help**

Of course I am at your disposition for any help needed on this PR and on AppVeyor.

Regards,
Adrien Ferrand", # Add AppVeyor CI configurationAdd AppVeyor CI configuration.
404,"Send the most detailed user credentials to the backend
Fixes #827 

This adds a new helper method that checks what linked accounts a user has.  If a linked account exists, we use those credentials when communicating with the backend rather than the web's local credentials.", # Fix Oasst API test
405,"Allow runtime modifications of HTTP flow filters for server replays
#### Description
Fixes #4506
`mitmproxy` during server-replay mode, calculates the hashes of flows from input files based on user defined filters and uses them to compare against hashes of incoming requests to serve the corresponding stored response by matching the hash. However, during runtime, if the user changes any of the filters, `mitmproxy` fails to recalculate the hashes of input flows and hence doesn't return the intended response. This PR fixes this issue by recomputing the hashes for every flow whenever a filter(option) used for computing hashes is changed.

#### Checklist

 - [x] I have updated tests where applicable.
 - [x] I have added an entry to the CHANGELOG.", # Allow runtime modifications of HTTP flow filters for server replaysThis PR allows runtime modifications of HTTP flow filters for server replays.
406,"MNT use api.openml.org URLs for fetch_openml
#### Reference Issues/PRs

According to https://github.com/openml/OpenML/issues/1135#issuecomment-1504114194, this is the preferred URL.

#### What does this implement/fix? Explain your changes.

This uses `api.openml.org` rather than `openml.org` in `fetch_openml`. This adapts the tests as well.

To take the example of a single URL, [`https://openml.org/api/v1/json/data/list/data_name/titanic/limit/2/data_version/1`](https://openml.org/api/v1/json/data/list/data_name/titanic/limit/2/data_version/1) redirects to [`https://www.openml.org/api/v1/json/data/list/data_name/titanic/limit/2/data_version/1`](https://www.openml.org/api/v1/json/data/list/data_name/titanic/limit/2/data_version/1) (`openml.org` -> `www.openml.org`) which redirects to [`https://api.openml.org/api/v1/json/data/list/data_name/titanic/limit/2/data_version/1`](https://api.openml.org/api/v1/json/data/list/data_name/titanic/limit/2/data_version/1) (`www.openml.org` -> `api.openml.org`)

#### Any other comments

I have added the ""no changelog needed"" label, let me know it you think a changelog entry is needed
", # Update openml.py
407,"fix lambda function URLs when they don't exist or the service is not loaded



## Motivation

I noticed an error when calling non-existing lambda function URLs. The code we had was apparently faulty, and I got this error:

```
2024-04-11T17:20:40.966 ERROR --- [et.reactor-0] l.aws.handlers.logging     : exception during call chain
Traceback (most recent call last):
  File ""/opt/code/localstack/.venv/lib/python3.11/site-packages/rolo/gateway/chain.py"", line 166, in handle
    handler(self, self.context, response)
  File ""/opt/code/localstack/.venv/lib/python3.11/site-packages/rolo/gateway/handlers.py"", line 27, in __call__
    router_response = self.router.dispatch(context.request)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/code/localstack/.venv/lib/python3.11/site-packages/rolo/router.py"", line 378, in dispatch
    return self.dispatcher(request, handler, args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/code/localstack/.venv/lib/python3.11/site-packages/rolo/dispatcher.py"", line 71, in _dispatch
    result = endpoint(request, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/code/localstack/localstack/services/lambda_/urlrouter.py"", line 79, in handle_lambda_url_invocation
    match = FULL_FN_ARN_PATTERN.search(lambda_url_config.function_arn).groupdict()
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
```

After writing a test, I further ran into a problem that we've had in the past, which is that, services that have a data plane are not properly loaded based on calling URLs of the data plane, even though we could.

Previously localstack would behave like this when calling a lambda function URL without lambda being loaded first (e.g., by calling `awslocal lambda list-functions`.

```
 % curl http://a38wes0ubqxh7ipckjdl8ilptt40uiha.lambda-url.us-east-1.localhost.localstack.cloud:4566
{""__type"": ""InternalError"", ""message"": ""exception while calling lambda with unknown operation: Traceback (most recent call last):\n  File \""/opt/code/localstack/localstack/aws/protocol/parser.py\"", line 557, in parse\n    operation, uri_params = self._operation_router.match(request)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \""/opt/code/localstack/localstack/aws/protocol/op_router.py\"", line 321, in match\n    rule, args = matcher.match(path, method=method, return_rule=True)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \""/opt/code/localstack/.venv/lib/python3.11/site-packages/werkzeug/routing/map.py\"", line 631, in match\n    raise NotFound() from None\nwerkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \""/opt/code/localstack/.venv/lib/python3.11/site-packages/rolo/gateway/chain.py\"", line 166, in handle\n    handler(self, self.context, response)\n  File \""/opt/code/localstack/localstack/aws/handlers/service.py\"", line 63, in __call__\n    return self.parse_and_enrich(context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \""/opt/code/localstack/localstack/aws/handlers/service.py\"", line 67, in parse_and_enrich\n    operation, instance = parser.parse(context.request)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \""/opt/code/localstack/localstack/aws/protocol/parser.py\"", line 172, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \""/opt/code/localstack/localstack/aws/protocol/parser.py\"", line 559, in parse\n    raise OperationNotFoundParserError(\nlocalstack.aws.protocol.parser.OperationNotFoundParserError: Unable to find operation for request to service lambda: GET /\n""}%  
```

In this situation:
* the service is identified as ""lambda"" because of the hostname matching rule (`.lambda-url.`)
* the service hasn't been loaded yet, so the edge routes for lambda (i.e., the data plane) haven't been added yet either
* therefore, the request moves on to the service request parser, which fails because no operation is associated with the request.

bad and ugly!

instead, localstack now correctly loads the lambda service:

```
curl http://a38wes0ubqxh7ipckjdl8ilptt40uiha.lambda-url.us-east-1.localhost.localstack.cloud:4566
{""Message"": null}
```

I had to
* adapt the service loader so it correctly loads services even when there is no api operation set (for the life of me i cannot remember why i thought it would be useful to check individual operations rather than just whole services).
* add a special type of service loader that only checks the hostname rules



## Changes

* A selected set of services are now properly loaded when calling data plane URLs. Specfically, URLs of APIGW (`.execute-api.`), S3 website (`.s3-website.`) (cc @bentsku) and lambda (`.lambda-url.`)
* Calling non-existing lambda function URLs now returns the correct HTTP response

<!-- The following sections are optional, but can be useful! 

## Testing

Description of how to test the changes

## TODO

What's left to do:

- [ ] ...
- [ ] ...

-->

",
408,"[Datasets] Add a test case for spark-on-ray




## Why are these changes needed?
Thanks to the previous discussion on this issue, I make a test case for it.


## Related issue number
[issue #21980 ](https://github.com/ray-project/ray/issues/21980)


## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",
409,"Fix cuDNN tests
Move `times = []` from the outer to the inner loop (because the speed-up is calculated for each inner loop)
Delete `clear_session()` which is redundant with `keras_test` (thus the outer loop should be transformed to `pytest.mark.parametrize`)
Reduce the example size under the 3x speed-up is satisfied (the sample size 10000 is too large) ", # [MRG+1] Fix test_cudnn_rnn_timingFixes #1000.
410,"[UI] Stream unicode properly
Currently, the console could only stream English ASCII words, separated by space. This PR enables streaming of general unicode in rich style.", # Fix RichChatIO
411,"Some preliminary documentation updates to mention renew verb
This isn't really detailed but @bmw pointed out that we really do want to point to the renew verb in all of our documentation now that it's there, because people will start looking! So this is a first cut at doing that so that something useful will be there when people look.
", # Update docs to reflect changes to the client
412,"update CODEOWNERS, set default reviewer for ASF Update PRs
This PR updates the `CODEOWNERS` file:
- Orders the service owners alphabetically.
- Adds missing service sections which have an owner (ACM / @alexrashed, Api Gateway / @calvernaz, Logs / @steffyP, Route53 / @giograno).
- Changed codeowner of IAM from @dominikschubert to @dfangl.
- Changed codeowner of CloudWatch from @silv-io to @steffyP.
- Adds the cloudformation models to some of the sections.
- Adds the generated API code (`localstack.aws.api.`) to each section (i.e. codeowners will be added to ASF Update PRs automatically if anything changes for their service).

I changed this proactively once I realized that some parts are outdated. Please let me know if any of the sections should be set differently (as a comment or in a DM).

In addition, I added myself as a default reviewer for PRs created by the ASF Update Action.", # [localstack] Add reviewers for ASFAdd reviewers for ASF
413,"üåê Add translation for `docs/zh/docs/advanced/response-cookies.md`
Help developer in China", # Ê∑ªÂä†ÂìçÂ∫îCookies
414,"Add Pyschonauts API to Games & Comics


- [x] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added Pyschonauts APIAdded Pyschonauts API to the list of APIs.
415,"[pre-commit.ci] pre-commit autoupdate

updates:
- [github.com/astral-sh/ruff-pre-commit: v0.1.9 ‚Üí v0.1.11](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.9...v0.1.11)
", # Update pre-commit config
416,"Change registering unsafely without email logging level to info
Fixes #4408.", # Use info instead of warning for registering without email
417,"gh-104799: PEP 695 backward compatibility for ast.unparse



* Issue: gh-104799

"," # Enable :func:`ast.unparse` to unparse function and class definitions created without the new ``type_params`` field from :pep:`695`. Patch by Jelle Zijlstra.This PR enables :func:`ast.unparse` to unparse function and class definitions created without the new ``type_params`` field from :pep:`695`. Patch by Jelle Zijlstra.[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ast&package-manager=pip&previous-version=2.7.19&new-version=2.7.20)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.[//]: # (dependabot-automerge-start)[//]: # (dependabot-automerge-end)---Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)- `@dependabot use these labels` will set the current labels of this PR to the ones you are specifying- `@dependabot use these assignees` will set the current assignees of this PR to the ones you are specifying- `@dependabot use these reviewers` will set the current reviewers of this PR to the ones you are specifying- `@dependabot use these tags` will set the current tags of this PR to the ones you are specifying- `@dependabot use these milestones` will set the current milestone of this PR to the one you are specifying- `@dependabot use these labels (all viewable users)` will set the current labels of this PR to the ones you are specifying for all viewable users- `@dependabot use these assignees (all viewable users)` will set the current assignees of this PR to the ones you are specifying for all viewable users- `@dependabot use these reviewers (all viewable users)` will set the current reviewers of this PR to the ones you are specifying for all viewable users- `@dependabot use these tags (all viewable users)` will set the current tags of this PR to the ones you are specifying for all viewable users- `@dependabot use these milestones (all viewable users)` will set the current milestone of this PR to the one you are specifying for all viewable users"
418,"Ignore empty auth header in api / Add live token count in gui
",
419,"Added Deep Learning with Python, Second Edition
Hi,
Branko from Manning here, I thought this book might be a good resource here.
Thanks for your consideration!"," # Add Deep Learning with Python, Second EditionAdded Deep Learning with Python, Second Edition to the list of courses."
420,"Bilibili: fix ""ÁúüÂΩ© HDR"" video_resolution
Video resolution of Bilibili ""ÁúüÂΩ© HDR"" is 2160p (3840x2160), not 3840p.", # [bilibili] update video resolution
421,"Update Detections() self.n comment
```python
        self.n = len(self.pred)  # number of images (batch size)
```

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Enhanced code comments for clarity in `models/common.py`.

### üìä Key Changes
- Improved comments for the `self.n` variable in the detection results class.

### üéØ Purpose & Impact
- **Purpose:** Clarify the purpose of the `self.n` variable within the code.
- **Impact:** Provides better understanding of the code for developers and maintainers, potentially reducing confusion and aiding in future debugging or development. This change does not alter functionality but improves code readability. üìñ‚ú®", # [common] fix batch size
422,"Add Aqueduct to the list
Aqueduct is an open-source MLOps framework that allows you to write code in vanilla Python, run that code on any cloud infrastructure you'd like to use, and gain visibility into the execution and performance of your models and predictions. @josephmisiti ", # Add AqueductAdded Aqueduct to the list of tools.
423,"Add get_coco128.sh for downloading the coco128 dataset
Add a script get_coco128.sh for downloading the coco128 dataset, which accelerates training validation and testing.

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Introducing a simple script for easy downloading of the COCO128 dataset.

### üìä Key Changes
- New `get_coco128.sh` bash script added to automate dataset download and setup.
- Allows quick downloading and setup of the COCO128 dataset for training with just one command.

### üéØ Purpose & Impact
- üéØ Simplifies the process of obtaining the COCO128 dataset, making it more user-friendly for both beginners and advanced users.
- üöÄ Can accelerate the setup time for training YOLOv5 models, as it provides a quick way to access a small, yet useful dataset.
- üë©‚Äçüíª Benefits users looking to experiment with or prototype object detection models without requiring the full COCO dataset's size and complexity.", # Add COCO128 datasetAdd COCO128 dataset to the YOLOv5 repository.
424,"fix(discover): Various bugs with top events and Other
- This corrects how conditions were being constructed for other in top
  events by using demorgans, and OR-ing the top level conditions instead
  of AND-ing them together
- This also flips tests over to use the new feature flag
- Also fixes a bug with the index of Other being off by one
- Also fixes a bug where Other wasn't compatible with equations",
425,"New rule: sl -> ls
When typing quickly, I make this mistake all the time. This addition allows you to unfuck sl, replacing it with ls.
", # Add sl_ls rule
426,"update dask compatibility for 1.5.0
Update verified dask version and test script instructions

## Why are these changes needed?



## Related issue number



## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
", # [MRG+1] Add 1.5.0 to dask-on-ray testsAdds 1.5.0 to the tests.
427,"Update sort.py to make the list ""alphabetically sorted""
Hi there,
This PR is related to PR https://github.com/vinta/awesome-python/pull/768.
This is a simple script to do the sorting stuff.
Thanks.
", # Sorting the README.md
428,"ElectraForQuestionAnswering
This PR adds `ElectraForQuestionAnswering`. One of the missing models in this [project](https://github.com/huggingface/transformers/projects/17)

@LysandreJik , @sgugger ",
429,"Reapply ""Hyundai Azera: allow fingerprinting without comma power (#31717)""
I just realized why we might only see EPS on some cars, and it's probably from https://github.com/commaai/openpilot/pull/31334", # Add Ecu.eps to whitelist for HyundaiAdd Ecu.eps to whitelist for Hyundai. 
430,"New option: --no-caption
Fix #861.

The `--no-caption` option suppresses the download of captions (danmaku, lyrics, subtitles) from
- Bilibili
- music.163.com
- YouTube (see also https://github.com/soimort/you-get/pull/705#issuecomment-159485291)

Example:

``` console
$ you-get http://www.bilibili.com/video/av3535049/
Site:       bilibili.com
Title:      ‰πâËñÑ‰∫ëÂ§©ÔºÅÂ∞èÂ•≥Â≠©‰∏∫‰∫ÜÊïëËá™Â∑±ÁöÑÊúãÂèãÔºåÊçêËÇùËÑèÊ≠ª‰∫éÊâãÊúØÂè∞
Type:       Flash video (video/x-flv)
Size:       113.04 MiB (118531404 Bytes)

Skipping ./‰πâËñÑ‰∫ëÂ§©ÔºÅÂ∞èÂ•≥Â≠©‰∏∫‰∫ÜÊïëËá™Â∑±ÁöÑÊúãÂèãÔºåÊçêËÇùËÑèÊ≠ª‰∫éÊâãÊúØÂè∞.mp4: file already exists

Downloading ‰πâËñÑ‰∫ëÂ§©ÔºÅÂ∞èÂ•≥Â≠©‰∏∫‰∫ÜÊïëËá™Â∑±ÁöÑÊúãÂèãÔºåÊçêËÇùËÑèÊ≠ª‰∫éÊâãÊúØÂè∞.cmt.xml ...
```

``` console
$ you-get --no-caption http://www.bilibili.com/video/av3535049/
Site:       bilibili.com
Title:      ‰πâËñÑ‰∫ëÂ§©ÔºÅÂ∞èÂ•≥Â≠©‰∏∫‰∫ÜÊïëËá™Â∑±ÁöÑÊúãÂèãÔºåÊçêËÇùËÑèÊ≠ª‰∫éÊâãÊúØÂè∞
Type:       Flash video (video/x-flv)
Size:       113.04 MiB (118531404 Bytes)

Skipping ./‰πâËñÑ‰∫ëÂ§©ÔºÅÂ∞èÂ•≥Â≠©‰∏∫‰∫ÜÊïëËá™Â∑±ÁöÑÊúãÂèãÔºåÊçêËÇùËÑèÊ≠ª‰∫éÊâãÊúØÂè∞.mp4: file already exists

Skipping danmaku.
```



[](https://reviewable.io/reviews/soimort/you-get/864)


", # [netease] add --no-caption option
431,"Add support for Pinterest, as a showcase of using VideoExtractor
As requested in #744.

At this point, the usage of `VideoExtractor` was limited on just a few sites: **YouTube**, **Youku**, and **IQiyi**. All of them are non-trivial to implement; and relevant code is hard to read. As I understood, this has been a major obstacle for starters who wish to implement new extractors using `VideoExtractor`.

I implemented the code for extracting images from **Pinterest**, as a showcase of using `VideoExtractor` - it's all in some 50 lines of code, well commented and easy to make sense for anyone (hopefully).

It seems I'm unlikely to refactor this part for at least a while. So, you may use [`pinterest.py`](https://github.com/soimort/you-get/blob/f44a99536680c3d6529a28cf0f10ce09f2f86279/src/you_get/extractors/pinterest.py) here in this PR as a minimal boilerplate of implementing your own `VideoExtractor` instance. It can't be perfect, but should just work.

```
Œª  you-get-develop [pinterest] ./you-get -i https://www.pinterest.com/pin/243827767295808495/
site:                Pinterest
title:               Nyhavn is a 17th century waterfront, canal, and entertainment district in Copenhagen, Denmark.
streams:             # Available quality and codecs
    [ DEFAULT ] _________________________________
    - format:        original
      container:     jpg
      size:          0.8 MiB (881940 bytes)
    # download-with: you-get --format=original [URL]

    - format:        small
      container:     jpg
      size:          0.1 MiB (70598 bytes)
    # download-with: you-get --format=small [URL]
```

Example links to test with:
- https://www.pinterest.com/pin/243827767295808495/
- https://www.pinterest.com/pin/135600638756980545/
- https://www.pinterest.com/pin/328410997798990469/
- https://www.pinterest.com/pin/44965696253076739/
- https://www.pinterest.com/pin/471681760952953557/
- https://www.pinterest.com/pin/471681760952953562/



[](https://reviewable.io/reviews/soimort/you-get/756)


", # Add Pinterest support
432,"fix format
"," # [Communication] Fix Pipeline P2P communication## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/...] PR`- [ ] I have added relevant tags if possible for us to better distinguish different PRs- [ ] The description explains the purpose and effect of the PR## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?- [ ] üåù Yes, I do.- [ ] üåö No, I don't.Tell us more if you don't enjoy contributing to Colossal-AI."
433,"Use built-in 8-bit compression method instead of huggingface/accelerate
", # Update README.md
434,"Dynamically choose python binary
Different approach to solving the problem discussed in #681.

Thoughts @jmhodges, @kuba? 
", # Fixes #1002
435,"ACME: pylint to 80 chars
", # [acme] Fixes #1006
436,"docs: fix PromptGuard docs
<!-- Thank you for contributing to LangChain!

Replace this entire comment with:
  - Description: a description of the change, 
  - Issue: the issue # it fixes (if applicable),
  - Dependencies: any dependencies required for this change,
  - Tag maintainer: for a quicker response, tag the relevant maintainer (see below),
  - Twitter handle: we announce bigger features on Twitter. If your PR gets announced and you'd like a mention, we'll gladly shout you out!

Please make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.

See contribution guidelines for more information on how to write/run tests, lint, etc: 
https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md

If you're adding a new integration, please include:
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use. These live is docs/extras directory.

If no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17, @rlancemartin.
 -->

Fix PromptGuard docs. Noticed several trivial issues on the docs when integrating the new class.
cc @baskaryan 
", # Fix typo in docs
437,"fix pf.conf on macOS
As mentioned in https://github.com/mitmproxy/mitmproxy/issues/3255

Didn't find out how to deal with the ```redir_users = ""{ !="" $tproxy_user ""}""``` syntax, and I removed it üòÖ , feel free to enlight me", # Fix typo in howto-transparent.md
438,"Fix documentation typo: accesible ‚Üí accessible
Fixes #3597

While this change will not be necessary after #3975 is merged, that could take a while, or not happen at all.", # fix typo in request.py
439,"Docker fix
", # Update Dockerfile to use Python 3.10.3
440,"fix: rename the invalid function name of GoogleSerperResults Tool for OpenAIFunctionCall
- Description: rename the invalid function name of GoogleSerperResults Tool for OpenAIFunctionCall
- Tag maintainer: @hinthornw

When I use the GoogleSerperResults in OpenAIFunctionCall agent, the following error occurs:
```shell
openai.error.InvalidRequestError: 'Google Serrper Results JSON' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'functions.0.name'
```

So I rename the GoogleSerperResults's property ""name"" from ""Google Serrper Results JSON"" to ""google_serrper_results_json"" just like GoogleSerperRun's name: ""google_serper"", and it works.
I guess this should be reasonable.", # Fix typo in GoogleSerperResults
441,"Filter Media into separate categories
The Media category was becoming too vague and too cluttered with items that fell into other, already existing, categories. By breaking up this category, we are able to allow viewers to quickly find what they need, instead of making them search the category they want and then have to double-check the ""catch-all"" basin that was Media. 

These changes should cover issue #127.
",
442,"Fix broken link not compatible with MkDocs
Relative github link `Cloud%20-%20Azure%20Pentest.md/#azure-recon-tools` is converted with MkDocs to:
```
https://swisskyrepo.github.io/PayloadsAllTheThingsWeb/Methodology%20and%20Resources/Active%20Directory%20Attack/Cloud%20-%20Azure%20Pentest.md/#azure-recon-tools
```
Instead of
```
https://swisskyrepo.github.io/PayloadsAllTheThingsWeb/Methodology%20and%20Resources/Cloud%20-%20Azure%20Pentest/#azure-recon-tools
```

A fix on this could be interesting. We could even go further and convert automatically links in .md files such as `https://github.com/swisskyrepo/PayloadsAllTheThings/` to `https://swisskyrepo.github.io/PayloadsAllTheThingsWeb`.", # Update link to AzureHound
443,"fix underscore missing in repl
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [ ] I've run the latest [black](https://github.com/ambv/black) with default args on new code.
- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [ ] I accept that @willmcgugan may be pedantic in the code review.

## Description

Fixes https://github.com/willmcgugan/rich/issues/235", # [5.2.1] Fix underscore with display hookFixes #235
444,"Add basic load tests
* closes #1622

I‚Äôve used locust to write a basic load test which will hit two endpoints sequentially that mimic the text-client in the inference server.
* `/chat` to start a new conversation with chat_id
* `/chat/{chat_id}/message` to send a message to the Assistant

An isolated load test user workflow is summarised by first spawning X users every Y seconds to a maximum amount of N concurrent users

1. A user starts a conversation with the Assistant
2. Then they enter a conversation loop
    a. Send a chat message to the Assistant
    b. Wait until Assistant responds
    c. Wait Z further seconds
Repeat

I've tested this locally on my MacBook and results show the Bot seems to be capable of scaling to 100's of users without any adverse errors (but response times do naturally increase). I'll be able to provide more quantitative results once I run it in a more realistic setup with GPUs."," # [inference] fix inference server### Describe your change:* [x] Add an algorithm?* [ ] Fix a bug or typo in an existing algorithm?* [ ] Documentation change?### Checklist:* [x] I have read [CONTRIBUTING.md](https://github.com/oobabooga/text-generation-webui/blob/master/CONTRIBUTING.md).* [x] This pull request is all my own work -- I have not plagiarized.* [x] I know that pull requests will not be merged if they fail the automated tests.* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.* [x] All new Python files are placed inside an existing directory.* [x] All filenames are in all lowercase characters with no spaces or dashes.* [x] All functions and variable names follow Python naming conventions.* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
445,"BOTMETA: remove hekonsek from team_scaleway
##### SUMMARY

[As requested](https://github.com/ansible/ansible/pull/48671#issuecomment-438755239):
* remove `hekonsek` contributor from `team_scaleway`
* don't notify contributor anymore.

##### ISSUE TYPE
- Bugfix Pull Request

##### COMPONENT NAME
.github/BOTMETA.yml", # fix typo in BOTMETA.yml
446,"Fix unstable unarchive test
##### SUMMARY

There is a bug in the time calculation used to determine if a change was made or not. This results in the task reporting changed when it should not, and the test failing. This seems to only happen on Ubuntu1604, but it is documented in the code.

https://github.com/ansible/ansible/blob/58145dff9ca1a713f8ed295a0076779a91c41cba/lib/ansible/modules/unarchive.py#L472-L474

Add `mode` to copy tasks to preserve the existing file mode.

These tests were added in #65666.


##### ISSUE TYPE

- Test Pull Request

##### COMPONENT NAME

`test/integration/targets/unarchive`",
447,"Chat history download creates more detailed file names
Chat history downloads used to contain the name of the character or mode and a timestamp. That made it easy for me to put all my exports into a folder and have it organized, especially when using Instruct mode. However, when I recently updated to the newest version, I noticed all history downloads were now named ""exported_history.json""
I decided to make a fork using the formatting code from a previous commit in order to restore the more detailed file names. Most of my changes are put into one function that works similarly to `save_persistent_history`. 
I briefly tested the code in Chat and Instruct mode on Windows.", # Save history at user request
448,"DOC Fix docstring in sklearn.metrics._ranking.label_ranking_loss #21350 #pariswimlds
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->
Addresses https://github.com/scikit-learn/scikit-learn/issues/21350


#### What does this implement/fix? Explain your changes.

Adding description for the return value
#### Any other comments?
Fix docstring in sklearn.metrics._ranking.label_ranking_loss

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
", # [MRG] Add docstring for label_ranking_loss
449,"bpo-38291: Fix a deprecation warning in typing tests
The test was accessing typing.{io,re}.__all__, which triggered the
warning. This check isn't necessary anymore, since the objects from
typing.{io,re}.__all__ are in typing.__all__ as well, since Python 3.10.

A NEWS should not be required, since this affects the tests only.

Cc @serhiy-storchaka 


https://bugs.python.org/issue38291

", # Remove io/re typing tests
450,"Jupyter progress
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [x] Other

## Checklist

- [ ] I've run the latest [black](https://github.com/ambv/black) with default args on new code.
- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [ ] I accept that @willmcgugan may be pedantic in the code review.

## Description

Enables progress bars with Jupyter
",
451,"Fix for bug causing failing test keras/utils/vis_utils_test.py test_layer_range_value_fail second value (empty list).
According to the tests, an empty list passed for `layer_range` should cause an exception in `model_to_dot`. As implemented an empty list is ignored. This changes to the behaviour to match the test.", # Fix #10000Fix #10000
452,"feat(browser-starfish): move data around in resource summary
1. Add time spent cell
2. Move resource info around to match mocks
![image](https://github.com/getsentry/sentry/assets/44422760/0d4caa46-3c86-4feb-a20b-4931fb38fec3)
", # [performance] Add time spent percentage to resource summary page### DescriptionAdds a `timeSpentPercentage` to the `ResourceSummaryPage` view. This is a percentage of the total time spent on the request.### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/getsentry/sentry/blob/master/CONTRIBUTING.md#start-contributing-pull-requests) - [x] I have performed a self-review of my own code- [x] My code follows the [style guidelines](https://github.com/getsentry/sentry/blob/master/CONTRIBUTING.md#start-contributing-pull-requests)- [x] My code passes [tests](https://github.com/getsentry/sentry/blob/master/CONTRIBUTING.md#start-contributing-pull-requests)
453,"Fix dummy_inputs() to dummy_inputs in symbolic_trace doc string
# What does this PR do?

<!--
Congratulations! You've made it this far! You're not quite done yet though.

Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.

Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.

Once you're done, someone will review your PR shortly (see the section ""Who can review?"" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.
-->



## Before submitting
- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors who may be interested in your PR.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

Models:

- albert, bert, xlm: @LysandreJik
- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj
- longformer, reformer, transfoxl, xlnet: @patrickvonplaten
- fsmt: @stas00
- funnel: @sgugger
- gpt2: @patrickvonplaten, @LysandreJik
- rag: @patrickvonplaten, @lhoestq
- tensorflow: @LysandreJik

Library:

- benchmarks: @patrickvonplaten
- deepspeed: @stas00
- ray/raytune: @richardliaw, @amogkam
- text generation: @patrickvonplaten
- tokenizers: @n1t0, @LysandreJik
- trainer: @sgugger
- pipelines: @LysandreJik

Documentation: @sgugger

HF projects:

- datasets: [different repo](https://github.com/huggingface/datasets)
- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)

Examples:

- maintained examples (not research project or legacy): @sgugger, @patil-suraj
- research_projects/bert-loses-patience: @JetRunner
- research_projects/distillation: @VictorSanh

 -->
", # Fix typo in fx.py
454,"Fix RobotEnv rgb_array rendering
Issue #1000 also applies to `RobotEnv`: when `env.render` is called with `mode='rgb_array'`, currently only a 500x500 square from the bottom-left corner of the image is drawn. We fix it here using the same patch.

(As Issue #1000 notes, this code is shared between `RobotEnv` and `MujocoEnv`. Ideally we would move this to a more abstract class. I'm not sure what the best way of doing this is; for the time being I propose we just put up with a kludgy fix in two separate places.)", # [gym] Add render() to robotics environmentsAdd render() to robotics environments.
455,"[3.11] gh-93738: Documentation C syntax (:c:type:`FILE` -> :c:expr:`FILE`) (GH-97769)
:c:type:`FILE` -> :c:expr:`FILE`
(cherry picked from commit 192d401ba53224020f5f9ca6e1ff2c9f89511ac4)


Co-authored-by: Adam Turner 


* Issue: gh-93738

", # Fix docstrings for c-api functions
456,"[ie/CloudflareStream] Improve `_VALID_URL`
Closes #9171

Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)


", # [cloudflarestream] Add support for customer-aw5py76sw8wyqzmh.cloudflarestream.com
457,"Add disable_tls_verify arg for use with self-signed certs
**Describe what this pull request is trying to achieve.**

This PR adds support for `disable-tls-verify` CLI arg and updates gradio version in `requirements.txt` to latest which added support for this flag.

**Additional notes and description of your changes**

More technical discussion about your changes go here, plus anything that a maintainer might have to specifically take a look at, or be wary of.

**Environment this was tested in**

List the environment you have developed / tested this on. As per the contributing page, changes should be able to work on Windows out of the box.
 - OS: Windows, Linux by making changes to gradio/automatic manually
 - Browser: n/a
 - Graphics card: 4090
", # Add --disable-tls-verify
458,"Respect the order of keys in a Dict's observation space when flattening
Prior to this change, during flattening, the order of the key/values in the observation was used instead of the order in the Dict's observation space. unflatten already uses the order specified by the Dict's observation space.", # [gym] Fix flattening of Dict spacesFixes #1000.
459,"Add signum function
### Describe your change:



* [x] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.

Fixes: #7525", # Add signum functionAdd signum function
460,"gh-101100: Fix Sphinx nitpicks in `library/collections.abc.rst`
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y]  (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->



* Issue: gh-101100




----
üìö Documentation preview üìö: https://cpython-previews--113116.org.readthedocs.build/

",
461,"Fix oauth TypeError (int + string)
Ensure that authorization `expires_in` token is an integer before adding it to another int

This is my first PR to sentry in and the contributing guidelines don't mention if I need to provide more information, stack errors etc. Let me know if you want them and I'll endeavor to add to future PRs", # Fixed #10064
462,"Black formatting
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [x ] Other

## Checklist

- [ x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [ x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ x] I've added tests for new code.
- [ x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Perform black formatting
",
463,"feat(node): add AWS app-runner #645
As noticed in the 645 issue App-runner was missing.
https://github.com/mingrammer/diagrams/issues/645", # Add AppRunner node
464,"Bump moto-ext to 4.2.2.post2
Ext run passing :heavy_check_mark: ( see Ext Integration Tests # 2367 )

cc: @macnev2013 ", # bump moto-ext to 4.2.2.post2Bumps moto-ext to 4.2.2.post2.
465,"fix arg typo in SimpleDirectoryReader
", # Fix typo in file.py
466,"Fix figsize issue when using matplotlib locally
This is a pretty minor issue, but I'm seeing the following when passing `figsize=(20,10)` when plotting a Series in the `ipython --pylab` environment:

![Series_figsize](https://f.cloud.github.com/assets/440095/267751/46f8b184-8ebd-11e2-8631-2131ce0421f6.png)

Everything's there - the window is just initialized to the wrong size. Without the `--pylab` flag and manually calling `plt.show()`, the window shows up as the default size (which is incorrect).

The issue appears to be that `plot_series()` will call `plt.gca()` before `figsize=` has been passed to `plt.figure()`. This initializes the window to the default size and it apparently isn't updated when redrawn.

What this patch does is use `plt.get_fignums()` to see if we have any existing figures. If so, we can call `plt.gca()` without automatically creating a figure and window at the default sizes.

The addition of `new_ax.right_axis = new_ax` is to accommodate Series plotted with `secondary_y=True` and thus getting `new_ax` as their `Axes`. It renders fine without it but a few tests expect `right_axis` to exist. This could be handled differently if this is inappropriate.

Finally, there's a test to check that `figsize=` is at least implemented on the figure. I don't know of a way to test this bug in a backend-independent way, so this only checks that we're not regressing to the pre-v0.10.0 state where `figsize=` was silently ignored by `plot_series()`.
",
467,"Variable dropout rate

**Describe what this pull request is trying to achieve.**

Implements variable dropout rate from #4549

Fixes hypernetwork multiplier being able to modified during training, also fixes user-errors by setting multiplier value to lower values for training.

Changes function name to match torch.nn.module standard.

Fixes RNG reset issue when generating previews by restoring RNG state.

**Additional notes and description of your changes**

These changes were tested in [extension](https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension/blob/main/patches/hypernetwork.py), but only variable dropout related changes are imported.

Also, now hypernetwork has `.optional_info` attribute that may store additional informations, maybe training information, dataset, etc. 
![image](https://user-images.githubusercontent.com/35677394/211474164-757e4bb1-f2ac-4da0-a8b6-81aabbb83d69.png)
Currently its read-only.

**Environment this was tested in**

List the environment you have developed / tested this on. As per the contributing page, changes should be able to work on Windows out of the box.
 - OS: Windows
 - Browser: Chrome and Edge
 - Graphics card: NVDIA RTX 3070

**Screenshots or videos of your changes**

Hypernetwork loading change, to check any compatibility issues:
![image](https://user-images.githubusercontent.com/35677394/211473318-9e1874cb-2ce8-423c-b824-fc2d9626fef3.png)

Testing variable dropout hypernetwork, and image test:
![image](https://user-images.githubusercontent.com/35677394/211474573-2f4fb2e5-7a47-4814-9bc2-d0965a268ac1.png)


Training newly created hypernetwork works correctly:
![image](https://user-images.githubusercontent.com/35677394/211473610-693e3ac3-2a7a-40aa-a709-c9bd2b141e14.png)

UI change, for variable dropout rate sequence:
![image](https://user-images.githubusercontent.com/35677394/211473707-97fb6f55-0e2d-46d9-94f8-de8554ad3a7e.png)

For safety, generated images are not attached regardless of its subject.",
468,"fixbug: #1095
**Features**
fixbug: #1095", # Fix bug fix code plan and change action
469,"Added type hints to dependency injection pattern
Added type hints to _dependency injection_ pattern and also checked with mypy.", # [patterns] Add typing to dependency injection
470,"fix typo: ""Python'd"" -> ""Python's""
", # Fix typo in contributing.rst
471,"Documented additional parameters
These are included in a recent PR (https://github.com/tiangolo/fastapi/pull/1166) but not in the docs yet.
* response_model_exclude_none
* response_model_exclude_defaults", # Add info about `exclude_defaults` and `exclude_none`
472,"feat(suggested-solution): Add suggested solution to sentry options conf
Related to https://github.com/getsentry/sentry/pull/47771", # Add AI Suggested Solution to Organization Details
473,"Fixed #23861 -- Added an API to deprecate model fields.
https://code.djangoproject.com/ticket/23861
",
474,"È¢ÑÊµãÁªìÊûú‰øùÂ≠òÂ¢ûÂä†Êç¢Ë°å
Á¨¨140Ë°å ` fout.write(file + ""\t"" + info) ` Êîπ‰∏∫  `fout.write(file + ""\t"" + info + ""\n"")`
Âéü‰ª£Á†Å‰øùÂ≠òÁªìÊûúÊ≤°ÊúâÊç¢Ë°åÔºåÊ†ºÂºèÂêÑËÆ∞ÂΩïÁ≤òÂú®‰∏ÄËµ∑‰∫Ü„ÄÇ",
475,"Update Nginx ciphersuites to use Mozilla Intermediate
Related to #4284, but only partially solves the problem.",
476,"Fix netatmo weatherstation setup error 
## Description:
Check if station data is received before adding the sensor.
Reduce method calls.

**Related issue (if applicable):** fixes #24727 and possibly #22066

**Pull request with documentation for [home-assistant.io](https://github.com/home-assistant/home-assistant.io) (if applicable):** home-assistant/home-assistant.io#

## Example entry for `configuration.yaml` (if applicable):
```yaml

```

## Checklist:
  - [x] The code change is tested and works locally.
  - [ ] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**
  - [x] There is no commented out code in this PR.
  - [x] I have followed the [development checklist][dev-checklist]

If user exposed functionality or configuration variables are added/changed:
  - [ ] Documentation added/updated in [home-assistant.io](https://github.com/home-assistant/home-assistant.io)

If the code communicates with devices, web services, or third-party tools:
  - [ ] [_The manifest file_][manifest-docs] has all fields filled out correctly. Update and include derived files by running `python3 -m script.hassfest`.
  - [ ] New or updated dependencies have been added to `requirements_all.txt` by running `python3 -m script.gen_requirements_all`.
  - [ ] Untested files have been added to `.coveragerc`.

If the code does not interact with devices:
  - [ ] Tests have been added to verify that the new code works.

[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html", # [netatmo] Fix sensor setup## Type of change- [ ] Bug fix- [ ] New feature- [ ] Documentation / docstrings- [ ] Tests- [ ] Other## Checklist- [ ] I've run the latest [black](https://github.com/psf/black) with default args on new code.- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.- [ ] I've added tests for new code.- [ ] I accept that @willmcgugan may be pedantic in the code review.## DescriptionFixes #10083## Checklist- [ ] I've run `format.sh` to lint the changes in this PR.- [ ] I've included any docstring updates needed.- [ ] I've made sure the relevant tests are passing (if applicable).
477,"fix(performance): Remove max from performance histogram
This was copied from the web vitals histogram where the max was needed to render
the baseline marker. This isn't necessary for the landing page, and removing it
gives us a better looking y axis.

# Screenshots

## Before

![image](https://user-images.githubusercontent.com/10239353/115927225-16b27600-a452-11eb-9aa7-c375db929891.png)

## AFter

![image](https://user-images.githubusercontent.com/10239353/115927232-1a45fd00-a452-11eb-8a71-61b19dbfb621.png)
", # Remove max from histogramChart.tsx
478,"Add `RecordVideo` docs
", # [gym] Deprecate Monitor wrapper### DescriptionThe Monitor wrapper is deprecated in favor of gym.wrappers.RecordVideo and gym.wrappers.RecordEpisodeStatistics (see https://github.com/openai/gym/issues/2297).### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/openai/gym/blob/master/CONTRIBUTING.md).- [x] I have performed a self-review of my own code.- [x] My code follows the [style guidelines](https://github.com/openai/gym/blob/master/CONTRIBUTING.md#code-style).- [x] My code passes [tests](https://github.com/openai/gym/tree/master/tests).
479,"BugFix: A single term is larger than the allowed chunk size
Related issue:
https://github.com/jerryjliu/llama_index/issues/1031", # Fix text splitter
480,"Fixed typo
", # Fix typo in C++ Core Guidelines
481,"update readme with data interpreter usage
1. Provide Data Interpreter example in README
2. Streamline README, replace Docker instruction with reference to the doc site", # Update README.md
482,"Toyota: Add Lexus GS F 2016
**Checklist**
- [ ] added entry to CarInfo in selfdrive/car/*/values.py and ran `selfdrive/car/docs.py` to generate new docs
- [x] test route added to [routes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/car/tests/routes.py)
- [x] route with openpilot: ab9b64a5e5960cba|2023-10-17--18-59-12
- [x] route with stock system: ab9b64a5e5960cba|2023-10-14--00-38-19",
483,"‰øÆÂ§çnp.int
", # [ppocr] fix box score
484,"Bump docker/setup-buildx-action from 1 to 2
Bumps [docker/setup-buildx-action](https://github.com/docker/setup-buildx-action) from 1 to 2.

Release notes
Sourced from docker/setup-buildx-action's releases.

v2.0.0

Node 16 as default runtime by @‚Äãcrazy-max (#131)

This requires a minimum Actions Runner version of v2.285.0, which is by default available in GHES 3.4 or later.



Full Changelog: https://github.com/docker/setup-buildx-action/compare/v1.7.0...v2.0.0
v1.7.0

Standalone mode by @‚Äãcrazy-max in (#119)
Update dev dependencies and workflow by @‚Äãcrazy-max (#114 #130)
Bump tmpl from 1.0.4 to 1.0.5 (#108)
Bump ansi-regex from 5.0.0 to 5.0.1 (#109)
Bump @‚Äãactions/core from 1.5.0 to 1.6.0 (#110)
Bump actions/checkout from 2 to 3 (#126)
Bump @‚Äãactions/tool-cache from 1.7.1 to 1.7.2 (#128)
Bump @‚Äãactions/exec from 1.1.0 to 1.1.1 (#129)
Bump minimist from 1.2.5 to 1.2.6 (#132)
Bump codecov/codecov-action from 2 to 3 (#133)
Bump semver from 7.3.5 to 7.3.7 (#136)

v1.6.0

Add config-inline input (#106)
Bump @‚Äãactions/core from 1.4.0 to 1.5.0 (#104)
Bump codecov/codecov-action from 1 to 2 (#101)

v1.5.1

Explicit version spec for caching (#100)

v1.5.0

Allow building buildx from source (#99)

v1.4.1

Fix docker: invalid reference format (#97)

v1.4.0

Update dev deps (#95)
Use built-in getExecOutput (#94)
Use core.getBooleanInput (#93)
Bump @‚Äãactions/exec from 1.0.4 to 1.1.0 (#85)
Bump y18n from 4.0.0 to 4.0.3 (#91)
Bump hosted-git-info from 2.8.8 to 2.8.9 (#89)
Bump ws from 7.3.1 to 7.5.0 (#90)
Bump @‚Äãactions/tool-cache from 1.6.1 to 1.7.1 (#82 #86)
Bump @‚Äãactions/core from 1.2.7 to 1.4.0 (#80 #87)

v1.3.0

Display BuildKit version (#72)

v1.2.0

Remove os limitation (#71)
Add test job for config input (#68)



... (truncated)


Commits

dc7b971 Merge pull request #131 from crazy-max/node16
f55bc08 Merge pull request #141 from crazy-max/fix-test
aa877a9 ci: fix standalone test
130c56f Node 16 as default runtime
See full diff in compare view





[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docker/setup-buildx-action&package-manager=github_actions&previous-version=1&new-version=2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


"," # Update docker.yml to use docker/setup-buildx-action@v2### Describe the changes you have made:Updates docker.yml to use docker/setup-buildx-action@v2### Reference any relevant issues (e.g. ""Fixes #000""):### Pre-Submission Checklist (optional but appreciated):- [ ] I have included relevant documentation updates (stored in /docs)- [ ] I have read `docs/CONTRIBUTING.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/ROADMAP_RELEASE.md`- [ ] I have read `docs/COVERAGE.md`- [ ] I have read `docs/TESTING.md`- [ ] I have performed a self-review of my own code- [ ] I have commented my code, particularly in hard-to-understand areas- [ ] I have made corresponding changes to the documentation- [ ] My changes generate no new warnings- [ ] I have added tests that prove my fix is effective or that my feature works- [ ] New and existing unit tests pass locally with my changes- [ ] I have added Google Colab notebook support for new or updated PRs (or an explanation why not)"
485,"DOC: Corrected code_checks.sh
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).

Towards https://github.com/pandas-dev/pandas/issues/37875

", # [ci] Add examples for end_time
486,"[NFC] polish colossalai/kernel/cuda_native/csrc/multi_tensor_l2norm_k‚Ä¶
‚Ä¶ernel.cu code style"," # [L2Norm] Fix L2Norm kernelFixes #1000## Why are these changes needed?- [ ] Fixes a bug (resolves an issue)- [ ] Adds feature (non-breaking change)- [ ] Breaks the API (fixes a bug, but changes the interface)- [ ] This change requires user interaction## Related issue number- [ ] Fixes #000- [ ] Adds support for #000- [ ] This is a new bug fix for #000- [ ] This is a feature pull request for #000## Checklist- [ ] I have read [contributing wiki page](https://github.com/colossalai/colossalai/wiki/Contributing)- [ ] I have performed a self-review of my own code- [ ] My code follows the [style guidelines](https://github.com/colossalai/colossalai/wiki/Contributing#code-style)- [ ] My code passes [tests](https://github.com/colossalai/colossalai/wiki/Tests)"
487,"fix iqiyi tiltes when accessed with curid=
#1894

test cases:
```
./you-get -i 'http://www.iqiyi.com/v_19rr9y7d7s.html?vfm=m_103_txsp#curid=625521800_eb5dcb7fbd6399a6ef85a45386f51e3b'
site:                Áà±Â•áËâ∫ (Iqiyi)
title:               È≠îÂäõÁæéÈ£ü_20170228Êúü
streams:             # Available quality and codecs
    [ DEFAULT ] _________________________________
    - format:        TD
      container:     m3u8
      video-profile: 720p
    # download-with: you-get --format=TD [URL]

    - format:        HD
      container:     m3u8
      video-profile: 540p
    # download-with: you-get --format=HD [URL]

    - format:        SD
      container:     m3u8
      video-profile: 360p
    # download-with: you-get --format=SD [URL]

    - format:        LD
      container:     m3u8
      video-profile: 210p
    # download-with: you-get --format=LD [URL]
```

```
./you-get -id 'http://www.iqiyi.com/v_19rr9y7d7s.html?vfm=m_103_txsp#curid=598026100_0bf7ea3bed1c77c42590927fba73d3d8'
[DEBUG] get_response: http://www.iqiyi.com/v_19rr9y7d7s.html?vfm=m_103_txsp#curid=598026100_0bf7ea3bed1c77c42590927fba73d3d8
[DEBUG] get_content: http://mixer.video.iqiyi.com/jp/mixin/videos/598026100
[DEBUG] get_content: http://www.iqiyi.com/v_19rr9xpp20.html
[DEBUG] get_content: http://cache.m.iqiyi.com/tmts/598026100/0bf7ea3bed1c77c42590927fba73d3d8/?t=1493013134556&sc=71c5088ffe7f22b3bc0cd452c36709b6&src=76f90cbd92f94a2e925d83e8ccd22cb7
site:                Áà±Â•áËâ∫ (Iqiyi)
title:               È≠îÂäõÁæéÈ£ü_20170106Êúü
streams:             # Available quality and codecs
    [ DEFAULT ] _________________________________
    - format:        TD
      container:     m3u8
      video-profile: 720p
    # download-with: you-get --format=TD [URL]

    - format:        HD
      container:     m3u8
      video-profile: 540p
    # download-with: you-get --format=HD [URL]

    - format:        SD
      container:     m3u8
      video-profile: 360p
    # download-with: you-get --format=SD [URL]

    - format:        LD
      container:     m3u8
      video-profile: 210p
    # download-with: you-get --format=LD [URL]
```

current behavior
```
you-get -i 'http://www.iqiyi.com/v_19rr9y7d7s.html?vfm=m_103_txsp#curid=625521800_eb5dcb7fbd6399a6ef85a45386f51e3b'
site:                Áà±Â•áËâ∫ (Iqiyi)
title:               È≠îÂäõÁæéÈ£ü_20170104Êúü
streams:             # Available quality and codecs
    [ DEFAULT ] _________________________________
    - format:        TD
      container:     m3u8
      video-profile: 720p
    # download-with: you-get --format=TD [URL]

    - format:        HD
      container:     m3u8
      video-profile: 540p
    # download-with: you-get --format=HD [URL]

    - format:        SD
      container:     m3u8
      video-profile: 360p
    # download-with: you-get --format=SD [URL]

    - format:        LD
      container:     m3u8
      video-profile: 210p
    # download-with: you-get --format=LD [URL]
```
title for 19rr9y7d7s got, which is incorrect.

This should also fix #1740", # iqiyi: fix title
488,"[Windows] Create an installer for Certbot
This PR is the first step to create an official distribution channel of Certbot for Windows. It consists essentially in creating a proper Certbot Windows installer.

Usually distributing an application requires, in a way or another, to stabilize the application logic and its dependencies around a given version. On Windows, this usually takes the form of a freezed application, that vendors its dependencies into a single executable.

There are two well-known solutions to create an executable shipping a Python application on Windows: [py2exe](http://www.py2exe.org/) and [pyinstaller](https://www.pyinstaller.org/). However these solutions create self-executable `.EXE` files: you run the `.EXE` file that launches immediately the software.

This is not a end-user solution. Indeed when a Windows user wants to install a piece of software, he expects to find and download an installer. When run the installer would interface with Windows to setup configuration entries in the Registry, update the environment variable, add shortcuts in the Start Menu, and declare a uninstaller entry into the Uninstaller Manager. Quite similarly, this is what you would get from a `.deb` or `.rpm` package.

A solution that builds proper installers is [pynsis](https://pynsist.readthedocs.io/en/latest/). It is a Python project that constructs installers for Python software using [NSIS](https://sourceforge.net/projects/nsis/), the most known free Windows installer builder solution.

This PR uses pynsist to build a Windows installer. The Powershell script to launch the installer build is `.\windows-installer\construct.ps1`. Once finished, the installer is located at `.\windows-installer\build\nsis\certbot-[CERTBOT_VERSION]-win32_install.exe`.

This installer will do the following operations during the installation:
* copy in the install path a full python distribution used exclusively for Certbot
* copy all Python requirements gathered from the `setup.py` of relevant certbot projects
* copy `certbot`, `acme` and all dns plugins packages
* pre-build python binary assets
* create a shortcut on the start menu to open the online Certbot documentation
* register the existence of the application correctly in Windows Registry
* prepare a procedure to uninstall Certbot
* and of course, expose `certbot` executable to the Windows command line, like on Linux, to be able to launch it as any CLI application from Batch or Powershell

This installer support updates: downloading a new version of it and running it on a Windows with existing installation of Certbot will replace it with the new version.

Future capabilities not included in this PR:
* auto-update of Certbot when a new release is available
* online documentation for Windows (that should be the target 
for the created shortcut in Start Menu)
* register a scheduled task for certificate renewal
* installer distribution (continuous deployment + distribution channels)
* method to check the downloaded installer is untampered", # Windows installer
489,"Cache linting venv on CI.
Ensure that we cache the linting virtualenv as well as the pip cache for the `pip install -e langchain` step.

This is a win of about 60-90s overall.

Before:
![image](https://github.com/langchain-ai/langchain/assets/2348618/f55f8398-2c3a-4112-bad3-2c646d186183)

After:
![image](https://github.com/langchain-ai/langchain/assets/2348618/984a9529-2431-41b4-97e5-7f5dd7742651)
", # Add caching for pip install
490,"Update flatpages.txt
Fixed typo
", # Fixes #20060.
491,"[youtube] fix `KeyError: 'url'` on some videos
Hopefully this fixes https://github.com/soimort/you-get/pull/2811.", # [youtube] fix signature cipher
492,"Remove stale action workflow file
", # Remove stale workflow
493,"Slight correction to <str>.strip descriptions
Removes \ (or whitespace) from start of \ up to the first
non-\ and from the end of \ up to the last non-\.

[Python 3 Docs](https://docs.python.org/3/library/stdtypes.html?highlight=strip#str.strip)", # Fixes #1006
494,"fix download issue
thx to @GianlucaFicarelli

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [ ] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)
- [x] this is a fix motivated by @GianlucaFicarelli

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

closes #18741 

### Description of your *pull request* and other information

Explanation of your *pull request* in arbitrary form goes here. Please make sure the description explains the purpose and effect of your *pull request* and is worded well enough to be understood. Provide as much context and examples as possible.", # [dtube] fix ipfs url
495,"ÈíàÂØπxx_net.shÂÅöÁöÑ‰øÆÊîπ
1,mv xx_net.sh to 'root' dir,for no need to change the service link when do update.
2,according code/version.txt to start the specific version xx_net
3,add 'status' command for service", # xx-net: add status
496,"[Doctest] Add `configuration_decision_transformer.py`
Add `configuration_decision_transformer.py` to `utils/documentation_tests.txt` for doctest.

Based on issue https://github.com/huggingface/transformers/issues/19487

@ydshieh could you please check it?
Thank you :)", # Fix documentation for DecisionTransformerConfig
497,"Added a warning that the signin email link might be going to spam
", # Fix typo in verify page
498,"Refresh Multi Modal Doc to include more docs
# Description

Adding more docs into MM doc for use cases part

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [x] Added new notebook (that tests end-to-end)
- [ ] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] I have added Google Colab support for the newly added notebooks.
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] I ran `make format; make lint` to appease the lint gods
", # Add Multi-Modal LLM use-case
499,"na_ontap_dns: Add new parameter skip_validation
##### SUMMARY

Add skip_validation parameter to bypass the DNS configuration check on the Netapp Ontap. Refers to the skip-config-validation parameter on the SDK.



##### ISSUE TYPE

- Feature Pull Request

##### COMPONENT NAME

na_ontap_dns

##### ADDITIONAL INFORMATION


Tested on FAS8200 with DOT 9.4 with DNS and domain not reachabled (Create and Modify): OK


```paste below

```
", # Add skip_validation option to na_ontap_dns moduleAdd skip_validation option to na_ontap_dns module.
500,"[ie/hotstar] Support `/clips/` URLs
Closes #7699


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at 462b368

### Summary
üéûÔ∏èüîß‚úÖ

<!--
1.  üéûÔ∏è - This emoji represents the `clips` category, which is a type of short video content that HotStar offers. It also suggests the idea of extracting or downloading clips from the website.
2.  üîß - This emoji represents the update to the URL regex, which is a technical task that involves modifying the pattern that matches HotStar URLs. It also suggests the idea of fixing or improving something.
3.  ‚úÖ - This emoji represents the addition of a test case, which is a way of verifying that the extractor works as expected and handles different scenarios. It also suggests the idea of checking or confirming something.
-->
Support `clips` category in HotStar extractor. Update `yt_dlp/extractor/hotstar.py` to handle `clips` URLs and extract metadata from `content` API endpoint.

> _We're the extractors of the night_
> _We rip the clips from HotStar's site_
> _We update our regex to catch them all_
> _We map them to the content and we make them fall_

### Walkthrough
*  Update regex for matching HotStar video URLs to include `clips` category ([link](https://github.com/yt-dlp/yt-dlp/pull/7710/files?diff=unified&w=0#diff-0a6703759f63eb9f8d2a82b989320bcfddf8e3cd634bbc3b4e4c10e643f6ed9eL87-R87))
*  Add new key-value pair to `_FEED_TYPES` dictionary to map `clips` type to `content` endpoint ([link](https://github.com/yt-dlp/yt-dlp/pull/7710/files?diff=unified&w=0#diff-0a6703759f63eb9f8d2a82b989320bcfddf8e3cd634bbc3b4e4c10e643f6ed9eR175))
*  Add test case for a video from the `clips` category with expected metadata and format information ([link](https://github.com/yt-dlp/yt-dlp/pull/7710/files?diff=unified&w=0#diff-0a6703759f63eb9f8d2a82b989320bcfddf8e3cd634bbc3b4e4c10e643f6ed9eR146-R157))




", # [hotstar] fix hotstar.py
501,"Add NAVER API


- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added NAVERAdded NAVER to the list of supported social networks.
502,"Do not hardcode the home directory
Fixes #369

Use [`os.path.expanduser()`](https://docs.python.org/3/library/os.path.html#os.path.expanduser) to avoid hardcoding the home directory.", # Use os.path.expanduser() to get user's home directoryThis is a small change to the hackingtool.py file. It uses os.path.expanduser() to get the user's home directory. This is a more portable solution than using /home/hackingtoolpath.txt.
503,"üîß Add new Gold Sponsor vim.so üéâ
üîß Add new Gold Sponsor vim.so üéâ", # Add Vim.so sponsor
504,"Fix an exception when auto-casting dicts to fp16
Deepspeed raises an exception when using fp16 auto_cast mode with a model that takes a dictionary as input. Quick test on `0.7.3` to display what I'm talking about:

```
$ cat test.py
import torch
import deepspeed
import argparse

parser = argparse.ArgumentParser(description='Test model')
parser.add_argument('--local_rank', type=int, default=-1,
                    help='local rank passed from distributed launcher')
parser = deepspeed.add_config_arguments(parser)
cmd_args = parser.parse_args()

class ValueDoubler(torch.nn.Module):
    def forward(self, d):
        return d[""value""] * 2

m = ValueDoubler()
m, _, _, _ = deepspeed.initialize(args=cmd_args, model=m)

print(""Torch: "", torch.__version__)
print(""DeepSpeed: "", deepspeed.__version__)
print(""New value: "", m({""value"": 1.0}))
$ cat ds.json
{""fp16"": {""auto_cast"": true, ""enabled"": true}, ""train_batch_size"": 1}
$ deepspeed test.py --deepspeed --deepspeed_config ds.json
...
Torch:  1.12.1+cu102
DeepSpeed:  0.7.3
Traceback (most recent call last):
  File ""test.py"", line 20, in 
    print(m({""value"": 1.0}))
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/utils/nvtx.py"", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/runtime/engine.py"", line 1664, in forward
    inputs = self._cast_inputs_half(inputs)
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/runtime/engine.py"", line 1693, in _cast_inputs_half
    new_inputs.append(self._cast_inputs_half(v))
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/runtime/engine.py"", line 1697, in _cast_inputs_half
    for k, v in inputs:
ValueError: too many values to unpack (expected 2)
```

And testing on master (I had to fuss it a little to get master to work):
```
$ deepspeed test.py --deepspeed --deepspeed_config ds.json
...
Torch:  1.12.1+cu102
DeepSpeed:  0.7.4+eed4032
Traceback (most recent call last):
  File ""test.py"", line 20, in 
    print(m({""value"": 1.0}))
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/utils/nvtx.py"", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/runtime/engine.py"", line 1664, in forward
    inputs = self._cast_inputs_half(inputs)
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/runtime/engine.py"", line 1693, in _cast_inputs_half
    new_inputs.append(self._cast_inputs_half(v))
  File ""/data/home/mattks/.local/share/virtualenvs/test-t-h-loqS/lib/python3.8/site-packages/deepspeed/runtime/engine.py"", line 1697, in _cast_inputs_half
    for k, v in inputs:
ValueError: too many values to unpack (expected 2)
```

This PR fixes this:
```
$ deepspeed test.py --deepspeed --deepspeed_config ds.json
Torch:  1.12.1+cu102
DeepSpeed:  0.7.4+45d39d7
New value:  2.0
```", # Fix RuntimeEngine.half()Fix RuntimeEngine.half()
505,"[requires.io] dependency update on main branch
",
506,"removed Resource > Website > Python Hackers due to dead link (status ‚Ä¶
I'm suggesting that that you remove a dead resource.  The URL no longer exists.  ", # Remove Python Hackers
507,"[3.9] bpo-39883: Use BSD0 license for code in docs (GH-17635)
The PSF board approved this use.
(cherry picked from commit e223d06a8b2067c68e9f97c4628c2b0f056dcae6)


Co-authored-by: Todd 


https://bugs.python.org/issue39883

"," # [3.9] BPO-39883: Make code, examples, and recipes in the Python documentation be licensed under the more permissive BSD0 license in addition to the existing Python 2.0 license.<!--Thanks for contributing a pull request! Please ensure you have taken a look atthe contribution guidelines: https://docs.python.org/3/CONTRIBUTING.html--!"
508,"#1096: Rule: Bypass failed git hook

#1096 ", # Add git_hook_bypass rule
509,"Created folder for losses in Machine_Learning
### Describe your change:
Added a directory named `losses` in `machine_learning` that contains two loss functions namely `binary_cross_entropy.py` and `mean_squared_error.py`


* [x] Add an algorithm?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [x] If this pull request resolves one or more open issues then the description above includes the issue number(s) with a [closing keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue): ""Fixes #ISSUE-NUMBER"".
", # Add binary cross-entropy and mean squared error loss functions
510,"Add Python 3.8 official support
Fixes #4085", # [3.8] Remove Leveldb storage backend# What does this PR do?Removes the Leveldb storage backend from the scrapy/extensions/httpcache.py module.# How did you achieve it?- [x] I have the latest version of the codebase- [x] I have done a self-review of my code- [x] I have tested the code on my own machine- [x] I have added an entry to the latest `doc/source`- [x] I have followed the [development checklist][dev-checklist][dev-checklist]: https://github.com/scrapy/scrapy/blob/master/scrapy/development.rst#development-checklist
511,"Remove show footer embed option
## Describe your changes

This PR fully removes the useless `showFooter` embed option. There isn't any need for this option since we recently removed the footer.

## GitHub Issue Link (if applicable)

- Closes https://github.com/streamlit/streamlit/issues/7785

## Testing Plan

- Updated tests

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",
512,"Primer: Virtualenv is now formatted with newest Black
Re: https://github.com/pypa/virtualenv/pull/1939"," # Remove expect_formatting_changes from primer.jsonThis is a minor change, but it's a good idea to remove the expect_formatting_changes from primer.json. This is because the primer.json is not used to create the virtualenv, but rather to create the black_primer."
513,"Errbot chatbot (http://errbot.io)
## Why this framework/library/software/resource is awesome?

The easiest and most popular chatbot to implement ChatOps in Python.
Very gentle learning curve but very powerful once you start to master
the tool (conversation flows, security, markdown formatting and
template, ...). It comes with developer friendly text and graphical
consoles to debug your plugins easily.

It is compatible out of the box with Slack, Hipchat, XMPP, IRC and lot
more. But you can also extend it easily to support a custom chat system.

Already 300+ public plugins are available !
Check out the list here: https://github.com/errbotio/errbot/wiki
## Vote for this pull request

Who agrees that this change should be merged could add your reactions (e.g. :+1:) to this pull request.
", # Add ErrbotAdded Errbot to the list of awesome tools.
514,"Allow to open images in new browser tab by MMB.
## Description

Basically, as a shortcut for context-menu -> Open Image in New Tab.

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Fixes #1000
515,"Add to authors and fix case
Fix sentence case requests by sigmavirus24 here: https://github.com/kennethreitz/requests/pull/2168
Added myself to authors.
", # Fix typo in AUTHORS.rst
516,"bug fix - run_internal_graph()
See #9565", # Fix masking for multiple outputsFixes #1000.
517,"infra: rm api build CI
", # Remove API docs build workflow
518,"feat/startup-script: Feature to avoid package installation errors when installing custom nodes.
Currently, in ComfyUI-Manager, automatic installation of dependencies is performed when installing custom nodes. However, this can lead to module conflicts or failure to install due to file locking issues, especially in Windows environments.

To address this problem, a solution has been implemented where the imports are minimized at the top of main.py, allowing the install script to run in an environment with minimal imports.", # Add prestartup script executionAdds execution of prestartup scripts for custom nodes.
519,"UI: lazy onboarding widgets init
`OnboardingWindow::showEvent` is always called on startup  which will cause the TermsPage to be initialized every time( in `TermsPage::showEvent`).~and the screen may flicker.~", # Fix offroad onboarding
520,"Vevo sig changed again, please update for us! Thanks very much! (fixes #...
...1375)
", # Fix YouTube extractorFixes #10064
521,"Enum.2: typo/formatting
", # Fix typo in C++ Core Guidelines
522,"Pin to PyTest 8.0.0
Fix failures in nv-accelerate-v100 unit tests.

Fix running on this PR: https://github.com/microsoft/DeepSpeed/actions/runs/7923894998/job/21634533848
Original failure [here](https://github.com/microsoft/DeepSpeed/actions/runs/7961285826/job/21748664124?pr=5129#step:7:415):
```
    from _pytest.doctest import (
E   ImportError: cannot import name 'import_path' from '_pytest.doctest' (/tmp/actions-runner/_work/DeepSpeed/DeepSpeed/unit-test-venv/lib/python3.8/site-packages/_pytest/doctest.py)
```", # bump pytest to 8.0.0Bump pytest to 8.0.0.
523,"Fixed docstrings in keras/optimizer_v2/learning_rate_schedule.py
Minor doc correction:
```
The schedule a ... -> The schedule is a ... 
```", # Fix typo in docstring for LearningRateSchedule
524,"Fix code snippet in config.rst for env vars Fixes #3117
Changes the snippet in the config documentation to no longer assign a bool as the default value from os.environ.get()", # [3.1.0] Fix config.rst
525,"Added rasa_nlu(Natural language understanding) to the list of python-nlp
Natural Language Understanding(NLU) is the next step of NLP. There are very few libraries implementing NLU. As of now, we can include it to the list of python-nlp. Later, when we have sufficient NLU libraries, we can create a separate section for the same.

Please add this to the list,

Thanks,
Hitesh", # Add Rasa NLUAdd Rasa NLU to the list of general-purpose machine learning tools.
526,"Fixed #34513 -- Added system check for relational fields in ModelAdmin.list_display.
Fixed [ticket #34513](https://code.djangoproject.com/ticket/34513)
Add system check for wrong related fields in `ModelAdmin.list_display`.", # Fix #20833: Admin check for many-to-many fieldsFixes #20833.
527,"Use xfail marker for a test expected to fail without Internet connection
This is only a minor improvement on the great work of https://github.com/kennethreitz/requests/pull/2859 that permits to run tests on hosts without Internet connection without failures.
"," # [MRG+1] Add xfail for auth on redirect off host### Describe your change:Add xfail for auth on redirect off host### Reference any relevant issues (e.g. ""Fixes #000""):### Pre-Submission Checklist (optional but appreciated):- [ ] I have included relevant documentation updates (stored in /docs)- [ ] I have read `docs/CONTRIBUTING.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/ROADMAP.rst`- [ ] I have read `docs/CHANGELOG.md`- [ ] I have read `docs/COPYRIGHT.md`"
528,"Fix device problem
Before, the one_hot could only run in device='cuda'. Now it will run on input device automatically.", # fix mixup target
529,"Import urllib3's Retry location from the right place
Importing from urllib3's top-level location causes the namespace to be
urllib3.util.retry.Retry instead of
requests.packages.urllib3.util.retry.Retry. Without this fix, an using
requests with an un-vendored version of urllib3 will break when urllib3's
retry handling kicks in.

Closes shazow/urllib3#567
", # Fix #1006Fix #1006
530,"minor cleanup and dead code removal in bootstrap.py
Just some minor cleanup I did while looking through bootstrap.py to better understand what it does", # Remove chmod docker.sock fixThis is a followup to #1000.
531,"Falcon support
- Include 'einops' in requirements for Falcon support
- Append Falcon details to README regarding 'trust-remote-code'
- Implement 'trust-remote-code' option in UI
- Integrate Falcon configuration", # Add autogptq optionAdd autogptq option
532,"Fix assignment of template field in `__init__` in `analyticdb_spark.py`
related: https://github.com/apache/airflow/issues/36484

removed the templated field because it's been run over in the constructor and has no meaning. (this can be cause an issue if someone will inherited from those classes).

fix:
```
AnalyticDBSparkSQLOperator's constructor lacks direct assignments for instance members corresponding to the following template fields (i.e., self.field_name = field_name or 
super.__init__(field_name=field_name, ...) ):
['spark_params']
AnalyticDBSparkSQLOperator's constructor contains invalid assignments to the following instance members that should be corresponding to template fields (i.e., self.field_name = field_name):
['self.spark_params']
AnalyticDBSparkBatchOperator's constructor lacks direct assignments for instance members corresponding to the following template fields (i.e., self.field_name = field_name or 
super.__init__(field_name=field_name, ...) ):
['spark_params']
AnalyticDBSparkBatchOperator's constructor contains invalid assignments to the following instance members that should be corresponding to template fields (i.e., self.field_name = field_name):
['self.spark_params']
```

cc: @shahar1


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->




---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
", # [alibaba] fix analyticdb_spark operator
533,"Add fingerprint for 2019 Honda Civic Hatchback
Add fingerprint for Honda Civic Hatchback 1.0T Elegance (Europe - Poland).

Route: 742cb48652d68d6d|2021-10-01--17-07-24
Discord user: miglanz", # Honda: add 37805-5AK-T530
534,"[docs] streaming contents: use app.response_class
Examples should use app.response_class to encourage code that doesn't need to be changed should the response class be customized later on.", # Remove unnecessary imports from docs
535,"Create Web_Scraper.py
A python program to scrape job openings from naukri.com", # Web scraper
536,"ja: Fix translation in horizontal scaling section
- The Japanese translation is ambiguous about ‚Äúvertical scaling‚Äù means scaling out or scaling up.
- The word ‚Äúexpensive‚Äù is missing in the Japanese translation.", # ÁøªË®≥
537,"Fix training for newer PyTorch builds
When training, the in-place operations in `process_tokens()` can cause an error during the backward pass. This PR fixes that.", # Fix sd_hijack_clip
538,"[infoq] Add audio only format if available
Refactor cookie code into a function.
Renamed formats to http_video, http_audio, rtmp_video
Renamed extract functions to video instead of videos as they return
one or no video.

## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Add audio only format for InfoQ extractor if available"," # [infoq] fix http downloads## Please follow the guide below- You will be asked some questions, please read them **carefully** and answer honestly- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])- Use *Preview* tab to see how your *pull request* will actually look like---### Before submitting a *pull request* make sure you have:- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)### What is the purpose of your *pull request*?- [x] Bug fix- [ ] Improvement- [ ] New extractor- [ ] New feature---### Description of your *pull request* and other informationThis PR fixes the http downloads for infoq.com. The http downloads are not working properly and the rtmp downloads are not working at all. This PR fixes the http downloads and adds the rtmp downloads."
539,"rawgpsd tests
closes #28382", # [rawgps] fix rawgpsd- fix rawgpsd- fix rawgpsd tests- fix rawgpsd tests timeout- fix rawgpsd tests timeout
540,"Adds support for using message metadata.
# Description
Modifies the `load_data` method of the Discord Reader class with an additional optional parameter to return complete message metadata, namely by way of a boolean value `complete_metadata` (defaulted to false). 

This change is needed for users who wish to query information about the users and allows for further advanced filtering (such as NSFW content, among others). This change requires no dependency changes.


Fixes # (issue)

## Type of Change

Please delete options that are not relevant.


- [x] New feature (non-breaking change which adds functionality)
- [x] This change requires a documentation update

# How Has This Been Tested?

Ran a modified version of the [Discord Reader Demo](https://gpt-index.readthedocs.io/en/stable/examples/data_connectors/DiscordDemo.html) locally both with and without the flag and queried the index/engine for a list of users who sent messages in the specified channel (query: `list all users who posted to the channel` produced an output similar to `There is no information provided about the users who posted ideas to the channel.` with the flag set to `False`, and produced an accurate list when the metadata was provided by way of the override flag.

- [x] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [x] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [x] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [x] New and existing unit tests pass locally with my changes
- [x] I ran `make format; make lint` to appease the lint gods
", # Fix DiscordReader
541,"introduce six lib, used python-modernize + manual fix
",
542,"Combine cookies from original request and session file
This pull request should address #824. Cookies that are set through a request in the CLI are added to the session cookies. @gmelodie",
543,"West Australia open data


- [X] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [X] My addition is ordered alphabetically
- [X] My submission has a useful description
- [X] The description does not have more than 100 characters
- [X] The description does not end with punctuation
- [X] Each table column is padded with one space on either side
- [X] I have searched the repository for any relevant issues or pull requests
- [X] Any category I am creating has the minimum requirement of 3 items
- [X] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add West Australia Open Data
544,"Fix Rag example docstring
# What does this PR do?

<!--
Congratulations! You've made it this far! You're not quite done yet though.

Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.

Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.

Once you're done, someone will review your PR shortly (see the section ""Who can review?"" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.
-->



Fixes #7829


## Before submitting
- [x] This PR fixes a typo or improves the docs (you can dimiss the other checks if that's the case).
- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests), 
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to the it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests? 


## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors which may be interested in your PR.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

 albert, bert, XLM: @LysandreJik 
 GPT2: @LysandreJik, @patrickvonplaten
 tokenizers: @mfuntowicz
 Trainer: @sgugger
 Benchmarks: @patrickvonplaten
 Model Cards: @julien-c
 Translation: @sshleifer
 Summarization: @sshleifer
 examples/distillation: @VictorSanh
 nlp datasets: [different repo](https://github.com/huggingface/nlp)
 rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)
 Text Generation: @patrickvonplaten, @TevenLeScao
 Blenderbot, Bart, Marian, Pegasus: @sshleifer
 T5: @patrickvonplaten
 Rag: @patrickvonplaten, @lhoestq
 EncoderDecoder: @patrickvonplaten
 Longformer, Reformer: @patrickvonplaten
 TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten
 examples/seq2seq: @sshleifer
 examples/bert-loses-patience: @JetRunner
 tensorflow: @jplu
 examples/token-classification: @stefan-it
 documentation: @sgugger
 -->
", # [rag] fix bug in generate
545,"Remove already migrated cache e2e test
## Describe your changes

This test already got migrated to https://github.com/streamlit/streamlit/blob/develop/e2e_playwright/st_cache_data.py using `cache_data`. The spec also already got deleted, so the test script is not even been run anymore.

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
", # Remove cached_widget_replay_widget_key.pyThis file was never used and was just a copy of cached_widget_replay_widget_key.py.
546,"IP address regex updated to not provide a false positive
Updated the IP address regex from `\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b` to `^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$` the latter will not provide a false positive. The old style regex would match anything as long as it's in the format `0.0.0.0` including `999.999.999.999` see [here](https://regex101.com/r/hcQKT9/5) for examples. The newer style regex will not match anything over `255.255.255.255` see [here](https://regex101.com/r/hcQKT9/3) for examples of the new regex.

Basic examples:

```
>>> import re
>>> IP_REGEXS = [r""\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b"", r""^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$""]
>>> IP_ADDRS = [""127.0.0.1"", ""255.255.255.255"", ""999.999.999.999"", ""257.12.34.543"", ""12.09.87.24""]  # Only the first two should match (127.0.0.1, 255.255.255.255)
>>> for item in IP_REGEXS:
	for ip in IP_ADDRS:
		if re.match(item, ip):
			print(""{} matched {}"".format(item, ip))
		else:
			print(""{} did not match {}"".format(item, ip))

			
\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b matched 127.0.0.1
\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b matched 255.255.255.255
\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b matched 999.999.999.999
\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b matched 257.12.34.543
\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b matched 12.09.87.24
^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$ matched 127.0.0.1
^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$ matched 255.255.255.255
^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$ did not match 999.999.999.999
^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$ did not match 257.12.34.543
^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$ did not match 12.09.87.24  # Did not match because ..09.. is not a valid IP address, valid would just be 9
>>> 
```", # Fix IP regex
547,"bump 290
", # bump version
548,"Clear sampler and garbage collect before decoding images to reduce VRAM
## Description

Follow-up to https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/12514, more significant VRAM reduction. For a batch size of 4 with hires fix (512x512 -> 1024x1024) this cut off around 2GB of VRAM for me. For a **single** 512x512 @ hr = 2 image (not part of a batch), it cut off around 750MB, and 512x768 @ hr = 2 a bit over 1GB.
This was being done [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/da80d649fd6a6083be02aca5695367bd25abf0d5/modules/processing.py#L1105-L1108) but it can be performed even earlier and should be since decoding the latents is pretty heavy.

~~I hadn't tested this with SDXL yet, not sure if this causes any issue for the refiner. I'm assuming it doesn't but I haven't taken the time to review how that's implemented yet. Probably will reduce VRAM usage for SDXL in general though too if this works as I expect.~~ Occurred to me this is not related to SDXL code at all, so this doesn't affect it.

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # [MRG] Remove sampler and gc after token merging
549,"Fixed links to Sphinx docs.
dependent on https://github.com/sphinx-doc/sphinx/pull/4801", # Fix typo in writing-documentation.txt
550,"hwp
Added hwp reader module. ", # Add HWPReaderAdd HWPReader
551,"Fix gan128
This is a fix to GAN128 to patch out the multi gpu until Keras updates their upstream issue (as mentioned in #287 )

In addition, while I was debugging, I fixed the exception handling in train.py so that it properly passes errors that it doesn't catch..", # [GAN128] Fix multi-gpu issue
552,"Tests on traceback to 100% coverage
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [x] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/ambv/black) with default args on new code. **But** there was a file (`tests/_card_render.py`) about which black complained, but this one isn't included in the changes.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Another small contribution to #37 . I am not so sure about the last two tests, because I couldn't exactly pinpoint what the traceback is supposed to do in those cases. 

Also: I added a `no cover` statement. I noticed that when I add a print statement before the `break`, both the `break` and the print are reached according to coverage (which makes sense). When I remove the print, the `break` isn't reached anymore. Not sure what happens there, might be a bug in ~~pytest~~ _coveragepy_?

Happy to make some changes / additions to this PR. Let me know if you need or want it. Thanks!


**Edit:** formatting and small change in wording", # [traceback] Add tests for syntax errorsAdd tests for syntax errors.
553,"Add support for specifying (persistent) id for SVG exports
As part of Airflow's CI we save SVG images of our command's help output and commit them to git.

Without this change a single character change in the help text results in every single class and id in the SVG changing, which makes the diffs unreadable.

This adds an option for us to be able to specify a fixed prefix so that our git diffs are minimized.

(I also tided up the help docstring for export_svg and save_svg which didn't match signature any more)
", # Add unique_id to export_svgAdd unique_id to export_svg.
554,"Prevent first part of KoboldAI API responses from getting cut off with --chat enabled
This is related to issue [1053](https://github.com/oobabooga/text-generation-webui/issues/1053)

I'm not sure what the intent of the [len(prompt):] part was, but it causes the first part of API responses to be cut off.", # Add token count endpointAdds a token count endpoint to the KoboldAI API.
555,"Not sorting OrderedDict
If the input is already an OrderedDict, its keys were getting sorted (as `isinstance(spaces, dict)` evaluates to `True`), which is usually not desired.", # [gym] Fix dict space
556,"Add ability to pass `response` to `HTTPError()`
Just a little refactoring, but it seems nicer to me to be able to pass
the response when constructing the `HTTPError` instance instead of
constructing it and then changing the member variable.
", # Add response to HTTPError
557,"Fixed #33515 -- Prevented recreation of migration for ManyToManyField to lowercased swappable setting.
ticket-33515

Thanks Chris Lee for the report.

Regression in 43289707809c814a70f0db38ca4f82f35f43dbfd.

Refs ticket-23916.", # Fix #33515: Prevent infinite migrations for swappable ManyToManyFieldFixes #33515.
558,"Fix import ordering s.t. future versions of pylint won't warn on it.
pylint gets more strict about import order in the future, so adjust it now to make upgrading smoother. pylint is following the order from PEP-8:

> Imports should be grouped in the following order:
> 1. standard library imports
> 2. related third party imports
> 3. local application/library specific imports
> 
> You should put a blank line between each group of imports.
", # Remove unused imports
559,"Singly linked list with all operations
", # Singly Linked List
560,"add vyos action plugin for handling local operations
This plugin extends the functions of the net_config plugin to vyos
", # vyos_config: add vyos_config action
561,"fsync_dir: remove goto
", # Fix fsync_dir
562,"[XMinus] Added new extractor
New extractor for x-minus.org as requested in #4300 
", # [xminus] Add support for x-minus.org
563,"Rename GCD File
GCD was wrongly written as ""Greater Common Divisor"", instead of ""Greatest Common Divisor"".", # Fix typo in gcd function
564,"E.30: Remove suggestion to use `throw()`
Removed the suggestion to use `throw()` from E.30 (""Don't use exception specifications""), as it was deprecated by C++11, and is rejected by C++20.", # Fix typo in C++ Core Guidelines
565,"[version] bump version to 0.8.9
", # Bump llama_index to 0.8.9Bump llama_index to 0.8.9
566,"üìù Update `Annotated` notes in `docs/en/docs/tutorial/schema-extra-example.md`
When working on the translation, I noticed that this page is missing the annotated tips that can be found in the rest of the documentation (I checked, and it's the only page where they're missing).", # Add tip to use Annotated version if possible### Describe your change:Add tip to use Annotated version if possible.### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.md#start-contributing).- [x] I have performed a self-review of my own code.- [x] My code follows the [style guidelines](https://github.com/apache/airflow/tree/main/style).- [x] My code passes [tests](https://github.com/apache/airflow/tree/main/tests).
567,"#N/A: Improve how version is fetched for all shells
üêö‚Ñπ",
568,"Fix docs URL in submit button error message
The warning displayed when a form is missing a submit button contains an incorrect link to the relevant section of our API reference. 

**What it says:**
https://docs.streamlit.io/api.html#form

**What it should say:**
https://docs.streamlit.io/api.html#streamlit.form", # Fix typo in button docs link
569,"Optimized BaseDatabaseSchemaEditor._effective_default().
This eliminates an unneeded call to `datetime.now()` when `field.get_internal_type()` equals `""DateTimeField""`.", # Fix #28222: Fix timezone.now() for DateField and TimeFieldFixes #28222
570,"Added celery worker container to github actions 
Added worker and worker beat to ansible playbook as requested in the discord chat 

@olliestanley Let me know if anything major is missing ", # Add oasst-backend-worker and oasst-backend-worker-beat to the release workflow
571,"üíö Disable Gitter notification as it's currently broken
üíö Disable Gitter notification as it's currently broken

...no idea why yet. üòî", # Remove env from publish workflow
572,"Use name in xyz_grid

**Describe what this pull request is trying to achieve.**
X/Y/Z grid was still using the old hash, prone to collisions. This changes it to use the new `shorthash`, and calculates it if not yet known.

Should fix #10521.

**Additional notes and description of your changes**


Had the same issue as poster of issue #10521, where X/Y/Z grid would sometimes load the wrong model. Found out that in my case it was due to the hashes colliding, as X/Y/Z was using the old hash. This changes to use the new shorthash. Also, the shorthash is calculated if it wasn't known before. No extra work is done since it would otherwise be calculated while loading anyway.

**Environment this was tested in**

Should work on all platforms where loading models by shorthash works.

Tested on:
 - OS: Windows, Linux
 - Browser: Firefox
 - Graphics card: N/A (Nvidia RTX3070)", # Fix xyz_grid.py
573,"press enter to submit chat prompt
close #2518 ", # Fix ChatForm onKeyDown
574,"Basic documentation for custom_code.py template
Title says it all. Not sure I'm being totally accurate or missing anything else useful, I'm a bit of a novice.", # Add title and ui methods to Script classAdd title and ui methods to Script class.
575,"Update FAQ to indicate components can go in the sidebar
", # Add st.sidebar exampleAdd st.sidebar example
576,"Add Pusher's Beam Api
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Added Pusher Beams APIAdded Pusher Beams API to the list of APIs.
577,"fix partition activations issue when mp=2 and pp=2
The issue is caused by the original input tensor not passed from forward to backward, when using ctx.save_for_backward(), it is fixed by saving as a context attribute.
Also adding a new utility function for printing backward tensors, it is useful in debugging this type issues.

Fix #1538"," # [deepspeed] Print backward tensors## Why are these changes needed?## Related issue number (if applicable)## Checks- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.- [ ] I've run `format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed for https://docs.github.com/en/github/writing-on-github/about-code-documentation- [ ] I've made sure the relevant tests are passing (if applicable)."
578,"Test BipedalWalker hardcore kwargs. Refer to #2767
As a continuation of  #2767 I'm adding a test for the argument `hardcore` of BipedalWalker. The `hardcore=False` version create only grass terrain while the `hardcore=True` version create also pit, stumps and ladders.", # Add test for BipedalWalker hardcore creation
579,"CLN: Deprecation of assert_
#7131: Run s/self.assert_(/self.assertTrue( on remaining instances I can find. These were the multi-line expressions, and I tried to retain the formatting of the expressions
",
580,"Fix for ""Scheduler selection"" #15333
## Description

- Fix ""X/Y/Z plot"" [not working](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/15333#issuecomment-2014964014) with ""Schedule type""
- Fix ""Schedule type"" not being saved to ""params.txt""

## Screenshots/videos:
![Screenshot 2024-03-23 004916](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/44464226/840dc222-23a0-438f-85e9-8859c4cbbbf8)


## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # [sd] Add schedulers to xyz_grid
581,"fix #4280
This PR should fix #4280 on master, I'll follow up with a test on the sans-io branch.", # Fixes #1006
582,"[requires.io] dependency update on main branch
", # bump requests to 2.25.2
583,"[3.1.x] Added admin translatable string.
"," # Add missing translations for Django 3.1.1<!--Thanks for your contribution!Please read this comment in its entirety. It's quite important.# Pull Request titleIt should be in the following format:```bpo-XXXX: Summary of the changes made```Where:- `bpo-XXXX` is the issue number in the https://bugs.python.org.- `XXXX` is the issue number within that bug fix.Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.# Backport Pull Request titleIf this is a backport PR (PR made against branches other than `master`),please ensure that the PR title is in the following format:```[X.Y]  (GH-XXXX)```Where:- `[X.Y]` is the branch name, in this case, `3.1.1`.- `GH-XXXX` is the PR number from `master`.-->## Type of changes- [ ] Bug fix- [ ] New feature- [ ] Documentation / docstrings- [ ] Tests- [ ] Other## Checklist- [ ] I have updated `CHANGELOG.md` where appropriate.- [ ] I have added an entry in `AUTHORS.md` if necessary.- [ ] I have added tests that prove the change is effective.- [ ] I have added Google Analytics tracking code. See README.md for more information.- [ ] I have added an entry in `master` that points to this PR.## Description<!--Thank you for contributing to Django!Please be sure to include your name in a comment above.--->### Before submitting a pull request, review the following:- [ ] This PR fixes a typo or improves the docs (cherry picked from the latest master branch).- [ ] This PR adds/changes functionality (cherry picked from the latest master branch).- [ ] This PR requires a new/updated dependency (cherry picked from the latest master branch).### In order to be accepted and merged into Django,- [ ] the code must be in public view (make sure the relevant files are included in `AUTHORS.md`)- [ ] the code must pass `python -m flake8`- [ ] the code must pass `git diff upstream/master -u -- ""*.py"" | flake8 --diff`- [ ] the code must pass `git diff upstream/master -u -- ""*.py"" | tox`### Description<!--Thanks for contributing to Django!In order to help make things go a little more smoothly, please answer these questions:--->### What is the purpose of your *pull request* (please be concise)?<!--Additional information to go above. Please be concise.--->### Any other comments?<!--Please be sure to include your name in a comment above.--->"
584,"Add OpenVINO metadata to export
Write .yaml file automatically when exporting model to openvino to be used during inference

<!--
Thank you for submitting a YOLOv5 üöÄ Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ‚úÖ [Contributing Guide](https://github.com/ultralytics/yolov5/blob/master/CONTRIBUTING.md) for more details.
-->


## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Improved metadata handling for OpenVINO exports and model class name loading in YOLOv5.

### üìä Key Changes
- üîß Added `yaml` import for metadata handling.
- ‚öôÔ∏è Modified `export_openvino` function to include the model parameter.
- ‚ú® OpenVINO export now saves a `meta.yaml` file with model stride and class names.
- üîç The `__init__` method in `models/common.py` no longer loads class names from `data.yaml` directly.
- üì¶ New `_load_metadata` method in `MultiBackend` class to load metadata from `meta.yaml`.
- üõ†Ô∏è Refactored code related to warmup to ensure GPU model warmup.

### üéØ Purpose & Impact
- üîÑ The changes allow for better integration and metadata management when exporting models to OpenVINO format, enabling users to retain important information about the model such as stride and class names.
- üß† This improves the ease of use and compatibility of YOLOv5 models with the OpenVINO toolkit, potentially broadening the user base involved in deploying YOLOv5 on different platforms.
- üèÉ‚Äç‚ôÇÔ∏è Warmup refactoring ensures that the models are correctly primed for inference, particularly on GPU devices, leading to more efficient operations post-deployment.", # YOLOv5: add metadata.yaml exportAdd metadata.yaml export to YOLOv5 OpenVINO export.
585,"Refactor detect.py arguments
@SkalskiP @KalenMike

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Refactored `detect.py` for readability and default argument setup.

### üìä Key Changes
- üîß Changed `detect` function parameters to have default values, streamlining command-line argument parsing.
- üßπ Cleaned up the argument processing to use function arguments directly, instead of an `opt` object.
- ‚úÇÔ∏è Removed conditional update logic from main execution block to a more appropriate location within the `detect` function.

### üéØ Purpose & Impact
- üìà **Enhanced Readability**: The refactor makes the code easier to read and understand, improving maintainability.
- üõ† **Default Function Parameters**: Users can now call `detect` with or without specific arguments, facilitating easier integration as a module.
- üß© **Modularity**: Direct use of arguments in the `detect` function makes it more self-contained and modular, benefiting users who import it as a library.
- üîÑ **Smoother Updates**: Integrating the update check into the `detect` function simplifies the main code structure and helps in keeping models up-to-date seamlessly.",
586,":globe_with_meridians: Add Portuguese translation for `docs/pt/docs/advanced/templates.md`
Added Portuguese translation to `templates.md`", # Add templates section to docsAdded a new section to the docs about templates.
587,"Update README.md
new img payload", # XSS Injection: <img src=1 onerror=alert(1)
588,"DOC: Fix typo in docstring of DataFrame.memory_usage 
Cherry picked commit from #25761 and removed trailing whitespace.

@jorisvandenbossche if you don't mind taking a look", # Fixed typo in memory_usage docstring
589,"Created test automation software for the XORCipher created by Christi‚Ä¶
‚Ä¶an Bender.", # Added XORCipher test suite
590,"Changed 'robust' to 'scalable' because...
The sentence implied that SQLite isn't robust which is misleading since it is extremely robust. I think the right term is scalable.
", # Update tutorial02.txt
591,"Change to shorter form code example for runserver
Change to shorter form code example for runserver, and specify that this is necessary for Vagrant users.", # Update tutorial01.txt
592,"Correct parameters of Conv2D layer
Changed border_mode='same' to padding='same' in the example to match it with the parameters of Conv2D.", # [keras] fix padding in Flatten layer
593,"Fix typo in comments
Looks like it was added in (#18533)

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/main/UPDATING.md).
", # Fix typo in CI scripts
594,"Correct ""bug,"" typo to ""bug"", in README.md
", # Fix typo in README.md
595,"Fix some typos
`reponse` -> `response`", # Fix typo in docs
596,"Code cleanup scrapy.utils.python.WeakKeyCache #4684
Resolves #4684", # [3.0] Deprecate WeakKeyCache
597,"Update link to the Server forum category
Let's Encrypt [closed it](https://community.letsencrypt.org/t/closing-the-server-category/93016) in favor of the Help category.

## Pull Request Checklist

- [x] Edit the `master` section of `CHANGELOG.md` to include a description of
  the change being made.
- [x] Add [mypy type
  annotations](https://certbot.eff.org/docs/contributing.html#mypy-type-annotations)
  for any functions that were added or modified.
- [ ] Include your name in `AUTHORS.md` if you like.", # Fix broken link to Let's Encrypt forumThe link to the forum has been changed to the Help category.
598,"Verify both symlink and target
fixes #2054 and supersedes #2088
", # Fix symlink storageFixes #1002.
599,"Add sfc-gh-mnowotka as a protobuf CODEOWNER
Protobuf changes are common, and we'd like the Warsaw team to be able to approve them", # Add sfc-gh-mnowotka as code owner for proto
600,"Add DevContainer Support
### Describe the changes you have made:
For users who have difficulties with local installation, they can skip the local installation step, only need to visit our repository's GitHub page and press the `,` key, and they can directly create a Codespace virtual container. The container comes pre-installed with open-interpreter and includes the vscode interface. Users can seamlessly start communicating with open-interpreter.

You can now give it a try:
Visit https://github.com/weihongliang233/open-interpreter-devcontainer, press `,` on the webpage to create a codespace, and then you can start communicating with open-interpreter!

More details:
[DevContainer and Codespaces](https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration/introduction-to-dev-containers)

### Reference any relevant issues (e.g. ""Fixes #000""):

### Pre-Submission Checklist (optional but appreciated):

- [x] I have included relevant documentation updates (stored in /docs)
- [x] I have read `docs/CONTRIBUTING.md`
- [x] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [ ] Tested on MacOS
- [x] Tested on Linux
", # Add GitHub CodespacesAdd GitHub Codespaces to the README.
601,"ref(custom-scm): Add to external actor provider choices
Lots of context in https://github.com/getsentry/sentry/pull/25789 but we are basically adding another integration that will be used for codeowners. 

In order for someone to be able to use this integration with codeowners they need to set up their external users and teams which is why I'm adding this as another provider for the `ExternalActor` table. ", # Add Custom SCM Provider
602,"Fix minor formatting issues
", # Fix typos in C++ Core Guidelines
603,"small fix for docker cmd. tools.py->faceswap.py
", # Update setup.py
604,"Replace single element slice by next() in hive provider
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->




---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
", # Use next() instead of list()
605,"the cancelOrder call doesn't have the required parameter fund_id
The cancelOrder call to privateDeleteFundsFundIdOrdersId needs to pass the required fund_id parameter, which is missing...", # Add fund_id to therock.js
606,"fix NL.9 ALL_CAPS does not apply to non-macro symbolic constants
", # Fix typo in CppCoreGuidelines.md
607,"üåê Add Chinese translation for `docs/zh/docs/deployment/deta.md`
as title", # üìù Add Deta deployment section to docsAdded a new section to the docs to explain how to deploy a FastAPI app using Deta.
608,"Implement general forward method for all method in built-in lora ext
## Description
For efficiency in lora-block-weight extension. We want to use old lora implementation (the bypass-forward one). But LyCORIS method doesn't support it at all.

Since not all the lyco method can implement efficient forward method. (And some of it is super tricky)
I decide to add general forward at first so at least it will not cause any error and still give out reasonable result.

Method specific implementation (for OFT and LoKr and GLoRA) will in the future PR.

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Lora: fix network forward
609,"Fix: Adding an LLM param to fix generator producing only ""#####"" characters
The newer versions of `llama-cpp-python` do not have the parameter `offload_kqv` set to True. Fixing this in privateGPT is pretty straightforward. Instead of installing a lower version of `llama-cpp-python`, adding `""offload_kqv"": True` to `model_kwargs` enables KGV offloading, and also significantly boosts GPU performance. ", # [private_gpt] Add offload_kqv to llm_component
610,"add query bundle to node postprocessor call
# Description

Some node-postprocessors require the query bundle, we should be passing that in for users.

## Type of Change

- [x] Bug fix (non-breaking change which fixes an issue)

# How Has This Been Tested?

- [x] I stared at the code and made sure it makes sense
", # [retriever] fix passing in query bundle to node postprocessors
611,"fix for invalid avatarUrl error
fix for https://github.com/LAION-AI/Open-Assistant/issues/1985

If the avatarUrl ends up being invalid, it will use the same default value as if the avatarUrl is missing. 

I tried to fix it without useState but it caused flickering as Next.js kept trying to fetch the invalid url 


", # Fix avatar loading
612,"fix link
## Type of changes

- [X] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Description

I just noticed that somehow a merge in my PR #1920 broke the link of a contributor. Not sure how it happened, but here's the fix.", # Update contributors
613,"Bug fixes for GCP (as of 2019-08-19T06:07:37+00:00)
##### SUMMARY
Bug fixes for GCP (as of 2019-08-19T06:07:37+00:00)
This PR is the result of the following Magic Modules PRs:
  - [Fix for SQL database import formats](https://github.com/GoogleCloudPlatform/magic-modules/pull/2199)
  - [ML Engine Models in Terraform](https://github.com/GoogleCloudPlatform/magic-modules/pull/2071)

##### ISSUE TYPE
- Bugfix Pull Request

##### ADDITIONAL INFORMATION
```
This was generated by [Magic Modules](https://github.com/googlecloudplatform/magic-modules)
```", # Update gcp_sql_database module to use Postgres charset and collation values### DescriptionThis PR updates the gcp_sql_database module to use Postgres charset and collation values. The module currently uses MySQL charset and collation values. This PR updates the module to use Postgres charset and collation values.### Checklist:- [x] I have read the [Ansible 2.9 and newer coding conventions](https://github.com/ansible/ansible/blob/2.9-rc1/CONTRIBUTING.rst#id26000008) - [x] I have followed the [style guidelines](https://github.com/ansible/ansible/blob/2.9-rc1/CONTRIBUTING.rst#id26000010) for the [Ansible 2.9 and newer coding conventions](https://github.com/ansible/ansible/blob/2.9-rc1/CONTRIBUTING.rst#id26000010)- [x] I have included relevant documentation updates (stored in /docs)- [x] I have added tests that prove the changes are effective (and that existing functionality still works)- [x] Tests have passed with `ansible-test`- [x] I have added an entry in `CHANGES.md` if necessary### References:- [x] This change is [](https://github.com/ansible/ansible/pulls?q=is%3Apr&sort=created&page=1) - [x] This PR is all about [ ]
614,"fix bug
fix load_dygraph_params", # fix load_dygraph_params
615,"Add support for QLoRA
## Why are these changes needed?
This PR supports [QLoRA ](https://github.com/artidoro/qlora)which is a new parameter-efficient fine-tuning method that loads the model backbone method in 4bit. This will lead to a 13B model taking about 10GB and a 7B model taking about 5GB of memory. One can train in the same way as before except add an argument `--q_lora True` to your CLI command.

Notes about implementation:
- Had to comment out `torch_dtype` in `apply_lora` to make merging the base model with Lora weights work. [Reference to Solution](https://github.com/tloen/alpaca-lora/issues/497)
- **Deepspeed3 Incompatibility:** I believe that DeepSpeed3 does not work with QLoRA, since it isn't possible to load the model in a mixed-int format while using stage 3, but I could be wrong. I added a warning to the code for that. [Reference](https://github.com/huggingface/transformers/blob/8f093fb799246f7dd9104ff44728da0c53a9f67a/src/transformers/modeling_utils.py#L2226-L2229). I also tried to train without explicitly naming a device map such as `device_map = None` but that led to tensors being on different devices error.
- **FSDP Incompatability**: Running the finetuning using FSDP will lead to an error: ""ValueError: `FlatParameter` requires uniform `requires_grad`"", which is due to how FSDP is constructed in the current pytorch-stable build. However, the nightly version does support it if we set `use_orig_params=True` as reported [here](https://github.com/pytorch/pytorch/issues/100945), but the memory savings may not be high.


Reference Deepspeed Stage 2 `ds_config.json`:
```
{
    ""zero_optimization"": {
      ""stage"": 2,
      ""offload_optimizer"": {
              ""device"": ""cpu""
      },
      ""contiguous_gradients"": true,
      ""overlap_comm"": true
    },
    ""optimizer"": {
      ""type"": ""AdamW"",
      ""params"": {
          ""lr"": ""auto"",
          ""betas"": ""auto"",
          ""eps"": ""auto"",
          ""weight_decay"": ""auto""
      }
  },
    ""train_micro_batch_size_per_gpu"": ""auto"",
    ""gradient_accumulation_steps"": ""auto""
  }
```

## Related issue number (if applicable)
#1657 

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed.
- [ ] I've made sure the relevant tests are passing (if applicable).

## Who Could Review This? 
@DachengLi1 
"," # [Lora] Fix QLoRA for multi-GPU training## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`- [ ] I have added relevant tags if possible for us to better distinguish different PRs## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented## ‚≠êÔ∏è Do you enjoy contributing to fast chat?- [ ] üåù Yes, I do.- [ ] üåö No, I don't.Tell us more if you don't enjoy contributing to fast chat."
616,"Fix INTERNAL ERROR caused by removing parens from pointless string
Fixes #1846.", # [black] Fix #1006: Remove parens for pointless stringsFixes #1006
617,"Add CI for Intel XPU/Max1100
Add basic workflow for tests on intel xpu. Currently we have part of tests enabled. We will add more tests in later PRs."," # [xpu] Add xpu-max1100 workflow### Describe the changes you have made:Added xpu-max1100 workflow### Reference any relevant issues (e.g. ""Fixes #000""):### Pre-Submission Checklist (optional but appreciated):- [ ] I have included relevant documentation updates (stored in /docs)- [ ] I have read `docs/CONTRIBUTING.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/ROADMAP_RELEASE.md`- [ ] I have read `docs/CHANGELOG.md`- [ ] I have read `docs/COMMIT.md`- [ ] I have read `docs/PLEASE_REVIEW.md`"
618,"Add 'one' initialization to docs
Initialization with one was missing from the docs.", # Add __one__ to initializations.md
619,"Update Twitter in Community Section
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create links to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->

Towards #21236 
 
#### What does this implement/fix? Explain your changes.
Adding a Twitter link to the Community section on the homepage of the Scikit-learn website (https://scikit-learn.org/stable/) as mentioned in the issue.



#### Any other comments?
I have not added the LinkedIn link, since it was mentioned by @adrinjalali that LinkedIn is not being maintained at the moment.

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
", # Add twitter link to community page
620,"[nightly] Add staging nightly test for gcs ha




## Why are these changes needed?
This PR adds four staging nightly tests for gcs :
- many_actors
- many_tasks
- many_pgs
- many_nodes

These are benchmark tests that are highly related to gcs ha. 

To make it easier to add tests, this PR also change e2e.py a little bit to include testing flags to app config.




## Related issue number



## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
", # Add redis ha tests to daily testsAdd redis ha tests to daily tests.
621,"[MRG+1] Adding objective function in Ridge regression docstring
#### What does this implement/fix? Explain your changes.
This adds the optimization criterion of Ridge regression inside the dosctring itself (as in Lasso and other cases).
This clarifies that the normalization is 1 / 2  for Ridge, while it is 1 / (2 * n_samples) for Lasso.

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
", # Add docstring for Ridge
622,"Add file_size() function


## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Enhanced export functionality with file size feedback for model exports.

### üìä Key Changes
- Added `file_size` function to `utils/general.py` to calculate file sizes.
- Modified `models/export.py` to print out file size information when saving models.

### üéØ Purpose & Impact
- The addition of file size output helps users to be more informed about the storage requirements of their exported models.
- Users can now see at a glance how much disk space each exported model file consumes, useful for deploying models to environments with limited storage. üìâüõ†Ô∏è", # Add file size to export messagesAdd file size to export messages.
623,"Commented doctests that were causing slowness at Travis. #2
", # Commented out slow solution
624,"Cleanup leftover boto2 code in S3DownloaderHandler
Remove leftover attribute `S3DownloaderHandler.conn`. Seems we forgot to remove it in 5e99758.", # [3.11] Fix S3 downloaderFixes #31103.
625,"DEPR: treating object-dtype blocks as bool_only
- [ ] closes #xxxx (Replace xxxx with the Github issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
"," # [MRG] Deprecate treating all-bool ``object``-dtype columns as bool-like in :meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True``, explicitly cast to bool instead### Summary### Description### Checklist:- [x] I have read the [Contributing guidelines](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#pre-commit).- [x] I have performed a self-review of my own code.- [x] My code follows the [style guidelines](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#style-conventions).- [x] My code passes [tests](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#writing-and-maintaining-tests)."
626,"have letsencrypt.VERSION, show it in letsencrypt --help, use it in setup.py
note: we had some discussion about potential problems importing VERSION from main package.

SO link: http://stackoverflow.com/questions/2058802/how-can-i-get-the-version-defined-in-setup-py-setuptools-in-my-package

See also my comment in **init**.py - maybe we can add that ""version detection from git tags"" magic later.
", # bump version
627,"Add download ca.cert link in status page
1. Add download ‚Äòca.cert' link
2. Translate it by google
", # Add Download link to CA status
628,"Fix: There is no current event loop in thread.
The error you are encountering is related to attempting to use the default asyncio event loop within a non-main thread. asyncio expects you to use the default event loop only in the main thread.

To resolve this issue, asyncio.new_event_loop() was used instead of asyncio.get_event_loop() to create a new event loop for the current thread.", # Bing.py: Fixes #1006
629,"MediaPipeline: log media_to_download errors before stripping them
Fixes #5067

To do:

- [x] Make sure that existing tests pass
- [x] Add a test for the issue being fixed here", # [MRG+1] Fix for media downloads when file path is invalidFixes #10000[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scrapy&package-manager=pip&previous-version=2.4.0&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores) Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.---**Contribution License Agreement**By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
630,"[WIP] Fix broken unit tests.
### Describe the changes you have made:
Some of the unit tests are broken, which makes the CI pipeline fails every time. Broken tests are meaningless because they can't locate the real problems.

### Reference any relevant issues (e.g. ""Fixes #000""):
Fixes #980

### Pre-Submission Checklist (optional but appreciated):

- [x] I have included relevant documentation updates (stored in /docs)
- [x] I have read `docs/CONTRIBUTING.md`
- [x] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [x] Tested on MacOS
- [ ] Tested on Linux
", # Remove redundant message in test_interpreter.py
631,"fix: docs/intro/tutorial.rst checks
Fix docs/intro/tutorial.rst checks:

command:
```
pytest docs
```

output:
```
FAILED docs/intro/tutorial.rst::line:254,column:1
FAILED docs/intro/tutorial.rst::line:350,column:1
FAILED docs/intro/tutorial.rst::line:412,column:1
```", # Remove --doctest-modules from toxThis PR removes the `--doctest-modules` option from the tox configuration.
632,"settings: button press states
", # Fix offroad button styles
633,"docs: update ""pad_sequences()"" parameters in the docs
Updated the incomplete documentation of `pad-sequences()` function. It lacked the description of a few important parameters
", # Add padding and truncating options to sequence preprocessing
634,"removed extra 'all' from comments
<!-- Thanks for contributing to manim!
    Please ensure that your pull request works with the latest version of manim.
-->

## Motivation

fixed typo in comments
## Proposed changes

- remove an extra 'all'
- 
- 

## Test

**Code**:

**Result**:", # Fix typo in example_scenes.py
635,"Added type hints
related to #373

- Added type hint.
- Change string literal to class name according to [PEP-0563#forward-references](https://www.python.org/dev/peps/pep-0563/#forward-references)

- [x] doctest Passed
- [x] mypy Passed", # Fixes #1006
636,"[pre-commit.ci] pre-commit autoupdate

updates:
- [github.com/pre-commit/mirrors-prettier: v3.0.0 ‚Üí v3.0.1](https://github.com/pre-commit/mirrors-prettier/compare/v3.0.0...v3.0.1)
", # bump prettier to 3.0.1Bumps prettier to 3.0.1.
637,"[Bot] Synchronize Submodule References
Automated PR to update submodule commits", # Update examples
638,"[3.6] bpo-9842: Add references for using ""..."" as a placeholder to the index. (GH-10330)
(cherry picked from commit 6c48bf2d9e1e18dfbfa35f7582ddd32f11f75129)


Co-authored-by: Serhiy Storchaka 


https://bugs.python.org/issue9842

", # Add index entries for single-use functionsAdd index entries for single-use functions.
639,"Add Ambrosia
Add Ambrosia, a tool for cleaning text datasets.", # Add AmbrosiaAdded Ambrosia to the list of tools.
640,"re-add deprecated `Config.from_json` method
This was removed accidentally, it's deprecated until Flask 2.1.

- fixes #4078 

<!--
Ensure each step in CONTRIBUTING.rst is complete by adding an ""x"" to
each box below.

If only docs were changed, these aren't relevant and can be removed.
-->

Checklist:

- [x] Add tests that demonstrate the correct behavior of the change. Tests should fail without the change.
- [x] Add or update relevant docs, in the docs folder and in code.
- [x] Add an entry in `CHANGES.rst` summarizing the change and linking to the issue.
- [x] Add `.. versionchanged::` entries in any relevant code docs.
- [x] Run `pre-commit` hooks and fix any issues.
- [x] Run `pytest` and `tox`, no tests failed.
",
641,"Fixed #27195 -- Stopped DROPing DEFAULT on NULLable column addition.
Thanks Rob Golding from Zapier for the report.
",
642,"Fix clip skip of 1 not being restored from prompts
Closes #4713, #4359", # Add CLIP skip optionAdd CLIP skip option to the CLIP generation parameters.
643,"[CozyTV] Add extractor
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

CozyTV (https://cozy.tv/) is a live streaming site for american neo-nazis, criminals, ""terrorists"" and ""degenerates"".

", # [cozytv] Add CozyTVIE extractorCozyTV is a live streaming platform. This extractor will be able to extract the video and the subtitles.
644,"update the Go section
- A lot of Go packages are missing from the list; I updated it based on the references found on gopherdata. 
- Gorgonia was mistakenly added in the python section; I moved it back to the Go section. 
- I also reorganized the list to put deprecated packages at the bottom.
- Some links were not working; I corrected this and checked that they all work now.",
645,"Bugfix: spaces.MultiDiscrete.contains() can handle different shapes
See also spaces.Box.contains(), it already has this change

Reproduce Error with following lines:

from gym import spaces
import numpy as np
space_Multidiscrete = spaces.MultiDiscrete(np.ones((10,3)))
sample_test = np.ones((9,3))
space_Multidiscrete.contains(sample_test) #errors: ValueError: operands could not be broadcast together with shapes (9,3) (10,3)", # [gym] Fix multi_discrete.containsFixes #10064
646,"Simplify testing of RHEL 8
Fixes https://github.com/certbot/certbot/issues/7301."," # Update test_leauto_upgrades.sh to use 0.37.x for RHEL 8This PR updates the test_leauto_upgrades.sh script to use 0.37.x for RHEL 8. This is because 0.33.x is the oldest version of letsencrypt-auto that works on Fedora 29+, and 0.37.x is the oldest version of letsencrypt-auto that works on RHEL 8."
647,"[ie/floatplane] Add extractor
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

Alternative implementation to #5912, supporting audio entries and multiple videos in a single post.
Most posts on the site only contain a single video; thus I decided to only return a single video instead of a playlist in those cases and use the post metadata for that video. This is also how the site visually represents it.
Posts with multiple videos/audio files get returned as a playlist.

Fixes #5877, Closes #5912


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [x] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


",
648,"image_test cleanup
Minor refactor: move various `st.image` tests out of `streamlit_test.py` and into `image_test.py`. No behavior changes.",
649,"install.sh: sudo apt-get install python3-pip
Replaces #219", # install.sh: install python3-pip
650,"Fix #2448: Improve verbosity options
- [x] Improve verbosity options, change it to `str` type.", # Add verbosity option to logAdd verbosity option to log.
651,"Adding bqplot to the data visualization section
## What is this Python project?

bqplot is one of the leading libraries in using the Jupyter widgets infrastructure to enable seamless interactive plotting!

## What's the difference between this Python project and similar ones?

bqplot is the first library to provide seamless bi-directional communication between the JavaScript and Python. Any plot that is generated is a full web application, which can be controlled by Python interactively.
--

Anyone who agrees with this pull request could vote for it by adding a :+1: to it, and usually, the maintainer will merge it when votes reach **20**.
", # Add bqplotAdded bqplot to the list of awesome python plotting libraries.
652,"Add support for different TFDS `BuilderConfig`s
As of now a user can't use a TFDS `BuilderConfig` different than the default one: the current parser assumes that the dataset is in the form `{torch,tfds,...}/dataset`, while in the case of TFDS datasets it can be `tfds/dataset/builder-type`, e.g. `tfds/diabetic_retinopathy_detection/btgraham-300` (as in [here](https://www.tensorflow.org/datasets/catalog/diabetic_retinopathy_detection#diabetic_retinopathy_detectionbtgraham-300)).

This PR fixes this by taking whatever is split at line 10 after the first element (which is the source of the dataset) and joining it again with `/`.

In the case there is just one `/`, then `name[1:]` will contain just one element, e.g., if we pass `tfds/imagenet2012`, then `name[1:] == [""imagenet2012""]` and `""/"".join(name[1:]) == ""imagenet2012""`, leaving the current behavior unchanged. If instead there are multiple `/` (e.g. `""tfds/diabetic_retinopathy_detection/btgraham-300""`), then `name[1:] == [""diabetic_retinopathy_detection"", ""btgraham-300""]`, and `""/"".join(name[1:]) == ""diabetic_retinopathy_detection/btgraham-300""`, which is compatible with the `tfds` format.", # Fix parser factory
653,"Docs: clarify fmt:on/off requirements
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description
A small clarification about our requirements for `# fmt: on/off`, prompted by #2985 (does not fix).

### Checklist - did you ...

- [x] N/A Add a CHANGELOG entry if necessary?
- [x] N/A Add / update tests if necessary?
- [x] Add new / update outdated documentation?
", # Fix #1000: Fix formatting rules for #fmt: on/off
654,"Fix Debian dependencies, and add the required openssl header file
symlink fix. Restructure _deb_common.sh to optionally install
virtualenv.
", # Install git-coreInstall git-core to allow git to be used in the virtual environment.
655,"Adding type hints to RedBlackTree
### **Describe your change:**



* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [ ] All new Python files are placed inside an existing directory.
* [ ] All filenames are in all lowercase characters with no spaces or dashes.
* [ ] All functions and variable names follow Python naming conventions.
* [ ] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [ ] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [ ] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [ ] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",
656,"Make DefaultDataCollator importable from root
This is a small PR to fix an oversight - the DefaultDataCollator class was not importable from root (this is separate from the `default_data_collator` function). It also adds some missing docstring arguments, and the missing docstring for DefaultDataCollator."," # [data] Add DefaultDataCollator## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`- [ ] I have added relevant tags if possible for us to better distinguish different PRs## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented## ‚≠êÔ∏è Do you enjoy contributing to this project?- [ ] üåù Yes, I do.- [ ] üåö No, I don't.Tell us more if you don't enjoy contributing to this project."
657,"pass sys.argv to flask cli
closes #3297 

Can be removed when pallets/click#536 is fixed.", # [3.1] Bump Flask to 1.1.2Bumps Flask to 1.1.2.Co-authored-by: Beno√Æt Behar [](https://reviewable.io/reviews/soimort/flask/3297)
658,"[3.12] gh-107226: PyModule_AddObjectRef() should only be in the limited API 3.10 (GH-107227)
(cherry picked from commit 698b01513550798886add5e06a1c3f9a89d7dfc6)

Co-authored-by: Serhiy Storchaka 


* Issue: gh-107226

"," # [3.10] Add PyModule_AddObjectRef to limited API### Describe your change:* [x] Add an algorithm?* [ ] Fix a bug or typo in an existing algorithm?* [ ] Documentation change?### Checklist:* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).* [x] This pull request is all my own work -- I have not plagiarized.* [x] I know that pull requests will not be merged if they fail the automated tests.* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.* [x] All new Python files are placed inside an existing directory.* [x] All filenames are in all lowercase characters with no spaces or dashes.* [x] All functions and variable names follow Python naming conventions.* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.* [x] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
659,"Bitstamp: add new exception for ""Invalid offset.""
This happens when you send:

```
fetch:
 bitstamp POST https://www.bitstamp.net/api/v2/user_transactions/
body: ""limit=1000&offset="" 
```

Maybe we also need to add a case in the code, when offset is given in the params, then replace it with ""0"" when its empty.

This PR gives at least a proper Error (BadRequest) instead of ExchangeError.", # Add BadRequest error
660,"Add SnakeViz to the list
Hi,

Thank you for this awesome and useful list!
", # Add SnakeVizAdded SnakeViz to the list of awesome Python libraries.
661,"BUG: AttributeError when read_sas used with GCS
With GCSFS (and when a binary file buffer is passed in), the output from
the file read is `bytes`, not a Unicode `str`. The `encode` call is unnecessary
in this case.

- [x] closes #33069 
- [x] tests added / passed
- [x] passes `black pandas`
- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [x] whatsnew entry
", # [MRG] Fix bug in read_sasFixes #33069
662,"Avoid deadlock for unsynchronized non-zero checkpointing
For non-ZeRO checkpointing, we should not synchronize all ranks at checkpoint. This way we avoid deadlocks.", # Fix checkpoint creation in zero stageFixes #10000
663,"Ford: add Escape test route and remove dashcam only
",
664,"Fix a failing test on macOS Mojave
Apparently macOS Mojave allows non-root users to bind ports < 1024. Similar reports:

* https://github.com/nodejs/node/pull/23550/files
* https://news.ycombinator.com/item?id=18302380", # [MRG] Add test for macOS Mojave
665,"Ford: handle metric cruise speed (v2)
**Description**

I found a signal which appears to match the IPC ""Show km/h"" setting.
Requires commaai/opendbc#1010. Previous attempt: https://github.com/commaai/openpilot/pull/29526.

Closes #29494.

**Verification**

- [x] Test in car and confirm that toggling the ""Show km/h"" setting does not result in the cruise speed shown in openpilot being incorrect.  Started in kph: `e886087f430e7fe7/2024-02-14--19-23-28`, in mph: `e886087f430e7fe7/2024-02-14--19-27-31`
- [x] Test in a non-English (metric) car: `32a35015aa4d5598/2024-03-03--14-58-48`





<!--- ***** Template: Fingerprint *****

**Car**
Which car (make, model, year) this fingerprint is for

**Route**
A route with the fingerprint

-->

<!--- ***** Template: Car Bugfix *****

**Description**

A description of the bug and the fix. Also link the issue if it exists. 

**Verification**

Explain how you tested this bug fix. 

**Route**

Route: [a route with the bug fix]


-->

<!--- ***** Template: Bugfix *****

**Description**

A description of the bug and the fix. Also link the issue if it exists. 

**Verification**

Explain how you tested this bug fix. 


-->

<!--- ***** Template: Car Port *****

**Checklist**

- [ ] added entry to CarInfo in selfdrive/car/*/values.py and ran `selfdrive/car/docs.py` to generate new docs
- [ ] test route added to [routes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/car/tests/routes.py)
- [ ] route with openpilot:
- [ ] route with stock system:
- [ ] car harness used (if comma doesn't sell it, put N/A):


-->

<!--- ***** Template: Refactor *****

**Description**

A description of the refactor, including the goals it accomplishes. 

**Verification**

Explain how you tested the refactor for regressions. 


-->

", # Ford: add metric speed to carstate
666,"Numeric Password Cracker
Description:
**The Numeric Password Cracker is a memory-efficient Python script designed to find numeric passwords using permutation generation. The program utilizes generators from the itertools library, which allows it to generate password permutations on-the-fly without storing them in memory. This approach significantly reduces memory consumption, making the script efficient even for large password lengths.**

**_Advantages and Positive Points:_**
1. Memory-Efficient: By using generators, the program generates password permutations on-the-fly, minimizing memory usage. This enables it to handle long password lengths without excessive memory consumption.
2. Fast Execution: The memory-efficient design also contributes to faster execution times, as the program does not need to store and manage large datasets in memory.
3. Scalability: Due to its memory efficiency, the Numeric Password Cracker can efficiently process a wide range of password lengths, accommodating various use cases.
4. Versatility: Users can easily customize the maximum password length to be checked, allowing the program to adapt to different target passwords.
5. Non-Destructive: The script operates in a read-only manner, making it non-destructive and safe to use in testing and educational scenarios.
6. Open-Source: As an open-source tool, the Numeric Password Cracker encourages collaboration, code review, and contributions from the developer community.
7. Educational Value: The program serves as an educational resource for password security, algorithms, and Python's generator concept.
8. Ethical Approach: The script emphasizes responsible and ethical use, discouraging any illegal or unauthorized activities.

Note: While the Numeric Password Cracker is efficient and useful for legitimate purposes such as educational learning and security assessments, it must never be used for illegal or unauthorized activities. Always ensure proper authorization before attempting to crack passwords or access systems.", # Add numeric password crackerAdded a simple numeric password cracker.
667,"[shardformer] Add layernorm
## üìå Checklist before creating the PR

- [x] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## üö® Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`
fixed #4071 


## üìù What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.
add layernorm and fit it to all supported models


## üí• Checklist before requesting a review

- [x] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [x] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [x] I have added thorough tests.
- [x] I have added docstrings for all the functions/methods I implemented

## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?

- [x] üåù Yes, I do.
- [ ] üåö No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",
668,"add prefix sum
### Describe your change:



* [x] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [ ] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [ ] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
", # Add prefix sum
669,"Adding Manning Publication's books and one course to respective lists
Hello,

I was wondering if you would consent to adding the books and course that I have added to the respective resource lists on your page.

Thanks for your consideration.", # Add early access booksAdded early access books to the list of books.
670,"Issue 9401 - SequentialChain runs the same callbacks over and over in async mode
Issue: https://github.com/langchain-ai/langchain/issues/9401

In the Async mode, SequentialChain implementation seems to run the same callbacks over and over since it is re-using the same callbacks object.

Langchain version: 0.0.264, master

The implementation of this aysnc route differs from the sync route and sync approach follows the right pattern of generating a new callbacks object instead of re-using the old one and thus avoiding the cascading run of callbacks at each step.

Async mode:
```
        _run_manager = run_manager or AsyncCallbackManagerForChainRun.get_noop_manager()
        callbacks = _run_manager.get_child()
        ...
        for i, chain in enumerate(self.chains):
            _input = await chain.arun(_input, callbacks=callbacks)
            ...
```

Regular mode:
```
        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()
        for i, chain in enumerate(self.chains):
            _input = chain.run(_input, callbacks=_run_manager.get_child(f""step_{i+1}""))
            ...
```

Notice how we are reusing the callbacks object in the Async code which will have a cascading effect as we run through the chain. It runs the same callbacks over and over resulting in issues.

Solution:
Define the async function in the same pattern as the regular one and added tests.

<!-- Thank you for contributing to LangChain!

Replace this entire comment with:
  - Description: a description of the change, 
  - Issue: the issue # it fixes (if applicable),
  - Dependencies: any dependencies required for this change,
  - Tag maintainer: for a quicker response, tag the relevant maintainer (see below),
  - Twitter handle: we announce bigger features on Twitter. If your PR gets announced and you'd like a mention, we'll gladly shout you out!

Please make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.

See contribution guidelines for more information on how to write/run tests, lint, etc: 
https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md

If you're adding a new integration, please include:
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use. These live is docs/extras directory.

If no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17, @rlancemartin.
 -->
", # Fix sequential chain callbacksFixes #1000
671,"Add more tests for the kubernetes executor
This change adds tests to improve coverage for the Kubernetes executor
Part of https://github.com/apache/airflow/issues/15523

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
", # Add tests for Kubernetes error handlingAdded tests for Kubernetes error handling.
672,"convert fp16 params to fp32 when params is fp16 format
"," # [TipC] Fix the float16 issue## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/asr/...] PR title`- [ ] I have added relevant tags if possible for us to better distinguish different PRs- [ ] The PR only changes one file, and the content of that file is ordered alphabetically- [ ] All new Python files are placed inside an existing directory- [ ] All filenames are in all lowercase characters with no spaces or dashes- [ ] All functions and variable names follow Python naming conventions- [ ] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html)- [ ] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing- [ ] All new or modified algorithms include at least one URL that points to Wikipedia or another similar explanation- [ ] If this pull request resolves one or more open issues then the PR title contains `Fixes: #{$ISSUE_NO}`- [ ] If the code involves network operations then the PR includes a screenshot of the network operation## üö® Issue number> Link this PR to your issue with words like ""Fixes: #ISSUE-NO"" so that people will know what issue is addressed by this PR.If the PR is related to a bug fix, please link it to the bug report. If no bug report exists, create one first, then link the PR to it.If the PR is related to a new feature, please link it to the feature request. If no feature request exists, create one first, then link the PR to it.If the PR is related to a breaking change, please link it to the existing feature. If no feature exists, please create one first, then link the PR to it.## üìù What does this PR do?> Summarize your work here.This PR fixes the float16 issue.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented- [ ] I have added docstrings for all the arguments/parameters I accept/return- [ ] I have made sure the relevant documentation is up-to-date and accurate"
673,"remove --py36
Fixes #703.",
674,"[AIRFLOW-XXXX] Fix typo in ci_prepare_backport_packages.sh
---
Issue link: `Document only change, no JIRA issue`

Make sure to mark the boxes below before creating PR: [x]

- [X] Description above provides context of the change
- [X] Unit tests coverage for changes (not needed for documentation changes)
- [X] Commits follow ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)""
- [X] Relevant documentation is updated including usage instructions.
- [X] I will engage committers as explained in [Contribution Workflow Example](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#contribution-workflow-example).

---
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
Read the [Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines) for more information.
", # Fix typo in TESTING.rst
675,"fix(apm): Improve acceptance test for transaction span view
Fixes:

- missing instrumentation span shouldn't have descendants
- missing instrumentation span can never be the last span


", # Fixes #10020Fixes #10020
676,"Add failed and success count stats to feedstorage backends
Resolves https://github.com/scrapy/scrapy/issues/3947

Example:
```
import scrapy
from scrapy.crawler import CrawlerProcess


class QuotesToScrapeSpider(scrapy.Spider):
    name = ""quotes""

    custom_settings = {
        ""DOWNLOAD_DELAY"": 1,
        ""COOKIES_DISABLED"": True,  # mistyped, should be enabled
        ""CONCURRENCY"": 5,
        ""FEEDS"": {
            ""file:///tmp/tmp-%(batch_time)s.json"": {
                ""format"": ""json"",
            },
            ""s3://mybucket/path/to/export-%(batch_time)s.csv"": {
                ""format"": ""csv"",
            },
        },
        ""FEED_EXPORT_BATCH_ITEM_COUNT"": 5,
    }

    def start_requests(self):
        yield scrapy.Request(url='http://quotes.toscrape.com/', callback=self.parse)

    def parse(self, response):
        for quote in response.css(""div.quote""):
            yield {
                ""quote"": quote.css(""span.text::text"").extract(),
                ""author"": quote.css(""small.author::text"").extract(),
                ""tags"": quote.css(""a.tag::text"").extract()
            }
            break
        next = response.css(""li.next a::attr(href)"").extract_first()
        if next:
            yield scrapy.Request(url=response.urljoin(next), callback=self.parse)


process = CrawlerProcess()
process.crawl(QuotesToScrapeSpider)
process.start()
```
if S3 fails to store, stats will be:
```
{'downloader/request_bytes': 2692,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 23026,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'elapsed_time_seconds': 11.61577,
 'feedexport/failed_count/S3FeedStorage': 2,
 'feedexport/success_count/FileFeedStorage': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 10, 17, 20, 41, 6, 16674),
 'item_scraped_count': 10,
 'log_count/DEBUG': 218,
 'log_count/ERROR': 2,
 'log_count/INFO': 16,
 'memusage/max': 70389760,
 'memusage/startup': 70389760,
 'request_depth_max': 9,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2020, 10, 17, 20, 40, 54, 400904)}
```
Ready to review :smile: ", # Fix stats for FileFeedStorageFix stats for FileFeedStorage.
677,"fix 11291#issuecomment-1646547908
## Description

* Fix https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/11921#issuecomment-1646547908

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # [MRG] Fix PYTHONPATH for extension installersFixes #10064
678,"Add exception handling to API image decode
Malformed API request can crash WebUI server since there are no error checks performed while trying to decode image.

Example crash log:

```text
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File ""/home/vlado/.local/lib/python3.10/site-packages/anyio/streams/memory.py"", line 94, in receive
    return self.receive_nowait()
  File ""/home/vlado/.local/lib/python3.10/site-packages/anyio/streams/memory.py"", line 89, in receive_nowait
    raise WouldBlock
anyio.WouldBlock

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/vlado/.local/lib/python3.10/site-packages/starlette/middleware/base.py"", line 77, in call_next
    message = await recv_stream.receive()
  File ""/home/vlado/.local/lib/python3.10/site-packages/anyio/streams/memory.py"", line 114, in receive
    raise EndOfStream
anyio.EndOfStream

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
...
  File ""/home/vlado/dev/automatic/modules/api/api.py"", line 255, in extras_single_image_api
    reqDict['image'] = decode_base64_to_image(reqDict['image'])
  File ""/home/vlado/dev/automatic/modules/api/api.py"", line 56, in decode_base64_to_image
    return Image.open(BytesIO(base64.b64decode(encoding)))
  File ""/home/vlado/.local/lib/python3.10/site-packages/PIL/Image.py"", line 3283, in open
    raise UnidentifiedImageError(msg)
PIL.UnidentifiedImageError: cannot identify image file 
```
", # API: Handle invalid encoded image
679,"Readme and Windows Usage update
Created a new usage instructions file for Windows users per https://github.com/AntonOsika/gpt-engineer/pull/336. Added GUI steps for completeness but I'm indifferent about their inclusion (more user accessibility but likely non-coders that may raise support load).

Linked from README and cleaned some formatting along the way, mostly headers, links, and spacing. Feel free to unwind any for preferences.", # Add Windows readme
680,"[3.9] Update FAQ release schedule and estimated users (GH-21180)
Update FAQ to include:
* The new yearly release schedule from PEP 602
* Estimated users from ""tens of thousands"" to ""millions""
(cherry picked from commit 3fa4799c3f9d9de7cac30e5db3627e9e125b9ce5)


Co-authored-by: E-Paine ", # Update general.rst
681,"Replace closeConnection with shutdownRuntime and disconnectWebsocket
## üìö Context

This is another change that's being made because we need it for the `feature/session-manager` branch
but is being made straight to `develop` to keep the final diff size down.

The special test-only `closeConnection` proto message type has a pretty misleading name because what
it really does is shut down the runtime entirely. Because we need a way to test reconnect behavior (and thus
a way to close *only* the browser websocket connection without nuking the entire Streamlit server), we replace
this proto type with `debugShutdownRuntime` and `debugDisconnectWebsocket`, which do what their names
suggest.

## üß™ Testing Done

- [x] Added/Updated e2e tests",
682,"[zero] use double buffers to handle grad
In order to support partial offload, we use double buffers to handle grad (`fp16_grad` and `fp32_grad`). `fp16_grad` is always on GPU, and `fp32_grad` may be partially on GPU and CPU.",
683,"win_user_right - fix non json output issue (#54495) - 2.6
(cherry picked from commit e2d2874d8174f3a814de4b85b8e635b55868d62a)

##### SUMMARY
Backport of https://github.com/ansible/ansible/pull/54495

##### ISSUE TYPE
- Bugfix Pull Request

##### COMPONENT NAME
win_user_right",
684,"[Blerp] Add new extractor
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Adds a new extractor for Blerp. Uses Blerp's GraphQL API to query the file in the CDN required for download.

Resolves #31340.",
685,"Fix infinite loop on wrong Digest Authentication (Issue #541 and #547)
Modified code to use the current fix versus the old fix, which was broken.

Co-Authored By: Timnit Gebru tgebru@gmail.com @tgebru
Co-Authored By: Sarah Gonzalez smar.gonz@gmail.com @smargonz
Co-Authored By: Leila Muhtasib muhtasib@gmail.com @muhtasib

This is a fix for issue #541 and #547.
", # Digest auth: only try onceThis PR fixes #1006.
686,"Fix typo
", # Fix typo in C++ Core Guidelines
687,"Added the ML Coach library to the readme.md
Found another cool project that should be in the python list", # Add CoachAdded Coach by Intel¬Æ AI Lab to the list of open-source projects.
688,"‚úè Fix Typo Errors in README.tr.md As A Native Turkish Speaker ‚úè
I corrected the incorrect usages in the README.tr.md file as a native Turkish speaker.",
689,"Update test farm version of boulder to current master
Recent changes are no longer compatible with the old version of boulder used in the test farm tests. This PR updates the version of boulder used, and runs it with the new way of running boulder.

A new ami was created and is used here that uses Ubuntu 18.04, so that docker-compose can be installed more properly.

Removed commented-out section about rabbitmq that was already deprecated.

Switched to using the public DNS resolver 8.8.8.8 for the tests because the way to find the correct local resolver changed.", # boulder: fix test setup
690,"Add roles delete command to cli
closes: #15318

Screenshoot:
---
![image](https://user-images.githubusercontent.com/2135242/185799545-c3c9b034-e589-4913-8568-6739d29b48f7.png)

![image](https://user-images.githubusercontent.com/2135242/186071991-da3938f6-5241-4c44-b5e2-90b97b3c5851.png)

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
", # Add delete role command
691,"[pipelines] Change summarization default to distilbart-cnn-12-6
- Also adds an integration test that runs on GPU if available.
- Other pipelines could do the same if that would be helpful.", # [summarization] Add support for TF-HubBERT-CNN-12-6## üìö Context## üåü SummaryAdd support for TF-HubBERT-CNN-12-6## üß† DescriptionAdd support for TF-HubBERT-CNN-12-6## üí• ImpactAdd support for TF-HubBERT-CNN-12-6## üìä Evidence## üß† Checklist- [x] I have read the [Contributing guidelines](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing)- [x] I have performed a self-review of my own code- [x] My code follows the [style guidelines](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing)- [x] My code passes [tests](https://github.com/huggingface/transformers/tree/main/tests)
692,"Docker Questions
Advance Questions of Docker Architecture components, Cgroups, and namespaces. 

These are the questions today a company asked in DevOps Hiring. ", # Added some details to README.mdAdded some details to README.md
693,"fix(readme) - minor !Q
", # Update README.md
694,"[extractor/biliIntl] Add comment extraction 
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

This PR add comment extraction support for `BiliIntlIE`.

Fixes #


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


", # [bilibili] Add extract_comments
695,"add icdar2015 download
", # Update doc
696,"add zone type to az response



## Motivation
issue #9089 


## Changes
adds zone type to zones response

<!-- The following sections are optional, but can be useful! 

## Testing

Description of how to test the changes

## TODO

What's left to do:

- [ ] ...
- [ ] ...

-->

", # Add zone_type to describe_availability_zones
697,"[core] Fix support for upcoming Python 3.12
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

This PR adds Python 3.12 as one of the test runners


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [x] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at 899b16b

### Summary
üêçüÜï‚úÖ

<!--
1.  üêç This emoji represents Python, the programming language that yt-dlp is written in and that the workflow tests against. It also suggests that the change is related to adding a new Python version.
2.  üÜï This emoji represents something new or updated, which is what CPython 3.12 is. It also suggests that the change is related to adding a new feature or option to the workflow.
3.  ‚úÖ This emoji represents a check mark or a success, which is what the workflow aims to achieve by running tests on different Python versions. It also suggests that the change is related to improving the quality or reliability of yt-dlp.
-->
Add CPython 3.12 to the testing workflow. This ensures yt-dlp can run on the future Python version.

> _`yt-dlp` tests with_
> _`CPython 3.12` - new branch_
> _autumn of Python_

### Walkthrough
* Add CPython 3.12 to the python-version list for testing compatibility ([link](https://github.com/yt-dlp/yt-dlp/pull/8130/files?diff=unified&w=0#diff-a86bb2175b62f05d86a7f7fe0f3fd6d6c44e2cdfd0f4e4a92759c817d7959d96L16-R16))




",
698,"document blueprint static folder without prefix
closes #348 

Documents that blueprint static URL is only accessible if the blueprint has a prefix, otherwise the application static URL takes precedence.", # Update docs/blueprints.rst
699,"[extractors/odnoklassniki] Add support for mobile URLs (closes #16081)
### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Support for another format of m.ok.ru links as described in https://github.com/rg3/youtube-dl/issues/16081", # [odnoklassniki] Fix extractor
700,"CI Fix lock-file update workflow
Follow-up of https://github.com/scikit-learn/scikit-learn/pull/28068

The update-lock-file failed, see [build log](https://github.com/scikit-learn/scikit-learn/actions/runs/7524548489/job/20479533590).

I used `--select-build-tag` instead of `--select-tag` (flip-flopped between the two namings) the right option in the workflow `.yml` ...
", # Update workflows
701,"bpo-31968: Documentation -- add clarification on the globals dict for exec()
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
bpo-NNNN: Summary of the changes made
```

Where: bpo-NNNN refers to the issue number in the https://bugs.python.org.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `master`),
please ensure that the PR title is in the following format:

```
[X.Y]  (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `master`.

-->



https://bugs.python.org/issue31968

", # Fix typo in docstring for exec
702,"fix env version attribute
if multiple versions of `httpie` are installed on a machine, the `env.config.__meta__.httpie` attribute doesn't have the current version from `__init__.__version__`
this can cause problems if the `env` object is used to make decisions to enforce compatibility based on the httpie version.", # [MRG+1] Add test for current version
703,"website: Add missing translation keys for stats page
This PR is self explanatory, there was some missing translations based on the keys returned from the server.", # Add initial prompt review to stats.json
704,"Alpha website candidate
I've uploaded my alpha site candidate to an S3 bucket, viewable [here](https://s3.amazonaws.com/public-apis-alpha/index.html). It utilizes Vue over JQuery and Bootstrap, minimizing libraries and crazy amounts of minified file fun. I'm more than happy to listen to suggestions on this plan, but I am going to keep pressing forward in this direction. There is still plenty of work to be done here, such as loading the JSON file locally to speed up the table rendering.",
705,"Release v0.2.29
", # bump version
706,"Add documentation for PDF JS PoC
", # Add README for PDF JS
707,"Create RayleighQuotient.py
https://en.wikipedia.org/wiki/Rayleigh_quotient

### Computes Rayleigh quotient. It is used in numerical solution of eigen value problems.

* [x] Add an algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
", # Add Rayleigh quotient function
708,"Add usage for MultiBinary space
All spaces come with a definition and an example usage except for Multibinary(). Adding usage provides uniformity in documentation and ease of understanding.", # Add docstring to MultiBinary
709,"Include plugin selection at the info logging level
Quick fix for #4988

@bmw I included the classnames of the used plugins (`.__class__`) for all the major subcommands  certonly, run, renew and install
", # Add logging for plugin selection
710,"[npu] support triangle attention for llama
## üìå Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [ ] I have added relevant tags if possible for us to better distinguish different PRs


## üö® Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`



## üìù What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.



## üí• Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?

- [ ] üåù Yes, I do.
- [ ] üåö No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",
711,"Fix README Syntax (#1651)
", # Fixes #1000
712,"2019 Rav4 Limited AWD
The XLE and Limited fingerprints are able to be combined because they are essentially the same.",
713,"Remove explicit unicode literal in README.md and doc
As the end of python 2 has come, I open this PR in order to get rid of the explicit unicode literal in the README file and the documentation.
I know that this could be against the PEP 414 https://www.python.org/dev/peps/pep-0414/ but it should be harmless for the project.", # Fix unicode in docs
714,"Fast CI
Average CI time should now be less than 12 minutes. Before we were lucky if our docker build job was 10-15 minutes, which every other job waited on. Compressed docker image is about 70MB smaller, but image size shouldn't affect CI runtime too much anymore. Also resolves #1422 by completely avoiding the buggy upload/download artifact for passing the docker image around. 

change in commit-to-green-check-mark times for individual tests:
* build release: 27 -> 4 minutes
* linter: 20 -> 2.5 minutes
* unit tests: 20 -> 6 minutes
* process replay: 23 -> 10 minutes
* longitudinal: 22 -> 7.5 minutes
* test car models: 26 -> 11 minutes

Overhead from docker/github actions is pretty minimal now, so any improvements in commit-to-green-check-mark time will come from improving our slower tests.",
715,"Allow custom samplers to request discard penultimate sigma
currently custom samplers can add themselves to the list of built-in samplers but there's no facility to request discarding the penultimate sigma. this minor change moves the list of samplers subject to discard penultimate sigma into a `set` that exists as a class property.

this allows a custom sampler that wants to skip the penultimate sigma to do something like:

```python
from comfy.samplers import KSampler
KSampler.DISCARD_PENULTIMATE_SIGMA_SAMPLERS.add('sonar_dpmpp_sde')
```"," # Fix dpm_2, dpm_2_ancestral, uni_pc, uni_pc_bh2"
716,"Add missing period
", # Fix typo in CppCoreGuidelines.md
717,"Add bond options field.
##### SUMMARY
Don't restrict users to specific bond options based on bond mode; allow users to specify both the desired mode and options as free text.

##### ISSUE TYPE
 - Feature Pull Request", # Update ovirt_host_networks module
718,"Allow copying of PreparedRequests without headers/cookies
Fixes #2077.
", # Fix #1006
719,"Cloudformation getatt for Firehose and ES Domain
Added missed cloudformation getatt for KinesisFirehose::DeliveryStream and Elasticsearch::Domain
", # Fix CloudFormation Elasticsearch Domain and Firehose OutputsFixes #1006
720,"Update interpreter for azure inventory script
##### ISSUE TYPE
- Feature Pull Request
##### ANSIBLE VERSION

```
ansible 2.0.2.0
  config file =
  configured module search path = Default w/o overrides
```
##### SUMMARY

Removed the hardcoded path to the Python interpreter, this make it easier for virtual environments. Fixed whitespace.
", # fix #10075
721,"Test on Ubuntu 19.10
Fixes https://github.com/certbot/certbot/issues/7851.

You can see tests successfully running with this change at https://travis-ci.com/github/certbot/certbot/builds/160641256.

The AMI-ID was taken from https://cloud-images.ubuntu.com/locator/ec2/. As of writing this, it is the only Ubuntu 19.10 AMI on that page in `us-east-1` using EBS for storage that isn't running on ARM. The instance store AMI cannot be used because that storage type is not available for the instance size we use. See https://aws.amazon.com/ec2/pricing/on-demand/ and https://travis-ci.com/certbot/certbot/builds/113021661 for proof of that.", # Add ubuntu19.10 to letstest
722,"Add PR template
This PR adds a PR template to streamline the reviewing process.", # Add PR templateAdded a PR template to help people fill out the PR more easily.
723,"Update README.md
", # Update blogs/deepspeed-chat/ds-chat-release-8-31/README.md
724,"Adjusting version number
", # sqlmap: change version from dev to stable
725,"[3.6] bpo-34602: Avoid failures setting macOS stack resource limit (GH-14546)
Under some conditions the earlier fix for [bpo-18075](https://bugs.python.org/issue18075), ""Infinite recursion
tests triggering a segfault on Mac OS X"", now causes failures on macOS
when attempting to change stack limit with resource.setrlimit
resource.RLIMIT_STACK, like regrtest does when running the test suite.
The reverted change had specified a non-default stack size when linking
the python executable on macOS.  As of macOS 10.14.4, the previous
code causes a hard failure when running tests, although similar
failures had been seen under some conditions under some earlier
systems.  Reverting the change to the interpreter stack size at link
time helped for release builds but caused some tests to fail when
built --with-pydebug.  Try the opposite approach: continue to build
the interpreter with an increased stack size on macOS and remove
the failing setrlimit call in regrtest initialization.  This will
definitely avoid the resource.RLIMIT_STACK error and should have
no, or fewer, side effects.
(cherry picked from commit 5bbbc733e6cc0804f19b071944af8d4719e26ae6)


Co-authored-by: Ned Deily 


https://bugs.python.org/issue34602

", # Fix #18075: Increase stack size limit on macOSThis PR fixes #18075.  The default stack size limit on macOS is too small for the default recursion limit.  This causes the test suite to crash.  This PR increases the stack size limit to 10MBytes.  This is a temporary fix.  The interpreter is being built with a larger default stack size.  This PR is no longer needed.
726,"Added type hints to dependency injection pattern
Added type hints to _dependency injection_ pattern and also checked with mypy.", # [patterns] Add typing to dependency injection
727,"Switch to using docker compose v2
Azure recently dropped the `docker-compose` standalone executable (aka docker-compose v1), and since it's not receiving updates anymore, let's get with the times and update to v2 as well.", # Fix Docker compose commandFixes #9435.
728,"Issue 741: Fix background
This solves issue #741. You many need to perform a hard refresh to clear your browser cache for changes to take effect.",
729,"feat(ui): Add power-features icon
I wonder if this belongs more in getsentry?", # Add icon for power features
730,"Backport PR #32746: DOC: start 1.0.3
https://github.com/pandas-dev/pandas/pull/32746", # Add v1.0.3 to whatsnew
731,"Fixed ""CodeFormer visibility:"" rounding to 2 decimals.
", # Fix rounding of codeformer_visibility
732,"Fixing a Link in the Docs
There was a trailing `>` in this link that borked it.

Dope project, btw.", # Fix typo in docs/open_models.md
733,"Fixes typo
", # Fix typo in unit testing support link
734,"Feature mute stream log for info level
**Features**
see issue : #1109 
llm stream_response alway been print regardless of debug flag
I modified `logs.py` rather than `config2.py`.
This is because log is been set via `define_log_level` rather than `config.yaml`
To keep things simple, a global variable `_print_level` is introduced in `logs.py`
    
**Influence**
`define_log_level(print_level=""INFO"")` will mute `log_llm_stream`
", # [metagpt] fix logs.py
735,"bipedal_walker: trivial fixes
I'll have some time this weekend to fix more bugs
", # Fix bipedal_walker.py
736,"Support other features only modes for EfficientNet
This allows using other feature extraction helpers for effnet (besides the original custom class).

```
mm = timm.create_model('tf_efficientnet_b2', pretrained=True, features_only=True, feature_cfg=dict(flatten_sequential=True), out_indices=[-2, -1])
```",
737,"Update EdgeNeXt to use ClassifierHead as per ConvNeXt
EdgeNeXt has the same style as ConvNeXt, updating classification head code to match ConvNeXt.", # [edgenext] fix head
738,"VW MQB: Add FW for 2023 TROC
route nameÔºö0bbe367c98fa1538|2023-12-22--10-53-18--0
and modify model year to 2023 and remove MQB-A0 to MQB



<!--- ***** Template: Fingerprint *****

**Car**
Which car (make, model, year) this fingerprint is for

**Route**
A route with the fingerprint

-->

<!--- ***** Template: Car Bugfix *****

**Description**

A description of the bug and the fix. Also link the issue if it exists. 

**Verification**

Explain how you tested this bug fix. 

**Route**

Route: [a route with the bug fix]


-->

<!--- ***** Template: Bugfix *****

**Description**

A description of the bug and the fix. Also link the issue if it exists. 

**Verification**

Explain how you tested this bug fix. 


-->

<!--- ***** Template: Car Port *****

**Checklist**

- [ ] added entry to CarInfo in selfdrive/car/*/values.py and ran `selfdrive/car/docs.py` to generate new docs
- [ ] test route added to [routes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/car/tests/routes.py)
- [ ] route with openpilot:
- [ ] route with stock system:
- [ ] car harness used (if comma doesn't sell it, put N/A):


-->

<!--- ***** Template: Refactor *****

**Description**

A description of the refactor, including the goals it accomplishes. 

**Verification**

Explain how you tested the refactor for regressions. 


-->

",
739,"Add user friendly wildcard error for ACMEv1
Part of #5367.

Checking for wildcards in ACME doesn't have to worry about bytes, because the relevant documentation says the value must be unicode/str and none of Certbot's code paths violates this. (`acme.crypto_util._pyopenssl_cert_or_req_all_names` which is used in `BackwardsCompatibleClientV2` before calling this function returns unicode/str in Python 2/3 respectively.) ", # Fix ACME client for wildcard domainsThis PR fixes the ACME client for wildcard domains.
740,"Fix pytests
2 issues were causing pytests to fail:
- Tensorflow required `scipy==1.4.1`
- cx-Oracle `8.0.0` broke `test_sqlalchemy_engine_2_oracle`",
741,"HangMan Game
This is a 'HangMan Game' Program which was written in 'Python' Language.", # HangMan Game
742,"[3.9] bpo-39096: Improve description of 'e', 'f' and 'g' presentation types (GH-23537)
* Improve description of 'e', 'f' and 'g' presentation types

* Drop the 'E' from Scientific 'E' notation; remove >= 0 qualifications

* Fix false statement that the alternate form is valid for Decimal

* Nitpick: remove the Harvard/Oxford comma

* Add note that the decimal point is also removed if no digits follow it, except in alternate form
(cherry picked from commit c642374b3ef72f6f300616f07aea2a3f9ed83e51)


Co-authored-by: Mark Dickinson 


https://bugs.python.org/issue39096

", # Update string.rst
743,"BREEZE: add troubleshooting section to cover ETIMEDOUT during start-airflow
closes: #30947
related: #30947

- Adds section under `troubleshooting` to describe a potential ETIMEDOUT condition when running breeze to start airflow, and inform readers of potential symptoms , reasons, and way to avoid it.", # Breeze: ETIMEOUT error
744,"Revert ""Update bubble_sort.py""
def bubbleSort(alist):
    for passnum in range(len(alist)-1,0,-1):
        for i in range(passnum):
            if alist[i]>alist[i+1]:
                temp = alist[i]
                alist[i] = alist[i+1]
                alist[i+1] = temp

alist = [54,26,93,17,77,31,44,55,20]
bubbleSort(alist)
print(alist)
", # Bubble sort fix
745,"Improve main documentation
The resulting docs look like:
![Screen Shot 2019-11-27 at 2 38 27 PM](https://user-images.githubusercontent.com/6504915/69763933-989a5480-1123-11ea-8538-76a3a354b2bd.png)

I deleted the exceptions because I think it's not feasible to document the possible exceptions raised by all of Certbot.", # Fix documentation for main.py
746,"Improve dropblock impl, add fast variant, better AMP speed, inplace‚Ä¶
",
747,"‰øÆÂ§çË•øÁìúËßÜÈ¢ë‰∏ãËΩΩÂ§±Ë¥•ÈóÆÈ¢ò;
fix problem:the JSON object must be str, bytes or bytearray, not NoneType",
748,"Linkify Github usernames in authors list
- Linkify github usernames
- Remove usernames that do not exist

Change-Id: Ib88b70a3010e915b3570ae5062c8cb416c9a6462
", # Update AUTHORS.rst
749,"Fix whisper STT
Users who updated to `gradio==4.26.0` have reported that the `whisper_stt` extension has stopped working. It appears that the error stems from the fact that passing `None` as the new value to a `gradio.Audio` component (to reset the component) now causes an exception to occur when the `.change` listener is used. This PR simply changes the event listener to `stop_recording`, which fixes the issue while keeping the UI behavior the same.

Fixes https://github.com/oobabooga/text-generation-webui/issues/5850 and perhaps https://github.com/oobabooga/text-generation-webui/issues/5805

## Checklist:

- [X] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
", # Stop recording when auto-transcribing
750,"kraken - fetchTradingFee
- Remove hardcoded fees
- Add `fetchTradingFee`", # Kraken: fix fees
751,"Store Message Toxicity in database
Implementing the calculation of the message toxicity in the workflow as well as storing its value in the database.",
752,"Added default file_metadata to get basic metadata that many postprocessor use
# Description

- minor import error fixed
- added default file_metadata to get basic metadata that many postprocessor use

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [x] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [x] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [x] I have performed a self-review of my own code
- [x] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [x] I have added tests that prove my fix is effective or that my feature works
- [x] New and existing unit tests pass locally with my changes
- [x] I ran `make format; make lint` to appease the lint gods
", # Add default file metadataAdd default file metadata to file reader.
753,"Socks proxy support for Websockets 
added support for Socks proxies for websockets,.
have been testing for quite some while and they work

[fixes #20315]",
754,"Add Github Action for black formatting check




## Why are these changes needed?

Easier validation of PRs. `format.sh` fails on pylint, so it never even runs black.

## Related issue number (if applicable)

#270

## Checks

- [X] I've run `format.sh` to lint the changes in this PR.
- [X] I've included any doc changes needed.
- [X] I've made sure the relevant tests are passing (if applicable).
",
755,"Add ParamountPlusSeriesIE.
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Closes https://github.com/yt-dlp/yt-dlp/issues/602
", # [cbs] Add ParamountPlusSeriesIE
756,"DataTalks.Club podcast, newsletter and blog
Also changed the formatting to lists", # Update blogs
757,"create a new ConfigResource and deprecate /?_config_
Relates to #7465

We're adding a migration path to `ConfigUpdateProxyListener(ProxyListener)`

It currently allows to update the config with a POST on `/?_config_`, and some services can set up listeners to react to the changes. 

This endpoint will be deprecated.

We can't remove the current ProxyListener and will log a deprecation message.
It currently match on `/?_config_`, a query string, which we cannot use the router to match. The new route is at `/_localstack/config` and make uses of `LocalstackResources`. 

\cc @thrau for the change in `LocalstackResources`", # Add config update endpointAdds a new endpoint to allow config updates.
758,"Replace the easy v. secure prompt with more clear choices
Fixes #3328, though we should still make the larger change to a more expressive, expansive UI."," # Add ""No redirect"" option to redirect menu"
759,"Merge dev branch
",
760,"Update README.md
-fixed some grammatical errors
-improved word choice", # Update README.md
761,"Fix pydantic and autodoc_pydantic version to <2.0.0 until support is added.
- pydantic is working on updating to a 2.0.0 that is not backwards compatible, we will need to add this, but since this will break our CI when it is released, this is a preventative step.
- autodoc_pydantic hasn't addressed how they will handle this, though it will be tracked in [this issue](https://github.com/mansenfranzen/autodoc_pydantic/issues/146).  I assume they will update to 2.0.0 once they add support as well.
- Once pydantic 2.0.0 is released, fixes will be added in #3289.", # Update requirements for readthedocs
762,"Support unknown backends in entrypoint_prod.sh
Close: https://github.com/apache/airflow/issues/22868

@don1uppa Can you check it?
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/main/UPDATING.md).
", # Fix docker entrypoint scriptFixes #1000
763,"Add installation documentation for ubuntu
The conf.py is broken when eulertour merged his doc fork to master. To test the doc add ``master_doc = ""index""`` to conf.py  

I have not test this on a fresh system, the installation process is inferred from my bash history.  ", # Add Ubuntu installation instructions
764,"Fixed #35056 -- Fixed system check crash on reverse m2m relations with related_name in ModelAdmin.filter_horizontal/vertical.
ticket-35056

Thanks Thomas Feldmann for the report.

Regression in 107865780aa44914e21d27fdf4ca269bc61c7f01.", # Fixed #35056: Admin check for reverse many-to-many fields with related_nameFixes #35056
765,"handle printing even if sys.stdout.buffer is not available
Related: #729, #879", # Fix UnicodeEncodeError in transcribe.pyFixes #729
766,"[tune] Hotfix Ax breakage when fixing backwards-compat


## Why are these changes needed?

A variable misname for a code-path added recently for avoiding backwards
compat breakage.


## Related issue number



## Checks

- [x] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/latest/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failure rates at https://ray-travis-tracker.herokuapp.com/.
- Testing Strategy
   - [x] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested (please justify below)", # Remove deprecated AxSearchAxSearch is deprecated and will be removed in the future.
767,"Store the key file in the config dir
**Description:**
This PR changes the default path where the `media_player.webostv` and `notify.webostv` store their config (ie. pairing key file). It used to be `$HOME/.pylgtv` and now defaults to `$HASS_CONFIG_DIR/webostv.conf`.

**Related issue (if applicable):** fixes #5645

**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** home-assistant/home-assistant.github.io#1951

**Example entry for `configuration.yaml` (if applicable):**
```yaml
media_player:
  - platform: webostv
    host: mytv.lan
    filename: webostv.conf

notify:
  - platform: webostv
    host: mytv.lan
    filename: webostv.conf
```

**Checklist:**

If user exposed functionality or configuration variables are added/changed:
  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)

If the code communicates with devices, web services, or third-party tools:
  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**
  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).
  - [x] New dependencies are only imported inside functions that use them ([example][ex-import]).
  - [x] New dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.
  - [x] New files were added to `.coveragerc`.

If the code does not interact with devices:
  - [ ] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**
  - [ ] Tests have been added to verify that the new code works.

[ex-requir]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L16
[ex-import]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L51
", # Update pylgtv to 0.1.3
768,"[extractor/vidio] Add support for /embed link, fix test in VidioIE
### Description of your *pull request* and other information



<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

ADD DESCRIPTION HERE
This PR add support for `/embed` link in vidio.com. Some sites like enamplus.liputan6.com use this embed link. This PR also fix test error based on test return 

Fixes #


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))
", # [vidio] Add embed url
769,"[URPlay] Fix extractor
### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Closes #28073.
", # [urplay] Fix urplay extractor
770,"Fix model download link in documentation
", # fix typo
771,"Adding sensible UI logging for typical user
Closes #599 

There are 2 rules I followed when adjusting the logging level of certain messages.

First, I refrained from changing messages from info to warning (although some messages seemed like they belong more to warning, but that could be done in another PR).

And second, I tried to make it as possible to what a normal user would understand, without the messages being pedantic.
", # Use debug logging for dry runThis PR uses debug logging for dry run.
772,"zb error types
",
773,"Add IP Location API
", # Add IP Location APIAdded IP Location API
774,"Fixing inference api for FP32 and non-masking GPT-based models
This PR solves https://github.com/microsoft/DeepSpeed/issues/1192 and https://github.com/microsoft/DeepSpeed/issues/1203"," # [transformer] fix softmax_context_fp32### Describe the changes you have made:- fix softmax_context_fp32### Reference any relevant issues (e.g. ""Fixes #000""):- Fixes #000### Pre-Submission Checklist (optional but appreciated):- [ ] I have included relevant documentation updates (stored in /docs)- [ ] I have read `docs/CONTRIBUTING.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/DOCUMENTATION.md`"
775,"Apache conf library
More conf files.  And a very hackish script to run each of them through the client, so you can see that it does what you expect (though in some cases, what you expect is breakage because of the nature of the test).
",
776,"community[patch]: Use uuid4 not uuid1
Using UUID1 is incorrect since it's time dependent, which makes it easy to generate the exact same uuid
",
777,"Feature/verify trigger rule
Make the dag classes verify the syntax on trigger_rule.

Because you can enter text in this field and typo can cost a lot on this, since the scheduler does not complain about unknown statuses.
", # Add validation for trigger_rule
778,"Fix misdetection of project root with `--stdin-filename`
There are a number of places this behaviour could be patched, for
instance, it's quite tempting to patch it in `get_sources`. However
I believe we generally have the invariant that project root contains all
files we want to format, in which case it seems prudent to keep that
invariant.

Fixes #3207", # Fix misdetection of project root and verbose logging of sources in cases involving `--stdin-filename`Fixes #3216
779,"Fixing pool set and pool delete via cli
There was a typo in 1.10.15 which was causing pool set and pool delete to fail when done via the new CLI command.
Fixed the typos.

closes: #14940
related: #14940
"," # Fix CLI pool_set and pool_deleteFixes #10333 ## Type of changes- [ ] Bug fix- [ ] New feature- [ ] Documentation / docstrings- [ ] Tests- [ ] Other## Checklist- [ ] I've run the latest [black](https://github.com/psf/black) with default args on new code.- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.- [ ] I've added tests for new code.- [ ] I accept that @willmcgugan may be pedantic in the code review.## DescriptionPlease describe your changes here. If this fixes a bug, please link to the issue, if possible.### Before submitting- [ ] This PR only changes the code, not the documentation, tests, or CHANGELOG.- [ ] I have included relevant documentation updates, if needed.- [ ] I have added tests that prove the code works.- [ ] I have added an entry in the [Commits](https://github.com/apache/airflow/tree/master/airflow/hooks/base_hooks) that links to this PR.- [ ] If the Airflow 2.0 branch is relevant, this PR only changes documentation, tests, or CHANGELOG."
780,"TST/REF: collect tests from test_multilevel
", # [MRG] Add test for setitem with expansion on MultiIndex
781,"Update sites.md
", # 305 sites
782,"Fix sparse attention for small block-sizes
This fixes https://github.com/microsoft/DeepSpeed/issues/1513", # [deepspeed] Fix sparse_attention matmul
783,"Introducing a custom converter for regex
I've been trying to introduce a new `BaseConverter` to match an arbitrary regex for custom endpoints. Need some direction from @thrau üòá ", # Add regex converter to router
784,"CP.44 improve example and add more accurate discussion
", # Fix #10064
785,"python 3.11 need this
", # Update numpy version
786,"Added: Cross-Site WebSocket Hijacking (CSWSH)
Hi

This adds Cross-Site WebSocket Hijacking (CSWSH).

Cool repo btw :)

Best regards,
Emanuel", # Add Cross-Site WebSocket Hijacking (CSWSH) to Web Sockets README
787,"[TIPC] Fix amp
att",
788,"Fix Typo
Fixed typo", # Fix typo in README.md
789,"Atari env fix
remove redundant repeated local variable assigments", # Remove unused import
790,"Add support for GPT4All-13B-Snoozy
## Why are these changes needed?

Add support for the GPT4All-13B-Snoozy model: A finetuned LLaMa 13B model on assistant style interaction data trained by Nomic AI.
Model Card: https://huggingface.co/nomic-ai/gpt4all-13b-snoozy

Results:
![image](https://github.com/lm-sys/FastChat/assets/49086305/62756f43-b01d-48f6-a6c1-331c0f2b51f6)


## Related issue number (if applicable)

Closes #863

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [ ] I've made sure the relevant tests are passing (if applicable).
", # Add GPT4All-13B-SnoozyAdd GPT4All-13B-Snoozy to the list of models.
791,"feat(extensions): Allow hiding link connectors
Thank you for adding this feature (linksRenderMode) to core. I would like to add the ""Hidden"" option (invalid number 3 will just hide the connector lines), so that I can remove that extension from my extension pack to prevent conflicts

https://github.com/failfa-st/failfast-comfyui-extensions", # Add Hidden link render mode
792,"place the logo in the middle in README.md
I placed the logo in the center in README.md.
because I think it's better.

and I placed title in the middle too.", # Update README.md
793,"Remove pdb from llama_cpp
# Description

During the fix of https://github.com/jerryjliu/llama_index/issues/7547, a call to `pdb` was introduced, in https://github.com/jerryjliu/llama_index/commit/94912afd2c15fc10b7eddbe7f95cba8555fd1fc6. It should not be in the final code.

Fixes #7653  

## Type of Change

Please delete options that are not relevant.

- [X] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [X] I stared at the code and made sure it makes sense

No need to test. Just a minor clean up.

# Suggested Checklist:

- [X] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [X] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
", # Remove pdb import
794,"Fix type confusion bug
fixes #4325", # Fix decodePage()
795,"Update README.md
added new source to Deep Learning on how to create neural network using Keras.", # Add Keras beginner tutorial linkAdded a link to a beginner tutorial on Keras.
796,"configurable masks color and default brush color
Oh my eyes my eyes
I'm blinded by the Light

## Description
https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/682ff8936df018330e0d2a259794a262dc3251b2 I know you're overjoyed
but at least make it consistent and configurable

the default brush color for the color sketch is not important, as we have a `color picker` built into the tool
but since you changed it on `Inpaint sketch` and not for `sketch` I decide to annoy you to put all three options in
> and set the default color black to annoy you, change it to white if you want

unfortunately I don't think there is a `color picker` on the noirmal `sketch` tool (only on the `color-sketch`)
so we cannot change the mask brush color during use
and the mask color is not updated by the settings immediately and requires a Reload
maybe it's achievable if we do some messing around with JavaScript

able to change the transparent mask color is important
as depending on what images you're working on some mask color may not be suited

## Screenshots/videos:
before pr

https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/40751091/87d663b5-ec3a-4490-afa7-255e18cb7027

after PR
![image](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/40751091/35a9b32b-0a12-441c-93ba-68dc6e65e5ef)


## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Add brush color options for img2img sketch and inpaint sketchAdd brush color options for img2img sketch and inpaint sketch.
797,"Reword proxies section and add warning
This adds a warning around the Session proxies issues in Requests 2.x and cleans up a few erroneous sentences in the following section. Notably, rewording the environment intro to match the warning above, and removing `curl_ca_bundle` which was added in #5670. It's not particularly relevant to this section and is covered elsewhere.

## Preview Render

", # Fix docs for advanced usersFixes #2018.
798,"Added escape and double escape character(s).
", # Add \\ to blns.json
799,"Remove the need for TRAVIS to be set.
I initially added this when the script was doing things like migrating all LXD containers to the snap. I think the external side effects are now pretty minimal thought so I think we can remove the need for this environment variable which makes it easier to use outside of CI for manual testing.", # Remove build_and_install.sh CI checkThis script is not needed in CI.
800,"skflow, simplified interface to tensorflow by Google, added
", # Add skflow
801,"Solve issue add sound in Windows 10
Change way to remove sound_file_path
", # Fix for sound file deletion
802,"gh-93351: Ensure the position information in AST nodes created by the parser is always consistent
Closes: #93351
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y]  (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->
", # Validate position information
803,"Bump minimum Python version to 3.5.2
See https://github.com/scrapy/scrapy/pull/4243#issuecomment-632899356", # bump python version to 3.5.2Bump python version to 3.5.2.
804,"fix onprem storage incorrect config
fix: https://github.com/mingrammer/diagrams/issues/344", # Fix aliases for onprem storage
805,"Approve functions used as default arguments
### **Describe your change:**

Use linter directive `# noqa: B0008` for these functions because they set a seed value and `BaseBackend` is reused across all calls and `LinearCongruentialGenerator.__init__()` is only called once for each instance.

[flake8-bugbear](https://pypi.org/project/flake8-bugbear) ___B008 Do not perform function calls in argument defaults.  The call is performed only once at function definition time. All calls to your function will reuse the result of that definition-time function call.  If this is intended, assign the function call to a module-level variable and use that variable as a default value.___

* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [ ] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
", # Fixed flake8-bugbear errors
806,"Fix requirements in gui  api
", # Remove unused imports
807,"Fix various item tags (missing colons)
I.2, C.10, A.1, A.2, A.4, NL.5", # Fix typos in C++ Core Guidelines
808,"Forcing pip to use https on older docker images (Wheezy & Precise)
As was pointed out in PR #5205, certain integration tests on Travis tests are failing because it seems PyPi now requires HTTPS, and the default for pip on Wheezy and Precise is to use HTTP. This PR updates the Dockerfiles to use HTTPS.", # Add PIP_INDEX_URL to Dockerfile
809,"Exception of CP.100 refined to include the ""sequentially consistent memory model"" only
Atomic variables are safe with the sequentially consistent memory model (**memory_order_seq_cst**) only. Weakly ordered atomics cannot be considered safe for mainstream use. The exception clause of CP.100 refined.
", # Update CppCoreGuidelines.md
810,"Fix crash when email submission endpoint unavailable
Handle KeyError and ValueError so that if the email submission endpoint
goes down, Certbot can still run.

Add tests to eff_test.py:
 - simulate non-JSON response as described in issue #5858
 - simulate JSON response without 'status' element

Non-JSON response throws an uncaught ValueError when attempting to
decode as JSON. A JSON response missing the 'status' element throws an
uncaught KeyError when checking whether status is True or False.

Teach _check_response to handle ValueError and KeyError and report an
issue to the user.

Rewrite if statement as assertion with try-except block to make error
handling consistent within the function. Update test_not_ok to make
mocked raise_for_status function raise a requests.exceptions.HTTPError.

Resolves #5858", # Fix EFF tests for HTTP errorsFixes #1006.
811,"[MRG+1] Remove --lsprof command-line option. 
See #1531 for motivation.
", # Remove lsprof option
812,"Fix tf-idf
Fix #2974
"," # Update tf-idf weighting schemeThe original tf-idf weighting scheme is based on the paper ""A Tensor-based Approach to Text Classification"" by Y. Zhang and J. Zhang. The paper uses a weighting scheme 1, which is not the same as the one used in the original tf-idf implementation. The original tf-idf implementation uses a weighting scheme 2, which is the one used in the Wikipedia article."
813,"Requirements version bump
This bumps the versions of:

- scandir
- h5py
- Keras
- opencv-python

to their latest vesions.

Virtual Environment will need to be setup again to make use of these.",
814,"Add rauth.
Added rauth to the list of modules.
", # Add rauth to out-there.rst
815,"remove `fix_return_consumed_capacity`, fixes #6437
`fix_return_consumed_capacity` was added for issue #2049.

This seems to be the cause of issue #6437 and it doesn't solve the problem for issue #2049 from what I can tell.
If `ReturnValues` are not specified it always forces `ReturnConsumedCapacity` as `TOTAL`.

Steps to try reproduce #2049 without success:
```bash
# Create table to repro the issue
awslocal dynamodb create-table \
  --table-name ""put-item-response"" \
  --billing-mode ""PAY_PER_REQUEST"" \
  --attribute-definitions \
    AttributeName=pkey,AttributeType=S \
  --key-schema \
    AttributeName=pkey,KeyType=HASH \
  --region eu-west-1

# This works as expected, no values are returned as there is no previous item
awslocal dynamodb put-item \
  --table-name ""put-item-response"" \
  --item '{""pkey"":{""S"":""test""}}' \
  --return-values ""ALL_OLD""

# This works as expected, the values for the previous item is returned.
awslocal dynamodb put-item \
  --table-name ""put-item-response"" \
  --item '{""pkey"":{""S"":""test""},""val"":{""S"":""foo""}}' \
  --return-values ""ALL_OLD""

# Cleanup resources
awslocal dynamodb delete-table \
  --table-name ""put-item-response""
```", # Fix return values for put_itemFixes #2049
816,"Enable multipage apps by default
## üìö Context

We initially merged the multipage apps PR with the `ui.hideSidebarNav` config option defaulting to
`True` to use the option as a kind of ""feature flag"" (we need the option either way in case we ever want
to turn off the nav component and instead build one into Cloud).

Now that we're closer to the release of the multipage apps feature, we can toggle the option to enable
MPAs by default.

- What kind of change does this PR introduce?

  - [x] Feature
", # Fix description of hideSidebarNav option
817,"Remove ansible-galaxy login
##### SUMMARY
* GitHub is removing the underlying API used to implement the `login` command. Since the general consensus seems to be that relatively nobody currently uses this command (in favor of explicit token passing), support was simply removed for interactive login. If a future need arises, this command should be reimplemented via OAuth Device Auth Grants (eg, see https://github.com/ansible/ansible/pull/71628)
* login or role login commands now produce a fatal error with a descriptive message
* updated 2.10 and 2.11 porting guide entries

fixes #71560

##### ISSUE TYPE
- Bugfix Pull Request

##### COMPONENT NAME
Galaxy CLI

##### ADDITIONAL INFORMATION




```paste below

```
",
818,"Use call to `inspect_reponse()` that works on 0.24.x
Otherwise, when the spider is executed from a standalone script as described in http://doc.scrapy.org/en/stable/topics/practices.html#run-scrapy-from-a-script it triggers an exception like this:

```
.../site-packages/scrapy/shell.py"", line 131, in inspect_response
...
from scrapy.project import crawler
...
exceptions.ImportError: cannot import name crawler
```
", # Fix shell.rst example
819,"Bug Fix - #8415
  - Issue: #8415 ", # Fix #1006
820,"Add self to data code owners
A couple of the `/data/` code owners are less active on the project recently and we have a few PRs to that directory piling up. Adding myself to code owners so I can review these PRs. Also created a code owner category for `/oasst-data/`.", # Update CODEOWNERS
821,"[MRG+1] py3 fix HttpProxy and Retry Middlewares
",
822,"Add phishstats.info
", # Added PhishStats APIAdded PhishStats API to the list of APIs.
823,"üåê Add German translation for `docs/de/docs/advanced/testing-websockets.md`
‚Üê `advanced/events.md` (#10693)
‚Üí `advanced/testing-events.md` (#10704)

[German translation progress](https://github.com/tiangolo/fastapi/discussions/10582)", # Add German translation for docs/de/docs/advanced/testing-websockets.md
824,"Make st.write render sets as list instead of strings
<!--
Before contributing (PLEASE READ!)

‚ö†Ô∏è If your contribution is more than a few lines of code, then prior to starting to code on it please post in the issue saying you want to volunteer, then wait for a positive response. And if there is no issue for it yet, create it first.

This helps make sure:

  1. Two people aren't working on the same thing
  2. This is something Streamlit's maintainers believe should be implemented/fixed
  3. Any API, UI, or deeper architectural changes that need to be implemented have been fully thought through by Streamlit's maintainers
  4. Your time is well spent!

More information in our wiki: https://github.com/streamlit/streamlit/wiki/Contributing
-->

## üìö Context

_Please describe the project or issue background here_

- What kind of change does this PR introduce?

  - [ ] Bugfix
  - [ ] Feature
  - [ ] Refactoring
  - [x] Other, please describe:

This PR is related to [Issue-#4923](https://github.com/streamlit/streamlit/issues/4923). It makes `st.write` to serialize `set` as `list` instead of `string`, so the user can benefit on existing collapse mechanism when browsing the data.

## üß† Description of Changes

- _Add bullet points summarizing your changes here_

  - [ ] This is a breaking API change
  - [ ] This is a visible (user-facing) change

**Revised:**

_Insert screenshot of your updated UI/code here_

**Current:**

Currently `set` is serialized to string, when using `st.write`, like this:

```
{
  ""list"": [],
  ""set"": ""set()"",
  ""dict"": {}
}
```
I'd like to render them as `list`, so we can benefit on existing `st.json` collapse mechanism when browsing the data.

_Insert screenshot of existing UI/code here_

## üß™ Testing Done

- [ ] Screenshots included
- [ ] Added/Updated unit tests
- [ ] Added/Updated e2e tests

## üåê References

_Does this depend on other work, documents, or tickets?_

- **Issue**: Closes [#4923](https://github.com/streamlit/streamlit/issues/4923)

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
", # st.json: convert sets to lists## Why are these changes needed?- [ ] This change fixes an issue (closes #xxxx)- [ ] This change adds feature (closes #xxxx)- [ ] This change is to do things the right way (closes #xxxx)- [ ] This change is to meet a new requirement (GH-xxxx)- [ ] This change is to keep up with the latest versions of dependencies (GH-xxxx)## Related issue number (if applicable)## Checks- [ ] I've run `format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed.- [ ] I've made sure the relevant tests are passing (if applicable).
825,"[generation] consistently add eos tokens
Currently beam search returns inconsistent outputs - if hypos have different lengths we get eos, if they are the same - we don't. I found a sentence where if I change one letter in one of the input words the beam search outputs all suddenly lack eos, which is an inconsistent behavior.

This PR makes the output more consistent. (but not 100%, please see below)

---------


Also why not replace:

```
            if sent_lengths[i] < max_length:
                decoded[i, sent_lengths[i]] = eos_token_id
```
with:
```
            decoded[i, sent_lengths[i]] = eos_token_id
```
Shouldn't eos always be there? If generated data gets truncated, the caller needs to use a larger `max_length`.

Currently, if the hypos lengths are on the cusp of `max_length`, some of them will get eos, whereas others won't, which is again inconsistent.

Please correct me if my logic is flawed.

-----

I also looked at `_generate_no_beam_search` - there eos adding logic uses a somewhat different logic. 

Should the two functions (beam/no_beam) be consistent eos-injection wise?

", # Fix generation_utils.py
826,"Add `dtype=float32` to PadSequencesTest
For function `keras.utils.pad_sequences`, it says

    sequences: List of sequences (each sequence is a list of integers).

but floats here also work. This commit add test for float type

Modifications to the function itself and document may involve API stability, so no changes have been made, further consideration may be needed", # Add float test for pad_sequences
827,"Continue on Docker failure (all backends)
Signed-off-by: Glenn Jocher 

<!--
Thank you for submitting a YOLOv5 üöÄ Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ‚úÖ [Contributing Guide](https://github.com/ultralytics/yolov5/blob/master/CONTRIBUTING.md) for more details.
-->


## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Improved GitHub Actions workflow for YOLOv5 Docker image deployment üöÄ

### üìä Key Changes
- Enabled `continue-on-error: true` in the GitHub Actions workflow for the Docker job.
- The `continue-on-error` parameter has been moved from the ""Build and push arm64 image"" step to the job level.

### üéØ Purpose & Impact
- üõ†Ô∏è **Purpose:** Ensures that the entire Docker job can proceed in the face of errors, rather than stopping at the first failure within a specific step.
- ‚úÖ **Impact:** This should improve the robustness of the continuous integration/continuous deployment (CI/CD) pipeline. Users can expect more consistent Docker image updates, even if one part of the build process encounters issues."," # [ultralytics/yolov5] Fix Docker workflow### Describe your change:Fix Docker workflow### Reference any relevant issues (e.g. ""Fixes #000""):### Pre-Submission Checklist (optional but appreciated):- [ ] I have included relevant documentation updates (stored in /docs)- [ ] I have read `docs/CONTRIBUTING.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/ROADMAP.md`- [ ] I have read `docs/CHANGELOG.md`"
828,"Unicode string that often causes rendering issues
Adding string containing three ‡∏î‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá‡πá‡πâ‡πâ‡πâ‡πâ‡πâ‡πá‡πá‡πá‡πá characters that often causes rendering issues.", # Add accents to unicode subscript/superscript
829,"Fix http.Response.make type annotation
", # fix typing for headers
830,"Update tasks.json (Catalan translation).
Fixed Catalan translation:
- Given uniformity regarding formality (tu-v√≥s)
- Homogenized terminology
- Fixed typos", # Update labels
831,"Roll back widget_id (commit 0577857)
Turns out the original commit broke the case where one widget depends on the output from another:

```py
country = st.selectbox(""Country"", countries)
states = country_state_map[country]
state = st.selectbox(""State"", states)
```", # Fix DeltaGeneratorFixes #1006
832,"Remove false positives
I currently do not have enough time to find a fix for the false positives. So those sites have been removed for now.",
833,"[Whisper] Move decoder id method to tokenizer
# What does this PR do?

Moves the method `get_decoder_prompt_ids` from the processor to the tokenizer. The primary reason for this change is that the ASR pipeline class does not load the processor object, but rather the feature extractor and tokenizer separately (see [docs](https://github.com/huggingface/transformers/blob/699e90437f984d69ad3c9b891dd2e9d0fc2cffe4/src/transformers/pipelines/automatic_speech_recognition.py#L123)). Therefore, as things currently stand, pipeline does not have access to the processor method `get_decoder_prompt_ids`. By moving it to the tokenizer, it will be able to call this method with pipeline.

Note that this is not a breaking change: we retain a method `get_decoder_prompt_ids` in the processor. This method simply calls the `get_decoder_prompt_ids` from the tokenizer:

https://github.com/huggingface/transformers/blob/ca8b332d31a1b90e18f134620e69063418add69e/src/transformers/models/whisper/processing_whisper.py#L44-L45


## Before submitting
- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors who may be interested in your PR.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

Models:

- albert, bert, xlm: @LysandreJik
- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj
- longformer, reformer, transfoxl, xlnet: @patrickvonplaten
- fsmt: @stas00
- funnel: @sgugger
- gpt2: @patrickvonplaten, @LysandreJik
- rag: @patrickvonplaten, @lhoestq
- tensorflow: @LysandreJik

Library:

- benchmarks: @patrickvonplaten
- deepspeed: @stas00
- ray/raytune: @richardliaw, @amogkam
- text generation: @patrickvonplaten
- tokenizers: @n1t0, @LysandreJik
- trainer: @sgugger
- pipelines: @LysandreJik

Documentation: @sgugger

HF projects:

- datasets: [different repo](https://github.com/huggingface/datasets)
- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)

Examples:

- maintained examples (not research project or legacy): @sgugger, @patil-suraj
- research_projects/bert-loses-patience: @JetRunner
- research_projects/distillation: @VictorSanh

 -->
"," # [whisper] fix language code### Describe your change:* [x] Add an algorithm?* [ ] Fix a bug or typo in an existing algorithm?* [ ] Documentation change?### Checklist:* [x] I have read [CONTRIBUTING.md](https://github.com/oobabooga/text-generation-webui/blob/master/CONTRIBUTING.md).* [x] This pull request is all my own work -- I have not plagiarized.* [x] I know that pull requests will not be merged if they fail the automated tests.* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.* [x] All new Python files are placed inside an existing directory.* [x] All filenames are in all lowercase characters with no spaces or dashes.* [x] All functions and variable names follow Python naming conventions.* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.* [x] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`."
834,"Toward Devkit Consistency
## ÁõÆÊ†á

‰øÆÊîπ‰ª£Á†Å‰ª•ÊèêÂçáPaddleCVÂ•ó‰ª∂‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂ÈÄÇÈÖçXÈ°πÁõÆ„ÄÇ‰øÆÊîπÂêéÔºåÂ•ó‰ª∂Â∫îÊª°Ë∂≥Â¶Ç‰∏ã‰∏ÄËá¥ÊÄßË¶ÅÊ±ÇÔºö

1. Â∞ÜËÆ≠ÁªÉËøáÁ®ã‰∏≠ÊúÄ‰ºòÔºà‰∏ÄËà¨ÊòØÈ™åËØÅÈõÜ‰∏äÁ≤æÂ∫¶ÊúÄÈ´òÔºâÁöÑÊ®°ÂûãÊùÉÈáçÂ≠òÂÇ®Âú®ËæìÂá∫ÁõÆÂΩïÁöÑ`best_model`Â≠êÁõÆÂΩï‰∏≠ÔºåÊñá‰ª∂ÂëΩÂêç‰∏∫`model.pdparams`„ÄÇ‰∏é‰πãÁõ∏ÈÖçÂ•óÁöÑ‰ºòÂåñÂô®ÂèÇÊï∞ÔºàÂ¶ÇÊûúÂ≠òÂÇ®ÁöÑËØùÔºâÊñá‰ª∂ÂëΩÂêç‰∏∫`model.pdopt`Ôºå‰πüÂ≠òÂÇ®Âú®ËØ•ÁõÆÂΩï‰∏≠„ÄÇ
2. ÊîØÊåÅÂ∞ÜËÆ≠ÁªÉ„ÄÅÈ™åËØÅËøáÁ®ã‰∏≠VisualDL‰∫ßÁîüÁöÑ.logÊ†ºÂºèÊó•ÂøóÊñá‰ª∂‰øùÂ≠òÂú®ËæìÂá∫ÁõÆÂΩï‰∏≠ÔºàÊó†ÂµåÂ•óÂ≠êÁõÆÂΩïÔºâ„ÄÇ
3. Â•ó‰ª∂Ê†πÁõÆÂΩïÂ≠òÂú®`requirements.txt`Êñá‰ª∂ÔºåÊåáÂÆö‰ΩøÁî®Â•ó‰ª∂Âü∫Á°ÄÂäüËÉΩÈúÄË¶ÅÁöÑ‰æùËµñ„ÄÇÂú®Â•ó‰ª∂Ê†πÁõÆÂΩïÂèØÈÄöËøá`pip install .`Êàñ`pip install -e .`ÊñπÂºèÔºàËá≥Â∞ëÂÖ∂‰∏≠‰∏ÄÁßçÔºâÂÆâË£ÖÂ•ó‰ª∂Ê†∏ÂøÉÂ∫ì„ÄÇ
4. ÂØπ‰∫éÊ®°ÂûãÂØºÂá∫ÂäüËÉΩÔºåÈªòËÆ§ÊîØÊåÅÊàñÈÄöËøáÂëΩ‰ª§Ë°åÈÄâÈ°π/ÈÖçÁΩÆÊñá‰ª∂Á≠âÊâãÊÆµÊîØÊåÅÂØºÂá∫‰∏∫FDÊ†ºÂºè„ÄÇ„ÄéFDÊ†ºÂºè„ÄèÁöÑÂØºÂá∫ÁªìÊûúÈÄöÂ∏∏ÂåÖÂê´Â¶Ç‰∏ãÊñá‰ª∂Ôºö
- `inference.pdiparams`Ôºö‰øùÂ≠òÊùÉÈáçÂèÇÊï∞„ÄÇ
- `inference.pdiparams.info`Ôºö‰øùÂ≠ò‰∏éÂèÇÊï∞ÊúâÂÖ≥ÁöÑÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ
- `inference.pdmodel`Ôºö‰øùÂ≠òÊ®°ÂûãÁªìÊûÑÊèèËø∞‰ø°ÊÅØ„ÄÇ
- ÔºàÂèØÈÄâÔºâ`inference.yml`ÔºöÈ¢ÑÂ§ÑÁêÜÈÖçÁΩÆÊñá‰ª∂„ÄÇ

## ‰ª£Á†ÅÂèòÂä®

1. „Äê‰∏ÄËá¥ÊÄßÊèêÂçá„Äë‰ΩøËÆ≠ÁªÉÊó∂Ê£ÄÊü•ÁÇπÂ≠òÂÇ®‰ΩçÁΩÆÊª°Ë∂≥‰∏ÄËá¥ÊÄßË¶ÅÊ±Ç1„ÄÇ
2. „Äê‰∏ÄËá¥ÊÄßÊèêÂçá„Äë„Äê**‰∏çÂÖºÂÆπÂçáÁ∫ß**„Äë‰øÆÊîπVisualDLÊó•ÂøóÂ≠òÂÇ®‰ΩçÁΩÆ‰ª•Êª°Ë∂≥‰∏ÄËá¥ÊÄßË¶ÅÊ±Ç2„ÄÇ
3. „ÄêÂäüËÉΩÂ¢ûÂº∫„Äë‰øÆÊîπ`tools/infer_det.py`‰∏≠`raw_det_res`ÂØπ„ÄéÈõ∂ÁõÆÊ†áÊ°Ü„ÄèÊÉÖÂΩ¢ÁöÑÂ§ÑÁêÜÈÄªËæëÔºåÂú®ËØ•ÊÉÖÂΩ¢‰∏ã‰ªçÁÑ∂Â≠òÂÇ®ÂõæÂÉèÔºàÂ≠òÁöÑÊòØÂéüÂõæÔºâÔºå‰ªéËÄå‰ΩøÁî®Êà∑Âú®ÂêÑÁßçÊÉÖÂÜµ‰∏ãÂùáËÉΩËé∑ÂæóËæìÂá∫ÂõæÂÉèÔºåËÄåÊó†ÈúÄÂÖ≥Ê≥®ÁõÆÊ†áÊ°ÜÊï∞Èáè„ÄÇ
4. „ÄêÂäüËÉΩÂ¢ûÂº∫„ÄëË∞ÉÊï¥signal handlersÁöÑËÆæÁΩÆÊó∂Êú∫„ÄÇ‰øÆÊîπÂâçÔºåsignal handlersÂú®ÊØèÊ¨°ËΩΩÂÖ•`ppocr.data`Êó∂Ëá™Âä®ËÆæÁΩÆÔºå‰ΩÜËøôÁßçÂÅöÊ≥ïÊúâ‰ª•‰∏ãÁº∫ÁÇπÔºö1) Áî®Êà∑Âú®‰ΩøÁî®Python REPLÊàñËøõË°åÊñ≠ÁÇπË∞ÉËØïÊó∂ÁªèÂ∏∏ÈúÄË¶ÅËæìÂÖ•Ctrl+CÔºåËÄåËøôÂ∞ÜÁõ¥Êé•Ëß¶ÂèëÁ®ãÂ∫èÁöÑÁªàÊ≠¢Ôºå‰ª§Áî®Êà∑ÊÑüÂà∞ÁñëÊÉëÂíå‰∏ç‰æøÔºõ2) ‰ªéË∞ÉÁî®ÂÖ≥Á≥ªÁöÑËßíÂ∫¶Êù•ÁúãÔºå‰Ωú‰∏∫calleeÔºåÈÄªËæë‰∏äÊù•ËØ¥Â∫îÂΩìÂ∞ΩÂèØËÉΩÂáèÂ∞ëÂØπcallerÁöÑÂΩ±ÂìçÔºåËÄåÁõÆÂâçÁöÑÂÆûÁé∞ÊòæÁÑ∂‰∏çÊª°Ë∂≥Ëøô‰∏ÄÁÇπÔºõ3) Â¶ÇÊûúÂ∫ìÂú®Â≠êËøõÁ®ã‰∏≠Ë¢´Ë∞ÉÁî®Ôºå‰Ωú‰∏∫Â≠êËøõÁ®ãÔºåÂç≥‰Ωø‰∏çËÄÉËôëÊùÉÈôêÈóÆÈ¢òÔºåÂè™‰ªéËµÑÊ∫êÂõûÊî∂ÁöÑËßíÂ∫¶Êù•ÁúãÔºåËØïÂõæÈÄöËøá`SIGKILL`ÊùÄÊ≠ªÂåÖÊã¨Áà∂ËøõÁ®ã‰ª•ÂèäÂÖ∂ÂÆÉÊóÅÊîØËøõÁ®ãÂú®ÂÜÖÁöÑÊï¥‰∏™ËøõÁ®ãÁªÑÂÜÖÁöÑÊàêÂëò‰ªçÊòØÂç±Èô©ÁöÑË°å‰∏∫„ÄÇ‰øÆÊîπÂêéÔºåsignal handlersÂè™Âú®ÂΩìÂâçËøõÁ®ã‰∏∫ËøõÁ®ãÁªÑleader„ÄÅ‰∏îÁî®Êà∑ÈÄöËøáËÑöÊú¨ÊâßË°åÔºàÊéíÈô§‰∫ÜREPLÁöÑÊÉÖÂÜµÔºâÁöÑÊÉÖÂÜµ‰∏ãË¢´ËÆæÁΩÆ„ÄÇÊ≠§ÂÅöÊ≥ï‰ªçÊúâ‰ºòÂåñÁ©∫Èó¥ÔºåËØ¶ËßÅ`ppocr/data/__init__.py`‰∏≠ÁöÑÊ≥®Èáä„ÄÇ

## ÈÅóÁïôÈóÆÈ¢ò

1. ÂØπ‰∫é‰ª£Á†ÅÂèòÂä®1Âíå2Ôºå**Â∞öÊú™Êõ¥Êñ∞Áõ∏ÂÖ≥ÊñáÊ°£**„ÄÇËã•Ê≠§PRÂêàÂÖ•ÔºåÂèØËÉΩÈúÄË¶ÅÂ•ó‰ª∂ÂêåÂ≠¶ËøõË°åÊõ¥Êñ∞„ÄÇ
2. ËÄÉËôëÂà∞ÂèçÂêëÂÖºÂÆπÊÄßÔºåÊú¨Ê¨°ÊîπÂä®Êú™ÂØπPaddleOCRÂéüÊú¨ÁöÑÊúÄ‰ºòÊ®°ÂûãÂ≠òÂÇ®Êú∫Âà∂ËøõË°åÂèòÊõ¥ÔºåËÄåÂè™ÊòØËøΩÂä†‰∫Ü`best_model`ÁõÆÂΩï„ÄÇÂõ†Ê≠§ÔºåËæìÂá∫ÁõÆÂΩï‰∏≠Â∞ÜÂ≠òÂú®`model.pdparams`Âíå`model.pdopt`ÁöÑ‰∏§‰ªΩÊã∑Ë¥ù„ÄÇÂêéÁª≠ÈúÄËÄÉËôëÊ∏êËøõÂú∞ÊîπÂä®ÊóßÁöÑÂ≠òÂÇ®Êú∫Âà∂Ôºå‰ΩøÊúÄ‰ºòÊ®°ÂûãÂè™‰øùÁïô‰∏Ä‰ªΩ„ÄÇ",
835,"Spider constructor expects name as argument, not start_urls.
Fixes #4644", # [MRG+1] Fix #10064
836,"add param m3u8 , allow download video via m3u8 url
", # Add m3u8 support
837,"Fix ill-formed example C.65 (missing noexcept on declaration)
There cannot be a mismatch between the exception specification of a declaration and definition. The example in its current form fails to compile.", # [MRG] Add noexcept to Foo& operator=(Foo&&)
838,"Fix #903: docs version parsing
", # Fix docs.conf.py
839,"Edited few more answers in the Linux section and fixed some typos
Please review and merge if things are fine.
Thanks,
susenj", # Update README.md
840,"JSONLoader Documentation Fix
- Description: 
Updated JSONLoader usage documentation which was making it unusable
- Issue: JSONLoader if used with the documented arguments was failing on various JSON documents. 
- Dependencies: 
no dependencies
- Twitter handle: @TheSlnArchitect

If no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17, @rlancemartin.
 -->
", # [docs] Add text_content=False to JSONLoader
841,"Merge dev branch
", # Add OpenAI logits extensionAdd OpenAI logits extension to the list of extensions.
842,"Remove unnecessary period in documentation
Except for this one, I also notice that there are [two sentences](http://flask.pocoo.org/docs/dev/testing/#testing-cli-commands) end with period instead of colon before a code snippet, should we change it?", # Fix typo in docs/testing.rst
843,"cherry-pick #3236
", # Fix text_drawers.py
844,"C.138 initial content
Proposed content to the stub rule C.138 ""Create an overload set for a derived class and its bases with using"", based on bs_faq2 entry [Why doesn't overloading work for derived classes?](http://www.stroustrup.com/bs_faq2.html#overloadderived) and openoffice guideline on [Name hiding](https://wiki.openoffice.org/wiki/Writing_warning-free_code#Name_hiding).", # [MRG+1] Add example for hiding overload sets
845,"Fix some TF slow tests
# What does this PR do?

This PR fixes several slow tests related to saved model creation.
"," # [TF] Fix saved model loadingFixes #10000## Why are these changes needed?## Related issue number (if applicable)## Checks- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.- [ ] I've run `scripts/format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed for https://docs.github.com/en/github/writing-on-github/about-pull-requests- [ ] I've made sure the relevant tests are passing (if applicable)."
846,"Check for GPU or MPS availability before using CPU
### Describe the changes you have made:

In `point.py`, check for GPU or MPS before defaulting to CPU.

### Reference any relevant issues (e.g. ""Fixes #000""):

- Fixes https://github.com/OpenInterpreter/open-interpreter/issues/1131


### Pre-Submission Checklist (optional but appreciated):

- [x] I have included relevant documentation updates (stored in /docs)
- [x] I have read `docs/CONTRIBUTING.md`
- [x] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [x] Tested on MacOS
- [ ] Tested on Linux
", # Use GPU if available
847,"Make A Better Readme
I added emoji's and a better introduction to make the README.md look nicer.", # Update README.md
848,"[eval] update llama npu eval
## üìå Checklist before creating the PR

- [x] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## üö® Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`



## üìù What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.



## üí• Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ‚≠êÔ∏è Do you enjoy contributing to Colossal-AI?

- [x] üåù Yes, I do.
- [ ] üåö No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
"," # [colossal-eval] Use get_current_device() instead of torch.cuda.current_device()## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`- [ ] I have added relevant tags if possible for us to better distinguish different PRs## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented## ‚≠êÔ∏è Do you enjoy contributing to Colossal-Eval?- [ ] üåù Yes, I do.- [ ] üåö No, I don't.Tell us more if you don't enjoy contributing to Colossal-Eval."
849,"[Test] [Cherrypick] Fix agent stress failure
Signed-off-by: SangBin Cho 





## Why are these changes needed?

Cherry pick agent stress test failure fix

## Related issue number

Closes https://github.com/ray-project/ray/issues/30494

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
", # [dashboard] Remove atari.yaml## Why are these changes needed?- Remove atari.yaml as it is no longer needed.- Add workload.py to run the dashboard.- Add mem_check.py to check memory usage.## Related issue number- #1000## Checks- [ ] I've run `format.sh` to lint the changes in this PR.- [ ] I've included any doc changes needed.- [ ] I've made sure the relevant tests are passing (if applicable).
850,"expose AWS_REGION_NAME in S3FeedStorage
Similar PRs:
- https://github.com/scrapy/scrapy/pull/5092
- https://github.com/scrapy/scrapy/pull/4429
- https://github.com/scrapy/scrapy/pull/4417", # Add support for AWS region nameAdd support for AWS region name.
851,"Fix health check for HTTPS endpoints with self-signed certs
Fix health check for HTTPS endpoints with self-signed certificates - fixes #2387", # Fix SSL verification for LocalStack# DescriptionThis PR fixes the SSL verification for LocalStack. # Checklist- [x] I have read the [Contributing guidelines](https://github.com/localstack/localstack/blob/master/CONTRIBUTING.md).- [x] I have performed a self-review of my own code.- [x] My code follows the [style guidelines](https://github.com/localstack/localstack/blob/master/CONTRIBUTING.md#code-style).- [x] My code passes [tests](https://github.com/localstack/localstack/blob/master/CONTRIBUTING.md#writing-tests).
852,"[Classifier]: Replace print with LOGGER
This PR replaces all top level print statements in classifier.py with LOGGER

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Switch from print statements to a unified logger in the classifier script.

### üìä Key Changes
- Replaced `print` function calls with `LOGGER.info` for better logging management.
- Changes applied across various functions including `train`, `test`, `classify`, and `imshow`.

### üéØ Purpose & Impact
- üé® **Enhanced Readability**: By using a centralized logging system, the output is standardized and formatted consistently.
- üîç **Improved Debugging**: Centralized logs make it easier to troubleshoot issues by looking at a single stream of log data.
- üìà **Easier Integration**: Logger setup can later be configured for different log levels and destinations (e.g., files, monitoring systems), making the classifier module more versatile in various environments.
- üë• **User Experience**: For end-users, this change means cleaner console output and potentially access to log files for a historical record of operations.", # Logging
853,"Fix account restoration on renewal
Fixes https://github.com/certbot/certbot/issues/9805.", # Fix ACME account restoration on renewalFixes #9805.
854,"Homogenize Steering Fault Avoidance
Cleaned up the steering fault avoidance into a common function, since it will be common across a lot of cars.", # [car] add steering fault prevention
855,"[Veo] Add new extractor
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

https://github.com/ytdl-org/youtube-dl/issues/29445
"," # [veo] Add VeoIE extractor## Please follow the guide below- You will be asked some questions, please read them **carefully** and answer honestly- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])- Use *Preview* tab to see how your *pull request* will actually look like---### Before submitting a *pull request* make sure you have:- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)### What is the purpose of your *pull request*?- [x] Bug fix- [ ] Improvement- [ ] New extractor- [ ] New feature---### Description of your *pull request* and other informationAdd VeoIE extractor- [x] I have performed a self-review of my code- [ ] I have commented my code, particularly in hard-to-understand areas- [ ] I have made corresponding changes to the documentation- [ ] I have added Google Colab support for the following extractors (put these lines into `docs/source/source/extractors.rst`):  - [x] [VeoIE](https://github.com/yt-dlp/yt-dlp/blob/master/yt-dlp/extractor/veo.py)  - [ ] [VeoIE](https://github.com/yt-dlp/yt-dlp/blob/master/yt-dlp/extractor/veo.py)"
856,"docs: improve readability of Langchain Expression Language get_started.ipynb
**Description:** A few grammatical changes to improve readability of the LCEL .ipynb and tidy some null characters.
**Issue:** N/A", # Fixes #1000
857,"bpo-36710: Add runtime variable to Py_FinalizeEx()
* Add a 'runtime' variable to Py_FinalizeEx() rather than working
  directly on the global variable _PyRuntime
* Add a 'runtime' parameter to _PyGC_Fini(), _PyGILState_Fini()
  and call_ll_exitfuncs()


https://bugs.python.org/issue36710

", # Fix #30049 -- Fix #30049
858,"Generate localhost keys for tests on the fly
Fixes #4651",
859,"Correctly handle single-byte Content-Range
HTTPie fails if it continues a download with a single byte left. For example:
```
$ http -b -d example.org
Downloading 1.23 kB to ""index.html""
Done. 1.23 kB in 0.00043s (2.81 MB/s)
$ python3 -c 'import sys; sys.stdout.write(open(""index.html"").read()[:-1])' > index-short.html
$ http -b -d -c -o index-short.html example.org

http: error: ContentRangeError: Invalid Content-Range returned: 'bytes 1255-1255/1256'
```
The range is inclusive on both ends.", # [downloads] fix ContentRangeError
860,"Fix feedback from input api key
Removed getpass, added prompt_toolkit.
Now shows * when typing characters

### Describe the changes you have made:

### Reference any relevant issues (e.g. ""Fixes #000""):

### Pre-Submission Checklist (optional but appreciated):

- [ ] I have included relevant documentation updates (stored in /docs)
- [x] I have read `docs/CONTRIBUTING.md`
- [ ] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [x] Tested on Windows
- [ ] Tested on MacOS
- [ ] Tested on Linux
", # Update poetry.lock
861,"Rename of docs
some rename of .rst files

I tried to be smart about just renaming references to the client, but I've also changed some urls to certbot/certbot which will have to wait for the GH repo to be moved
", # Update copyright notice
862,"Build certbot snap without the isolation build
Fixes #8252

With @bmw we digged quite a lot on why the failure happens on ARM snap, and here we what we understood:
* the failure occurs since the version 50 of setuptools is available
* normally, we should not be impacted because the setuptools version used in the snap build should be the one installed by the `core20` base snap, because the build occurs in a `venv` created with `--system-site-packages`
* BUT associated with the build isolation provided by recent versions of pip (to implement PEP 517), a bad interaction happens: following the definition of the build system provided by `cryptography`, pip installs the most recent version of setuptools on a separate path for the build (because `cryptography` just asks for a minimal version of `setuptools`), then features of this version conflict with the old version of `setuptools` initially present
* the exact interaction is described here: https://github.com/pypa/pip/issues/6264#issuecomment-685230919. Basically the new version of `setuptools` triggers some hacks, that are then applied at runtime on the old version of `setuptools` that is also still available in `sys.path` at this point, and breaks the build.

To fix that, one can disable the isolation build on cryptography, by passing `PIP_NO_ISOLATION_BUILD=no` to pip. It is the purpose of this PR.

This will have the consequence to not be PEP 517 compliant: if needed the `cryptography` library will be built using the `setuptools` available in the system. In general I think it makes sense for the snap build purpose, since we control precisely the build environment, and makes consistent build that will not be broken by a new version of a build system if library maintainers did not provide a strict version of it in their build requirements. However we need now to take care about having a compatible build system for all libraries that may have specific requirements in their build system using the PEP 517 definition in `pyproject.toml`.

I think as of now that it is a safe move if we keep using the most recent version of `setuptools` available in Ubuntu 20.04, and it is the case here for snap builds. It may however be problematic if some libraries require another build system than `setuptools` and do not provide a fallback to a `setuptools` build. For the record, `dns-lexicon`, that I maintain, uses `poetry` and so a PEP 517 compliant definition of a build system, but provides also this fallback (https://github.com/AnalogJ/lexicon/blob/master/setup.py).


", # [snapcraft] disable build isolationDisable build isolation for snapcraft.
863,"Fix typo in doc comment of BitsAndBytesConfig
# What does this PR do?

Fix a typo in doc comments of `BitsAndBytesConfig` class.

It must be `nf4` instead of `fn4`.

Here is a comparison code in current main branch:

https://github.com/huggingface/transformers/blob/539e2281cd97c35ef4122757f26c88f44115fa94/src/transformers/utils/quantization_config.py#L166-L167

`qlora` implementations also uses `nf4`.

https://github.com/artidoro/qlora/blob/bdc655dfa71e5ef1553a078980fb5083c346a4cf/qlora.py#L138-L141

So I think it is better to fix doc, not a code.

## Before submitting
- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [x] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

@sgugger, @stevhliu @MKhalusova @younesbelkada and @sourabh112

Or @TimDettmers?
", # Fix typo in quantization config
864,"Prefer subprocess run over call
1. Fix resource warning in the destructor
```
/Users/REDACTED/.asdf/installs/python/3.10.0/lib/python3.10/subprocess.py:1067: ResourceWarning: subprocess 46612 is still running
  _warn(""subprocess %s is still running"" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback

```

2. Use preferred, non-legacy API per https://docs.python.org/3/library/subprocess.html#subprocess.call
3. Older call style no longer needed with Python 3.6+", # Use subprocess.run() instead of subprocess.call()
865,"Fix fused qkv sizing for bloom
Fix bug mentioned in https://github.com/microsoft/DeepSpeed/pull/4157.

Thanks @dc3671 and @inkcherry ", # fix: transpose fused qkv weight
866,"change the variables
I have changed the variables according to the standard sorting algorithms", # Bubble_sort.py
867,"Ignore broken E203
See https://github.com/python/black/issues/565", # Fix flake8 ignore rules
868,"Update CLI usage docs for --csr
With #2403 and #3046, `certbot` gained the ability to parse CSRs encoded as PEM and without a SAN extension. Update the CLI usage docs to reflect this change.
", # Fix --csr help message
869,"improve docker image size
# Description

Improves the docker image size. Summary of various changes

* Added `--no-install-recommends`, newlined install items and removed the apt list and cache as per [best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#run) 
* Merged the `mujoco` RUN directive with the `apt` RUN directive to reduce layers
* Added `--no-cache-dir` to the `pip` installs since the pip cache isn't needed for a docker image
* `mujoco` is now downloaded and piped to tar to location, previously it the `mujoco210-linux-x86_64.tar.gz` was left in the docker image when it wasn't needed
* Added `SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]` for safety
* Added quotes around various strings to ensure splitting doesn't occur

Followed rules from [hadolint](https://github.com/hadolint/hadolint) and [shellcheck](https://github.com/koalaman/shellcheck)


Running `docker build -t gym-orig --build-arg=PYTHON_VERSION=3 -f py.Dockerfile . --no-cache` with the original `Dockerfile`, the size (compressed) came out to 1.61GB and the same command with the `gym-new` tag it comes down to `1.45GB` compressed

```bash
$ docker images | grep gym
gym-new                                                                      latest          ab7f651f39f3   17 seconds ago   1.45GB
gym-orig                                                                     latest          aa7c83ec05ea   24 seconds ago   1.61GB
```

Similarly with the same build comparison but for x86 (since I'm on an M1 MacBook), i.e. ```DOCKER_DEFAULT_PLATFORM=linux/amd64 docker build -t gym-new --build-arg=PYTHON_VERSION=3 -f py.Dockerfile . --no-cache;```

```bash
$ docker images | grep gym
gym-orig                                                                     latest          9f513111ab2e   12 seconds ago   2GB
gym-new                                                                      latest          241544f82ab2   30 seconds ago   1.75GB
```

Fixes # (issue)

## Type of change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

### Screenshots
Please attach before and after screenshots of the change if applicable.

<!--
Example:

| Before | After |
| ------ | ----- |
| _gif/png before_ | _gif/png after_ |


To upload images to a PR -- simply drag and drop an image while in edit mode and it should upload the image directly. You can then paste that source into the above before/after sections.
-->

# Checklist:

- [] I have run the [`pre-commit` checks](https://pre-commit.com/) with `pre-commit run --all-files` (see `CONTRIBUTING.md` instructions to set it up)
- [x] I have commented my code, particularly in hard-to-understand areas
- [x] I have made corresponding changes to the documentation
- [x] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes

<!--
As you go through the checklist above, you can mark something as done by putting an x character in it

For example,
- [x] I have done this task
- [ ] I have not done this task
-->
", # Fixes #1000Fixes #1000
870,"BUG ensure that estimator_name is properly stored in the ROC display
We were storing `estimator.__class__.__name__` instead of `name` which wrongly label the curve when calling `disp.plot()` for the second time.", # [MRG] Fix plot_roc_curve bugFixes #16500
871,"Fix tests
And improve our `certbot-compatibility-test` Dockerfile as we never needed these dependencies.", # Remove dev/docs from compatibility testThis PR removes the dev/docs from the compatibility test.
872,"Stop auto queue on error
Today if there is an error the auto queue keeps queuing in loop, over and over again, this PR fix it.", # Fix UI to not queue when there is an error
873,"Update pipeline.rst - Fix query in `merge_data()` task
The alias for the subquery was missing in the `merge_data()` function's query, so it just needed to be added. Otherwise, the `employees` table remains empty. I found the error in the postgres container logs:
```
2023-01-25 08:00:03 2023-01-25 14:00:03.256 UTC [70428] ERROR:  subquery in FROM must have an alias at character 74
2023-01-25 08:00:03 2023-01-25 14:00:03.256 UTC [70428] HINT:  For example, FROM (SELECT ...) [AS] foo.
2023-01-25 08:00:03 2023-01-25 14:00:03.256 UTC [70428] STATEMENT:  
2023-01-25 08:00:03                 INSERT INTO employees
2023-01-25 08:00:03                 SELECT *
2023-01-25 08:00:03                 FROM (
2023-01-25 08:00:03                     SELECT DISTINCT *
2023-01-25 08:00:03                     FROM employees_temp
2023-01-25 08:00:03                 )
2023-01-25 08:00:03                 ON CONFLICT (""Serial Number"") DO UPDATE
2023-01-25 08:00:03                 SET ""Serial Number"" = excluded.""Serial Number"";
```

Thank you!

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
", # Update tutorial pipeline
874,"Bugfix to Tool - Mask - add missing
Corrects error from variable mis-spelling.", # Fix mask.py
875,"Console: add error message for older Windows versions
This fixes #4908.", # [MRG] Fix Windows 10 Build 10586 bughttps://github.com/microsoft/Windows-10-Build-10586-bug-fixes/issues/1
876,"Fixed test modifying data created in setUpTestData
", # Fix test_signals.py
877,"Expose full ClientHello object in tls_clienthello hook
This PR makes it possible to access the raw [`ClientHello`](https://github.com/mitmproxy/mitmproxy/blob/c4dd46c3db97eabedf14fc54a23dae8d167fdad2/mitmproxy/net/tls.py#L284) object in the `tls_clienthello` hook as `data.client_hello`.

```python
def tls_clienthello(data):
    print(data.client_hello)
```", # [TLS] Add establish_server_tls_first to ClientHelloDataThis PR adds a `establish_server_tls_first` flag to `ClientHelloData` that allows the client to pause the handshake and establish TLS with an upstream server first. This is useful for generating an interception certificate.
878,"Fix race in websocket broadcaster
", # Fix app.py broadcast
879,"Optimized numpy functions in Converter
This PR optimized the conversion speed.
This is done mainly by choosing more performant variants for the numpy processing in the `Converter` class.

The Converter now also gets whole batches from the `Predict.queue_out_frames` method. This was mainly done to enable batch processing and potential replacing numpy functions with keras ones later on, but it also increased my speed by about 3it/s.

Optimizing the worker Plugins remains to be done. They did not take enough time in my setup to be really relevant. This may be different with other settings.

Benchmarks:
- Current staging: 16.45 it/s
- This PR WITHOUT providing whole batches to the converter: 21.40 it/s
- This PR as is: 24.69 it/s

Tested on 10k frames with a resolution of 1280x720.
The tested model on my system can do raw prediction (without anything else) with about 37.2 it/s
", # Fixes #1006Fixes #1006
880,"Clarify result of lower_bound
To me, the previous formulation made it sound like the return value is always `last` if `val` is not in the range. It seems confusing to me, hence the clarification.", # Fix #2004
881,"Improve language just a bit
", # Fix typo in C++ Core Guidelines
882,"Configurable JPG downscale threshold
## Allowing the user to configure the image downscale parameters in setting

### this PR is a alternative solution to the issue describe by PR [#7549 Changed flag for 4chan from 4MB to 2MB. Real limit](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/7549)

this exposes the image downscale parameters in settings
allowing the user to configure downscale size to their specific needs

### changes

- added 2 new settings entries

1. `target_side_length` defalut to 4000 (same as original)
2. `img_downscale_threshold`  defalut to 4 MB (same as original)

- changes to the description of `export_for_4chan`

### backwards compatibility
no issue
as this change uses the default values the current behavior is not changed", # Add downscale threshold for export_for_4chanAdd downscale threshold for export_for_4chan.
883,"Update Readme - Include nlp.js
Include nlp.js to javascript natural language processing libraries", # Added nlp.jsAdded nlp.js to the list of resources.
884,"[ie/NeteaseMusic] more metadata
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

In the --embed-metadata option, add album title to the file metadata.

Closes #8530



Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))



Copilot Summary  

<!--
copilot:all
-->
### ü§ñ Generated by Copilot at d3d3824

### Summary
üéµüè∑Ô∏èüõ†Ô∏è

<!--
1.  üéµ - This emoji represents music and can be used to indicate that the change is related to a music extractor or service.
2.  üè∑Ô∏è - This emoji represents a label or tag and can be used to indicate that the change adds more metadata fields to the extracted information.
3.  üõ†Ô∏è - This emoji represents a tool or a fix and can be used to indicate that the change is part of a pull request that aims to improve the extractor and fix some issues.
-->
Add more metadata fields to `NetEaseMusicIE` extractor. Use existing helper functions to parse the JSON response from the API and extract fields such as `album_artist`, `album`, `thumbnail` and `average_rating`.

> _`NetEaseMusic` tracks_
> _More metadata extracted_
> _Winter of content_

### Walkthrough
* Add metadata fields for NetEaseMusic tracks ([link](https://github.com/yt-dlp/yt-dlp/pull/8531/files?diff=unified&w=0#diff-ef518849a6d7b0f3923c20058cda5da3f6931526cf36aadce1eda0f4e7620f5cL256-R265)) by using `traverse_obj` to access the JSON response and helper functions to convert the values




", # [neteasemusic] Add album and average rating
885,"Update `check_python(minimum=3.6.2)`
In looking at the `torch` package they have a minimum of 3.6.2, we should probably stick to that, which I think will keep the R Pi people happy who run on 3.6.9.
https://pypi.org/project/torch/

## üõ†Ô∏è PR Summary

Made with ‚ù§Ô∏è by [Ultralytics Actions](https://github.com/ultralytics/actions)

### üåü Summary
Updated the minimum required Python version for compatibility.

### üìä Key Changes
- The minimum Python version check has been lowered from `3.7.0` to `3.6.2`.

### üéØ Purpose & Impact
- **Purpose:** This change makes the software accessible to users who are running slightly older Python versions.
- **Impact:** Expands the user base by allowing installation on systems with Python `3.6.2+`, while previously systems needed `3.7.0+`. This can be particularly beneficial for those on environments with restrictions on software updates.üîÑ", # Update check_python() to check for 3.6.2
886,"Add troubleshooting instructions to the finish_release script for snapcraft credential expiry.
Inspired by the recent release process.", # fix: snapcraft login error
887,"TST/CI: disable hypothesis deadline for test_tick_add_sub
- [x] closes #24641 
- [x] tests added / passed
- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [ ] whatsnew entry", # [MRG] Add deadline to ticks testsAdd deadline to ticks tests.
888,"ENH Better spacing & padding in html repr
After having conversations with some users, increasing the spacing & padding was suggested to improve the visualization:

#### PR


#### main


", # Fixes #10064
889,"Added CodeFormer to Credits
request from Shangchen Zhou", # Add CodeFormerAdded CodeFormer to the list of stable diffusion models.
890,"Checkpoint backwards-compatbility workaround
Fix #2382 
", # [deepspeed] fix fragment_address
891,"[requires.io] dependency update on master branch
", # bump pyinstaller to 4.2
892,"[TagesschauIE] Add extractor for tagesschau.de (fixes #3049)
Fixes #3049.
", # [tagesschau] Add extractor
893,"Remove subpackages symlinks.
This is a follow-up for merged
https://github.com/letsencrypt/boulder/pull/459.
", # Remove letsencrypt-apache and letsencrypt-nginx
894,"404 when thumb file not found
## Description
Response 404 instead of crash when thumb file is not found.

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Add HTTPException for missing files
895,"Fix order of arguments in rainmachine sensors

## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->

Fixes
```
2021-10-16 07:41:21 ERROR (MainThread) [homeassistant.components.binary_sensor] Error while setting up rainmachine platform for binary_sensor
Traceback (most recent call last):
  File ""/usr/src/homeassistant/homeassistant/helpers/entity_platform.py"", line 248, in _async_setup_platform
    await asyncio.shield(task)
  File ""/usr/src/homeassistant/homeassistant/components/rainmachine/binary_sensor.py"", line 133, in async_setup_entry
    [
  File ""/usr/src/homeassistant/homeassistant/components/rainmachine/binary_sensor.py"", line 134, in 
    async_get_sensor(description.api_category)(entry, controller, description)
  File ""/usr/src/homeassistant/homeassistant/components/rainmachine/__init__.py"", line 336, in __init__
    ""configuration_url"": f""https://{entry.data[CONF_IP_ADDRESS]}:{entry.data[CONF_PORT]}"",
KeyError: ip_address
2021-10-16 07:41:21 ERROR (MainThread) [homeassistant.components.sensor] Error while setting up rainmachine platform for sensor
Traceback (most recent call last):
  File ""/usr/src/homeassistant/homeassistant/helpers/entity_platform.py"", line 248, in _async_setup_platform
    await asyncio.shield(task)
  File ""/usr/src/homeassistant/homeassistant/components/rainmachine/sensor.py"", line 116, in async_setup_entry
    [
  File ""/usr/src/homeassistant/homeassistant/components/rainmachine/sensor.py"", line 117, in 
    async_get_sensor(description.api_category)(entry, controller, description)
  File ""/usr/src/homeassistant/homeassistant/components/rainmachine/__init__.py"", line 336, in __init__
    ""configuration_url"": f""https://{entry.data[CONF_IP_ADDRESS]}:{entry.data[CONF_PORT]}"",
KeyError: ip_address
```






## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [x] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] ü•à Silver
- [ ] ü•á Gold
- [ ] üèÜ Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
", # Remove unnecessary arguments from sensor.py
896,"Update README.md for Latex injection
Hi üëã 

Adding a payload to read multi line file.
I also state that injections may need to be wrapped.

Cheers", # LaTeX Injection: Read file
897,"Improving performance for PDF loader
The PyMuPDF brings much better performance for PDF loading.

https://pymupdf.readthedocs.io/en/latest/about.html#performance
Here is a comparison article:
https://medium.com/social-impact-analytics/comparing-4-methods-for-pdf-text-extraction-in-python-fd34531034f

It's about **5x-30x faster** for text extraction.

And In my few test cases, PyMuPDF have better result in CJK characters, Although they both may display a lot of garbled characters.

The different is PDFMinerLoader make a single document object but PyMuPDFLoader make each page as a document object.

This PR already contains the change that I've made for this update:
https://github.com/imartinez/privateGPT/pull/560/files

* Remove read subscript [0] only for _loader.load()_
* Update _results.append(doc)_ to  _results.extend(docs)_"," # Update ingest.py to use PyMuPDF instead of PDFMiner.six### DescriptionPDFMiner.six is no longer maintained and has been deprecated. This PR replaces it with PyMuPDF.### Checklist:- [x] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).- [x] This pull request is all my own work -- I have not plagiarized.- [x] I know that pull requests will not be merged if they fail the automated tests.- [x] This PR only changes one or more open issues, and the commit message references them.- [x] If the code changes in this PR are substantial (more than 10%), then the issue should be updated to reflect this.- [x] All new and outdated dependencies have been added to the `requirements.txt` file.- [x] All tests have passed. Note that there may be a few flaky tests, see the recent failures at the end of this section."
898,"MAINT Parameters validation for sklearn.model_selection.permutation_test_score
#### Reference Issues/PRs

Towards #24862.

#### What does this implement/fix? Explain your changes.

Automatic parameters validation for [sklearn.model_selection.permutation_test_score](https://github.com/scikit-learn/scikit-learn/blob/c3bfe86b4/sklearn/model_selection/_validation.py#L1207)", # [MRG] Fix validation for permutation_test_scoreFixes #10064
899,"fixbug#979 : `RuntimeError: fail to reduce message length` 
#979 
**Features**
- updated MAX-TOKEN according to openai document
- minior optimization of code style
- fixed issues `RuntimeError: fail to reduce message length`
   
**Influence**
before gpt-3.5-turbo will raise error, this pr fixed it
", # Update token counter for gpt-3.5-turbo
900,"Bump pygments from 2.7.3 to 2.7.4
Bumps [pygments](https://github.com/pygments/pygments) from 2.7.3 to 2.7.4.

Release notes
Sourced from pygments's releases.

2.7.4


Updated lexers:


Apache configurations: Improve handling of malformed tags (#1656)


CSS: Add support for variables (#1633, #1666)


Crystal (#1650, #1670)


Coq (#1648)


Fortran: Add missing keywords (#1635, #1665)


Ini (#1624)


JavaScript and variants (#1647 -- missing regex flags, #1651)


Markdown (#1623, #1617)


Shell

Lex trailing whitespace as part of the prompt (#1645)
Add missing in keyword (#1652)



SQL - Fix keywords (#1668)


Typescript: Fix incorrect punctuation handling (#1510, #1511)




Fix infinite loop in SML lexer (#1625)


Fix backtracking string regexes in JavaScript/TypeScript, Modula2
and many other lexers (#1637)


Limit recursion with nesting Ruby heredocs (#1638)


Fix a few inefficient regexes for guessing lexers


Fix the raw token lexer handling of Unicode (#1616)


Revert a private API change in the HTML formatter (#1655) --
please note that private APIs remain subject to change!


Fix several exponential/cubic-complexity regexes found by
Ben Caller/Doyensec (#1675)


Fix incorrect MATLAB example (#1582)


Thanks to Google's OSS-Fuzz project for finding many of these bugs.



Changelog
Sourced from pygments's changelog.

Version 2.7.4
(released January 12, 2021)


Updated lexers:


Apache configurations: Improve handling of malformed tags (#1656)


CSS: Add support for variables (#1633, #1666)


Crystal (#1650, #1670)


Coq (#1648)


Fortran: Add missing keywords (#1635, #1665)


Ini (#1624)


JavaScript and variants (#1647 -- missing regex flags, #1651)


Markdown (#1623, #1617)


Shell

Lex trailing whitespace as part of the prompt (#1645)
Add missing in keyword (#1652)



SQL - Fix keywords (#1668)


Typescript: Fix incorrect punctuation handling (#1510, #1511)




Fix infinite loop in SML lexer (#1625)


Fix backtracking string regexes in JavaScript/TypeScript, Modula2
and many other lexers (#1637)


Limit recursion with nesting Ruby heredocs (#1638)


Fix a few inefficient regexes for guessing lexers


Fix the raw token lexer handling of Unicode (#1616)


Revert a private API change in the HTML formatter (#1655) --
please note that private APIs remain subject to change!


Fix several exponential/cubic-complexity regexes found by
Ben Caller/Doyensec (#1675)


Fix incorrect MATLAB example (#1582)


Thanks to Google's OSS-Fuzz project for finding many of these bugs.



Commits

4d555d0 Bump version to 2.7.4.
fc3b05d Update CHANGES.
ad21935 Revert &quot;Added dracula theme style (#1636)&quot;
e411506 Prepare for 2.7.4 release.
275e34d doc: remove Perl 6 ref
2e7e8c4 Fix several exponential/cubic complexity regexes found by Ben Caller/Doyensec
eb39c43 xquery: fix pop from empty stack
2738778 fix coding style in test_analyzer_lexer
02e0f09 Added 'ERROR STOP' to fortran.py keywords. (#1665)
c83fe48 support added for css variables (#1633)
Additional commits viewable in compare view





[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pygments&package-manager=pip&previous-version=2.7.3&new-version=2.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


", # bump pygments to 2.7.4
901,"Update CONTRIBUTING.md
Minor changes to align with proper project naming (gpt-engineer vs other variants of the name)", # Fix typo in contributing guidelines
902,"fix get_anchors for VectorizedPoints
Fixes `VectorizedPoint.get_anchors()`, which previously returned an empty array when called on a `VectorizedPoint` (https://github.com/3b1b/manim/issues/455).

I tested by running the code found in that issue and verifying that the rectangles were placed properly.", # Fix for vectorized mobjects with single point
903,"boardd/can_recv_thread: improve caching for can_frame
", # Fix can_recv_thread
904,"Remove usage of buildkit
Fixes #8355 

During the troubleshooting of #8355, I came to the conclusion that using buildkit was creating the problem. Without it all docker images are built correctly. Initially buildkit was enabled to avoid a building problem in Azure Pipeline, but I also found in my recent tests that this problem was not there anymore.

You can find more details about the troubleshooting and reasoning in #8355.

As a consequence, I disable the usage of buildkit in this PR which will solve the issue.
", # Remove build.sh comment
905,"[3.10] gh-95166: cancel map waited on future on timeout (GH-95169)



* Issue: gh-95166

",
906,"Merge output format
As explained in https://github.com/rg3/youtube-dl/issues/3610, https://github.com/rg3/youtube-dl/issues/2765 there are cases when downloading separate video and audio and then merging when the video container (usually webm containing VP8/VP9) is incompatible with the audio codec (aac/mp3). By default, youtube-dl attempts to create a merge in the container format of the video file.

This is a redo of pull request https://github.com/rg3/youtube-dl/pull/4577. This time around I've added a video option called ""merge-ouput-format"" that specifies what container format the merge output should be put into. It is only used if merging is required (something like ""-f best"" will not use it for instance). If you provide nothing for it, the video part's container format will be used, just like before.
", # [youtube-dl] Add --merge-output-format option
907,"created a simple clock widget using Tkinter
Details instruction to run the widget is in the README.md ", # Add clock app
908,"Add Kalimdor.js - Machine Learning library for the web and Node!
Hi, I've recently developed a Machine Learning library in Typescript. It is still evolving every day and I've already solved a few Kaggle challenges using this library!

In short, the library is:
- Simple to use
- Solves real world problems
- Has an excellent documentation

Homepage: https://www.kalimdor.io/
Github: https://github.com/jasonshin/kalimdorjs

Cheers =)", # Add Kalimdor.jsAdded Kalimdor.js to the list of machine learning libraries.
909,"Enable compression for manifest.json


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Now that compression is ~5x faster than base zlib, it makes sense to compress this since it works out to a ~70% reduction in size.


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] I have followed the [perfect PR recommendations][perfect-pr]
- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
", # Enable compression for ManifestJSONViewEnabling compression for the ManifestJSONView component.
910,"Subaru: fix forester weight
from https://github.com/commaai/openpilot/pull/31550

validation scripts:

```bash
STARTING_BRANCH=$(git rev-parse --abbrev-ref HEAD)

git checkout 556f9738960526d6eeaab9fe639d0340a6d5d6c9 # before any config has changed

python dump.py > original.txt

git checkout $STARTING_BRANCH

python dump.py > new.txt

cmp -s original.txt new.txt
```

```python
#!/usr/bin/env python3

from selfdrive.car import gen_empty_fingerprint
from selfdrive.car.car_helpers import interfaces
from selfdrive.car.fingerprints import all_known_cars

if __name__ == ""__main__"":
  for car in sorted(all_known_cars()):
    CarInterface, CarController, CarState = interfaces[car]
    car_fw = []
    fingerprints = gen_empty_fingerprint()
    CP = CarInterface.get_params(car, fingerprints, car_fw, experimental_long=False, docs=False)
    print(f""{CP.carFingerprint}: {CP.mass=} {CP.wheelbase=} {CP.steerRatio=} {CP.minEnableSpeed=} {CP.minSteerSpeed=} {CP.centerToFront=}"")
```", # Subaru Forester 2019 specs mass changed
911,"Require explicit confirmation of snap plugin permissions before connecting
Fixes #7667.

Implements the plan described in #7667.

Here's a terminal log showing that it does so:

```
# sudo snap connect certbot:plugin certbot-dns-dnsimple
error: cannot perform the following tasks:
- Run hook prepare-plug-plugin of snap ""certbot"" (run hook ""prepare-plug-plugin"": 
-----
Only connect this interface if you trust the plugin author to have root on the system
Run `snap set certbot trust-plugin-with-root=ok` to acknowledge this and then run this command again to perform the connection
-----)
# snap set certbot trust-plugin-with-root=ok
# sudo snap connect certbot:plugin certbot-dns-dnsimple
# sudo snap disconnect certbot:plugin certbot-dns-dnsimple:certbot
# sudo snap connect certbot:plugin certbot-dns-dnsimple
error: cannot perform the following tasks:
- Run hook prepare-plug-plugin of snap ""certbot"" (run hook ""prepare-plug-plugin"": 
-----
Only connect this interface if you trust the plugin author to have root on the system
Run `snap set certbot trust-plugin-with-root=ok` to acknowledge this and then run this command again to perform the connection
-----)
```", # Require explicit confirmation of snap plugin permissions before connectingThis PR requires explicit confirmation of snap plugin permissions before connecting.This is a security improvement to prevent a user from accidentally connecting to a snap plugin that has root permissions.This PR also fixes a bug in the snap plugin connection process.
912,"Add A B√≠blia Digital


- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not have more than 100 characters
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add A B√≠blia Digital APIAdded A B√≠blia Digital API to the list of APIs.
913,"added Linktree
", # Add LinktreeAdd Linktree to the data.json file.
914,"Add Hardkernel ODROID-M1
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Breaking change
<!--
  If your PR contains a breaking change for existing users, it is important
  to tell them what breaks, how to make it work again and why we did this.
  This piece of text is published with the release notes, so it helps if you
  write it towards our users, not us.
  Note: Remove this section if this PR is NOT a breaking change.
-->


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Add Hardkernel ODROID-M1 machine. ODROID-M1 is a Rockchip RK3568B2 SoC based single board computer with 4xCortex-A55, NVMe support and up to 8GB of RAM.


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [x] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
", # Add support for ODROID-M1Add support for ODROID-M1
915,"F.21 add loop increment in bad example
to mimic the previous examples and avoid an infinite loop.", # Fix C++17 example
916,"Increased letsencrypt and letsencrypt-nginx cover minimums
Pretty self explanatory. Our coverage minimums can be increased.
", # [tox] fix tox.cover.sh
917,"üë∑ Add GitHub Action gate/check
This adds a GHA job that reliably determines if all the required dependencies have succeeded or not.

It also allows to reduce the list of required branch protection CI statuses to just one ‚Äî `check`. This reduces the maintenance burden by a lot and have been battle-tested across a small bunch of projects in its action form and in-house implementations of other people.

It is now in use in aiohttp (and other aio-libs projects), CherryPy, attrs, coveragepy, some of the Ansible repositories, pip-tools, pydantic, spaceship-prompt, all of the jaraco's projects (like `setuptools`, `importlib_metadata`), some PyCQA, PyCA, PyPA and pytest projects, a few AWS Labs projects.

The story behind this is explained in more detail at https://github.com/marketplace/actions/alls-green#why.", # Add a test for all-green branch protectionThis PR adds a test for all-green branch protection.
918,"[MRG] Update joblib to 0.9.3
Bug fix release to fix joblib/joblib#263: interactively defined functions can not be used in parallel for Python 3 (because the default start method is forkserver).

This needs to be merged for 0.17, fix for #5623, overrides PR #5624 by @lesteve.
", # [MRG+1] Fix for OS X BLAS crash with multiprocessingThis PR fixes the issue of BLAS crashing on OS X when using multiprocessing. The issue is caused by the forkserver start method used by joblib. The forkserver start method is not compatible with BLAS libraries that use an internal thread pool. The solution is to set the JOBLIB_START_METHOD environment variable to either forkserver or spawn. This PR also fixes the typo in the docstring of the joblib.parallel.parallel module.
919,"Add Monitoring Tool | General-Purpose Machine Learning Section
", # Add NannyMLAdded NannyML to the list of Python libraries for data analysis and data visualization.
920,"time checks in locationd


<!--- ***** Template: Car bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

**Route**
Route: [a route with the bug fix]

-->

<!--- ***** Template: Bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

-->

<!--- ***** Template: Car port *****

**Checklist**
- [ ] added to README
- [ ] test route added to [test_routes.py](../../selfdrive/test/test_routes.py)
- [ ] route with openpilot:
- [ ] route with stock system:

-->

<!--- ***** Template: Refactor *****

**Description** [](A description of the refactor, including the goals it accomplishes.)

**Verification** [](Explain how you tested the refactor for regressions.)

-->
", # Fix locationd kalman reset
921,"updated eop imports
", # Remove unused imports
922,"Better RWKV Prompt




## Why are these changes needed?



## Related issue number (if applicable)



## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x ] I've made sure the relevant tests are passing (if applicable).
", # fix typo in conversation template
923,"Bump fetch-mock from 7.7.3 to 9.11.0 in /frontend
Bumps [fetch-mock](https://github.com/wheresrhys/fetch-mock) from 7.7.3 to 9.11.0.

Release notes
Sourced from fetch-mock's releases.

Babel upgrades
In theory, this should not cause anybody any problems
Fixes various types
No release notes provided.
Allow overwriting regex routes
No release notes provided.
Add lastResponse to type defs
No release notes provided.
Refactor routes to be wrapped in a class
No release notes provided.
Fix mocking requests with bodies in safari
Merge pull request #585 from lambdalisue/hotfix-584
Patch native fetch on Safari to fix #584
Make typescript types available when importing the esm build
No release notes provided.
Prevent responses from hanging in node-fetch
No release notes provided.
Add matchPartialBody to typings
No release notes provided.
Allow response bodies to be inspected
No release notes provided.
Correct release with response inspection
No release notes provided.
Allow inspecting responses
No release notes provided.
v9.9.1
No release notes provided.
Full support for coercing objects into query string matchers
No release notes provided.
Added support for multi-value query string matching
No release notes provided.
Added support for sticky routes
No release notes provided.


... (truncated)


Commits

4b54e6d browsers again
838f667 aaargh - lint!
18041fb fix a test that should've always failed reallyI guess node 15 is stricter abo...
f6f4d08 revert to old browsers docker image
bf6d08c correct browser docker image name
6ca3e64 babel config file name chamnge
7d4bb27 hopefully fix all failnig jobs
ac06de1 install browsers
a3665e0 use lts and current aliases for images
5a43afe fix some docker image names
Additional commits viewable in compare view





[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=fetch-mock&package-manager=npm_and_yarn&previous-version=7.7.3&new-version=9.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---


Dependabot commands and options


You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


", # babel: upgrade fetch-mock to 9.11.0Upgrade fetch-mock to 9.11.0
924,"Set up 2.0 pre-releases
This implements the majority of https://docs.google.com/document/d/1t02y0qQvTgc4eNPY4OwfYu7oW41DEBNhr8fq_O97kXo/edit?usp=sharing. The work that remains after this is merged into master is merging this into the 2.0 branch, setting up the 2.0-prerelease pipeline for the 2.0 branch, writing documentation on how to use that pipeline, doing a prerelease, and writing a post on the community forum.

One change I made in this PR that's not easily seen/understandable is I removed the reference to https://github.com/certbot/certbot/issues/7931 for the reason I wrote at https://github.com/certbot/certbot/issues/7931#issuecomment-1238650122.

I also set up a dummy 2.0 prerelease pipeline to test this at https://dev.azure.com/certbot/certbot/_build?definitionId=6&_a=summary which seems to be working properly.",
925,"Fixed #26652 -- Documented removal of model instance _(default/base)_manager attributes.
", # Remove ``_base_manager`` and ``_default_manager`` attributes from model instancesThis PR removes the ``_base_manager`` and ``_default_manager`` attributes from model instances. They remain accessible on the model class.This PR is a follow-up to #20066.
926,"Basic support for the temperature parameter
", # Add temperature parameter to DeepInfra
927,"Fixed #29939 -- Increased Group.name max_length to 150 characters.
This PR increases the max_length of `django.contrib.auth` model `Group` field `name` to 191, to match recent changes to `username`, `first_name`, and `last_name` in the `User` model. ([Ticket](https://code.djangoproject.com/ticket/29939))", # Increase max length of group name from 80 to 150 charactersFixes #2200 
928,"Run lint/typechecking in latest python + update pre-commit
- Lets move to latest and greatest of lints
- Update mypy + flake8", # Update flake8 and mypy to latest versions
929,"üìù Add note to docs about Separate Input and Output Schemas with FastAPI version
üìù Add note to docs about Separate Input and Output Schemas with FastAPI version", # Add info about `separate_input_output_schemas`Add info about `separate_input_output_schemas` was added in FastAPI `0.102.0`. ü§ì
930,"Removed fit call from regularizers tests.
As suggested in #8990 I removed fit calls. 

Here in the regularization tests (the assert is all that is really needed).

The speed gain is going to be very small, but if we can reduce the number of lines in the codebase, It's not a bad thing.", # Remove unnecessary epochs in regularizers tests
931,"[TVer] remove FujiTV redirect
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

These changes are taken from https://github.com/nao20010128nao/ytdl-patched/commit/4e1880fdbac7ff243a293cc7825605437163d03d , which is my own work.

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information
It seems FujiTV have migrated to Brightcove as other stations do.    
This PR removes FujiTVFODPlus7IE and redirects to Brightcove.

This fixes #28767.
", # [tver] Fix broken extractor
932,"Create Program to print table of given number
", # Program to print table of given number
933,"Add FAQ entry referencing Request.meta usage
", # Add FAQ entryAdd FAQ entry for how to scrape an item with attributes in different pages.
934,"Switching the deploy workflow to use environment secrets
Fixes #755 

This migrates the deployment workflows away from repository secrets to environment secrets.", # Update deploy-to-node.yaml to use NEXTAUTH_SECRET
935,"Clean chat data
",
936,"Add link to official Discord chat server
All Pallets projects should have a link to the official chat server on Discord.", # Add official chat linkAdd official chat link to README.rst
937,"implement SQS lambda destination

addresses https://github.com/localstack/localstack/issues/3373",
938,"Device agnostic testing
This PR changes the test suite to allow running the tests on any hardware.

In order to do this I tried to make the test suite device agnostic and allow setting the device and backend through environment variables. This is hopefully a future proof way for allowing the test suite to be run on any hardware.

I've also added the functionality to change timeouts on tests that run on hardware.

In all the changes I've tried to keep previous functionality working if using the CI in the ""normal"" way. If the environment variables are not used, previous values are used as defaults.

Example usage:
`TORCH_DEVICE=fancy_new_hw TORCH_BACKEND=new_torch_backend pytest tests/`

",
939,"fix high CPU utilization when on network
", # [GAE] Add sleep time for scan_exist_ip
940,"#509: Fixed correction on windows machine running other shells

Fix #509 ", # Fixes #1002
941,"Updated README in Japanese.
Hello :)

I found this great repository on github trends and wanted to create a PR to see if I could contribute in any way.
I have corrected some translations that looked strange from my Japanese point of view.

I hope it will be useful for many people üôè

Thanks.", # Êó•Êú¨Ë™û„ÅÆREADME-ja-JP.md „ÅÆ‰øÆÊ≠£
942,"feat(perf tooltips): adding to index and latency cleanup
**Before:**
![Screen Shot 2020-04-03 at 9 34 28 AM](https://user-images.githubusercontent.com/4830259/78384055-54fe9e00-758e-11ea-9ff4-79deea2c370a.png)
![Screen Shot 2020-04-03 at 9 34 20 AM](https://user-images.githubusercontent.com/4830259/78384065-56c86180-758e-11ea-9ff7-43e3476dc592.png)

**After:**
![Screen Shot 2020-04-03 at 9 32 42 AM](https://user-images.githubusercontent.com/4830259/78383946-21bc0f00-758e-11ea-9921-f79891fabe89.png)
![Screen Shot 2020-04-03 at 9 38 08 AM](https://user-images.githubusercontent.com/4830259/78384337-d9e9b780-758e-11ea-88f7-9a0267ae384a.png)
![Screen Shot 2020-04-03 at 9 32 53 AM](https://user-images.githubusercontent.com/4830259/78383937-1ec11e80-758e-11ea-8df6-3b9a17f20300.png)",
943,"Error resolved in wave_sort.py
", # Added wave sort
944,"[3.8] bpo-41162: Clear audit hooks later during finalization (GH-21222)
Co-authored-by: Konge 

<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
bpo-NNNN: Summary of the changes made
```

Where: bpo-NNNN refers to the issue number in the https://bugs.python.org.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `master`),
please ensure that the PR title is in the following format:

```
[X.Y]  (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `master`.

-->



https://bugs.python.org/issue41162

", # Fix #41162: Audit hooks are now cleared later during finalization to avoid missing events.Fixes #41162.
945,"Do not include /etc/nginx/mime.types in nginx integration testing.
This file (or /etc/nginx in whole) might not exist on the target system.
", # Fix #1007
946,"Fix grammatical error
", # Fix typo in README.md
947,"Explicitly require setuptools, httpie/plugins/manager.py imports pkg_resources
", # Add setuptools to setup.pyAdd setuptools to setup.py
948,"Fix some small code quality issues.

## What do these changes do?
Some code quality issues were fixed in this PR:
1. some methods should be declared as `const`.
2. some ctors should be specified `explicit`.
3. fix the difference between declaration and definition of `RegisterDriver`.", # Fix constness of client connectionFixes #1000.
949,"Ruby: add slim
"," # Add plural form of ""injection"""
950,"Hyundai : AZERA_HEV_6TH_GEN (Update fingerprints.py)
Hyundai AZERA_HEV_6TH_GEN

<!--- ***** Template: Fingerprint *****

**Car**
Hyundai Azera HEV, 6th Generation, 2019

**Route**
3a0cde9552891b34/2024-03-03--10-33-30

-->", # Hyundai fingerprints
951,"[model_cards]: üáπüá∑ Add new ELECTRA small and base models for Turkish
Hi,

this PR introduces model cards for new ELECTRA small and base models for Turkish üáπüá∑.

More information (checkpoint evaluation, downstream evaluation on Pos Tagging and NER, loss curves, TensorBoards) see [this repository](https://github.com/stefan-it/turkish-bert/tree/electra/electra).", # Add dbmdz/electra-base-turkish-cased-discriminator
952,"fix:update file desc
", # fix test file name
953,"Fix: requirements.txt was not written to the disk
While the Python packages requirements are correctly detected and saved into the json task file, requirements.txt was always empty. Since it was trying to get packages with the wrong key, packages were always empty when writing in requirements.txt


**Features**


    
**Feature Docs**


**Influence**


**Result**


**Other**
", # fix: fix the typo in the project_management.py
954,"Added Keras GPT Copilot to the list
Keras GPT Copilot is a Python package that integrates a Large Language Model (LLM) copilot into the Keras model development workflow. It provides iterative feedback for model enhancement, supports compatibility with OpenAI's GPT-4 and other LLMs.", # Add Keras GPT CopilotAdd Keras GPT Copilot - A python package that integrates an LLM copilot inside the keras model development workflow.
955,"updated collective ops api
", # Remove on_cpu argument in collective functionsRemove on_cpu argument in collective functions.
956,"fix autocast
", # [patch_clip] Fix dtype for cuda
957,"Pin all build dependencies for the Windows installer
This PR uses pipstrap to bootstrap the venv used to build Windows installers. This effectively pin all build dependencies, since `pynsist` is already installed through `pip_install.py` script.", # Update NSIS version
958,"Allow Peft models to share their base model




## Why are these changes needed?

This adds a special environment variable that activates shared Peft model base weights.  Currently when loading two Peft models that have the same base model, those model weights are loaded once.  With this flag activated, all Peft models will share the same base model.

To make this work it requires a few work around due to how Huggingface's Peft model has implemented LoRA adapters, the most popular variant.  These modify the base model's pytorch modules directly and thus adapters sharing the same base model must live within the same model object and a `set_adapter` method must be called to switch between them.  

## Related issue number (if applicable)

Expands #1805

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).
"," # [peft] Support sharing base weights## üìå Checklist before creating the PR- [ ] I have created an issue for this PR for traceability- [ ] The title follows the standard format: `[doc/gemini/...] PR title`- [ ] I have added relevant tags if possible for us to better distinguish different PRs## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.## üí• Checklist before requesting a review- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible- [ ] I have performed a self-review of my code- [ ] I have added thorough tests.- [ ] I have added docstrings for all the functions/methods I implemented## ‚≠êÔ∏è Do you enjoy contributing to fast.ai?- [ ] üåù Yes, I do.- [ ] üåö No, I don't.Tell us more if you don't enjoy contributing to fast.ai."
959,"Backport PR #35882 on branch 1.1.x (BUG: item_cache invalidation in get_numeric_data)
Backport PR #35882: BUG: item_cache invalidation in get_numeric_data", # [MRG] Fix DataFrame.corr()Fixes #35882
960,"Fix grammar in README, backend docs and initializers docs
### Summary
Fixed several grammar problems in the README, backend docs and initializers docs.

### Related Issues
None

### PR Overview
Fixed grammar errors in README.md, backend.md and initializers.py

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
", # Fix typo in README.md
961,"Fix amcrest detection of sensor reset
## Proposed change
Previous versions of pyamcrest passed a boolean to home assistant
depending on whether the event was the activation of a sensor or not.
This was used by the amcrest integration to decide the state of the
binary sensors.

The latest pyamcrest passes through a non-empty payload dictionary
instead, which is a true-value and the binary sensor would always
be deemed active.

Look into the payload for an ""action"": ""start"" item instead.

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [x] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #50214

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] ü•à Silver
- [ ] ü•á Gold
- [ ] üèÜ Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
", # Fix event_actions payloadFixes #10088.
962,"Subclass getstate from pydantic's BaseModel to fix cannot pickle and unpickle TextNode
# Description

Cannot pickle and then unpickle TextNode object. This is due to `BaseComponent`'s `__getstate__` completely overwrites `pydantic.BaseModels`'s `__getstate__`. Example:

```python
import pickle
from llama_index.schema import TextNode

abc = TextNode(text=""abc"")

# save ok
with open(""abc.pkl"", ""wb"") as fo:
    pickle.dump(abc, fo)

# error when load
with open(""abc.pkl"", ""rb"") as fi:
    data = pickle.load(fi)
```

Stack trace:
```
File ~/.cache/pypoetry/virtualenvs/llama-index-Jalitqr9-py3.9/lib/python3.9/site-packages/pydantic/main.py:416, in pydantic.main.BaseModel.__setstate__()

KeyError: '__dict__'
```

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [x] I stared at the code and made sure it makes sense
- [x] Test with the snippet above

# Suggested Checklist:

- [x] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] I have added Google Colab support for the newly added notebooks.
- [x] My changes generate no new warnings
- [x] I have added tests that prove my fix is effective or that my feature works
- [x] New and existing unit tests pass locally with my changes
- [x] I ran `make format; make lint` to appease the lint gods
", # [MRG] Fix pickling of tokenizerFixes #8880
963,"Fix a docstring type in cli.py.
", # Fix typo in CLI docstring
964,"add new gradio themes
## Description

* adds a few new hand selected gradio themes, all tested at least once so make sure they work properly

## Checklist:

- [X] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [X] I have performed a self-review of my own code
- [X] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [X] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Add more themesAdded more themes to the list of themes.
965,"Correct previous change to Exchange.aggregate
Expansion needs to be done on bidasks, rather than items", # Fixes #1006Fixes #1006
966,"Allow open ranges for chapters
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information



This will allow `--download-sections` and its relatives to allow using range with the other end missing (e.g. `*2-`, `*-60`)


Template 

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [x] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))
", # Fix download-sections optionFixes #1002.
967,"[wip/s2s] DistributedSortishSampler
This allows sortish sampler logic to work on multiple GPU.

The strategy is 
1) find the indices that the current rank's data loader should be using (like `DistributedSampler`)
2) reorder those using the `SortishSampler` logic.

### Results 
The results on a small MT task are similar to the 1 GPU setting. 
+ 2 GPU, random sampler: 13 mins/epoch  BLEU 8.6
+ 2 GPU, `DistributedSortishSampler`: 10 mins/epoch, BLEU 8.6

In the chart below, you can see that the sortish sampler gets to a higher BLEU score in the same number of minutes (x axis) (because it has finished a full epoch rather than 70% of one).

![image](https://user-images.githubusercontent.com/6045025/92787937-87030000-f377-11ea-822a-69e50debe95d.png)

@sgugger let me know if you want this in Trainer!", # Fix sortish sampler for distributed training
968,"fix:const.py add CONFIG_ROOT
**Features**



- xx
- yy
    
**Feature Docs**


**Influence**


**Result**


**Other**
", # Update METAGPT_PROJECT_ROOT
969,"[MRG+1] Use ""url"" variable in the example
Instead of hardcoded http://www.example.com, as noticed by Andr√©s P√©rez-Albela H.: without it url variable is unused and only one request will make it past dupefilter.
", # fix #2800
970,"[mypy] Fix type annotations for maths directory
### Describe your change:



* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [ ] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",
971,"dir buttons start with / so only the correct dir will be shown and no‚Ä¶
## Description

* fixed  #13895 
when show dirs is selected, a / is not only inserted after the folder name, but also before it. so that only the selected folder is actually displayed, and not also other folders whose name is a substring of the selected folder.

## Screenshots/videos:
![image](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/65122811/b848cfcb-97be-43bc-81af-c76b744b7834)


## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Add option to add '/' to directory buttonsAdds an option to add '/' to directory buttons.
972,"Removed a Python 2 fallback in certbot.Reverter.
## Pull Request Checklist

- [x] If the change being made is to a [distributed component](https://certbot.eff.org/docs/contributing.html#code-components-and-layout), edit the `master` section of `certbot/CHANGELOG.md` to include a description of the change being made.
- [x] Add or update any documentation as needed to support the changes in this PR.
- [x] Include your name in `AUTHORS.md` if you like.
"," # Remove sys.version_info check for csv moduleThis PR removes the `sys.version_info` check for the csv module. This check was added in #1006, but it is no longer needed."
973,"[Peertube] Add playlist extractor and update instances list
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Explanation of your *pull request* in arbitrary form goes here. Please make sure the description explains the purpose and effect of your *pull request* and is worded well enough to be understood. Provide as much context and examples as possible.
", # [peertube] Add playlist support
974,"Fix GitHub Actions build warnings, Marker style should be `*`
Addressed:
> 16132:1-16132:75   warning  Marker style should be `*`  unordered-list-marker-style
> 16133:1-16133:39   warning  Marker style should be `*`  unordered-list-marker-style
> 16134:1-16134:57   warning  Marker style should be `*`  unordered-list-marker-style
> 16135:1-16135:62   warning  Marker style should be `*`  unordered-list-marker-style
> 16136:1-16136:240  warning  Marker style should be `*`  unordered-list-marker-style
> 16137:1-16137:194  warning  Marker style should be `*`  unordered-list-marker-style
> 16141:1-16141:72   warning  Marker style should be `*`  unordered-list-marker-style
> 16142:1-16142:49   warning  Marker style should be `*`  unordered-list-marker-style", # Fix typo in CppCoreGuidelines.md
975,"Update rod_cutting.py
A hopefully clearer implementation without dependence on global variables.", # Dynamic programming: rod cutting
976,"BLD Removes post from release on website
Removes post from release name on the website. This is so the name on the top of the webpage does not have ""post"" in it:

With https://github.com/scikit-learn/scikit-learn/pull/16609

![Screen Shot 2020-03-03 at 12 14 07 PM](https://user-images.githubusercontent.com/5402633/75803941-3cac2100-5d4d-11ea-819c-ea2d173dbebf.png)

Cherry picking this PR on top:

![Screen Shot 2020-03-03 at 12 46 25 PM](https://user-images.githubusercontent.com/5402633/75803952-433a9880-5d4d-11ea-8360-bd57f14b4512.png)



", # Fixes #1006
977,"fix: fix syntax errors
## Description

python syntax error.

## Screenshots/videos:

![image](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/40930677/243aa6ca-f863-478f-a169-a433e774d711)

## Checklist:

- [ ] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [ ] I have performed a self-review of my own code
- [ ] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [ ] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
", # Fix upscaler.py
978,"Fix unexpected extensions load after gradio restart
## Checklist:

- [x] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
", # Fix #1006
979,"Support for yum invalid commands.
This rule replaces incorrect yum commands, such as `yum isntall` into `yum install` and `yum remove` into `yum uninstall`.",
980,"Fix and document Zero Shot Image Classification
# What does this PR do?

This PR fixes 3 issues with `zero-shot-image-classification`

* It does not pick a default model, although there is one. This leads to weird error message

```python
pipe = pipeline(""zero-shot-image-classification"")
>> ValueError: The task defaults can't be correctly selected. You probably meant ""translation_XX_to_YY""
```

* The pipeline is not in the list at top of https://huggingface.co/docs/transformers/main_classes/pipelines
* The filter for available models has a typo, although right now this still leads to no models (ok just one).

## Before submitting
- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [x] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

@Narsil @sgugger 
"," # [pipelines] Add ZeroShotImageClassificationPipeline## üìå Checklist before creating the PR- [x] I have created an issue for this PR for traceability- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`- [x] I have added relevant tags if possible for us to better distinguish different PRs## üö® Issue number> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge>> e.g. `fixed #1234`> If the PR is related to multiple issues then link issue 1, 2, ...## üìù What does this PR do?> Summarize your work here.> if you have any plots/diagrams/screenshots/tables, please attach them here.Add ZeroShotImageClassificationPipeline## üß† Did you read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines)?> If yes, describe your changes here to help us reproduce the issue/feature you resolved/added.> If no, describe what kind of change this is and what is the motivation behind it.## üí• Checklist before requesting a review- [x] The code change is tested and works locally.- [x] Local tests pass. **Your PR cannot be merged unless tests pass**- [x] There is no commented out code in this PR.- [x] I have followed the [style guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines#code-style)- [x] I have added relevant tags if possible for us to better distinguish different PRs- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`- [x] I have added relevant notes if possible"
981,"DOC fix of sample_weight in _multinomial_loss_grad and _multino‚Ä¶
Fixes #13020
", # Fix typo in docstring for LogisticRegressionFix typo in docstring for LogisticRegression.
982,"Updated fibonacci.py with dp
", # Implement dynamic programming to improve runtime of fibonacci
983,"Create factorial_iterative.py
### **Describe your change:**



* [x] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
", # Add factorial_iterative.py
984,"ignore generated alert header file
", # Add translations to .gitignore
985,"Fix Certbot Apache plugin on Oracle Linux Server, a clone of CentOS, RHEL
[Oracle Linux Server](https://en.wikipedia.org/wiki/Oracle_Linux) is a [clone of CentOS/RHEL](https://www.oracle.com/linux/index.html). The Certbot Apache plugin cannot auto-detect the Oracle Linux Apache setup, causing a generic (but incorrect) Apache Linux configuration to be used, which emits this error:

> The apache plugin is not working; there may be problems with your existing configuration.
> The error was: NoInstallationError('Cannot find Apache control command apache2ctl',). Skipping.

On Oracle Linux Server, [the Apache control command](https://docs.oracle.com/cd/E52668_01/E54669/html/ol7-s2-websvc.html) is `apachectl` just like CentOS/RHEL.

The `/etc/os-release` file [on Oracle Linux](https://www.veritas.com/support/en_US/article.000087964) contains `ID=""ol""` which does not match any existing override class. My simple one-line PR adds this missing OS override. After this one-line change is applied, then Certbot Apache plugin works as designed on Oracle Linux.

Without this code change, a hack/workaround for Oracle Linux is [to add (_missing_)](https://www.freedesktop.org/software/systemd/man/os-release.html#ID_LIKE=) `ID_LIKE=""centos rhel""` to the [`/etc/os-release` file](http://0pointer.de/blog/projects/os-release.html). This forces the Certbot Apache plugin to treat OL like CentOS/RHEL.
", # Add support for OLAdd support for OL.
986,"Hijack VQModelInterface back to AutoEncoder (to get LDSR working again)
The LDSR upscaler relies on the `VQModelInterface` as defined in the `ldm\models\autoencoder.py` of the Compvis Stable Diffusion repo.

The Autoencoder shipped in the Stability AI SD v2.0 git repo has the VQModelInterface removed, which obviously broke LDSR.

This hijack is to add `VQModelInterface` back so that LDSR (and maybe other things that relies on it) working again.

Related to issue #5087",
987,"BUG: Non-unique indexing via loc and friends fixed when slicing (GH3659_)
closes #3659

This is if you try a non_monotonic selection on a non_unique index (a mouthful)!
The reason is we cannot determinate a proper start/end point on what to include

```
In [11]: df = DataFrame({'A' : [1,2,3,4,5,6], 'B' : [3,4,5,6,7,8]}, 
           index = [0,1,0,1,2,3])

In [18]: df
Out[18]: 
   A  B
0  1  3
1  2  4
0  3  5
1  4  6
2  5  7
3  6  8

In [12]: df.loc[1:]
KeyError: 'cannot perform a slice operation on a non-unique non-monotonic index'
```

On a non_unique, but monotonic index, however, slicing works normally
(notice, since we are using loc, that both endpoints ARE included)

```
In [13]: df = DataFrame({'A' : [1,2,3,4,5,6], 'B' : [3,4,5,6,7,8]}, 
       index = [0,1,0,1,2,3]).sort(axis=0)

In [14]: df
Out[14]: 
   A  B
0  1  3
0  3  5
1  2  4
1  4  6
2  5  7
3  6  8

In [15]: df.loc[1:]
Out[15]: 
   A  B
1  2  4
1  4  6
2  5  7
3  6  8

In [16]: df.loc[1:2]
Out[16]: 
   A  B
1  2  4
1  4  6
2  5  7
```
", # [MRG] Fixed non-unique indexer with loc sliceFixes #3659_
988,"Error out earlier in apache installer when mod_ssl is not available
Fixes #7612.

Testing for `ssl_module` patterned after `openssl_version()` code here: https://github.com/certbot/certbot/blob/master/certbot-apache/certbot_apache/_internal/configurator.py#L274

Previously we were getting tests to pass by setting `ssl_module` to `None`, because `enable_mod` figures out if it needs to enable the mod by [testing inclusion](https://github.com/certbot/certbot/blob/master/certbot-apache/certbot_apache/_internal/override_debian.py#L108). Now we error even if it exists but is `None`, so tests need to be updated. Also, I checked through all the places we expect errors to be raised in Apache tests to make sure we weren't accidentally catching the wrong error now, and I couldn't find any past the ones that are fixed here. I'd also expect coverage to catch those, and the ones it was catching are now taken care of."," # Improve error message in apache installer when mod_ssl is not availableThis PR improves the error message in the apache installer when mod_ssl is not available.The error message currently says ""Unable to find an SSLCertificateFile directive"" which is not very helpful.This PR adds a check to see if mod_ssl is available and if not, raises a MisconfigurationError with a more helpful error message."
989,"HomeMatic dependency upgrade + IP Wall Thermostat support
## Description:
This PR upgrades the dependency and adds support for the HmIP-STHD Wall Thermostat.
The pyhomematic upgrade fixes the BC-PB-2-WM device and adds HM-LC-Ja1PBU-FM to the list of supported covers.

## Checklist:

If the code communicates with devices, web services, or third-party tools:
  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**
  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).
  - [x] New dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.

[ex-requir]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L14
[ex-import]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L54
", # Update homematic.py
990,"bpo-24334: Remove inaccurate match_hostname call
Commit 141c5e8c re-added match_hostname() call. The resurrection of the
function call was never intended and was solely a merge mistake.

Signed-off-by: Christian Heimes 



https://bugs.python.org/issue24334

"," # Remove check_hostname from SSL contextThis is a no-op, but it's a good idea to remove it."
991,"Pin memory only when training on GPU
`pin_memory()` gives the following error when training on CPU or MPS.
Tested with `pytorch 1.13.1` and `MacBook Air M2`.

## Training command
```
python train.py \
  --dataset=shakespeare \
  --n_layer=4 \
  --n_head=4 \
  --n_embd=64 \
  --compile=False \
  --eval_iters=1 \
  --block_size=64 \
  --batch_size=8 \
  --device=mps
```
## MPS:
```
Traceback (most recent call last):
  File ""/Users/nyn/Github/nanoGPT/train.py"", line 232, in 
    X, Y = get_batch('train') # fetch the very first batch
  File ""/Users/nyn/Github/nanoGPT/train.py"", line 116, in get_batch
    x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)
NotImplementedError: Could not run 'aten::_pin_memory' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_pin_memory' is only available for these backends: [MPS, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].
```
## CPU:
```
Traceback (most recent call last):
  File ""/Users/nyn/Github/nanoGPT/train.py"", line 232, in 
    X, Y = get_batch('train') # fetch the very first batch
  File ""/Users/nyn/Github/nanoGPT/train.py"", line 116, in get_batch
    x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)
NotImplementedError: Could not run 'aten::_pin_memory' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_pin_memory' is only available for these backends: [MPS, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].
```", # [train] fix for CPU/MPS training
992,"Add Dailymotion API
Add Dailymotion API under Video. Dailymotion is a video-hosting site similar to Vimeo and YouTube.
", # Add Dailymotion API
993,"Network: use active AP signal
This signal is safe to add as it only saves the contents of the signal (rather than do calls on the signal, blocking UI)", # Fix wifiManager
994,"Removed 500px API
Removed 500px API as it was shutdown on June 15th
https://support.500px.com/hc/en-us/articles/360002435653-API-

Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [ x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [ ] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [ ] Any category you are creating has the minimum requirement of 3 items
- [ x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Remove 500px API
995,"Add Icon Horse API to Design


- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: 
", # Add Icon Horse APIAdded Icon Horse API to the list of APIs.
996,"Fixes wobble on new CRV
Prior to actuator delay update, I felt like .8/.24 was working well here. After this change though, steer oscillation is very apparent, maybe worst than before. Dropping this value proportionately by 1/4 seems to effectively remove wobble and drastically improves drive-quality."," # Honda steerKpV, steerKiV"
997,"Add missing instructions to make test passed
", # [MRG+1] Fix #10064
998,"added the py311 to target-version config
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

The documentation currently doesn't share that python 3.11 is supported as part of the `-t, --target-version` flag. This PR updates the documentation to support that.

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [ ] Add an entry in `CHANGES.md` if necessary?
- [ ] Add / update tests if necessary?
- [x] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
Issue: https://github.com/psf/black/issues/3897", # Update the docs to reflect the latest supported versions
999,"Add literal + - * / characters to input options 
Also, if the user enters an invalid character, it will ask again", # Simple Calculator
