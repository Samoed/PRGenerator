Unnamed: 0,target,generated_val
0,"ReadTheDocs improvements
",# ReadTheDocs integration
1,"Permit empty environment variables as unset in `setup.py`
This change fixes a bug that causes `setup.py` to fail when any of its configuration environment variables are the empty string.

For example, running the following:
```bash
export DS_BUILD_OPS=""""
pip install deepspeed
```
Currently fails with the following message:
```
BUILD_OP_DEFAULT = int(os.environ.get('DS_BUILD_OPS', BUILD_OP_PLATFORM))
ValueError: invalid literal for int() with base 10: ''
```
Because `os.environ.get` does not use its fallback argument when an environment variable exists, but is empty.
Similarly, `key in os.environ` returns `True` for empty (but still set) keys.

Shells usually do not distinguish between unset variables and empty variables, so setting variables to the empty string is usually seen as another way to unset them. This specifically arose as an issue for me while I was writing a Dockerfile, since those have no way to unset `ENV` and `ARG` directives—only to set them to the empty string (or to figure out and hardcode what the default *would have* resolved to for each `ARG`). I figure fixing this here is more helpful than writing weird workarounds.

This changes `setup.py` to treat unset and empty environment variables identically. This behaviour could potentially be changed in other files, as well, but that is not included here.

Co-authored-by: Eta0 <Eta0@users.noreply.github.com>",# Fix #1111
2,"Fix _PIP_ADDITIONAL_REQUIREMENTS case for docker-compose
Recent versions of Airflow do not allow to run `pip install` as
root but the `init` job runs as root so when the variable
_PIP_ADDITIONAL_REQUIREMENTS is set, the init container fails.

This PR forces _PIP_ADDITIONAL_REQUIREMENTS to be empty for the init
job.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragement file, named `{pr_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",# [AIRFLOW-1111] Add _PIP_ADDITIONAL_REQUIREMENTS to docker-compose.yamlFixes #1111
3,"[Callin] Add new extractor
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Adds a new extractor for Callin. Works for both Python2 and Python3.
Supersedes, closes #31230.

Special thanks to @dirkf for the insights provided in the issue thread.",# [callin] New extractor
4,"增加language选项的说明
增加language选项的说明，中文(ch)，英文(en)和韩文(ko)",# update readme
5,"cryptocom: remove transfer & fetchtransfer
Those apis were deprecated.",# cryptocom: remove transfer and fetchTransfers
6,"Change scheduled CIs to use torch 1.12.1
# What does this PR do?

To align with CircleCI tests.",# Update pytorch version to 1.12.1
7,"Fix Issue #11384 - Explaining how to load external backends in the documentation
### Summary
Created additional documentation for the ""Switching from one backend to another"" section of the documentation, including an example of an edited keras.json configuration file.

### Related Issues
Solves issue #11384 

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",# Added documentation for external backends
8,"bpo-31801:  Enum:  add _ignore_ as class option
_ignore_ is a list, or white-space seperated str, of names that will not
be candidates for members; these names, and _ignore_ itself, are removed
from the final class.

<!-- issue-number: bpo-31801 -->
https://bugs.python.org/issue31801
<!-- /issue-number -->
",# bpo-31801: Add _ignore_ to EnumAdd _ignore_ to Enum so temporary variables can be used during class construction without being turned into members.https://bugs.python.org/issue31801
9,"Bump mislav/bump-homebrew-formula-action from 1 to 2
Bumps [mislav/bump-homebrew-formula-action](https://github.com/mislav/bump-homebrew-formula-action) from 1 to 2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/mislav/bump-homebrew-formula-action/releases"">mislav/bump-homebrew-formula-action's releases</a>.</em></p>
<blockquote>
<h2>bump-homebrew-formula 2.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Use Node 16 by <a href=""https://github.com/chenrui333""><code>@​chenrui333</code></a> in <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/36"">mislav/bump-homebrew-formula-action#36</a></li>
<li>Bump minimist from 1.2.5 to 1.2.6 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/33"">mislav/bump-homebrew-formula-action#33</a></li>
<li>Bump node-fetch from 2.6.6 to 2.6.7 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/34"">mislav/bump-homebrew-formula-action#34</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/chenrui333""><code>@​chenrui333</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/36"">mislav/bump-homebrew-formula-action#36</a></li>
</ul>
<h2>bump-homebrew-formula 1.16</h2>
<ul>
<li>Replaces broken v1.15 tag, thanks <a href=""https://github.com/hendrikmaus""><code>@​hendrikmaus</code></a> <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/issues/32"">mislav/bump-homebrew-formula-action#32</a></li>
<li>Add <code>push-to</code> option, thanks <a href=""https://github.com/codefromthecrypt""><code>@​codefromthecrypt</code></a> <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/30"">mislav/bump-homebrew-formula-action#30</a></li>
<li>Fix syntax error, thanks <a href=""https://github.com/hendrikmaus""><code>@​hendrikmaus</code></a> <a href=""https://github.com/wata727""><code>@​wata727</code></a> <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/27"">mislav/bump-homebrew-formula-action#27</a></li>
<li>Ensure repeated placeholders in <code>commit-message</code> are expanded, thanks <a href=""https://github.com/hendrikmaus""><code>@​hendrikmaus</code></a> <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/pull/29"">mislav/bump-homebrew-formula-action#29</a></li>
</ul>
<h2>bump-homebrew-formula 1.14</h2>
<ul>
<li>Ignore HTTP 409 error when fast-forwading the main branch of <code>homebrew-tap</code> fork</li>
</ul>
<h2>bump-homebrew-formula 1.13</h2>
<ul>
<li>Add <code>create-pullrequest</code> input to control whether or not a PR is submitted to <code>homebrew-tap</code></li>
<li>Add <code>download-sha256</code> input to define the SHA256 checksum of the archive at <code>download-url</code></li>
<li>Fix creating a new branch in the forked repo failing with HTTP 404</li>
</ul>
<h2>bump-homebrew-formula 1.12</h2>
<ul>
<li>Fix Actions CJS loader halting on <code>foo?.bar</code> JS syntax</li>
</ul>
<h2>bump-homebrew-formula 1.11</h2>
<ul>
<li>New optional <code>formula-path</code> input accepts the filename of the formula file to edit (default <code>Formula/&lt;formula-name&gt;.rb</code>).</li>
<li>Remove <code>revision N</code> lines when bumping Homebrew formulae.</li>
</ul>
<h2>bump-homebrew-formula 1.10</h2>
<ul>
<li>The new optional <code>tag-name</code> input allows this action to be <a href=""https://docs.github.com/en/actions/managing-workflow-runs/manually-running-a-workflow"">manually triggered via <code>workflow_dispatch</code></a> instead of on git push to a tag.</li>
</ul>
<h2>bump-homebrew-formula 1.9</h2>
<ul>
<li>Fix following multiple HTTP redirects while calculating checksum for <code>download-url</code></li>
</ul>
<h2>bump-homebrew-formula 1.8</h2>
<ul>
<li>Enable JavaScript source maps for better failure debugging</li>
</ul>
<h2>bump-homebrew-formula 1.7</h2>
<ul>
<li>
<p>Allow <code>download-url</code> as input parameter</p>
</li>
<li>
<p>Add support for git-based <code>download-url</code></p>
</li>
</ul>
<h2>bump-homebrew-formula 1.6</h2>
<ul>
<li>Control the git commit message template being used for updating the formula file via the <code>commit-message</code> action input</li>
</ul>
<h2>bump-homebrew-formula 1.5</h2>
<ul>
<li>Support detection version from <code>https://github.com/OWNER/REPO/releases/download/TAG/FILE</code> download URLs</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/fcd7e28e549f14d3aebc53b4d9e929de579f372f""><code>fcd7e28</code></a> lib</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/33989a8502c3e0e8f10aa573822cb197ba12416d""><code>33989a8</code></a> Merge branch 'main' into v2</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/5983bb6c5927ad5c4bc757af789cc409ec9e6cfe""><code>5983bb6</code></a> Improve extracting complex tag names from URLs</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/9750a1166b188c9d191826c9709f694d756a3f0b""><code>9750a11</code></a> lib</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/64410e9c960837db57b7e35627eb716faaaaec51""><code>64410e9</code></a> v2</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/677d7482a32a66d2f02f743c055b2b684bbc5838""><code>677d748</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/issues/36"">#36</a> from chenrui333/node-16</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/f364e76079bee9fa7e64be01eb392e1d26d25e00""><code>f364e76</code></a> also update some build dependencies</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/c08fd9bee59ec4187ebe9e93e8694631bbf8cf00""><code>c08fd9b</code></a> deps: update to use nodev16</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/280f532e9a9102e9dc2513c910c57f0bc3e72b8d""><code>280f532</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/mislav/bump-homebrew-formula-action/issues/34"">#34</a> from mislav/dependabot/npm_and_yarn/node-fetch-2.6.7</li>
<li><a href=""https://github.com/mislav/bump-homebrew-formula-action/commit/5d94a66af35c6bb4116471cc38b8be76c5d1b955""><code>5d94a66</code></a> Bump node-fetch from 2.6.6 to 2.6.7</li>
<li>Additional commits viewable in <a href=""https://github.com/mislav/bump-homebrew-formula-action/compare/v1...v2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mislav/bump-homebrew-formula-action&package-manager=github_actions&previous-version=1&new-version=2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update bump-homebrew-formula-action to v2
10,"Merge dev branch
",# Update README.md
11,"Parse variables without whitespace separator correctly for CentOS/RHEL/Fedora
When parsing /etc/sysconfig/httpd to find out Define statements on Apache command line, Certbot fails to parse variables without whitespace separator, for example -DSSL compared to -D SSL.

Fixes: #5317 ",# Apache: handle -D vars with no whitespace separatorFixes #4444.
12,"BUG: ensure the global _console object is initialized properly when rich.reconfigure is called
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

(really not sure how to test this properly)

## Description

fix #1425

",# Fix crash when calling `rich.reconfigure` in `pytest_configure`
13,"Namedays - additional countries supported
I would like to have list of supported countries in the description as it will be helpful for other developers.


Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
",# Update README.md
14,"car info: function that sorts all car info into tiers
One function returns all car info in a list, sorted by make and model, another sorts that into tiers and make and model.

So we can pass this into the website template for harness information without it being in tiers and get correct natural sorting",# car/docs: generate cars.md with all cars
15,"Fix release script
",# Release script: ensure leauto is signed
16,"Invert logo color for dark theme
We can check the result here:
https://github.com/Sea-n/wtfpython#readme",# Add dark mode logo
17,"NMS --classes 0 bug fix
I found that if I use only 0 to filter the classes in the non_max_suppression then it won't go through the if statement for the classes. Therefore I added a quick fix.

```python
if classes is not None:
    x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhancement of class filtering in non-maximum suppression function.

### 📊 Key Changes
- Updated the condition for class filtering from `if classes:` to `if classes is not None:`

### 🎯 Purpose & Impact
- **Purpose:** Ensure that class filtering is correctly applied only when `classes` variable is explicitly set, not just when it's truthy.
- **Impact:** Prevents potential bugs and makes behavior more predictable for end-users when specifying classes for object detection models. This should improve the model's accuracy in scenarios where selective class detection is needed. 🎯🐞

This change will not be immediately noticeable to end-users but ensures more reliable and precise object detection in development.",# Fix for None class
18,"Fix test timeouts on Travis
This should fix current build failure with timeout
https://travis-ci.org/github/chubin/cheat.sh/builds/741308362#L402",# Travis CI: fix timeout
19,"Update NMS `max_wh=7680` for 8k images
In response to discussion on 8k inference in #6137 

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Increased maximum bounding box size in NMS.

### 📊 Key Changes
- The maximum width and height for bounding boxes in non-maximum suppression (NMS) has been increased from 4096 to 7680 pixels.

### 🎯 Purpose & Impact
- 📈 This change allows the system to handle larger images, which could be beneficial for high-resolution datasets.
- 🌐 Users working with high-resolution imagery will benefit from this change as it improves the model's ability to detect large objects.
- 💡 There should be minimal impact on existing users unless they work with high-resolution images, where they'll see improved detection capabilities.",# Update general.py
20,"Added new backpropagation tool for Python
",# Added XAD
21,"[Core][nightly test] add dataset shuffle data loader test
This adds tests for dataset shuffle data loader (https://github.com/ray-project/ray/issues/17553).

running: https://beta.anyscale.com/o/anyscale-internal/projects/prj_SVFGM5yBqK6DHCfLtRMryXHM/clusters/ses_mfZFWrXQ8X681qTEVfewUZFe",# [release] Add dataset shuffle benchmark
22,"Updated flyweight with metaclass, made it more generic
I guess current implementation is not clean enough.
Updated implementation will work for python2, for python3 minor updates are required
",# Flyweight with metaclass
23,"[ci] replace the ngc docker image with self-built pytorch image
Fixed the workflow problem mentioned in #671 .",# [ci] use frankleeeee/pytorch-cuda as ci image
24,"build: Fix defining env var for webpack
Fixes overriding the Sentry Release version in the frontend using an environment variable. We were not defining the env var in webpack configuration.",# feat: Add SENTRY_RELEASE_VERSION to webpack config
25,"Redirect to chat page after login
",# Redirect to chat after login
26,"Update faq.rst
It seems that spider.DOWNLOAD_DELAY is deprecated.
",# Fix typo in FAQ
27,"Update CHANGELOG.md
My bad I didn't notify that I was still making changes... 
Here the last changes with all the versions.
",# Update changelog
28,"Deleted minmax.py. Fixes #8098
### Describe your change:
Fixes #8098
There were two identical files with the same filename minmax.py. 
Deleted one minmax.py

* [ ] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [ ] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [x] If this pull request resolves one or more open issues then the description above includes the issue number(s) with a [closing keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue): ""Fixes #ISSUE-NUMBER"".
",# Remove minimax.py
29,"add opt. service deps, opt-in services to test selection
## Motivation
Now that we have the selective test execution for opt-in services introduced in https://github.com/localstack/localstack/pull/10301, we can onboard additional services to the test selection.
In this PR I added the services I own to the list (😻), but it might make sense to collect the first iteration of opt ins here and merge them together.
So please feel free to push to this PR if you want the tests of your service being selectively executed in PRs here.
In order to to so, just:
1. Make sure the mandatory and optional service dependencies in `localstack/utils/bootstrap.py` are correct.
  - They should list your service (if it's not completely self-contained).
  - `API_DEPENDENCIES`
    - This mapping states that a service requires one or more other services to provide it's basic functionality.
    - f.e. the following example means that `firehose` depends on `kinesis` to work: 
      ```python
      ""firehose"": [""kinesis""],
      ```
 - `API_DEPENDENCIES_OPTIONAL`
   - This mapping states that a service needs one or more other services for certain non-basic parts, f.e. with optional integrations.
   - On the example of `firehose` that would be at least `opensearch` and `elasticsearch`, because these are _potential_ targets for `firehose` streams.
2. Add your service provider code and the test code to the `OPT_IN`. The list is alphabetically sorted, I expect it to grow quite fast (and then become obsolete).

## Changes
- Introduces the notion of optional service dependencies, in contrast to ""normal"" / mandatory service dependencies.
- Adds the following services to the Opt-In of the selective test execution:
  - ACM
  - ElasticSearch
  - OpenSearch
  - SNS

## TODO
- [x] Discuss if we should split the optional from the mandatory service dependency definition.
  - `API_DEPENDENCIES` is used for strict service loading, where it is used as a mandatory service definition.
    - f.e. `lambda` cannot work without `s3` and `sts`
  - For the test selection, we are using this mapping for all dependencies (including optional dependencies).
    - f.e. `firehose` can work without `opensearch` for as long as you don't use it as a target. However, it cannot work without `kinesis` at all.
  - /cc @bentsku @steffyP @thrau",# Add optional service dependencies
30,"Add option `--no-break-on-existing`
<details open><summary>Template</summary> <!-- OPEN is intentional -->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)

### What is the purpose of your *pull request*?
- [x] Core bug fix/improvement

</details>
",# Add --no-break-on-existing option
31,"merge C.151 into R.22, leaving a redirect behind
this applies the directions from https://github.com/isocpp/CppCoreGuidelines/issues/1612#issuecomment-639026822",# C.151: Use `make_shared()` to construct objects owned by `shared_ptr`s
32,"Proper handling of output values in Masking layer
The following - rather artificial - example shows a potential flaw in the current masking approach:

``` python
X = np.asarray([[[1e+30]]])
y = np.ones((1, 1, 1))

model = Sequential()
model.add(Masking(mask_value=1e+30))
model.add(SimpleRNN(1, 1, init='one', activation='relu', return_sequences=True))
model.compile(loss='mse', optimizer='sgd')

logs = model.fit(X, y, nb_epoch=3)
```

Produces the following output:

```
Epoch 0
1/1 [==============================] - 0s - loss: inf
Epoch 1
1/1 [==============================] - 0s - loss: nan
Epoch 2
1/1 [==============================] - 0s - loss: nan
```

**Explanation:** In all recurrent layers, the input value is multiplied with some matrix (usually `W`) before the time dimension is evaluated (Theano `scan`). The mask is currently only applied within the Theano `scan` loop, whereas the first multiplication is unmasked. This works fine as long as `0` is chosen as a `mask_value`. For other values this however results in unwanted behavior, as shown here for the extreme case of `mask_value=1e+30`.

**Fix:** By replacing all the values which are to be masked with `0` in the output of the `Masking` layer, everything works again as expected.
",# Masking layer with non-zero mask value
33,"unused local variable acrobot
remove redundant local variable",# Fix acrobot.py
34,"Add vicuna dataset
#2341

This PR adds the vicuna dataset. We use the filtered vicuna dataset since it only contains english conversations.

The sanity checks are necessary here and filter quite a number of IMO unuseful conversations (where the conversation is empty, where we have less than 2 speakers and where the speakers are not in adjacent order). After all filterings we are left with 84260 of 85071 conversations.",# Add Vicuna dataset
35,"jenkins: don't rely on SSH params
",# ci: setup ssh on ci
36,"add a node to allow growing of masks through dilation
Currently there is no way to expand masks (the actual masked values not the image borders). Scipy is already a project dependancy, so its dilate_grayscale_mask would be a lightweight solution.",# Add GrowMask
37,"Refs #31407 -- Handled potential exception in test cleanup.
The test view may not be called when running the tests with
--parallel=2 or greater. Catch the AttributeError for this case.

Seen reviewing #15421 (on macOS)

```
% ./runtests.py --parallel 2 handlers 
Testing against Django installed in '/Users/carlton/Projects/Django/django/django' with up to 2 processes
Found 31 test(s).
Creating test database for alias 'default'...
Cloning test database for alias 'default'...
Cloning test database for alias 'default'...
System check identified no issues (0 silenced).
...............................
Exception ignored in: <function CoroutineClearingView.__del__ at 0x106dfa7a0>
Traceback (most recent call last):
  File ""/Users/carlton/Projects/Django/django/tests/handlers/views.py"", line 70, in __del__
AttributeError: 'CoroutineClearingView' object has no attribute '_unawaited_coroutine'

----------------------------------------------------------------------
Ran 31 tests in 0.289s

OK
Destroying test database for alias 'default'...
Destroying test database for alias 'default'...
Destroying test database for alias 'default'...
```

It comes up because each process gets an instance of `CoroutineClearingView()` but only one of them runs the test to call it, setting the attribute. 

@felixxm reports **not** seeing the error doing the same on Linux. 🤔

//cc @smithdc1 ",# Fix test failure on Python 3.7
38,"Add Groq and Openai interfaces, Add integration tests
",# Add Openai provider
39,"Publishing on PyPI
These changes enable **automatic publishing of manim** to http://pypi.org. You just need to set a **git tag** - that's it!

```
git tag v0.1.4
git push --tags
```
(I've created some tags to test while developing this feature, so the version on PyPI is now on v0.1.3)

It does so by using the ""deploy"" task of travis. To demonstrate it, I've checked in the credentials of my PyPI account. It probably won't work after merging, since the credentials are encrypted for my travis account. Please, tell me your PyPI user accounts, so I'll give you full owner permissions for https://pypi.org/project/manimlib/ (@eulertour , @3b1b).

After creating your accounts, please install travis-cli and login

```
sudo gem install travis
travis login
```

Then, change the travis section to add your credentials, by executing this inside the project directory:

```
travis encrypt your-password-here --add deploy.password
```

(More exhaustive documentation at https://docs.travis-ci.com/user/deployment/pypi/)

Also note that I made some changes to `setup.py`. I'm using [pbr](https://docs.openstack.org/pbr/latest/). It automatically sets the right version of the package by looking at the git tags. Also, it uses the `requirements.txt` file, so we don't need to maintain a second dependency list inside `setup.py`

<s>The big_ol_pile_of_manim_imports was moved in large parts to `manimlib/shortcuts.py`. The ""scripts"" section in setup.py is meant to be for scripts you can use from the command line and can't be used to import stuff from. So I needed to move the shortcuts inside the manimlib package. To maintain compatibility, I'm importing in the big_ol_pile everything from `manimlib/shortcuts.py`</s>

Just saw that you created `manimlib/imports.py`. I'm removing my shortcuts, give me a second.",# Make manim a package
40,"ref(profiling): Clarify suspect functions are total time
Suspect functions use total time, make that clear in the table headers.

Closes getsentry/team-profiling#102
Closes getsentry/team-profiling#110",# Update column names in profiling table
41,"Add url and typing hint for BFS
### **Describe your change:**

Add typing for bfs and make the code more brief.

* [ ] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [x] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",# Rename bfs.py to breadth_first_search_2.py
42,"Updated Travis CI URL in README
The old URL appears to be broken, redirecting to https://travis-ci.org//kennethreitz/requests

Also, according to [their wiki](http://about.travis-ci.org/docs/user/status-images/) the _secure_ isn't required anymore.
",# Update README.rst
43,"fix: elevenlabs removed the need for the api key for refreshing voices
As per [this commit](https://github.com/elevenlabs/elevenlabs-python/commit/ba8b1775354db2f6d865c35c38816c19f2a50258)
The `refresh_voices()` function now no longer takes the `api_key` parameter for security reasons. This was causing the error ""TypeError: voices() got an unexpected keyword argument 'api_key'""",# Fix ElevenLabs TTS extension
44,"fix raise from None
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [ ] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [ ] I accept that @willmcgugan may be pedantic in the code review.

## Description

Fixes https://github.com/willmcgugan/rich/issues/468
",# Fix #468
45,"deepface + retinaface + chefboost
I added open source deepface, retinaface and chefboost project here.","# Added deepface, retinaface, chefboost"
46,"[common] retry if response.read() timeout
Recently I started to get timeout in response.read(), this commit will make it retry automatically if timeout.",# fix #1115
47,"AIRFLOW-3297 added possible states to the EMR step sensor
Make sure you have checked _all_ steps below.

### Jira

- [ ] My PR addresses [AIRFLOW-3297](https://issues.apache.org/jira/browse/AIRFLOW-3297)

### Description

- [ ] This PR implements correct behaviour to EMR step states. Previously, the states 'PENDING_CANCELLED' and 'INTERRUPTED' resulted in the Airflow task being marked as successful. This PR fixed this by mentioning those states as NON_TERMINAL_STATES and as FAILED_STATE, accordingly.

### Tests

- [ ] My PR adds the following unit tests - test_step_interrupted

### Code Quality

- [ ] Passes `flake8`



",# [AIRFLOW-1111] Add support for interrupted EMR step
48,"Update sql database agent example
<!-- Thank you for contributing to LangChain!

Replace this comment with:
  - Description: a description of the change, 
  - Issue: the issue # it fixes (if applicable),
  - Dependencies: any dependencies required for this change,
  - Tag maintainer: for a quicker response, tag the relevant maintainer (see below),
  - Twitter handle: we announce bigger features on Twitter. If your PR gets announced and you'd like a mention, we'll gladly shout you out!

Please make sure you're PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.

If you're adding a new integration, please include:
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use.

Maintainer responsibilities:
  - General / Misc / if you don't know who to tag: @baskaryan
  - DataLoaders / VectorStores / Retrievers: @rlancemartin, @eyurtsev
  - Models / Prompts: @hwchase17, @baskaryan
  - Memory: @hwchase17
  - Agents / Tools / Toolkits: @hinthornw
  - Tracing / Callbacks: @agola11
  - Async: @agola11

If no one reviews your PR within a few days, feel free to @-mention the same people again.

See contribution guidelines for more information on how to write/run tests, lint, etc: https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md
 -->
This PR fixes a minor documentation issue on the SQL database toolkit example notebook.",# Fix typo in sql_database.ipynb
49,"COMPAT: followup to #17491
",# TST: test iterable for Series and Index- [x] closes #10904- [x] closes #13236- [x] closes #13258- [x] closes #14216
50,"Add flag button
",# Add flag button
51,"Remove duplicated 'that' in the Plugins section
",# Fix broken link
52,"Migrate dsmr tests from coroutine to async/await
## Description:

Migrate dsmr tests from coroutine to async/await

## Checklist:
  - [x] The code change is tested and works locally.
  - [x] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**
  - [x] There is no commented out code in this PR.
  - [x] I have followed the [development checklist][dev-checklist]

If the code does not interact with devices:
  - [x] Tests have been added to verify that the new code works.

[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
",# Fix async/await syntax in tests
53,"[MRG] FIX SquaredHinge is a classification loss
Quick fix: SquaredHinge is a classification loss as it is only defined for `y` in `{-1, 1}`. I don't think this has any user-visible impact though.

@mblondel I am not sure why the Classification and Regression subclasses were introduced in the first place, can you please enlighten me? How could I add a test for this fix?
",# DOC fix docstring of SquaredHinge
54,"Remove invalid syntax in test
### Description

`uR` is not a legal string prefix, so this test breaks (`AssertionError: cannot use --safe with this file; failed to parse source file AST: invalid syntax`) if changed to one in which the file is changed (e.g. in #2885). I've changed the last test to have `u` alone, and added an `R` to the test above instead.

### Checklist - did you ...

- [X] Add a CHANGELOG entry if necessary?
- [X] Add / update tests if necessary?
- [X] Add new / update outdated documentation?
",# Fix docstring preview test
55,"Setup tox
`tox` may help to:
- support several python versions
- run same commands in CI and locally

",# Use tox for testing
56,"Catch PyTorch warning when saving/loading scheduler
When saving or loading the scheduler, PyTorch **always** sends a warning to save/load the optimizer state as well (with a typo). We are saving/loading the optimizer state along the scheduler but there is no way to tell that to PyTorch and avoid the annoying warning (and its typo).

This PR fixes that by catching all warnings while loading/saving the scheduler then reissuing the non-expected ones.
",# [MRG] Reissue PT LR SCHEDULER WARNING
57,"Fix a crash with PyTorch backend when using `weighted_metrics` with a GPU.
This patch makes sure the `sample_weights` are on the default device. Before, it can happen that `sample_weights` are on CPU while values are on GPU (unless the `sample_weights` were moved to GPU by a dataloader, for example).

Note that the `y_true` are moved to the default device already during metric computation; for example https://github.com/keras-team/keras/blob/d4f23eac3a9469646a070129d723a532fdb07090/keras/metrics/accuracy_metrics.py#L9-L10 or https://github.com/keras-team/keras/blob/d4f23eac3a9469646a070129d723a532fdb07090/keras/metrics/f_score_metrics.py#L159-L160

I understand that a corresponding issue, reproducible example and a suitable test would be the ideal way to proceed, but unfortunately, my current time constraints only allow me to create this pull-request.",# Fix sample_weight conversion in reduction metricsSample_weight is not always a tensor. This PR fixes the conversion to tensor in the reduction metrics.
58,"Bump myst-parser from 0.16.1 to 0.17.2 in /docs
Bumps [myst-parser](https://github.com/executablebooks/MyST-Parser) from 0.16.1 to 0.17.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/executablebooks/MyST-Parser/releases"">myst-parser's releases</a>.</em></p>
<blockquote>
<h2>v0.17.2</h2>
<h2>What's Changed</h2>
<ul>
<li>♻️ REFACTOR: Replace attrs by dataclasses by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/557"">executablebooks/MyST-Parser#557</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/executablebooks/MyST-Parser/compare/v0.17.1...v0.17.2"">https://github.com/executablebooks/MyST-Parser/compare/v0.17.1...v0.17.2</a></p>
<h2>v0.17.1</h2>
<h2>What's Changed</h2>
<ul>
<li>📚 DOC: Update auto-generated header anchors section by <a href=""https://github.com/choldgraf""><code>@​choldgraf</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/524"">executablebooks/MyST-Parser#524</a></li>
<li>🐛 FIX: Heading anchor resolution for parallel builds by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/525"">executablebooks/MyST-Parser#525</a></li>
<li>📚 DOCS: Fix typo by <a href=""https://github.com/rowanc1""><code>@​rowanc1</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/526"">executablebooks/MyST-Parser#526</a></li>
<li>📚 DOCS: Fix typos by <a href=""https://github.com/kianmeng""><code>@​kianmeng</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/535"">executablebooks/MyST-Parser#535</a></li>
<li>🔧 MAINTAIN: Change git to https in pre-commit-hooks by <a href=""https://github.com/eyllanesc""><code>@​eyllanesc</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/539"">executablebooks/MyST-Parser#539</a></li>
<li>📚 DOCS: Fix dependencies by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/552"">executablebooks/MyST-Parser#552</a></li>
<li>🧪 TESTS: Fix test failure with Sphinx 4.5 by <a href=""https://github.com/mitya57""><code>@​mitya57</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/542"">executablebooks/MyST-Parser#542</a></li>
<li>📚 DOCS: Fix date of  0.17.0 release by <a href=""https://github.com/soxofaan""><code>@​soxofaan</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/550"">executablebooks/MyST-Parser#550</a></li>
<li>📚 DOCS: Fix typo - &quot;to use write Sphinx&quot; by <a href=""https://github.com/bhagerty""><code>@​bhagerty</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/538"">executablebooks/MyST-Parser#538</a></li>
<li>🧪 TESTS: Fix regression output on 32-bit systems to match 64-bit systems by <a href=""https://github.com/stefanor""><code>@​stefanor</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/523"">executablebooks/MyST-Parser#523</a></li>
<li>🔧 MAINTAIN: Move from setuptools to flit by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/553"">executablebooks/MyST-Parser#553</a></li>
<li>🔧 MAINTAIN: Directly specify attrs dependency by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/555"">executablebooks/MyST-Parser#555</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/kianmeng""><code>@​kianmeng</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/535"">executablebooks/MyST-Parser#535</a></li>
<li><a href=""https://github.com/eyllanesc""><code>@​eyllanesc</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/539"">executablebooks/MyST-Parser#539</a></li>
<li><a href=""https://github.com/mitya57""><code>@​mitya57</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/542"">executablebooks/MyST-Parser#542</a></li>
<li><a href=""https://github.com/soxofaan""><code>@​soxofaan</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/550"">executablebooks/MyST-Parser#550</a></li>
<li><a href=""https://github.com/bhagerty""><code>@​bhagerty</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/538"">executablebooks/MyST-Parser#538</a></li>
<li><a href=""https://github.com/stefanor""><code>@​stefanor</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/523"">executablebooks/MyST-Parser#523</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/executablebooks/MyST-Parser/compare/v0.17.0...v0.17.1"">https://github.com/executablebooks/MyST-Parser/compare/v0.17.0...v0.17.1</a></p>
<h2>v0.17.0</h2>
<p>See: <a href=""https://myst-parser.readthedocs.io/en/latest/develop/_changelog.html"">https://myst-parser.readthedocs.io/en/latest/develop/_changelog.html</a></p>
<h2>What's Changed</h2>
<ul>
<li>👌 IMPROVE: Add <code>bullet</code> attribute to <code>bullet_list</code> node by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/465"">executablebooks/MyST-Parser#465</a></li>
<li>👌 IMPROVE: Use correct renderer for <code>state.inline_text</code> by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/466"">executablebooks/MyST-Parser#466</a></li>
<li>🧪 TESTS: Use <code>publish_doctree</code> to test error reporting by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/472"">executablebooks/MyST-Parser#472</a></li>
<li>🧪 TESTS: Ensure myst-docutils does not install sphinx by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/473"">executablebooks/MyST-Parser#473</a></li>
<li>♻️ REFACTOR: Parsing logic of Markdown links by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/467"">executablebooks/MyST-Parser#467</a></li>
<li>♻️ REFACTOR: <code>default_parser</code> -&gt; <code>create_md_parser</code> by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/474"">executablebooks/MyST-Parser#474</a></li>
<li>⬆️ UPGRADE: Drop python 3.6, support 3.10 by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/475"">executablebooks/MyST-Parser#475</a></li>
<li>👌 IMPROVE: Docutils parser settings by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/476"">executablebooks/MyST-Parser#476</a></li>
<li>🐛 FIX: front-matter rendering with docutils by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/477"">executablebooks/MyST-Parser#477</a></li>
<li>👌 IMPROVE: Code block highlighting by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/478"">executablebooks/MyST-Parser#478</a></li>
<li>🐛 FIX: Front matter -&gt; sphinx metadata regression by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/480"">executablebooks/MyST-Parser#480</a></li>
<li>👌 IMPROVE: <code>note_refname</code> for docutils internal links by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/481"">executablebooks/MyST-Parser#481</a></li>
<li>🐛 FIX: Ordered list starting number by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/483"">executablebooks/MyST-Parser#483</a></li>
<li>👌 IMPROVE: Propagate enumerated list suffix by <a href=""https://github.com/chrisjsewell""><code>@​chrisjsewell</code></a> in <a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/pull/484"">executablebooks/MyST-Parser#484</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/executablebooks/MyST-Parser/blob/master/CHANGELOG.md"">myst-parser's changelog</a>.</em></p>
<blockquote>
<h2>0.17.2 - 2022-04-17</h2>
<p>Full Changelog: <a href=""https://github.com/executablebooks/MyST-Parser/compare/v0.17.1...v0.17.2"">v0.17.1...v0.17.2</a></p>
<ul>
<li>♻️ REFACTOR: Replace <code>attrs</code> by <code>dataclasses</code> for configuration (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/557"">#557</a>)</li>
</ul>
<h2>0.17.1 - 2022-04-15</h2>
<p>Full Changelog: <a href=""https://github.com/executablebooks/MyST-Parser/compare/v0.17.0...v0.17.1"">v0.17.0...v0.17.1</a></p>
<ul>
<li>🐛 FIX: Heading anchor resolution for parallel builds (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/525"">#525</a>)</li>
<li>🔧 MAINTAIN: Move packaging from setuptools to flit (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/553"">#553</a>)</li>
<li>🔧 MAINTAIN: Directly specify attrs dependency (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/555"">#555</a>)</li>
</ul>
<h2>0.17.0 - 2022-02-11</h2>
<p>This release contains a number of breaking improvements.</p>
<p>Full Changelog: <a href=""https://github.com/executablebooks/MyST-Parser/compare/v0.16.1...v0.17.0"">v0.16.1...v0.17.0</a></p>
<h3>‼️ Markdown link resolution improvements</h3>
<p><strong>WARNING: This is a breaking change for links that rely on auto-generated anchor links</strong>. You should now <a href=""https://myst-parser.readthedocs.io/en/latest/syntax/optional.html?highlight=anchor#auto-generated-header-anchors"">manually enable auto-generated anchor links</a> if you see errors like <code>WARNING reference target not found</code>.</p>
<p>Markdown links are of the format <code>[text](https://github.com/executablebooks/MyST-Parser/blob/master/link)</code>.
MyST-Parser looks to smartly resolve such links, by identifying if they are:</p>
<ol>
<li>A link to an external resource, e.g. <code>[text](http://example.com)</code></li>
<li>A link to another source document, e.g. <code>[text](https://github.com/executablebooks/MyST-Parser/blob/master/file.md)</code>
<ul>
<li>If <code>header-anchors</code> are enabled, anchor links are also supported, e.g. <code>[text](https://github.com/executablebooks/MyST-Parser/blob/master/file.md#anchor)</code></li>
</ul>
</li>
<li>A link to an internal sphinx cross-reference, e.g. <code>[text](https://github.com/executablebooks/MyST-Parser/blob/master/my-reference)</code></li>
</ol>
<p>an additional situation is now supported:</p>
<ol start=""4"">
<li>A link to a source file, which is not a document, e.g. <code>[text](https://github.com/executablebooks/MyST-Parser/blob/master/file.js)</code>. This behaves similarly to the sphinx <code>download</code> role.</li>
</ol>
<p>In addition, configuration to more finely tune this behaviour has been added.</p>
<ul>
<li><code>myst_all_links_external=True</code>, will make all links be treated as (1)</li>
<li><code>myst_url_schemes=(&quot;http&quot;, &quot;https&quot;)</code>, sets what URL schemes are treated as (1)</li>
<li><code>myst_ref_domains=(&quot;std&quot;, &quot;py&quot;)</code>, sets what Sphinx reference domains are checked, when handling (3)</li>
</ul>
<p>See <a href=""https://github.com/executablebooks/MyST-Parser/blob/master/docs/syntax/syntax.md#markdown-links-and-referencing"">Markdown Links and Referencing</a> for more information.</p>
<h3>‼️ Dollarmath is now disabled by default</h3>
<p><strong>WARNING: This is a breaking change for dollar math</strong>. You should now manually enable dollar math (see below).</p>
<p>The default configuration is now <code>myst_enable_extensions=()</code>, instead of <code>myst_enable_extensions=(&quot;dollarmath&quot;,)</code>.
If you are using math enclosed in <code>$</code> or <code>$$</code> in your documents, you should enable <code>dollarmath</code> explicitly.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/8854d8415528b4f61b06931f3c8e996dee3f1e2b""><code>8854d84</code></a> 🚀 RELEASE: 0.17.2</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/fff28a461fef4347ae5928dc89dd01bc4bd84604""><code>fff28a4</code></a> ♻️ REFACTOR: Replace attrs by dataclasses (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/557"">#557</a>)</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/719de0a8e586a9974f357c67b0942abbc7cb2c52""><code>719de0a</code></a> 🔧 MAINTAIN: Fix deployment key for myst-docutils</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/8ea8a8b62cd130c3370fffb6de6055c59667c771""><code>8ea8a8b</code></a> 🚀 RELEASE: 0.17.1</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/0c33663094b3cd876773d682e5e783d2eadb9906""><code>0c33663</code></a> 🔧 MAINTAIN: Directly specify attrs dependency (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/555"">#555</a>)</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/ce1245b2577e0782a4a77a670f3e348403970ccb""><code>ce1245b</code></a> 🔧 MAINTAIN: Move from setuptools to flit (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/553"">#553</a>)</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/8f53a0bc55082dc8e21c813a153dc560a613f956""><code>8f53a0b</code></a> 🧪 TESTS: Fix regression output on 32-bit systems to match 64-bit systems (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/523"">#523</a>)</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/5cc398fdfd7d7cbac517c0b3edf5896454aca768""><code>5cc398f</code></a> 📚 DOCS: Fix typo - &quot;to use write Sphinx&quot; (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/538"">#538</a>)</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/3864d2be986664e7552295ca115a033dc75c9877""><code>3864d2b</code></a> 📚 DOCS: Fix date of  0.17.0 release (<a href=""https://github-redirect.dependabot.com/executablebooks/MyST-Parser/issues/550"">#550</a>)</li>
<li><a href=""https://github.com/executablebooks/MyST-Parser/commit/5916392f3937910219927db618060594238d4e5c""><code>5916392</code></a> 🧪 CI: Skip testing for Sphinx v3</li>
<li>Additional commits viewable in <a href=""https://github.com/executablebooks/MyST-Parser/compare/v0.16.1...v0.17.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=myst-parser&package-manager=pip&previous-version=0.16.1&new-version=0.17.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update myst-parser to 0.17.2
59,"Unable to decrypt signature length 93 (fixes #1461)
",# [youtube] fix signature decryption
60,"Adjusting version number
",# Update version string
61,"Fix flake8
As it turns out `flake8 *py` command checks only files by that mask in current folder, w/o going into subfolders. Fix required to also fix existing warnings.

In addition to that:
- added `# noqa` to `append_output.sh`  because multiline output string is also checked by flake8 (which is weird but it is current behavior discussed e.g. [here](https://github.com/PyCQA/pycodestyle/issues/45))
- suppressed one `pytest` warning regarding example TestRunner class from facade
- modified `setup.py` to correspond to changes in #270 (+py37)","# Fix flake8, add pytest filter"
62,"cabana: fix find similar bits
dynamic get `bit_to_find` from selected message bit:

>  if (address == selected_address && dat.size() > byte_idx) {
            bit_to_find = ((dat[byte_idx] >> (7 - bit_idx)) & 1) != 0;
          }

![2023-01-11_17-04](https://user-images.githubusercontent.com/27770/211763712-8da1914e-9513-4550-a659-303b9db86056.png)


@sshane Is it right to do like this? any comments?",# Find similar bits: add address filter
63,"Added python file to demerge large pdf to smaller ones
You can now create small pdfs of required size from a large pdf(like textbook of 1000 pages) within few clicks.",# Added quicksort_linkedlist.py
64,"Add DevContainer Support
### Describe the changes you have made:
For users who have difficulties with local installation, they can skip the local installation step, only need to visit our repository's GitHub page and press the `,` key, and they can directly create a Codespace virtual container. The container comes pre-installed with open-interpreter and includes the vscode interface. Users can seamlessly start communicating with open-interpreter.

You can now give it a try:
Visit https://github.com/weihongliang233/open-interpreter-devcontainer, press `,` on the webpage to create a codespace, and then you can start communicating with open-interpreter!

More details:
[DevContainer and Codespaces](https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration/introduction-to-dev-containers)

### Reference any relevant issues (e.g. ""Fixes #000""):

### Pre-Submission Checklist (optional but appreciated):

- [x] I have included relevant documentation updates (stored in /docs)
- [x] I have read `docs/CONTRIBUTING.md`
- [x] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [ ] Tested on MacOS
- [x] Tested on Linux
",# GitHub Codespaces
65,"Blueprint.app_url_value_preprocessor doesn't work correctly.
The code contains a typo, and additionaly it registers a blueprint-local preprocessor instead of a global one.
",# Fix #2465
66,"Add coding conventions
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Improvement


---

### Description of your *pull request* and other information
I added some coding conventions based on maintainers' reoccurring comments on pull requests. Issues included: inline values, collapsing fallbacks, and trailing parentheses. My hope is that these additions will save contributor's and maintainer's time.",# Add some coding guidelines
67,"Fast Youtube Downloader with aria2c
Download youtube videos parallel with threads using aria2c",# Added meme maker and youtube downloader
68,"Fix typo
",# Fix typo in advanced.rst
69,"Add Brew & BuyMeACoffee
Brew is a beautiful podcast player for the listeners and a simple yet powerful tool for creators.

Built by the makers of BuyMeACoffee.com.

And BuyMeCoffee.com is a free, fast and beautiful way for creators to receive tips.",# Added BuyMeACoffee and Brew
70,"[extractor/JStream] Add extractor
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

This PR adds extractor for J Stream, which is providing embedded players, like Brightcove

P.S. this is absolutely not hurry. please release first


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [x] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

</details>
",# [jstream] new extractor
71,"acme: socket timeout for HTTP standalone servers
Adds a default 30 second timeout to the StreamRequestHandler for clients
connecting to standalone HTTP-01 servers. This should prevent most cases
of an idle client connection preventing the standalone server from
shutting down.

Fixes #7386

## Pull Request Checklist

- [x] Edit the `master` section of `CHANGELOG.md` to include a description of the change being made.
- [x] Add [mypy type annotations](https://certbot.eff.org/docs/contributing.html#mypy-type-annotations) for any functions that were added or modified.
- [x] Include your name in `AUTHORS.md` if you like.
",# Fix standalone server hanging on idle connectionsFixes #6301.
72,"ci: pipx install poetry, and use setup-python cache support for poetry
As per my comments in #886 ",# Use pipx to install poetry
73,"Added document.cookie blacklist bypass
Added an alternative to document.cookie for situations when this text is blacklisted.",# Added Bypass document.cookie blacklist
74,"Use bf16 only if supported
Use `bfloat16` only if `torch.cuda.is_bf16_supported()` returns `True`.

This is needed to prevent the following error on NVIDIA GPUs withouts bfloat16 support
```
Traceback (most recent call last):
  File ""/home/fedora/workspace/nanoGPT/train.py"", line 110, in <module>
    ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)
  File ""/usr/local/lib64/python3.10/site-packages/torch/amp/autocast_mode.py"", line 234, in __init__
    raise RuntimeError('Current CUDA Device does not support bfloat16. Please switch dtype to float16.')
RuntimeError: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
```",# [bench] [sample] [train] use bfloat16 if supported
75,"Cherry pick #9829 for 2.7.4
",# Fix bug in certbot renewFixes #4096
76,"Added a few doctests for traversals
Added a few doctests 
```python
>>> root = TreeNode(1)
>>> tree_node2 = TreeNode(2)
>>> tree_node3 = TreeNode(3)
>>> tree_node4 = TreeNode(4)
>>> tree_node5 = TreeNode(5)
>>> tree_node6 = TreeNode(6)
>>> tree_node7 = TreeNode(7)
>>> root.left, root.right = tree_node2, tree_node3
>>> tree_node2.left, tree_node2.right = tree_node4 , tree_node5
>>> tree_node3.left, tree_node3.right = tree_node6 , tree_node7

>>> pre_order(root)
1 2 4 5 3 6 7 

>>> in_order(root)
4 2 5 1 6 3 7 

>>> post_order(root)
4 5 2 6 7 3 1 

>>> level_order(root)
1 2 3 4 5 6 7 

>>> level_order_actual(root)
1 
2 3 
4 5 6 7 

>>> pre_order_iter(root)
1 2 4 5 3 6 7 

>>> in_order_iter(root)
4 2 5 1 6 3 7 

>>> post_order_iter(root)
4 5 2 6 7 3 1 
```",# Add doctest for binary tree traversals
77,"Create Base Converter Number system
",# Base Converter
78,"[3.8] bpo-35771: IDLE: Fix flaky tool-tip hover delay tests (GH-15634)
Extending the hover delay in test_tooltip should avoid spurious test_idle failures.
One longer delay instead of two shorter delays results in a net speedup.
(cherry picked from commit 132acaba5a7f01373ca624b1a5975b190fe866f5)


Co-authored-by: Tal Einat <taleinat+github@gmail.com>

<!-- issue-number: [bpo-35771](https://bugs.python.org/issue35771) -->
https://bugs.python.org/issue35771
<!-- /issue-number -->
",# bpo-35771: Increase hover_delay in test_tooltip
79,"Fixing typos in R.11,15 and ES.76
Just simple typos, didn't see an open pull request that didn't already contain fixes for them
",# Fix typos
80,"ref(analytics): convert another discover analytics
",# feat(discover): track advanced analytics event for failed search
81,"bpo-37412: Fix os.getcwd() for long path on Windows
* Fix test for integer overflow.
* Add an unit test.

<!-- issue-number: [bpo-37412](https://bugs.python.org/issue37412) -->
https://bugs.python.org/issue37412
<!-- /issue-number -->
",# bpo-37412: Test os.getcwd() with long path
82,"Fix GPTQ
Fix some bugs in #1209 ",# Fix GPTQ import
83,"Bump goodwe to 0.2.18
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Breaking change
<!--
  If your PR contains a breaking change for existing users, it is important
  to tell them what breaks, how to make it work again and why we did this.
  This piece of text is published with the release notes, so it helps if you
  write it towards our users, not us.
  Note: Remove this section if this PR is NOT a breaking change.
-->


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Bump Goodwe to 0.2.18:
https://github.com/marcelblijleven/goodwe/compare/v0.2.15...v0.2.18

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [x] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #https://github.com/marcelblijleven/goodwe/issues/19
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Bump goodwe to 0.2.18
84,"fix(cpu_accelerator): :bug: Convert LOCAL_SIZE to integer
Currently, when using the CPU accelerator with the LOCAL_SIZE env var returns this error

```
'str' object cannot be interpreted as an integer
```

This is because in the `device_count` method we are returning a string instead of an integer. This PR fixes the issue https://github.com/microsoft/DeepSpeed/issues/3970",# Fix cpu_accelerator.py
85,"update arxiv link
",# fix missing citation
86,"Added needed flag to pacman invocation to only install packages that …
…are not already installed.

This makes for a better user experience on Arch.
",# Fix pacman -S in archlinux.sh
87,"[fx] added apex normalization to patched modules
",# [fx] add apex normalization to meta_patch
88,"Fix PPOCRLabel bugs, release PPOCRLabel 2.1.3 
[Fix PPOCRLabel bugs, release PPOCRLabel 2.1.3](https://github.com/PaddlePaddle/PaddleOCR/commit/088e62e6c9983e59ff5976fec613c36ab1f4413e)",# [PPOCRLabel] update version to 2.1.3
89,"TorchScript single-output fix


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Refined export options and inference flow.

### 📊 Key Changes
- Improved readability of the export formats list in `export.py`.
- Distinguished between PyTorch (`pt`) and TorchScript (`jit`) model inference flows in `common.py`.

### 🎯 Purpose & Impact
- Enhanced code clarity in export options supports easier maintenance and updates. 🛠️
- Separating inference handling provides cleaner code structure and allows for potential individual optimizations for PyTorch and TorchScript backends. 🚀
- These updates should not affect end users directly, but improved codebase health can lead to fewer bugs and better future features. 🌱",# Fix PyTorch inferenceFixes #1115
90,"Change gpu_batch_predict release test benchmark
## Why are these changes needed?

This should use latest numpy udf with numpy prediction now, also update single column selection code in new numpy predictor as it's not necessary.

Also this PR changes 
 - g3 compute template with g4dn 
 - re-enabled 100gb gpu prediction test -- we can now run it faster with less memory footprint !

```

4 x g4dn.12xlarge, 100GB data

'total_time_s', 'perf_metric_value': 304.01
'throughout_MB_s', 'perf_metric_value': 336.83102529522057

1 x g4dn.8xlarge, 20GB data

'total_time_s', 'perf_metric_value': 285.2
'throughout_MB_s', 'perf_metric_value': 71.80925666199158

1 x g4dn.8xlarge, 1GB data

'total_time_s', 'perf_metric_value': 46.12, 
'perf_metric_name': 'throughout_MB_s', 'perf_metric_value': 22.20294882914137
```

new runs on CI:

20GB image data https://buildkite.com/ray-project/release-tests-pr/builds/21577#01848692-1ff0-4ec5-bb83-7fdea0ca4e89
100GB image data https://buildkite.com/ray-project/release-tests-pr/builds/21577#01848692-1ff3-4f18-852f-9f660dbd1487


## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [x] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [x] I've run `scripts/format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [x] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [x] Release tests
   - [ ] This PR is not tested :(
",# [AIR] Update GPU batch prediction benchmark
91,"Add a small note about requests-toolbelt
We can add more info to discuss the inclusion of @lukasa's `SSLAdapter`. Are there any objections to adding this information to requests' documentation?
",# Add a note about streaming large files
92,"Fix Frozen Lake docstring
",# Fix typo in frozen lake docstring
93,"[MRG+1] Dns cache size and timeout options
Continuing of #1092 and #1120.
",# Add DNSCACHE_SIZE and DNS_TIMEOUT settings
94,"Make Certbot depend on josepy
Fixes #5519.",# Add josepy to dependencies
95,"[3.10] gh-102135: Update turtle docs to rename wikipedia demo to rosette (GH-102137)
(cherry picked from commit 8d46c7ed5e83e22d55fe4f4e6e873d87f340c1dc)

Co-authored-by: somebody <98094921+UndoneStudios@users.noreply.github.com>

<!-- gh-issue-number: gh-102135 -->
* Issue: gh-102135
<!-- /gh-issue-number -->

Automerge-Triggered-By: GH:hugovk",# bpo-38498: Remove duplicate demo script
96,"Remove airflow integration from community page
## Why are these changes needed?

We should provide a different airflow integration (one that actually works).

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(",# Remove Airflow image
97,"[extractor/bigo] Fix extractor
<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

### Description of your *pull request* and other information

</details>

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

DESCRIPTION

Fixes #4139
",# [bigo] fix studio extraction
98,"Add current_humidity attribute to mqtt humidifier
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Add current_humidity attribute to mqtt humidifier

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [x] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/27907

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [x] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] I have followed the [perfect PR recommendations][perfect-pr]
- [x] The code has been formatted using Black (`black --fast homeassistant tests`)
- [x] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
",# Add support for current humidity in MQTT humidifierThis PR adds support for current humidity in MQTT humidifier.
99,"Define and use a safe `isinstance` which handles exceptions
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

The ""Swig global variables object"" has an empty `dir()` (🤷‍♂️) so that attribute access of `.__class__` fails. I'm not sure what else we can do other than patch this particular case by checking for the `__class__` attribute.

Fixes #1838 
",# Fix inspect for edge case with Faiss libraryFixes #1838
100,"Change default value verbose=1 to verbose=0 for Sequential.predict_proba() and Sequential.predict_classes()
Change default value verbose=1 to verbose=0 in `Sequential.predict_proba()` and `Sequential.predict_classes()` for consistency with `Sequential.predict()`, for which the same change was introduced in https://github.com/fchollet/keras/commit/f30223096eb2d16a65e0e99cb5c31b1f8dfe0980, but not for these two functions.",# Fix #2085
101,"util: add safe write functions
","# util: add safe_fopen, safe_fwrite, safe_fflush"
102,"Hotfix/add grad all reduce for sequence parallel
## 📌 Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [ ] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`



## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.



## 💥 Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [ ] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# fix policy inference
103,"Fix the HTML export template
This PR fixes the HTML export template, addressing the issue raised in #3021

In doing so there's also an update to the pre-commit configuration (without it I wasn't able to commit the change -- the update is stolen from the same config file in Textual).",# Fix HTML export templateFixes #3021
104,"Allow multiple lambda docker networks configured
## Motivation
This PR will extend the functionality of `LAMBDA_DOCKER_NETWORK` to provide more than one network, as requested in #7338 .

Networks need to be provided comma separated, like this: `LAMBDA_DOCKER_NETWORK=network1,network2`.
As long as only one network is provided, the behavior does not change.

Fixes #7338.

## Changes
* Allow multiple docker networks to be respected (only new provider)
* Add test for LAMBDA_DOCKER_NETWORK with multiple networks.

## TODOs
* After this is merged, we should document this.",# [AWS-LAMBDA] Support for multiple container networksFixes #1595
105,"Fixed Debug default value in the docs
Fix Debug Default: By default Debug is only True when ENV is 'development' instead of 'production'

",# Fix typo in config.rst
106,"Replace deprecated NumPy aliases of builtin types
`np.bool` and `np.int` were originally [deprecated](https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations) in NumPy 1.20 and recently [removed](https://github.com/numpy/numpy/releases/tag/v1.24.0) in 1.24.

Using them in new versions (tested on 1.24.3 and 1.25.0) of NumPy raises an error:

```
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
```",# Fix int conversion in volo
107,"Bump llama-cpp-python to 0.2.6
## Checklist:

- [x] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
---
Held off on making a PR for this due to believing that there was a version conflict with pydantic that prevented installation.
I now believe that this was actually a separate issue and was fixed here: #3927

I haven't had any issues with it that I've noticed since, but this may require more thorough testing.

---
Written changelog: https://github.com/abetlen/llama-cpp-python/blob/v0.2.6/CHANGELOG.md
- 0.2.0
  - https://github.com/abetlen/llama-cpp-python/compare/v0.1.85...v0.2.0
- 0.2.1
  - https://github.com/abetlen/llama-cpp-python/compare/v0.2.0...v0.2.1
- 0.2.2
  - https://github.com/abetlen/llama-cpp-python/compare/v0.2.1...v0.2.2
- 0.2.3
  - https://github.com/abetlen/llama-cpp-python/compare/v0.2.2...v0.2.3
  - https://github.com/ggerganov/llama.cpp/compare/89e89599fd095172f8d67903b5e227467420f036...71ca2fad7d6c0ef95ef9944fb3a1a843e481f314
- 0.2.4
  - https://github.com/abetlen/llama-cpp-python/compare/v0.2.3...v0.2.4
- 0.2.5
  - https://github.com/abetlen/llama-cpp-python/compare/v0.2.4...v0.2.5
- 0.2.6
  - https://github.com/abetlen/llama-cpp-python/compare/v0.2.5...v0.2.6
  - https://github.com/ggerganov/llama.cpp/compare/71ca2fad7d6c0ef95ef9944fb3a1a843e481f314...80291a1d02a07f7f66666fb576c5b1e75aa48b46
- All changes
  - https://github.com/abetlen/llama-cpp-python/compare/v0.1.85...v0.2.6
  - https://github.com/ggerganov/llama.cpp/compare/89e89599fd095172f8d67903b5e227467420f036...80291a1d02a07f7f66666fb576c5b1e75aa48b46",# Update llama-cpp-python to 0.2.6
108,"Add Chips-n-Salsa Java library
## Chips-n-Salsa

A Java library for genetic algorithms, evolutionary computation, and stochastic local search, with a focus on self-adaptation / self-tuning, as well as parallel execution.

Project page: https://chips-n-salsa.cicirello.org/
GitHub repository: https://github.com/cicirello/Chips-n-Salsa",# Add Chips-n-Salsa
109,"Feature mute stream log for info level
**Features**
see issue : #1109 
llm stream_response alway been print regardless of debug flag
I modified `logs.py` rather than `config2.py`.
This is because log is been set via `define_log_level` rather than `config.yaml`
To keep things simple, a global variable `_print_level` is introduced in `logs.py`
    
**Influence**
`define_log_level(print_level=""INFO"")` will mute `log_llm_stream`
",# fix llm stream log
110,"Fix eos_config integration test failure


##### SUMMARY
<!--- Describe the change, including rationale and design decisions -->
Enable become for eos_config check_mode test cases
<!--- If you are fixing an existing issue, please include ""Fixes #nnn"" in your
commit message and your description; but you should still explain what
the change does.-->

##### ISSUE TYPE
<!--- Pick one below and delete the rest: -->
 - Test Pull Request

##### COMPONENT NAME
<!--- Name of the module, plugin, module or task -->
tests/cli/check_mode.yaml

##### ANSIBLE VERSION
<!--- Paste verbatim output from ""ansible --version"" between quotes below -->
```
2.5
```


##### ADDITIONAL INFORMATION
<!--- Include additional information to help people understand the change here.
For bugs that don't have a linked bug report, a step-by-step reproduction
of the problem is helpful. -->

<!--- Paste verbatim command output below, e.g. before and after your change -->
```

```
",# [eos_config] Fix check mode testsFixes #63067
111,"Fix doc build failure on main
",# [AIRFLOW-1111] Fix redshift cluster operator documentation
112,"Fix syntax error in last commit.
The last commit created a syntax error in the message. This commit fixes it.
",# Fix typo in requests/models.py
113,"🐛 Re-enable search bar after adding markdown-data plugin
🐛 Re-enable search bar after adding markdown-data plugin",# Add search plugin to mkdocs.yml
114,"ref(badges): Remove shim files for badges that were not in components/badges/*
In #68843 we moved a bunch of files around, and then getsentry/getsentry#13646 needed to follow suit. 
This cleans up the leftover stubs which we needed so build don't break along the way.

Follows: https://github.com/getsentry/sentry/pull/68843
Depends on https://github.com/getsentry/getsentry/pull/13646",# feat(badge): remove deprecated badge components
115,"[Windows|Unix] Reimplement reverter logic to make it cross-platform compatible
This PR is a part of the effort to remove the last broken unit tests in certbot codebase for Windows, as described in #6850.

This PR fixes the logic of `certbot.reverter` module to make it runnable on Windows. This critical module is used to revert modifications done by Certbot on a system when something goes wrong during a certificate deployment.

To do so, several piece of informations are stored on the filesystem, and will be used by `certbot.reverter` to know what need to be reverted at any point during a process. In particular, modified files and new files are stored this way. The form of the storage is a file, where each line represents a path:
```
/path/to/affected_file_1
/path/to/affected_file_2
```

Two problems arises on Windows:
* end of lines in Windows are CRLF, while the current logic of `certbot.reverter` expects LF end lines (Linux style)
* on Windows, `certbot.reverter` generates superfluous empty lines when writing, making the revert process failing when the persisted file is loaded, because each line is expected to contain a valid path.

So the format for theses files is a weak formatting, a separation of statements based on LF end of lines. It seems that it is not the first time that this is a problem, because another file (the shell commands issued by certbot), is using a CSV format. However, the `csv` module behavior is not consistent across Python 2.x/3.x, making necessary some specific mitigations in `certbot.reverter` code.

So I am proposing a new solution here, in order to correct `certbot.reverter` for Windows, while taking advantage of a less brittle and platform independant format for relevant files, and making a consistent implementation accross the various files use during a revert process.

The idea is to use the module `json`. Instead of writing/reading new paths lines by lines, or use the `csv` module, `certbot.revert` will write the list of paths using `json.dumps` in the file, and read the list of files using `json.loads` when needed. Here are the advantages:
* the format used in the files is JSON, which is a strong format, in particular not dependant to LF/CRLF end of lines
* `json` module is working consistently accross Python 2.x/3.x without specific code
* no parallel read/write, or writing line by line: files are read as a whole at one point, then written as a whole later

As a consequence, relevant unit tests in `certbot.tests.reverter_test` are reactivated.",# Fix reverter tests on WindowsFixes #4444.
116,"Components: allow fullscreen content
Adds ""fullscreen"" to our `iframe allow` feature policy. This applies to `components.iframe`, `components.html`, and `components.declare_component` components. 

With this attribute, components can use the `Element.requestFullscreen()` web API.

(We omitted this simply because we hadn't made a call on it. The team discussed it today, and we're all cool with allowing it.)

Fixes #1710 ",# feat(IFrame): add default feature policy to iframe
117,"athenad: fix memory leak in `_do_upload()`
",# athena: measure memory usage during file upload
118,"fix bilibili bangumi support
modify the regex to get eposide id

bilibili has changed their html source code, change the regex would help fix issue #1569

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/soimort/you-get/1586)
<!-- Reviewable:end -->
",# fix bilibili bangumi
119,"Deleted useless log out2
",# remove out2
120,"Correctly JSON-encode datetimes aware of non-UTC timezones
http_date() requires timetuple in UTC, but JSONEncoder.default() was
passing a local timetuple instead.

This fixes #2372.

<!--
Commit checklist:

* add tests that fail without the patch
* ensure all tests pass with ``pytest``
* add documentation to the relevant docstrings or pages
* add ``versionadded`` or ``versionchanged`` directives to relevant docstrings
* add a changelog entry if this patch changes code

Tests, coverage, and docs will be run automatically when you submit the pull
request, but running them yourself can save time.
-->
","# Fix JSON encoding of aware, non-UTC datetimesFixes #2374"
121,"[workflow] added status check for test coverage workflow
## 📌 Checklist before creating the PR

- [x] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`

N/A

## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.

This PR added the status check for the `Build on PR` workflow to the test coverage report workflow to ensure only successful build will produce the coverage report.

## 💥 Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [x] I have added thorough tests.
- [x] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [x] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# Only run test coverage on successful workflow runs
122,"fix error type issue in deepspeed/comm/ccl.py
get_global_rank would return a ValueError instead of RuntimeError",# Fix ccl.py
123,"[globo] Fix error on some globo videos #4346
I've fixed an error (#4346) on some globo videos. The problem was that some videos have a m3u playlist listed on the format's list. I'm new to python and youtube-dl, so I don't know if my fix is the best possible. 
",# [globo] fix extraction
124,"Fix gunicorn description
resolve #1713

## What is this Python project?

Gunicorn 'Green Unicorn' is a Python WSGI HTTP Server for UNIX. It's a pre-fork worker model. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy.

https://gunicorn.org/
https://github.com/benoitc/gunicorn
https://en.wikipedia.org/wiki/Gunicorn

--

Anyone who agrees with this pull request could submit an *Approve* review to it.
",# Update README.md
125,"cookiejar.iteritems() is broken after 2.1.0 update
```
Python 2.7.5+ (default, Sep 19 2013, 13:48:49) 
[GCC 4.8.1] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import requests
>>> requests.__version__
'2.1.0'
>>> r = requests.get('http://google.com')
>>> r.cookies
<<class 'requests.cookies.RequestsCookieJar'>[Cookie(version=0, name='NID', value='67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV', port=None, port_specified=False, domain='.google.ru', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=1403146705, discard=False, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False), Cookie(version=0, name='PREF', value='ID=7c3265d2706e8bea:FF=0:NW=1:TM=1387335505:LM=1387335505:S=LsdqbwGuUdHENT0m', port=None, port_specified=False, domain='.google.ru', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=1450407505, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False)]>
>>> dict(r.cookies)
{'PREF': 'ID=7c3265d2706e8bea:FF=0:NW=1:TM=1387335505:LM=1387335505:S=LsdqbwGuUdHENT0m', 'NID': '67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV'}
>>> r.cookies.items()
[('NID', '67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV'), ('PREF', 'ID=7c3265d2706e8bea:FF=0:NW=1:TM=1387335505:LM=1387335505:S=LsdqbwGuUdHENT0m')]
>>> r.cookies.iteritems()
<generator object iteritems at 0x1940dc0>
>>> list(r.cookies.iteritems())
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/kpp/build/trng_social/venv/lib/python2.7/_abcoll.py"", line 387, in iteritems
    yield (key, self[key])
  File ""/home/kpp/build/trng_social/venv/local/lib/python2.7/site-packages/requests/cookies.py"", line 267, in __getitem__
    return self._find_no_duplicates(name)
  File ""/home/kpp/build/trng_social/venv/local/lib/python2.7/site-packages/requests/cookies.py"", line 322, in _find_no_duplicates
    raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))
KeyError: ""name=Cookie(version=0, name='NID', value='67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV', port=None, port_specified=False, domain='.google.ru', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=1403146705, discard=False, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False), domain=None, path=None""
```

Because of this one can't for example build `OrderedDict` from `RequestCookieJar`.
","# Add iterkeys(), itervalues(), iteritems() to RequestsCookieJar"
126,"ES.23: two corrected typos in code example
Types changed from `initializer_int<int>` to `initializer_list<int>`.
",# Fix typo in C.14
127,"[extractor/wistia] Match IDs in embed URLs
</details>

Adds URL query string checks to Wistia embed extraction. Fixes #4985 

Confirmed that the embed JS parses the query params `wmediaid`, `wvideoid` and `wvideo` for ID values:
`https://fast.wistia.com/assets/external/E-v1.js`

Updates WistiaIE tests and generic Wistia embed tests.


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))
",# [wistia] Add support for video IDs in query
128,"Remove deprecated  --py36 option
The `--py36` option was deprecated in Black 19.3b0 (https://github.com/psf/black/pull/750):

> deprecated `--py36` (use `--target-version=py36` instead) (#724)

https://github.com/psf/black#193b0

It's been a year since it was deprecated, and has been deprecated in two releases (19.3b0 and 19.10b0).

Is it now time to remove the deprecation?

At least I think it would be good to remove before the non-prerelease Black release (https://github.com/psf/black/issues/517), and whilst still in beta too.
",# Remove --py36
129,"Update Dockerfile
Add pip3 install opencv-python==4.1.2.30 if you want to run the live webcam examples",# Add opencv-python to Dockerfile
130,"DeapLearningKit for Apple OSs added
",# Added DeepLearningKit
131,"Comment syntax
Prompt textareas can now use C-style comments",# Add support for C-style comments in dynamic prompts
132,"[gemini] add fake_release_chunk for keep-gathered chunk in the infere…
## 😎 What's new

I add a function called `fake_release_chunk ` to simulate the result generated by `chunk_reduce` but it does nothing. Thus, we can run normally in the inference mode. 

## 📌 Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`

`fixed #2562`

## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.

`fixed #2562`

## 💥 Checklist before requesting a review

- [x] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [x] I have added thorough tests.
- [x] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [x] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# [Gemini] Keep gathered chunk in inference mode
133,"Infer target version based on project metadata
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

<!-- Good things to put here include: reasoning for the change (please link
     any relevant issues!), any noteworthy (or hacky) choices to be aware of,
     or what the problem resolved here looked like ... we won't mind a ranty
     story :) -->

Fixes #3124

The logic implemented is as follows:
* If Black's `target_version` is specified in the `pyproject.toml`, we ignore the project metadata.
* If it is not specified, we try to read and parse the project metadata to determine a valid list of `TargetVersion`. If we fail for whatever reason, we continue without a `target_version`.
* The list of target versions should include all major Python versions allowed by the `requires-python` specifier.
  * `3.8.5` becomes `[""py38""]`
  * `>3.6,<3.11` becomes `[""py37"", ""py38"", ""py39"", ""py310""]`
  * `<3.7` becomes `[""py33"", ""py34"", ""py35"", ""py36""]` (Python 3.3 is the minimal supported version for Black)

_(for more examples, check the test cases)_

Changes:
* Updated `parse_pyproject_toml`
  * When reading the TOML file, we check if `target_version` is specified in Black's config. If not, we try to infer it from the project metadata.
  * This seemed like the logical place - since we are reading the file anyway, we might aswell extract the project metadata if we need it.
* Added basic functionality for reading project metadata.
  * Only the PyPA standard is now supported: `project` -> `requires-python`.
  * We could add support for Poetry or other tools later.
* Added parsing of the version / specifier based on `packaging`'s `Version` and `SpecifierSet`
  * There is some black magic (pun intended) going on in the `strip_specifier_set` function that I wrote. Unfortunately, working with these kinds of specifiers is nasty when it comes to edge cases. My implementation satisfies all specifier sets I could come up with, but there are probably some corner cases that I did not cover...
* Added `packaging>=20.0` as a dependency. This is the minimum version that includes the functionality needed for this implementation.
* Updated the help text for the CLI command.

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [x] Add a CHANGELOG entry if necessary?
- [x] Add / update tests if necessary?
- [x] Add new / update outdated documentation? _--> Updated the CLI argument help text_

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
",# Try to infer target version from pyproject.tomlFixes #3219
134,"Update badge for coverage
:art: Update badge for coverage. Use Shields.io, as Codecov's one shows coverage for the last PR from a fork from `master`.

So, it some times shows 99%, or 40% or different things, if a PR that is not yet merged has a lower coverage.",# Update badges
135,"escape unicode answer
gui need escape unicode answer to support Chinese",# Fix for non-ASCII characters in answer
136,"added assertion of 'NoFrameskip' in AtariPreprocessing
relevant to #1724 ",# Fix AtariPreprocessing
137,"Add --input-size option to scripts to specify full input dimensions f…
…rom command-line",# Add --input-size for inference
138,"Fix typo in examples/downloader.py
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [x] Other

## Checklist

- [ ] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [ ] I accept that @willmcgugan may be pedantic in the code review.

## Description

Please describe your changes here. If this fixes a bug, please link to the issue, if possible.
",# Fix typo in example
139,"Add WolneLektury.pl API to Books
<!-- Thank you for taking the time to work on a Pull Request for this project! -->
<!-- To ensure your PR is dealt with swiftly please check the following: -->
- [x] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added Wolne Lektury API
140," Replace literal constant 10 with variable num_classes in example/
",# Fix examples
141,"Correctness fix PP+ZeRO for gradient accumulation + updates from master
* Correctness fix PP+ZeRO for gradient accumulation
* Cherry picked round robin grad partitioning fixes from master
* Cherry picked ignore overlap/contiguous grad settings for ZeRO-1 from master",# [zero] add round robin gradient partitioning
142,"Bug fixes
A few simple bug fixes

- #1882
- #1878
- #1877
- #1875",# Fix some bugs
143,"elasticsearch updates
Hello, I tried to update some of Elasticsearch's answers. ",# Fixing some questions
144,"When on sagemaker use their env variables for saves
# What does this PR do?

When on SageMaker, the content of the env variable ""SM_OUTPUT_DATA_DIR"" should be used to save training artifacts (such as our checkpoint) so make it overwrite the `output_dir` (and make that argument optional so it doesn't need to be passed for sagemaker training).
Then the final model will be easy to deploy if it's also saved to the content of the env variable ""SM_MODEL_DIR"" so adding that as well.
",# [Sagemaker] Save model to SM_MODEL_DIR
145,"Add support for Opple light
## Description:


**Pull request in [home-assistant.io](https://github.com/home-assistant/home-assistant.io) with documentation (if applicable):** home-assistant/home-assistant.io#6328

## Example entry for `configuration.yaml` (if applicable):
```yaml
light:
  - platform: opple
    name: LIGHT_NAME
    host: IP_ADDRESS
```

## Checklist:
  - [x] The code change is tested and works locally.
  - [x] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**

If user exposed functionality or configuration variables are added/changed:
  - [x] Documentation added/updated in [home-assistant.io](https://github.com/home-assistant/home-assistant.io)

If the code communicates with devices, web services, or third-party tools:
  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).
  - [x] New dependencies are only imported inside functions that use them ([example][ex-import]).
  - [x] New or updated dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.
  - [x] New files were added to `.coveragerc`.


[ex-requir]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L14
[ex-import]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L54
",# [opple] Add Opple light component
146,"bpo-33642: IDLE: Use variable number of lines in CodeContext.


<!-- issue-number: bpo-33642 -->
https://bugs.python.org/issue33642
<!-- /issue-number -->
",# bpo-33642: Only display actual code context lines.
147,"[3.7] bpo-36454: Fix test_time.test_monotonic() (GH-12929)
Change test_time.test_monotonic() to test only the lower bound of elapsed time
after a sleep command rather than the upper bound. This prevents unnecessary
test failures on slow buildbots. Patch by Victor Stinner.
(cherry picked from commit d246a6766b9d8cc625112906299c4cb019944300)


Co-authored-by: Victor Stinner <vstinner@redhat.com>

<!-- issue-number: [bpo-36454](https://bugs.python.org/issue36454) -->
https://bugs.python.org/issue36454
<!-- /issue-number -->
",# bpo-36454: Fix test_time.test_monotonic() on slow buildbots
148,"Topic lookup speed increase, code quality improvement
## RFC
- ```rfc_describe``` helper function created.
- Topic lookup section changed from parsing ``` curl ""https://www.rfc-editor.org/search/rfc_search_detail.php?title=${ARG}"" 2>/dev/null \``` to simply doing a ```grep``` of the index file using the ```rfc_describe``` helper function.
- - This is faster because the index file is stored locally.

## OEIS
- hopefully fixed arg passing issue between ```cmd.py``` and ```oeis.sh``` by using a delimiter ",# RFC.sh: Use a function to describe RFCs
149,"Use the proper error message with caused exceptions
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [x] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

When an exception is raised using ""from"", the chained exception goes into
__cause__, which results in a different message using Python's native traceback
handler. This patch properly replicates that error message.
",# Fix traceback message with `from` exceptionsFixes #463
150,"Change 'c_adm' to 'y' in ControlNet.get_control
After latest updates, cond now has this data under 'y' key instead of 'c_adm'.",# fix controlnet
151,"add decorator for adding routes to a Router
This PR adds a decorator for the `Router` to add rules more easily and build cohesion between handlers and their routes. This can be used to simplify adding routes to the edge router, or other routers, which will appear more and more in service providers. Specifically, I'll use this to build the SQS Query API.

How to use it:

## Bind functions directly to a Router
This is essentially like flask's `@app.route` decorator. It will add the endpoint directly to the `router` instance. The function signature needs to match the expected input of the dispatcher configured for the Router (in this case it needs to match the `Handler` protocol)

```python
router: Router[Handler] = Router(dispatcher=handler_dispatcher())

@router.route(""/user/<user_id>"")
def my_route(request, user_id):
    return {}
```

## Define unbound routes and then bind them to a router

This is required when you want do add bound methods to a router. This is similar to flask's blueprints.

```python
class MyService:
    @route(""/user/<user_id>"")
    def my_route(request, user_id):
        return {}

my_service = MyService()

router = Router(dispatcher=handler_dispatcher())
router.add_route_endpoint(my_service.my_route)
```

## Batch bind routes of a class to a router

```python
class MyService:
    @route(""/user/<user_id>"")
    def get_user(request, user_id):
        return {}

    @route(""/user"")
    def list_user(request):
        return []

router = Router(dispatcher=handler_dispatcher())
router.add_route_endpoints(MyService())
```",# Add route decorator
152,"Use shared variable group
When setting up Azure Pipelines, I didn't like having to define `codecov_token` for each pipeline. This works around it by using a shared variable group.

You can see this working successfully at https://dev.azure.com/certbot/certbot/_build/results?buildId=3.",# Azure pipeline: use shared variable group
153,"[AIRFLOW-4844] Added optional is_paused_upon_creation argument for da…
…gs to configure initial pause status upon creation.

Make sure you have checked _all_ steps below.

### Jira

- [ ] My PR addresses the following [Airflow-4844](https://issues.apache.org/jira/browse/AIRFLOW-4844)

### Description

- [ ] Here are some details about my PR:
1. Adding the feature to configure each dag object with the initial state of is_paused flag
2. The corresponding changes for python2 branch will be submitted once this review is finalized.


### Tests

- [ ] My PR adds the following unit tests:
1. Adding unit test to test existing dags in database not being affected with the flag.
2. Adding unit test to test new dags following the flag passed. (there are already unit tests testing backward compatibility of the the code change.)

### Commits

- [ ] My commits all reference Jira issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)"":
  1. Subject is separated from body by a blank line
  1. Subject is limited to 50 characters (not including Jira issue reference)
  1. Subject does not end with a period
  1. Subject uses the imperative mood (""add"", not ""adding"")
  1. Body wraps at 72 characters
  1. Body explains ""what"" and ""why"", not ""how""

### Documentation

- [ ] In case of new functionality, my PR adds documentation that describes how to use it.
  - All the public functions and the classes in the PR contain docstrings that explain what it does
  - If you implement backwards incompatible changes, please leave a note in the [Updating.md](https://github.com/apache/airflow/blob/master/UPDATING.md) so we can assign it to a appropriate release

### Code Quality

- [ ] Passes `flake8`
",# [AIRFLOW-1111] Add is_paused_upon_creation flag to DAG
154,"TensorRT `--dynamic` fix
May resolve #9688 

Signed-off-by: Glenn Jocher <glenn.jocher@ultralytics.com>

<!--
Thank you for submitting a YOLOv5 🚀 Pull Request! We want to make contributing to YOLOv5 as easy and transparent as possible. A few tips to get you started:

- Search existing YOLOv5 [PRs](https://github.com/ultralytics/yolov5/pull) to see if a similar PR already exists.
- Link this PR to a YOLOv5 [issue](https://github.com/ultralytics/yolov5/issues) to help us understand what bug fix or feature is being implemented.
- Provide before and after profiling/inference/training results to help us quantify the improvement your PR provides (if applicable).

Please see our ✅ [Contributing Guide](https://github.com/ultralytics/yolov5/blob/master/CONTRIBUTING.md) for more details.
-->


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Improved ONNX export compatibility with TensorRT versions 7 and 8.

### 📊 Key Changes
- Removed `False` in the call to `export_onnx` function, now passing `dynamic` directly.
- Fixed indentation and formatting in the `dynamic` flag handling block.

### 🎯 Purpose & Impact
- 🛠 The update ensures better compliance with different TensorRT versions when exporting YOLOv5 models to ONNX format.
- ⚙️ The removal of the hardcoded `False` argument allows for the `dynamic` flag to be passed properly, improving the dynamic batching capabilities.
- 📈 This change could lead to more efficient model deployment for users who utilize TensorRT for inference, potentially enhancing performance and resource utilization.",# Fix TensorRT 7 exportFixes #6012
155,"Add Introduction to Data-Centric AI
",# Added MIT's Introduction to Data-Centric AI
156,"Add more deep learning MOOCs
Add deep learning MOOCs by Udacity, MIT and fast.ai",# Update courses.md
157,"add ""--"" to CLI arg for consistency
",# Fix typo in using.rst
158,"🌐 Add German translation for `docs/de/docs/project-generation.md`
← `fastapi-people.md` (#10285)
→ `external-links.md` (#10852)

[German translation progress](https://github.com/tiangolo/fastapi/discussions/10582)",# 🌐 Add German translation for `docs/de/docs/project-generation.md`🌐 Add German translation for `docs/de/docs/project-generation.md`
159,"framereader: use the same alignement as visionbuf
follow up of https://github.com/commaai/openpilot/pull/23200#event-5757453814",# Fix frame reader
160,"updating iter_content docstring to match functionality
Sorry to be bombarding you guys with PRs. This one is pretty minor but explains what I would say was non-obvious behaviour of the function before PR #3368 and PR #3365.
",# Add chunk_size type hint
161,"feat(TS): add more types and stub methods [ci deploy]
","# add balance, transfer, withdraw, createDepositAddress"
162,"Removes unofficial cartpole testfile
Accidentally left this one in :P.
",# Remove off_switch_cartpole_test.py
163,"utils.guess_filename fails if the given parameter looks like a file object but has a non-string name attribute
A cherrypy uploaded file behave like a regular file, except that its name attribute is an int and passing it directly to requests fails because of that

(not sure if i should add myself to AUTHORS for this?)
",# Fix #2405Fixes #2405
164,"[3.11] gh-92984: Explicitly disable incremental linking for Windows Release and PGO builds (GH-92985)
(cherry picked from commit 38feffa09c74d9a853745908b7813903bae33b96)


Co-authored-by: David Machaj <46852402+dmachaj@users.noreply.github.com>",
165,"PERF: ArrowExtensionArray.fillna when array does not contains any nulls
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v2.1.0.rst` file if fixing a bug or adding a new feature.

```
import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(1_000_000, 10), dtype=""float64[pyarrow]"")

%timeit df.fillna(0.0)
```

```
25 ms ± 5.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)        -> main
76.4 µs ± 4.43 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)  -> PR
```",# ARROW: fillna no-op returns a view
166,"Merge dev branch
",# Fix typo in Colab-TextGen-GPU.ipynb
167,"Fix typo in dictionary section
",# Fix typo in README.md
168,"Bump aiohomekit to 0.7.20
## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
I did a new release of `chacha20poly1305-reusable` tonight to fix a typing issue and realized I screwed up the version pin when I added it with poetry for `aiohomekit`.  I'm concerned it might cause a problem building images (hopefully not, but I don't want to find out otherwise on the day of release) so I'm bumping `aiohomekit` to resolve the version conflict.

- Fixes the chacha20poly1305-reusable dep pin

- Changelog: https://github.com/Jc2k/aiohomekit/compare/0.7.19...0.7.20

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [x] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Bump aiohomekit to 0.7.20
169,"Fix requirements in gui  api
",# Fix plyer import
170,"Run le_auto_xenial on every PR.
https://github.com/certbot/certbot/pull/7190/files removed our only `le_auto_*` tests on PRs. This PR fixes that by running `le_auto_xenial` on every PR which also includes running `modification-check.py` like we used to for Trusty.",# Travis: Use docker for le_auto_xenial
171,"after initial launch, disable --autolaunch for subsequent restarts
currently if one is to click the `Restart Gradio and Refresh components (Custom Scripts, ui.py, js and css only)` under settings the web ui will be restarted
![image](https://user-images.githubusercontent.com/40751091/197380676-a07a28da-9a8f-4971-a985-1181f0174789.png)

but if the `--autolaunch` option is used it will open a second web UI page
causing multiple web ui page to be opened in the browser

I believe this is undesirable Behavior

this change fixes this behavior
make it and only apply to the initial launch

> [--autolaunch](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings)
open the webui URL in the system's default browser upon launch
",# Disable --autolaunch after initial launch
172,"RealFace model plugin cli/gui description change
- altered brief model description to reflect it's capabilities more accurately",# Update cli.py
173,"Added model cards for Romanian BERT models
Added model card for ``dumitrescustefan/bert-base-romanian-cased-v1`` and ``dumitrescustefan/bert-base-romanian-uncased-v1``",# Add Romanian BERT models
174,"fix uuid highlighter
Fixes https://github.com/Textualize/rich/issues/2078
",# Add UUID regex
175,"Fix the supervisord.conf file using a full path
This is a fix for https://github.com/localstack/localstack/issues/6739. There is no breaking changes and the linting / format tests are passing.",# Fix infra command
176,"API deprecate penalty='none' for LogisticRegression
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->
Fixes #23749.

#### What does this implement/fix? Explain your changes.
This PR deprecates `penalty='none'` for LogisticRegression, so the usage of `penalty=None` is consistent among `SGDClassifier`, `SGDRegressor`, `Perceptron` and `LogisticRegression`.

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# DEP: Remove 'none' option from LogisticRegression penalty
177,"🌐 Add Japanese translation for `docs/ja/docs/advanced/nosql-databases.md`
Relates to #1572

This PR translates advanced/nosql-databases.md.

I left ""databases"" in the page title as it is because there is no word for the plural of database in Japanese.  
This is my first pull request, so I apologize if there are any problems. I would appreciate it if you could check it.",# 🌐 Add Japanese translation for `docs/advanced/nosql-databases.md`🌐 Add Japanese translation for `docs/advanced/nosql-databases.md`
178,"Add subliminal to downloaders
",# Add subliminal
179,"Add project_urls to setup
These are used by PyPI and other services.

<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->


#### What does this implement/fix? Explain your changes.


#### Any other comments?


<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# Add project_urls to setup.py
180,"idex2 safeSymbol
",# idex2: remove symbol lookup
181,"build(ci): Set branch name to intermediary environment variable
",# Use the ref from the github event
182,"Add Neural Magic DeepSparse tutorial to README
Signed-off-by: Ayush Chaurasia <ayush.chaurarsia@gmail.com>

@glenn-jocher we need to add the first 2 images to our assets repo. Those are not displaying through the original link
The third one is fine as it's an asset.
https://github.com/neuralmagic/deepsparse/blob/main/examples/ultralytics-yolo/ultralytics-readmes/deepsparse-readme.md

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Updated partnerships and improved inference speed in the YOLOv5 README.

### 📊 Key Changes
- Removed the link to ""Deci"" platform and added a link to ""Neural Magic"" in the README.
- Updated accompanying text to highlight the benefits of Neural Magic's DeepSparse.

### 🎯 Purpose & Impact
- The goal is to promote a new partnership with Neural Magic and its DeepSparse technology.
- Users can expect up to 6x faster inference speeds with YOLOv5 when leveraging Neural Magic's software, potentially enhancing the performance of their AI applications significantly. 🚀",# Update README.md
183,"add dataset counts script
This can be used for a part of #2174.

This PR contains:
 - a generic script to count the dataset entries for any dataset and any mode
 - updated model/model_training/README.md with some counts of datasets
 - some minor adjustments to model/model_training/utils.py so that the datasets can be returned as list. This is done so that this PR can reuse existing code and does not need to copy+paste.

",# Add dataset counts for sft
184,"[ie/MuseAI] Add extractor
Closes #7543


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [x] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


<!-- Do NOT edit/remove anything below this! -->
</details><details><summary>Copilot Summary</summary>  

<!--
copilot:all
-->
### <samp>🤖 Generated by Copilot at 12f8953</samp>

### Summary
:sparkles::video_camera::robot:

<!--
1.  :sparkles: This emoji represents the addition of a new feature or functionality, which is the case for the muse.ai extractor.
2.  :video_camera: This emoji represents the video-related nature of the change, as it involves downloading videos from a video hosting platform.
3.  :robot: This emoji represents the AI aspect of the change, as muse.ai is a platform that offers AI features for videos, such as transcription, translation, and summarization.
-->
This pull request adds a new extractor for `muse.ai`, a video hosting and sharing platform with AI features. It creates a new file `museai.py` that contains the MuseAIIE class, which inherits from the InfoExtractor base class and defines the methods for extracting video information and formats from muse.ai URLs. It also imports the MuseAIIE class in `_extractors.py` to enable the extraction of muse.ai videos.

> _`MuseAIIE` class_
> _Extracts videos with AI_
> _Winter of content_

### Walkthrough
*  Add support for muse.ai as a new extractor ([link](https://github.com/yt-dlp/yt-dlp/pull/7614/files?diff=unified&w=0#diff-780b22dc7eb280f5a7b2bbf79aff17826de88ddcbf2fc1116ba19901827aa4e3R1144), [link](https://github.com/yt-dlp/yt-dlp/pull/7614/files?diff=unified&w=0#diff-b2d7aab64ba385fb93f7e0c77083b5aec8ee53ba9909bb078e569266e68f6b45R1-R110))
   * Import the MuseAIIE class from `museai.py` in `_extractors.py` ([link](https://github.com/yt-dlp/yt-dlp/pull/7614/files?diff=unified&w=0#diff-780b22dc7eb280f5a7b2bbf79aff17826de88ddcbf2fc1116ba19901827aa4e3R1144))
   * Define the MuseAIIE class in `museai.py` that inherits from InfoExtractor and implements the methods for extracting video information and formats from muse.ai URLs ([link](https://github.com/yt-dlp/yt-dlp/pull/7614/files?diff=unified&w=0#diff-b2d7aab64ba385fb93f7e0c77083b5aec8ee53ba9909bb078e569266e68f6b45R1-R110))



</details>
",# [museai] New extractor
185,"fix Transfer-Encoding ""chunked"" on empty responses
Avoid returning `Transfer-Encoding` headers for HTTP 204 responses. Should fix the currently failing build on `master`.

Currently seeing connection/protocol errors like below:
```
            except (HTTPException, SocketError) as e:
                # This includes IncompleteRead.
>               raise ProtocolError(""Connection broken: %r"" % e, e)
E               urllib3.exceptions.ProtocolError: (""Connection broken: InvalidChunkLength(got length b'', 0 bytes read)"", InvalidChunkLength(got length b'', 0 bytes read))

.venv/lib/python3.8/site-packages/urllib3/response.py:458: ProtocolError
```

The issue is that `Transfer-Encoding` is being returned from some of the Flask APIs (Lambda DELETE operations that return a 204 status), which newer versions of `urllib3` cannot handle.

Was doing a quick search across recent changes in `urllib3`/`flask`/`hypercorn` to find out where this new behavior got introduced, but couldn't pinpoint the change so far.
 
The change to remove `Transfer-Encoding` seems safe in the general case, as 204 HTTP responses expect no content to be sent along with the response.",# Pin WerkzeugFixes #5773
186,"CP.41: Fix typo in code example
",# Fix typo in example
187,"[hotfix] fix sharded optim step and clip_grad_norm
Fix #1218 ",# [zero] optimize the backward function
188,"fix: support other regions for aws s3 storage
# Description

Support for other s3 regions in addition to default eu-west-2

Fixes # (issue)
Before: Users had to create buckets in the default regions
Now: Users can create their buckets in any region

## Type of Change

Please delete options that are not relevant.

- [ ] New feature (non-breaking change which adds functionality)
- [ ] This change requires a documentation update

# How Has This Been Tested?

- [ ] Added new notebook (that tests end-to-end)

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] My changes generate no new warnings
- [ ] I ran `make format; make lint` to appease the lint gods
",# Add region to MyMagicAI
189,"Set TQDM progress bar and state textinfo description
Set TQDM progress bar and state textinfo description for train textual inversion, hypernetwork, preprocess jobs
",# Update progress bar description
190,"rename PP-OCRv3 algorithm to SVTR_LCNet
att",# [PP-OCRv3] update config
191,"Improve classification comments


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhancement of documentation and examples for the Ultralytics YOLOv5 classification models.

### 📊 Key Changes
- Updated training checkpoint details, now including `weight_decay` parameter.
- Transitioned from showcasing the validation of the YOLOv5s-cls model to the YOLOv5m-cls model on the ImageNet-1k dataset.
- Predict section now suggests using the pretrained YOLOv5s-cls model to predict a single image (`bus.jpg`).
- Clarified the `Export` section by specifying the export of YOLOv5s-cls, ResNet, and EfficientNet models.
- Various documentation updates across the `classify` sub-module for clarity and consistency in instructions.

### 🎯 Purpose & Impact
- The added `weight_decay` parameter in documentation helps users understand model training configurations better.
- Highlighting the YOLOv5m-cls model provides insights into using a different category of pre-trained weights, possibly indicating a more robust or accurate model.
- Clarified examples make it easier for users to follow how to run individual tasks such as validating, predicting, and exporting models.
- The changes can lead to better user adoption and efficient usage of the YOLOv5 classification models, spreading knowledge on how to engage with the classification aspect of the Ultralytics ecosystem. 🚀",# Update README.md and README_cn.md
192,"Allow user to override sudo as root authorization method [minor revision requested]
This is a followup on pull request #1558 and offers the user the option to preset the SUDO environment variable to override automatic detection of whether sudo, su or nothing (i.e. already root) should be used.

The reason is that not everyone (e.g. me) may have sudo rights installed, even if sudo is present.
",# Allow to override auto-detection of root authorization mechanism
193,"Make PR template a checklist and suggest mypy
Suggesting people use `mypy` here came out of our most recent postmortem: https://docs.google.com/document/d/1CDFazf8MfHa5NA4BxrU0mLMrg1TD03TDdg8cO1Kjb8w/edit?usp=sharing

Also suggesting this in https://certbot.eff.org/docs/contributing.html#mypy-type-annotations is ~~coming in another PR~~ in https://github.com/certbot/certbot/pull/7224.",# Add checklist to pull request template
194,"[bibeltv] new implementation
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

ADD DESCRIPTION HERE

As brightcove support seems to be dropped, this extractor is now implemented by using webpage and JSON API extraction.
Added support for live stream and series as playlist (with tescases).

Note: 
- The site has some DRM protected content, this will be signaled when trying to download.
- Not sure if the auth-token is universally usable and how long it's valid


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

</details>
",# [bibeltv] refactor and add support for series and live streams
195,"[AIRFLOW-XXX] Group references in one section
Preview is available: http://frantic-station.surge.sh/ (10 Aug 2019, 15:26 CEST)

---

Make sure you have checked _all_ steps below.

### Jira

- [ ] My PR addresses the following [Airflow Jira](https://issues.apache.org/jira/browse/AIRFLOW/) issues and references them in the PR title. For example, ""\[AIRFLOW-XXX\] My Airflow PR""
  - https://issues.apache.org/jira/browse/AIRFLOW-XXX
  - In case you are fixing a typo in the documentation you can prepend your commit with \[AIRFLOW-XXX\], code changes always need a Jira issue.
  - In case you are proposing a fundamental code change, you need to create an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)).
  - In case you are adding a dependency, check if the license complies with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).

### Description

- [ ] Here are some details about my PR, including screenshots of any UI changes:

### Tests

- [ ] My PR adds the following unit tests __OR__ does not need testing for this extremely good reason:

### Commits

- [ ] My commits all reference Jira issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)"":
  1. Subject is separated from body by a blank line
  1. Subject is limited to 50 characters (not including Jira issue reference)
  1. Subject does not end with a period
  1. Subject uses the imperative mood (""add"", not ""adding"")
  1. Body wraps at 72 characters
  1. Body explains ""what"" and ""why"", not ""how""

### Documentation

- [ ] In case of new functionality, my PR adds documentation that describes how to use it.
  - All the public functions and the classes in the PR contain docstrings that explain what it does
  - If you implement backwards incompatible changes, please leave a note in the [Updating.md](https://github.com/apache/airflow/blob/master/UPDATING.md) so we can assign it to a appropriate release

### Code Quality

- [ ] Passes `flake8`
",# [AIRFLOW-1111] Reorganize documentation
196,"fix(ui): Add more whitespace to options in roleSelectControl
### Before

<img width=""394"" alt=""pr1-2"" src=""https://user-images.githubusercontent.com/1748388/163039161-d7cfc417-4043-4f3e-9d12-58c55219cbe2.png"">

### After 

<img width=""449"" alt=""pr1-1"" src=""https://user-images.githubusercontent.com/1748388/163039149-beaa0bc7-b5e6-4dc3-b5d8-c554d4663584.png"">

",# Add margin to role select control
197," Fixed model_worker generate_gate may blocked main thread (#2540)
<!-- Thank you for your contribution! -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number (if applicable)
Closes #2540
<!-- For example: ""Closes #1234"" -->

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).
",# fix: use asyncio.to_thread to ensure worker.generate_gate is executed in the main thread
198,"Update Where Are My Certs section.
This combines the `cert.pem` and `chain.pem` sections into a single paragraph,
making it clearer that they are closely connected. It also adds text indicating
that they are less common and moves them below the section for `fullchain.pem`.

Also update Getting Help to emphasize forums, and fix Nginx capitalization.
",# Update using.rst
199,"[downloader/ffmpeg] Accept output args from info dict
Needed for #9158


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)

### What is the purpose of your *pull request*?
- [x] Core bug fix/improvement

</details>
",# Add support for output arguments in ffmpeg downloaderFixes #1595
200,"Add BC Ferries API
<!-- Thank you for taking the time to work on a Pull Request for this project! -->
<!-- To ensure your PR is dealt with swiftly please check the following: -->
- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added BC Ferries API
201,"[3.12] gh-86650: Fix IndexError when parse emails with invalid Message-ID (GH-117934)
In particularly, one-off addresses generated by Microsoft Outlook:
https://learn.microsoft.com/en-us/office/client-developer/outlook/mapi/one-off-addresses

(cherry picked from commit f74e51229c83e3265f905dc15283bfe0ec1a659e)

Co-authored-by: Serhiy Storchaka <storchaka@gmail.com>
Co-authored-by: fsc-eriker <72394365+fsc-eriker@users.noreply.github.com>

<!-- gh-issue-number: gh-86650 -->
* Issue: gh-86650
<!-- /gh-issue-number -->
",
202,"[vimeo] Fix error parsing
Example video that fails - https://vimeo.com/109815029
",# [vimeo] fix extraction of config JSON
203,"PlotJuggler: add control gains to longitudinal layout
",# Add longitudinal control plots to plotjuggler
204,"Add PyTorch-NLP
## What is this Python project?

PyTorch-NLP is a toolkit for NLP research built on PyTorch, an up and coming deep learning library. It is also trending on https://github.com/trending/python! 

## What's the difference between this Python project and similar ones?

### [torchtext](https://github.com/pytorch/text)

torchtext and PyTorch-NLP differ in the architecture and feature set; otherwise, they are similar. torchtext and PyTorch-NLP provide pre-trained word vectors, datasets, iterators and text encoders. PyTorch-NLP also provides neural network modules and metrics. From an architecture standpoint, torchtext is object orientated with external coupling while PyTorch-NLP is object orientated with low coupling.

### [AllenNLP](https://github.com/pytorch/text)

AllenNLP is designed to be a platform for research. PyTorch-NLP is designed to be a lightweight toolkit.

--

Anyone who agrees with this pull request could vote for it by adding a :+1: to it, and usually, the maintainer will merge it when votes reach **20**.
",# Add PyTorch-NLP
205,"Allow hyphens in pod id used by k8s executor
Makes things more readable.  E.g. my-dag-my-task instead of mydagmytask.
",# [AIRFLOW-1111] Fix kubernetes pod name generationFixes #1111
206,"Remove commas in filename
This will immediately address the breakage reported in #6682 and tracked at #6685. Pip 19.0.0 and 19.0.1 don't allow commas in filenames, so don't use commas in filenames in certbot-apache test code.

I've confirmed that this fixes the issue on a machine that fails with the version of certbot-auto currently in master: recent version of virtualenv, python 2.7.

Steps to test:
- push master to test box
- run tools/venv.py
- activate venv
- pip --version: 19.0.1
- pip install ./certbot-apache/: fails
- push branch code to test box
- confirm pip --version still 19.0.1
- pip install ./certbot-apache/: success","# Rename old,default.conf to old-and-default.confFixes #6308."
207,"Add documentation for 'subset' and interpolation' arguments (ImageDataGenerator)
Methods flow (subset) and flow_from_directory (subset + interpolation) are currently missing it.",# Add support for interpolation in flow_from_directory
208,"Toyota: remove bad FW
Similar to https://github.com/commaai/openpilot/pull/28526

Added in https://github.com/commaai/openpilot/commit/bfa2d030d2927cb9cfdb01f8f1e614d3790d134b as part of a FW dump, likely a mistake. This FW should only be on the TSS-P Corolla.

Noticed when looking at shared part numbers, not having the length code (which usually means it's from the KWP query) is not common for TSS2 vehicles.",# Toyota: remove duplicate firmware value
209,"fix all b904s
",# Fix #2085
210,"Support LLaVA-LLaMA-2
**This is a PR in progress, please do not merge it yet.**

I am the author of LLaVA, and we have recently supported LLaMA-2, and will release more checkpoints this coming week. We are working on the integration of LLaVA-LLaMA-2 to `textgen-ui`.

This PR includes the initial support for the released checkpoint [LLaVA-LLaMA-2-13B-Chat-Preview](https://huggingface.co/liuhaotian/llava-llama-2-13b-chat-lightning-preview).

Command to run this checkpoint:
First download the checkpoints of [`llava-llama-2-13b-chat-lightning-4bit-128g`](https://huggingface.co/liuhaotian/llava-llama-2-13b-chat-lightning-gptq) to `models` folder under the cloned textgen-ui folder.
```Shell
python server.py \
    --chat \
    --model-dir models \
    --model llava-llama-2-13b-chat-lightning-4bit-128g \
    --multimodal-pipeline llava-llama-2-13b
```

TODO:

- [x] Currently it seems that exllama is not compatible with multimodal extension. I'll submit an issue about this.
- [x] More checkpoints will be added soon, and I'll make sure that all necessary pipelines are added before we merge the PR. (some new checkpoints involve a slight architecture change, will be addressed in a separate PR)

Screenshot
<img width=""811"" alt=""Screen Shot 2023-07-30 at 11 16 12 PM"" src=""https://github.com/oobabooga/text-generation-webui/assets/6631389/ab370bdd-b347-462b-99ae-fa5e92a7233e"">
",# Add LLaMA 2.13B LLava pipeline
211,"MAINT Python 3.9 in badge on README.rst
",# [MRG+1] Update README.rst
212,"Add HeroesWearMasks project
Add the HeroesWearMasks (https://heroeswearmasks.fun/) demo to the list.",# Add Heroes Wear Masks
213,"[4.2.x] Refs #34483 -- Fixed utils_tests.test_timesince crash on Python 3.8.
",# Fixed #28613 -- Fixed test_timesince.py for Python 3.7.
214,"switch signature verification to use pure cryptography
On systems that prevent write/execute pages this prevents a segfault that is caused by pyopenssl creating a dynamic callback in the verification helper.",# Support ECDSA signaturesFixes #4444
215,"MRG Fix dict learning random seeds and error message error
Fixes #1621.
Both the actual error and the randomness of the tests.
I think I picked the right alpha but maybe someone who is familiar with the code can confirm.
",# [MRG] Fix random_state in dictionary learning tests
216,"Fixed typo in README.md
asyncronously -> asynchronously",# Fix typo in README.md
217,"Update zero_to_fp32.py - to support deepspeed_stage_1
Since deepspeed 1 checkpoint structure is identical to deepspeed 2 (AFAIK), we should just change the stage check and add support accordingly

However I am not 100% sure if this is intentional by design, or some coincidence in my use case - so might need someone with more knowledge on this topic to weigh in 🤔",# [zero_to_fp32] support zero1
218,"Replace from file through replacement editor #1458
Replacement file can be specified from replacement editor. 
I think this kind of defeats the purpose of `--replace-from-file` though, because now a user can also do `--replace :~q:foo:file://<filepath>` 
Should this only be allowed in replacement editor and not from `--replace` ?",# Remove `ReplaceFile` and `replacement_files` option
219,"use DefaultAzureCredential if login not provided for Data Factory
closes: #19077 

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/main/UPDATING.md).
",# [AIRFLOW-1111] Azure Data Factory: fallback on DefaultAzureCredential
220,"Add title to the API workflow json.

Add title to the API workflow json.

Motivation: API client users can find nodes by title, instead of just by class_type.

Related 
* [[Feature Request] Custom API node IDs #1326](https://github.com/comfyanonymous/ComfyUI/issues/1326)
* [[Feature Request] Save json with title label value in API mode. #1433](https://github.com/comfyanonymous/ComfyUI/issues/1433)
* [custom names for nodes in API export #2031](https://github.com/comfyanonymous/ComfyUI/issues/2031)

",# Add title to node output
221,"Add libffi-dev to installation
libffi-dev is required by Cryptography which is the base of PyOpenSSL (I think). (Standalone-Authenticator currently uses PyOpenSSL.)

Since Cryptography seems to be the way forward #164. I don't think we should have too many qualms about adding it to the list of dependencies.

The setup of a new venv crashes otherwise.
",# Add libffi-dev to Ubuntu install instructionsFixes #1111
222,"Fix url French Address Search API
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Update French Address Search APIThe French Address Search API has been moved to a new domain.
223,"Add generic support for mpd manifests(dash formats)
the implementation is based on the information from the ISO/IEC 23009-1:2014.
i added support for vevo.
it can also the segments from kaltura and bbc and concatenate the audio segments.
but there is a problem with video concatenation:
for bbc ffmpeg complain about an unsupported codec.
and for kaltura it said: `could not find corresponding track id 1`
",# [dash] Extract MPD formats
224,"Remove duplicate comment.
",# Remove commented out config
225,"[options] Add --legacy-server-connect
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [ ] New extractor
- [x] New feature

---

### Description of your *pull request* and other information

In preparation for near-future release of OpenSSL 3.0.0 that disables legacy_server_connect by default. For example, Niconico videos will become not downloadable without this option because https://api.dmc.nico/ is a legacy server that does not support RFC 5746 secure renegotiation.",# Add --legacy-server-connect optionFixes #1590
226,"Added comments
",# Update Binary_search.py
227,"Use triton==2.0.0
",# Remove triton version check
228,"[Minor] code style improvements
Add some default parameters ",# Add AWQ support
229,"[democracynow] Update test
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature",# [democracynow] fix info dict
230,"Add missing FW for 2019 Civic EX
Generated for discord user jfire",# Honda: add AH20 transmission
231,"Clarify docs that Requests always uses certs from certifi
Since commit 0d7de6430eef0cf09f9662746daf0c28d83f144e, certifi is always used for certificates. Certify became a hard dependency of the package in 628633143d5b8590b1dbdf5371fe81fb8250dffd.

Now update the docs to clarify that Request will always use certificates from certifi.",# Update advanced.rst
232,"Update and answer devops questions
",# Added more commands
233,"Fan error message
I get a lot of support requests on this.  Added a bit more explicit info into the error message to remove that challenge.",# Update fan.py
234,"fix custom preset selection
",# Fix preset name in config drawer
235,"ref: upgrade attrs
this is a dependency to upgrading openapi

<!-- Describe your PR here. -->",# Update attrs
236,"Fixed download.py (Empty file downloads, encoding errors)
Fixed the following errors -
1. Python defaulting to ASCII encoding instead of Unicode.
Set global encoding to 'utf-8'
2. Script downloading 0kb empty FILE objects.
Some filenames being generated contained "":"", which is a restricted
character in filenames on Windows and MacOS and was truncating filenames
before the extension, added to the replacements list in clean_text.
3.  Download failures.
Used the requests library to improve success rates of downloads, which
seemed to work a bit better.",# Update download.py
237,"[#2077] Possbility to revert message deletion
Hello, here is the PR for that feature ! 

On the web side I've added a button when a message is deleted in the context menu : 
![image](https://user-images.githubusercontent.com/12647984/225399397-34c51336-8e52-4485-9726-60f0659e845b.png)

Also added that feature to the messages board :
![image](https://user-images.githubusercontent.com/12647984/225399584-b63a5e3c-09cd-431d-91a6-5897b0caae95.png)

With a warning message on reintroduction : 
![image](https://user-images.githubusercontent.com/12647984/225399750-4b46f418-91b1-4f49-8358-11aae2d317fc.png)

Might need to still do the translation part, however I don't see any ""admin"" local :/ 


Original issue : https://github.com/LAION-AI/Open-Assistant/issues/2077",# Add undelete message feature
238,"Add py.typed stub as per PEP-561
This marks the package as annotated to allow it's types to be inferred by [mypy][1] when used as a library some another application. More details about this in [PEP-561][2].

Without this, running mypy on some code that uses mitmproxy returns these errors:
```python
test_stubs.py:1: error: Cannot find implementation or library stub for module named 'mitmproxy'
test_stubs.py:2: error: Cannot find implementation or library stub for module named 'mitmproxy.net.http'
test_stubs.py:3: error: Cannot find implementation or library stub for module named 'mitmproxy.utils'
```

Once I added this to the package and installed the latest dev version, the errors are removed. Unfortunately, in some other modules I see these errors:

```python
/Users/pavel.savchenko/.virtualenvs/stub_test/lib/python3.6/site-packages/mitmproxy/optmanager.py:11: error: Cannot find implementation or library stub for module named 'ruamel'
```

This seems to be an issue with ruamel's namespace structure (I'm not sure what is the issue, but I tried to file a ruamel.yaml ticked [here][3])

[1]: https://mypy.readthedocs.io/en/latest/installed_packages.html#making-pep-561-compatible-packages
[2]: https://www.python.org/dev/peps/pep-0561/
[3]: https://bitbucket.org/ruamel/yaml/issues/328/mypy-complains-that-ruamel-is-missing-type",# Add py.typed file
239,"Update the link of the Chinese Ver. Docs
The old shaders branch is deprecated in CN Ver. Documentation. ",# Update index.rst
240,"fix: typo
",# Fix #1115
241,"Remove API Only
Site returns a ""welcome to nginx"" page
",# Remove API Only
242,"[MRG+1] fix P/R/F for truncated range(n_labels)
#### What does this implement/fix? Explain your changes.

Fixes https://github.com/scikit-learn/scikit-learn/issues/10307

for ex. if n_labels = 5, then passing labels = [0, 1, 2]
will give results similar to labels = [0, 1, 2, 3, 4], neglecting
the value of labels.

Currently in master branch:
```python
>>> y_true = np.array([[0, 1, 1], [1, 0, 0]])
>>> y_pred = np.array([[1, 1, 1], [1, 0, 1]])
>>> precision_recall_fscore_support(y_true, y_pred, average='samples', labels=[0, 1])
(0.58333333333333326, 1.0, 0.73333333333333339, None)
>>> precision_recall_fscore_support(y_true, y_pred, average='samples', labels=[1, 0])
(0.75, 1.0, 0.83333333333333326, None)
```

I'm not sure if this will require any changes to test_common, since labels=[0, 1] and labels=[1, 0] should give the same result for `average='samples'` (atleast for `average='samples'`, haven't thought about other averages), this is similar to commutative property w.r.t. `labels`.",# DOC Fix bug in precision_recall_fscore_supportFixes #10377
243,"Code to perform google search from terminal
The script is used to search for a keyword in google from the terminal. Top x (say 5) web pages will be displayed in separate tabs in the browser.",# Added Google Search Script
244,"Quora api requests robustness.
Found that the bottle-neck function of the quora api module may become an issue in some cases, hence slightly modified this method adding delay and logging to be more robust. 

Also added some tests to cover several different scenarios.

Seems that there are very few tests in the projects, so it may become quite useful in the future with recent issues. ",# Add retry mechanism to quora api
245,"handle NoneType when subseed is not initialized
",# fix subseed None
246,"Update README.md
Fixed the route for the WINDOWS_README.md file.",# Fix README.md
247,"Fix onnx model replay
<!-- Please copy and paste the relevant template -->

<!--- ***** Template: Car bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

**Route**
Route: [a route with the bug fix]

-->

<!--- ***** Template: Bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

-->

<!--- ***** Template: Car port *****

**Checklist**
- [ ] added entry to CarInfo in selfdrive/car/*/values.py and ran `selfdrive/car/docs.py` to generate new docs
- [ ] test route added to [routes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/car/tests/routes.py)
- [ ] route with openpilot:
- [ ] route with stock system:

-->

<!--- ***** Template: Refactor *****

**Description** [](A description of the refactor, including the goals it accomplishes.)

**Verification** [](Explain how you tested the refactor for regressions.)

-->
",# model replay onnx
248,"Fix NumberLine's unit_size
<!-- Thanks for contributing to manim!
    Please ensure that your pull request works with the latest version of manim.
-->

## Motivation
<!-- Outline your motivation: In what way do your changes improve the library? -->
Minor bugs concerning `unit_size` of `NumberLine`. 

1. The `get_unit_size` method 
https://github.com/3b1b/manim/blob/66817c4e2bc56f45f370498c2c93b033c1109951/manimlib/mobject/number_line.py#L125-L126 should return `self.get_length() / (self.x_max - self.x_min)`, not `(self.x_max - self.x_min) / self.get_length()`

2. If `width` is passed as an argument, the `unit_size` attribute (available via `CONFIG`) still remains 1 when it should be reset to appropriate value.
## Proposed changes
<!-- What you changed in those files -->
1. Fix the return value of `get_unit_size` method.
2. Reset the value of `unit_size` attribute if `width` is passed.  
",# Fix bug in NumberLine
249,"update dockerfile, add flag for high quality rendering
The dockerfile now installs manim directly into the container, so there is no need to bind mount the library when running it. That said, you will still have to bind mount the places to read the source and write the video.
1080p rendering is now possible by passing the `--high_quality` flag, and I changed the 1080p frame rate from 30fps to 60fps.",# Add high quality rendering
250,"Better local messaging
### Describe the changes you have made:

### Reference any relevant issues (e.g. ""Fixes #000""):

### Pre-Submission Checklist (optional but appreciated):

- [ ] I have included relevant documentation updates (stored in /docs)
- [ ] I have read `docs/CONTRIBUTING.md`
- [ ] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [ ] Tested on MacOS
- [ ] Tested on Linux
",# Update local profile
251,"rename docker compose to docker-compose
Docker compose is a separate binary called `docker-compose` and is not a command of `docker` itself.",# Update README.md
252,"[cli] added check installation cli
Added a CLI to check if Colossal-AI is built correctly.

Sample output for `colossalai check --help`
<img width=""537"" alt=""Screenshot 2022-04-20 at 12 07 57 PM"" src=""https://user-images.githubusercontent.com/31818963/164148537-41ed79f4-bb3a-4261-9df9-621d9f5b86f6.png"">

Sample output for `colossalai check -i`
<img width=""385"" alt=""Screenshot 2022-04-20 at 12 12 30 PM"" src=""https://user-images.githubusercontent.com/31818963/164149011-fd621da3-bb91-4511-8077-4e8efe31a30a.png"">
",# [cli] add check command
253,"Have UploadedFileManager react client fetch and use upload URLs
",# FileUploader: Use the new file upload URL and delete URL fields
254,"Add ~Zy~ to /website/src/data/team.json 
",# Add ~Zy~ to the moderation team
255,"bpo-36253: Remove use after free reference in ctypes test suite
Removes invalid reference to freed memory in ctypes test case.

Once buf is deleted and freed r becomes a dangling pointer, further use requires reading from freed memory.

Bug found using asan, full details and stack trace attached in the bug tracker.

<!-- issue-number: [bpo-36253](https://bugs.python.org/issue36253) -->
https://bugs.python.org/issue36253
<!-- /issue-number -->
",# bpo-39498: Fix ctypes test test_stringptr.py
256,"Update tokenizer.py
",# Update pat_str
257,"Fixes Azure gpt-35-turbo model not recognized 
# Description

Fixes problem where the Azure OpenAI models are not recognized when building VectorStoreIndex.  Added AZURE_TURBO_MODELS definition to ALL_AVAILABLE_MODELS

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)

# How Has This Been Tested?

Ran example from https://gpt-index.readthedocs.io/en/latest/examples/customization/llms/AzureOpenAI.html

# Suggested Checklist:

- [x] I have performed a self-review of my own code
- [x] My changes generate no new warnings
",# Add Azure Turbo models to OpenAI models
258,"Fix logging not handling onChange
This meant when the setting value was changed from its default by the settings loading, it was not reacting to the change.

I've also had a quick check of all other settings and they all appear correct.",# Update logging.js
259,"Fix loading of legacy states for gym.spaces.space:Space
CC: https://github.com/DLR-RM/stable-baselines3/issues/573",# Add support for legacy state picklingThis PR adds support for legacy state pickling in the gym spaces module.
260,"Skip `OpenAIWhisperParser` extremely small audio chunks to avoid api error
**Description**
This PR addresses a rare issue in `OpenAIWhisperParser` that causes it to crash when processing an audio file with a duration very close to the class's chunk size threshold of 20 minutes.

**Issue**
#11449

**Dependencies**
None

**Tag maintainer**
@agola11 @eyurtsev 

**Twitter handle**
leonardodiegues
",# Add chunk duration threshold to OpenAIWhisperParser
261,"Fix Wrapper ResizeObservation: Support list type shape
If you input the shape as a list to `ResizeObservation`, there will be an error:
```
TypeError: can only concatenate list (not ""tuple"") to list
```
Related to https://github.com/openai/gym/pull/1487 and these lines of code:
https://github.com/openai/gym/blob/220ae8487d9436fba0322b18bcb0402790c25335/gym/wrappers/resize_observation.py#L14-L16",# Fix bug in ResizeObservation
262,"tolerating missing optimizer states for MoE [2nd attempt]
Fixes #2737

When `load_optimizer_states=False` is used for MoE `load_checkpoint` - do not attempt to load the optimizer state files.

This currently fails as DeepSpeed still attempts to load those, even though they are not used afterwards.

Previous attempt: https://github.com/microsoft/DeepSpeed/pull/2738",# [Moe] Fix load optimizer state for moe
263,"[AIRFLOW-5368] Display DAG from the CLI
I always feel frustrated when I can't see what the DAG I created looks like. I can only preview how it looks in the webserver. However, the webserver requires a separate configuration for proper works and slowly refreshes the views. Adding the ability to display DAG from the CLI level will improve my workflow and allow me to prepare sample DAGs for system tests faster.

<img width=""1190"" alt=""Screenshot 2019-09-02 at 00 31 45"" src=""https://user-images.githubusercontent.com/12058428/64083103-e0befc00-cd19-11e9-9a42-8df2ab89e0fe.png"">

It can also be useful to other people if they want to generate documentation for DAGs. They can easily generate graphics that can be attached to the documentation.

Make sure you have checked _all_ steps below.

### Jira

- [ ] My PR addresses the following [Airflow Jira](https://issues.apache.org/jira/browse/AIRFLOW/) issues and references them in the PR title. For example, ""\[AIRFLOW-XXX\] My Airflow PR""
  - https://issues.apache.org/jira/browse/AIRFLOW-5368
  - In case you are fixing a typo in the documentation you can prepend your commit with \[AIRFLOW-XXX\], code changes always need a Jira issue.
  - In case you are proposing a fundamental code change, you need to create an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)).
  - In case you are adding a dependency, check if the license complies with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).

### Description

- [ ] Here are some details about my PR, including screenshots of any UI changes:

### Tests

- [ ] My PR adds the following unit tests __OR__ does not need testing for this extremely good reason:

### Commits

- [ ] My commits all reference Jira issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)"":
  1. Subject is separated from body by a blank line
  1. Subject is limited to 50 characters (not including Jira issue reference)
  1. Subject does not end with a period
  1. Subject uses the imperative mood (""add"", not ""adding"")
  1. Body wraps at 72 characters
  1. Body explains ""what"" and ""why"", not ""how""

### Documentation

- [ ] In case of new functionality, my PR adds documentation that describes how to use it.
  - All the public functions and the classes in the PR contain docstrings that explain what it does
  - If you implement backwards incompatible changes, please leave a note in the [Updating.md](https://github.com/apache/airflow/blob/master/UPDATING.md) so we can assign it to a appropriate release

### Code Quality

- [ ] Passes `flake8`
",# [AIRFLOW-1111] Add DAG rendering
264,"make agent action serializable
",# Update schema
265,"Squashed snap build
This PR is the squashed version of https://github.com/certbot/certbot/pull/7932.

### Checklist to merge this PR

- [ ] Merge it, don't squash it
- [ ] Add the PR description from https://github.com/certbot/certbot/pull/7932 to the merge commit.

(I can do the actual merge if you want.)

I've completed the checklist from https://github.com/certbot/certbot/pull/7932 and there is no diff between this branch and that one.",# Snap CI
266,"try fix colab
",# fix bug
267,"Renewer integration tests, quickfixes
Fixes `IOError: [Errno 2] No such file or directory: '/tmp/le/config/archive/renewer/privkey2.pem'`

With this patch I was able to successfully renew my certificates, @schoen! :)

Unfortunately, renewer didn't update `live` directory symlinks... :(
",# Renewer: fix #1115
268,"route53: re-use boto3 client in wait
This change re-uses the boto3 client in the wait method of the route53 authenticator in order to make it more mock-able for testing purposes.

I'm posting this change in a separate PR since I'm still learning how this class works and this refactoring may have non-obvious/unexpected side effects.

Part of #4688.",# Use self.r53 instead of boto3.client
269,"Add Nervana ""Neon Course"" to Python notebooks
Nervana Neon course materials
",# Add Neon Course
270,"Fix Redirect Verification
Closes #1620.
",# Apache: Add support for Apache 2.3.9 and aboveApache 2.3.9 and above has a new rewrite rule argument that is not supported by the current version of the Apache rewrite module. This PR adds support for this new argument.
271,"[VITS] Fix nightly tests
# What does this PR do?

Fixes the tokenizer integration test and multi-GPU test that failed on the nightly run: https://github.com/huggingface/transformers/actions/runs/6068405445/job/16461410319

The tokenizer fix is trivial (needed to update the commit ID)!

The multi-GPU test was failing because the output sequence length for VITS is a function of the model **inputs**, rather than being a function of the input **sequence lengths** only.

Let's say we have 2 GPUs over which we want to run DP:
* GPU 1 outputs a sequence length of `N`, which is computed based on the input in the first element of the batch `x`
* GPU 2 outputs a sequence length of `M`, which is computed based on the input in the second element of the batch `y`

=> there is nothing to enforce that `N = M`, since the VITS output sequence length is a function of the inputs. Thus, we cannot concatenate the inputs after running the forward pass, since they have different dims. 

```python
# pseudo code for data parallelism
input_1, input_2 = torch.split(input, 2, dim=0)

output_1 = model(input_1) 
output_2 = model(input_2)

output = torch.concatenate([output_1, output_2], dim=0)  # breaks because input_1 and input_2 have different sequence lengths
```

The fix for the test is to pass the same inputs to both GPUs, and disable the stochastic duration predictor. This way, we get consistent outputs across our GPUs.",# [VITS] Add multi-gpu test for VITS
272,"[No merge] TF integration testing
Adds integrationt tests for BERT, ELECTRA and Longformer to ensure that PR such as https://github.com/huggingface/transformers/pull/7605 do not impact the current state of models. RoBERTa not done because it's already done.

Patches a bug with the `ElectraForPreTraining` when batch size = 1",# [TF] Add integration tests for TF models
273,"Docs: Predibase Integration
This PR adds the Predibase Integration to the Llamaindex docs under the LLM section. Screenshots below: 

<img width=""1036"" alt=""Screen Shot 2023-08-01 at 4 56 32 PM"" src=""https://github.com/jerryjliu/llama_index/assets/32989166/b84297dc-49e8-45ab-8555-8525a60b0cf0"">


<img width=""1321"" alt=""Screen Shot 2023-08-01 at 4 56 44 PM"" src=""https://github.com/jerryjliu/llama_index/assets/32989166/6eeb6418-078a-4a12-b180-d5f6ca1c95fa"">

",# Add Predibase LLM example
274,"Removed obsolete django.test.utils.strip_quotes().
Django's test runners no longer discover doctests.",# Removed strip_quotes() from test.utils
275,"Warn about tool use
This PR adds additional warnings when using tools through the `from_hub` and `load_tool` methods to explicitly mention that this loads tools defined remotely.

This is done in addition to:
- the existing disclaimers within the runtime mentioning that you're downloading new files that you really should inspect
- the python method and class names which are already indicative of remote downloads",# [docs] Add warning when loading a tool from the Hub
276,"sync
",# fix taesd decoder path
277,"Update README.md
Update Android repo link

### Describe the changes you have made:
New URL because someone had to be difficult and change his username 

### Reference any relevant issues (e.g. ""Fixes #000""):

### Pre-Submission Checklist (optional but appreciated):

- [ ] I have included relevant documentation updates (stored in /docs)
- [ ] I have read `docs/CONTRIBUTING.md`
- [ ] I have read `docs/ROADMAP.md`

### OS Tests (optional but appreciated):

- [ ] Tested on Windows
- [ ] Tested on MacOS
- [ ] Tested on Linux
",# Update README.md
278,"BUG: merge between partial index and index fails when result is empty
- [x] closes #33814
- [x] tests added / passed
- [x] passes `black pandas`
- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [x] whatsnew entry

The Issue was caused when setting the name of an numpy array.","# BUG: Fix bug in merge when performing an inner join with partial index and right_index- [x] closes #33814- [x] tests added / passed- [x] passes `black pandas`- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`- [x] whatsnew entry"
279,"bump 308
",# bump version
280,"Add coverage for Blueprint.add_app_template_global
This tests the `Blueprint.add_app_template_global` mothod, which internally
calls the `Blueprint.app_template_global` method. The methods are used to
registering a function to the jinja template environment.
This PR increases the test coverage for module `flask.blueprint` by 4%.",# Add test for `app_template_global`
281,"ES.23: change example code to better match the rule
The example suggests that `int z = gsl::narrow_cast<int>(7.9);;` is OK. The rule says ""Use `=` only when you are sure that there can be no narrowing conversions."", which matches, but is also says ""For built-in arithmetic types, use `=` only with `auto`."", and this is not respected here. So replace the one line with both possibilities suggested by the rule.
",# Fix example in C.128
282,"Add PyTorch-only benchmark arg
Usage:
```
python utils/benchmarks.py --weights yolov5s.pt --img 640 --pt-only
```

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Added option to benchmark PyTorch models exclusively.

### 📊 Key Changes
- New argument `pt_only` added to the benchmarking utility.
- The benchmarking process can be terminated early after testing PyTorch if `pt_only` is set.
- CLI now accepts `--pt-only` as an option to enable this new feature.

### 🎯 Purpose & Impact
- 🎯 **Purpose**: Simplifies benchmarking for users who only want to test the performance of PyTorch models without completing benchmarks for other export formats.
- ✅ **Impact**: Users can save time and resources during benchmarking when only PyTorch model performance is of interest, making the process more efficient and tailored to specific needs.",# Add --pt-only flag to benchmarks
283,"Add `httpie cli plugins` in favor of the new cli namespace.
This PR moves `httpie plugins` command from the top level namespace to `cli` namespace, as `httpie cli plugins`. The `httpie plugins` is just a basic alias to the `httpie cli plugins` which we discourage and don't mention in our documentation. 

Also as discussed, the `httpie.manager.tasks` is now a package that contains each task as a submodule.",# Refactor plugins cli namespace
284,"fix: add render_mode getter to Wrapper
Currently, wrapped environments don't forward correctly the attribute `render_mode`.
This PR fixes this; thanks @Markus28 for spotting this",# Add render_mode property
285,"FIX take into account mask in the ordering in grid_to_graph
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist
-->

#### Reference Issues/PRs
Fixes #18963


#### What does this implement/fix? Explain your changes.
In `grid_to_graph` , index the vertices according to mask structure, not their occurrence in edge matrix.

#### Any other comments?


<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# DOC: add a note about the bug fix in image._to_graph
286,"fix: stop overwriting boolean config values
### Describe the changes you have made:

Without the default set to `None`, any boolean CLI flag that isn't passed manually via `-` or `--` reverts to its`False` even if it is configured in the `config.yaml` file.

### Reference any relevant issue (Fixes #507 )

- [x] I have performed a self-review of my code:

### I have tested the code on the following OS:
- [ ] Windows
- [x] MacOS
- [ ] Linux

### AI Language Model (if applicable)
- [ ] GPT4
- [ ] GPT3
- [ ] Llama 7B
- [ ] Llama 13B
- [ ] Llama 34B
- [ ] Huggingface model (Please specify which one)
",# Fix cli default value
287,"Add Mockaroo API to Test Data
Add Mockaroo API to Test Data.

- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not have more than 100 characters
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit
",# Add Mockaroo API
288,"Fix wrong prompt issue for network modules (#32426)


##### SUMMARY
<!--- Describe the change, including rationale and design decisions -->
* Fix wrong prompt issue for network modules

Fixes #31161
Fixes #32416

*  Store the device prompt in case of error
   from the remote device
*  Check for prompt value in ios action plugin

*  Add integration test
*  Update Changelog

(cherry picked from commit 26583adb582fa3baae4497be4094d920c4771681)
<!---
If you are fixing an existing issue, please include ""Fixes #nnn"" in your
commit message and your description; but you should still explain what
the change does.
-->

##### ISSUE TYPE
<!--- Pick one below and delete the rest: -->

 - Bugfix Pull Request

##### COMPONENT NAME
<!--- Name of the module/plugin/module/task -->
action/ios.py
connection/network_cli.py
##### ANSIBLE VERSION
<!--- Paste verbatim output from ""ansible --version"" between quotes below -->
```
2.4
```


##### ADDITIONAL INFORMATION
<!---
Include additional information to help people understand the change here.
For bugs that don't have a linked bug report, a step-by-step reproduction
of the problem is helpful.
  -->

<!--- Paste verbatim command output below, e.g. before and after your change -->
```

```
",# Fix wrong prompt issue for network modulesFixes #32426
289,"Fix HAR validation for HAR viewer
Following the comment on #2618, I confirmed the errors are present. I've double-checked the specification and confirmed some of the properties are indeed required. I've added stubs for them which prevents the validation from complaining.",# Add timing data to HAR
290,"Protect alphas_cumprod during refiner switchover
## Description

* There is currently a bug, mentioned in #14978, where when the refiner switches on, the first step it performs uses the original alphas_cumprod schedule, which causes problems if zero SNR is enabled.
* This stores and re-applies the model alphas_cumprod when refiner switchover happens.  This fixes outputs in rare cases where the change in noise schedules is significant enough to change the called timestep to something outside of the range of the refiner.

## Screenshots/videos:
Before fix, image generated on DPM++ 2M, overridden with Karras schedule and sigma_max of 1500, 50 steps:
![99942-36463525-(best quality, high quality,_1 5) by strange-fox, solo, anthro, male, rat, manly, clothed, jacket, shirt, detailed background, n](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/1313496/faf03e8a-a750-4cae-a6c2-54941fe253e0)
This specific schedule causes one of the sampling steps to be changed from timestep 190 to timestep 200.  The highest timestep a typical refiner is trained for is 199 (last 200, zero indexed), so this is out of the range for the model and causes extra noise in the output.

After the fix is applied:
![99943-36463525-(best quality, high quality,_1 5) by strange-fox, solo, anthro, male, rat, manly, clothed, jacket, shirt, detailed background, n](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/1313496/ae5e3f7f-7f2f-48b2-99f9-f9806f831614)
The resulting image looks much cleaner (particularly the background at the top left).

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Apply alpha schedule override to all models
291,"Fixed #28127 -- Allowed UserCreationForm's password validation to check all user fields.
* UserCreationForm runs password validation against full user instance,
  checking all fields in the form, not just the username",# Fixed #31498 -- Fixed UserCreationForm password validation.
292,"Change ProxyServerError to ServerException in the docstring
Fixes #1122
",# Fix #2035
293,"Update README.md
This functions in both Mac OS 11, as well as Mac OS X.",# Update README.md
294,"[audius] add support for profile pages
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Explanation of your *pull request* in arbitrary form goes here. Please make sure the description explains the purpose and effect of your *pull request* and is worded well enough to be understood. Provide as much context and examples as possible.

---

This PR addresses [https://github.com/yt-dlp/yt-dlp/issues/315](https://github.com/yt-dlp/yt-dlp/issues/315), and allows for downloading straight from someone's Audius profile as a playlist.",# [audius] Add support for artist profiles
295,"Update README_ZH.md
Made the Chinese Translate better.

### Describe the changes you have made:

### Reference any relevant issue (Fixes #000)

- [ ] I have performed a self-review of my code:

### I have tested the code on the following OS:
- [ ] Windows
- [ ] MacOS
- [ ] Linux

### AI Language Model (if applicable)
- [ ] GPT4
- [ ] GPT3
- [ ] Llama 7B
- [ ] Llama 13B
- [ ] Llama 34B
- [ ] Huggingface model (Please specify which one)
",# Update README_ZH.md
296,"Update README.md - Fixed some minor grammatical issues.
Fixed some minor grammatical issues.",# Fix typos in README.md
297,"Syntax error Fixed : GptGo.py
",# Fix typo
298,"Fix stacking of pos/neg logits for RM compute_metrics
Node positive & negative examples are stacked along last dimension so that compute_metrics receives predictions of size (val_examles, 2). The old code did not work with deepspeed if the number of validation examples was not divisible by the total batch size without remainder.",# [vscode] add debug config for training
299,"fix(brew_unknown_command): make subprocess.check_output return str
Fix `TypeError: can't concat bytes to str` error on Python 3.4.
",# brew prefix
300,"Added Site - Binary Search
",# Added BinarySearch
301,"Add `user_config_dir('Ultralytics')`


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Implementation of user configuration directory for platform-specific settings and font management in YOLOv5.

### 📊 Key Changes
- Added a new `user_config_dir` function to create or return a user-specific configuration directory.
- Updated the `check_font` function to use the new user config directory for downloading missing fonts.

### 🎯 Purpose & Impact
- 🛠 **Enhances platform compatibility**: The user configuration path adapts to the operating system, improving functionality across Windows, Linux, and macOS.
- 🖌 **Improves font management**: Fonts are now managed in the user's configuration directory, making the process cleaner and less intrusive.
- 📈 **Potential user impact**: Both developers and users benefit from a neater installation with settings and resources stored in a dedicated, user-specific location, which can reduce permission issues and improve the overall user experience.",# Update plots.py
302,"fixes & improvements
- improve '#welcome'

- fix 'tls_relay_front_logging'",# fix tls relay log
303,"Fixed Typo in news.rst file
Typo fixed in docs/news.rst file:
correponding -> corresponding",# Fix typo in docs/news.rst
304,"Start testing 3.7
Given that 3.7 is [now in beta](https://twitter.com/gvanrossum/status/958930025603977216) and scheduled for release in ~4 months, we should probably start testing it again.

EDIT: As far as I can tell appveyor hasn't had support for 3.7 added yet, likely due to it being an alpha release. We'll want to add that later when it becomes available.",# Travis: fix 3.7-dev
305,"[trivial] Use proper test cases on `unittest`
",# Use `assertIn` instead of `assertTrue`
306,"[ie/youtube] Improve detection of faulty HLS formats
Per https://github.com/yt-dlp/yt-dlp/issues/7747#issuecomment-1814662735, we need to extend the lookback window by another day

Closes #7747


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

</details>
",# [youtube] Increase the threshold for newly uploaded videos' HLS formats
307,"added note about build essentials
added note about build essentials",# Add build-essential to WSL installation guide
308,"Prevent Synology Camera doing I/O in event loop
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Breaking change
<!--
  If your PR contains a breaking change for existing users, it is important
  to tell them what breaks, how to make it work again and why we did this.
  This piece of text is published with the release notes, so it helps if you
  write it towards our users, not us.
  Note: Remove this section if this PR is NOT a breaking change.
-->


## Proposed change
<!-- 
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Fix Synology Camera doing I/O in the event loop. Reported by @S-Przybylski here https://github.com/home-assistant/core/issues/4210#issuecomment-616115455


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box! 
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [x] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Example entry for `configuration.yaml`:
<!--
  Supplying a configuration snippet, makes it easier for a maintainer to test
  your PR. Furthermore, for new integrations, it gives an impression of how
  the configuration would look like.
  Note: Remove this section if this PR does not have an example entry.
-->

```yaml
# Example configuration.yaml

```

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Fix Synology camera setupFixes #11195
309,"CLN: inconsistent kwarg name
A couple of days ago the ""setting"" kwarg got introduced in core.indexing, but I should have called it ""is_setter"" to match the existing pattern in that module.  This fixes that.",# TST: fix #38214
310,"Updated documentation for being able to use init_db method
minor change for being able to run tests within the tutorial.",# Fix some minor issues in the testing docs
311,"English comment translation
Translate native chinese comment to english for easy understanding by non chinese developer",# Update docstrings
312,"Bump requests requirement to >=2.10
Fixes #3804.",# acme: bump requests to 2.10Fixes #556
313,"Add 'restore index ' section to RedisIndexDemo doc.
# Description

As mentioned in ticket #6978, I have included detailed information and example codes in the RedisIndexDemo. This demonstration illustrates how to restore an existing index from Redis.

Fixes # (issue)

https://github.com/jerryjliu/llama_index/issues/6978

## Type of Change

- [✔️ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [✔️ ] I 've browse the documentation in Markdown browser mode, of which code added are tested end-to-end.

# Suggested Checklist:

- [ ✔️ ] I don't commit anything relate to code. It just documentation update.
",# Add RedisIndexDemo
314,"Fixed #29154 -- Corrected examples in pluralize template filter docstring and added tests.
Fix `pluralize` template filter and add some tests.",# Fixed #28613 -- Fixed pluralize filter documentation.
315,"Update Quick_Sort.py
iterate through list object through iterator instead of index",# Fixing the print statement
316,"fix(environments) Disallow `/` in future environment names
While we can't reasonably change existing data, we can prevent more in the future. Having `/` in an environment name makes it impossible to hide the environment.

Refs APP-323
Refs ISSUE-24",# Validate environment name
317,"Add hug to REST frameworks list
## Why this framework/library/software/resource is awesome?

hug is the fastest growing framework for microservices on Python3 and as such clearly deserves placement on this list.
## Vote for this pull request

+1

Adds hug, the fastest growing micro-service framework for Python
",# Added Hug
318,"Minor patch (--purge instead of --purge-output)
",# Update parse/cmdline.py
319,"mutagen has moved to Bitbucket
",# Update README.mdUpdate mutagen link
320,"fix gap between train_model predict and inference
fix issue #https://github.com/PaddlePaddle/PaddleOCR/issues/2080",# fix typo
321,"[YouTube] Fix n-sig for player e06dea74
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Fix parsing of YT player code in line with https://github.com/yt-dlp/yt-dlp/commit/48416bc4a8f1d5ff07d5977659cb8ece7640dcd8.

Fixes #30752.",# [youtube] fix #30097
322,"[C++ worker] delete unuseful test

## Why are these changes needed?

delete unuseful test: ray_remote_cluster_test
",# [cpp] remove ray_remote_cluster_test
323,"every chardet package maps to requests.packages.chardet.* package respectively
Added a fix for the issue mentioned here - https://github.com/psf/requests/issues/6223

Checked in the code, only one package of chardet was being mapped to requests.packages.chardet despite the for loop. 

Have added the fix so each chardet package maps to it's corresponding requests.packages.chardet.* respectively.",# Fix #2085
324,"Add (null) string
",# Update blns.txt
325,"Update DynamoDBDocstoreDemo notebook description
# Description

Added vector_store to StorageContext to load vector_index from DynamoDB storage. Current description will not load vector_store from the DynamoDB table. It also includes one small typo fix.

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [x] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [x] I have performed a self-review of my own code
- [x] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [x] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
",# Update DynamoDB docstore demo
326,"🌐 Add Korean translation for `docs/ko/docs/python-types.md`
Korean translated 'python-types.md' #2017 ",# 🌐 Add Korean translation for `docs/ko/docs/python-types.md`🌐 Add Korean translation for `docs/ko/docs/python-types.md`
327,"feat(project-creation): Link to issue stream after dsn
before:
![image](https://user-images.githubusercontent.com/5915546/31844472-bbac74d6-b5ad-11e7-91fb-1c4d5ca83a4f.png)
after:
![image](https://user-images.githubusercontent.com/5915546/31844474-c2391354-b5ad-11e7-8881-4926edc46505.png)
","# Add a ""Got it!"" button to the overview page"
328,"Fixed #32108 -- Made transaction.on_commit() raise TypeError when callback is not a callable.
Simple fix for https://code.djangoproject.com/ticket/32108 to catch early `None` parameter to `on_commit` hook.
Implements the [suggested assert guard from the first comment](https://code.djangoproject.com/ticket/32108#comment:1).",# Fixed #28698 -- Added check for callable in on_commit() callback.
329,"fix indentation of line breaks in long type hints by adding parens
### Description
The simple way of resolving #2316
I would personally prefer to resolve it by formatting it without added parentheses (i.e. option 3 in #2316) to save two unnecessary lines, but that will likely require a bunch of messing around in `_maybe_split_omitting_optional_parens` and could also impact some other cases - so I think I'll hold off on that one for the moment.

I had to extend `maybe_make_parens_invisible_in_atom` to also allow expressions, I was quite afraid this would have side effects elsewhere in the code - but it seems to be fine? I could be defensive and add a parameter that enables checking `syms.expr`, and only set it when called from `visit_tname`.

There's minor changes to two existing test cases, but they both seem fine to me.

### Checklist - did you ...
- [x] Add an entry in `CHANGES.md` if necessary? [TODO]
- [x] Add / update tests if necessary?
- [x] Add new / update outdated documentation? [I don't think this needs to be done]

",# Add preview for long type hints
330,"Workaround of Gradio --share UI hang with ngrok
Gradio share feature hangs WebUI after generating first batch of more than one images. When using UI in local, though, everything seems normal.
So I implemented ngrok functionality that can be used to create public link to the WebUI while not using gradio.app.
First, you need to sign up on ngrok website, and get an authtoken. Then you can use it with command-line argument `--ngrok <authtoken>`.
I also [edited the first colab notebook](https://colab.research.google.com/drive/1kiWnIFYbq4mk2JtVNfxwlo3NuVUpiFzb?usp=sharing) from ReadMe: I fixed double download of a standard SD model, added a link to waifu-diffusion one and explanation of `--ngrok` argument. This notebook is temporary, as it'll be useless after merging.

P.S. Apparently, PaperSpace locks your account if you launch ngrok proxy in it, so you shouldn't use ngrok with it. Also, please be careful in other cloud solutions. The only one that I can confirm working fine with ngrok is Google Colab.",# Add ngrok support
331,"Added Dockerface
**[Insert the URL to be listed]**
https://github.com/natanielruiz/dockerface

**[Explain what the project is about and why it should be listed]**
Dockerface is an easy to install and use deep learning face detection for images and video in a docker container. It is meant for research and open for industry and personal use. It deploys a trained Faster R-CNN network on Caffe through an easy to use docker image. Bring your videos and images, run dockerface and obtain videos and images with bounding boxes of face detections and an easy to use face detection annotation text file.

Cheers!

Nataniel",# Add dockerface
332,"Extend file access retries to check rename and remove as well
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

I'm still getting some file access errors on my laptop, so I extended the logic to cover a few more places. I added `try_remove`, matching `try_rename` to avoid bare `os.remove` calls. To avoid code duplication I turned the retry logic into a decorator that wraps `sanitize_open`, `try_remove` and `try_rename`.

Notes:
- `try_rename` had a custom error message. I couldn't add it to the decorator and I think it would have conflicted with the error handling so it now raises the built in error if it fails.
- I added `error.EINVAL` (error 22) to the list of errors to retry, as I also saw this error on my laptop (I'm pretty sure it's the same problem as the parameter looks fine and it doesn't fail every time).",# Wrap file access actions in a retry loopWraps file access actions in a retry loop to handle file access errors.
333,"Added MonkeyType to 'Code Analysis and Linter'
## What is this Python project?

It generates static type annotations by collecting runtime types. After collection is done it can insert generated stubs into your code.

## What's the difference between this Python project and similar ones?

- compared to [pyannotate](https://github.com/dropbox/pyannotate) it has Python3 support;
- compared to [pyannotate](https://github.com/dropbox/pyannotate) it does not need [special pytest plugin](https://github.com/kensho-technologies/pytest-annotate): ```monkeytype run `which pytest` ``` is enough;
- pyannotate is the Dropbox project, MonkeyType is the Instagram project;
- it stores analysis results in sqlite format.

PS. Neither `pyannotate` nor `pytest-annotate` is in this list, but I follow the contribution rule `1pr == 1 link`.

--

Anyone who agrees with this pull request could vote for it by adding a :+1: to it, and usually, the maintainer will merge it when votes reach **20**.
",# Add MonkeyType
334,"Update Thai translations
Update Thai translations",# Update main_th.ts
335,"[Datasets] Add `from_tf`
Signed-off-by: Balaji <balaji@anyscale.com>

**Blocked on**
- [x] #29590 

<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

<!-- Please give a short summary of the change and the problem this solves. -->

Parity with `from_huggingface`. Also, `SimpleTensorflowDatasource` is clunky. For more motivation, read #29430.

## Related issue number

<!-- For example: ""Closes #1234"" -->

Towards #29430. See also #29589.

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [x] I've run `scripts/format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [x] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# Remove SimpleTensorFlowDatasource
336,"Fix bug in docker image tf/tf:latest-gpu-py3
This is a bug fix in latest tf-gpu image, in which tensorflow cannot be load.

Altho this may be fixed later, I think it matters to commit a hot fix and btw, update some documentation.",# Fix tensorflow:latest-gpu-py3 image
337,"#184 - Added description of the Borg pattern.
Explanation of the Borg pattern.",# Added Borg pattern description
338,"Fix api and None provider
",# Add API testing
339,"Add CodeCarbon Integration
# What does this PR do?

This PR adds `codecarbon` for carbon footprint tracking. This is also useful for BigScience.

## Before submitting
- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors who may be interested in your PR.

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

Models:

- albert, bert, xlm: @LysandreJik
- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj
- longformer, reformer, transfoxl, xlnet: @patrickvonplaten
- fsmt: @stas00
- funnel: @sgugger
- gpt2: @patrickvonplaten, @LysandreJik
- rag: @patrickvonplaten, @lhoestq
- tensorflow: @LysandreJik

Library:

- benchmarks: @patrickvonplaten
- deepspeed: @stas00
- ray/raytune: @richardliaw, @amogkam
- text generation: @patrickvonplaten
- tokenizers: @n1t0, @LysandreJik
- trainer: @sgugger
- pipelines: @LysandreJik

Documentation: @sgugger

HF projects:

- datasets: [different repo](https://github.com/huggingface/datasets)
- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)

Examples:

- maintained examples (not research project or legacy): @sgugger, @patil-suraj
- research_projects/bert-loses-patience: @JetRunner
- research_projects/distillation: @VictorSanh

 -->
",# Add CodeCarbon integration
340,"Fix unfound ab_user table in the CLI session
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #34109

For some reason, the sqlalchemy sessions created in the CLI do not find the table `ab_user`, I tested different solutions such as providing the session to the method `task_test` using provide_session decorator, using deferrable constraint and other solutions, and they did not work, but moving the foreign key to the column fixed the issue. 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",# [AIRFLOW-1111] Add foreign key constraints to user_id columns
341,"Improve error message for prepare-plug-plugin hook when certbot isn't installed
Provides a partial fix for #8182 by improving the error message.",# Add a note about removing certbot-dns-* pluginsFixes #1045.
342,"Fixed typo shuld -> should and incorrect/incomplete sentence
Fixed typo shuld -> should and incorrect/incomplete sentence

Based on the context I assumed ""the top"" was meant in this non-rule.
",# Fix typo in NR.1
343,"Fixing pre-commit is using pyyaml with broken version
This is to resolve #3803 ",# Update pyyaml to 6.0.1
344,"[examples/images/diffusion]: README.md: malformed `xformers` version
## 📌 Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [ ] I have added relevant tags if possible for us to better distinguish different PRs



## 📝 What does this PR do?

Changed the suitable version of xformers from 0.12.0 to 0.0.12 (probably a typo).



## 💥 Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [x] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [x] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# fix xformers version
345,"Fix apex install bugs
apex updated their repo to be PEP 517 compliant, but their pyproject.toml didn't completely specify all dependencies, causing build errors.  There looks to be a bit more work there with getting all dependencies handled with things like torch from the right feed for those (like us) who build the cuda_ext.

For now, this PR just forces us to use the latest commit prior to these changes in apex.",# [ci] pin apex version
346,"Bump to V26.2
## Release notes

### Bugs Fixes 
* As `reset` now returns `(obs, info)` then in the vector environments, this caused the final `step`'s info to be overwritten. Now, the final observation and info are contained within the info as ""final_observation"" and ""final_info"" @pseudo-rnd-thoughts 
* Adds warnings when trying to render without specifying the `render_mode` @younik 
* Updates Atari Preprocessing such that the wrapper can be pickled @vermouth1992 
* Github CI was hardened to such that the CI just has read permissions @sashashura 
* Clarify and fix typo in `GraphInstance` @ekalosak 
 ",# Fix serialization error
347,"community: Add missing async_astra_db_client param to AstraDBChatMessageHistory
",# Add async AstraDB client to AstraDBChatMessageHistory
348,"Add remaining DNS plugins to mypy.ini and sort entries
",# mypy: enable type checking for dns plugins
349,"`#include`d instead of `#included`
",# Fix typos
350,"Fixes the NL.26 link.
",# Fix broken link
351,"do not blindly catch all AttributeErrors
see shazow/urllib3#618
",# Fix #2155
352,"[zero] added error message to handle on-the-fly import of torch Module class
The zero init context has a precondition that the module class has to be imported before entering the context. However, sometimes this is not always so. For example:

```
with ctx:
    model = transformers.BertModel(...)
```

This example will raise exception because BertModel is only imported on the fly. This PR adds an error message for easier debugging.",# Fix the error when using `torch.nn.Module` in the context manager
353,"Streaming responses require encoding to be set
Resolves the issues called out in #3359 and #3481 when `Response.iter_content(decode_unicode=True)` would return bytes instead of unicode. This is a breaking change as it raises an exception if `Response.encoding` is not set before invoking this function.
",# Raise an exception if encoding isn't set before consuming streaming responsesFixes #2860
354,"zhanqi TV now can use old algorithm, so revert recent 2 comments
https://github.com/soimort/you-get/issues/883
https://github.com/soimort/you-get/issues/887

<!-- Reviewable:start -->

[<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/soimort/you-get/894)

<!-- Reviewable:end -->
",# [zhanqi] fix rtmp url
355,"wex.nz => wex.link
https://twitter.com/WEXnz/status/1065241700237484038",# wex: update urls
356,"MRG: DOC: Simpler cross-validation iterator doc
Remove the reference to data arrays in the inline example and be more explicit to explain the difference between LOLO and `StratifiedKFold`.
",# DOC: fix examples in cross_validation module
357,"[autoparallel] adapt runtime passes
",# [AP] add shape consistency pass
358,"[applepodcast] Support new page format
## Please follow the guide below

---

### Before submitting a *pull request* make sure you have:
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Read [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site)
- [x] Read [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) and adjusted the code to meet them
- [x] Covered the code with tests (note that PRs without tests will be REJECTED)
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Pages from podcast.apple.com have begun to be served with a different structure, where the podcast metadata is found in JSON in an element with `id` `shoebox-media-api-cache-amp-podcasts` rather than `shoebox-ember-data-store`, and the JSON has a slightly different structure.

This PR adds support for the new format. On the assumption that this format will eventually be used for all podcast pages, the new format is tried first, and then the old format if that doesn't succeed. The block that handles the old format can be removed once it is determined that the old format is no longer served.

* Resolves #30216
* Resolves #30250
* Resolves #30413.
Additionally, the format information returned by the extractor comprised just the media URL, which broke a configuration with, eg, `-f bestaudio` as default.

* Resolves #29095.

Additionally, the default page image is extracted as `thumbnail`.

* Resolves #29197. ",# [applepodcasts] fix extraction
359,"XXE: OOB via FTP + remote DTD for XSLX files
better than the HTTP method, more robust approach, easier zip repackaging",# Update XXE Injection/README.md
360,"Add 2.0 release logic 
This cherry picks #9467 to this branch per the plan there in case we want to do 1.32 point releases.",# Only publish snaps for 1.x.y releases
361,"Update MSSQL Command execution
",# MSSQL Injection: Fix syntax
362,"Fix att loss
att",# fix rec_att_head
363,"Added `File:///` Vulnerability
",# Added File:///
364,"[3.10] gh-98716: Revert gh-96081: Escape lone stars in sqlite3 docs (GH-98720)
(cherry picked from commit 365852a03a0c934ccd9b6c2b8e24c71181c41f03)

Co-authored-by: Erlend E. Aasland <erlend.aasland@protonmail.com>

<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y] <title from the original PR> (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->


<!-- gh-issue-number: gh-98716 -->
* Issue: gh-98716
<!-- /gh-issue-number -->
",# bpo-39498: Fix docstrings for sqlite3
365,"this changes files extension
password is 4121
enter the names of files or use these two wildcards
* selects all r give random files range from 1 to 5 files 

enter the extensions add a dot before any extension e.g .mp4, .mp3 you can give more than one extension and it wil arrange them according to the files. Good luck. 

email: devpoison@outlook.com",# file_ext_changer.py
366,"Typo
Inference is the folder name",# Fix typo in README.md
367,"Documentation update to increase readability
**Readability change in modules_management.rst**
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",# Fix typo in modules_management.rst
368,"fix image replacement via clipboard paste or drag and drop on PNG Info tab
We have to wait for the ajax request after clearing the image before placing the new one

(also fixes #771)",# Fix PNG Info tab
369,"CSS: Remove forced visible overflow for Gradio group child divs
## Description

Title. This is most noticeable with the progress bar in the extras tab and in the gallery view when generating a batch of images. Removing this doesn't seem to break anything else in my tests.

## Screenshots/videos:

<details>
<summary>Before</summary>

![before](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/122327233/acc71120-6e2a-4e97-8e41-425565573bf5)
</details>

<details>
<summary>After</summary>

![after](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/122327233/f2dbfa57-1864-4f36-bc23-7e9232b486f2)
</details>

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Fix for gradio 3.39
370,"Read the signin env variables from server props
This is to ensure we always use the runtime variable instead of the build time variable.",# feat: enable email signin on signin page
371,"Support querying systemd container information
systemd writes a /run/systemd/container file in any container it starts to make it really easy to detect the container type.

This adds support for detecting systemd-nspawn containers (and any other container format that will write data there for compatibility). Otherwise we have to look for  `1:name=systemd:/system.slice/` in `/proc/1/cgroup`, which I'm not confident will be unique enough.
",# Add systemd container factsFixes #28515
372,"ref: bump sentry-arroyo to 2.12.1
Co-Authored-By: untitaker <837573+untitaker@users.noreply.github.com>
",# Bump sentry-arroyo to 2.12.1
373,"Better warning when loading a tokenizer with AutoTokenizer w/o Sneten…
…cePiece

Currently, initializing a `sentencepiece` `AutoTokenizer` without having `sentencepiece` installed results in the following error:

```
AttributeError: 'NoneType' object has no attribute 'from_pretrained'
```
This improves the error message to:
```
 This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
```

Fix #8864",# Fix error when using AutoTokenizer with SentencePiece
374,"[chatgpt]add inference example
## 📌 Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [ ] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`
fixed #2870 #2915 #


## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.
Add a demo of inference in Chatgpt/examples

## 💥 Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [ ] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# add inference example
375,"CI Adds environment to upload_anaconda
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->
Related to https://github.com/scikit-learn/scikit-learn/issues/24491#issuecomment-1935876029


#### What does this implement/fix? Explain your changes.
I added a new `upload_anaconda` environment to the repo: https://github.com/scikit-learn/scikit-learn/settings/environments with the tokens for uploading to anaconda.

With environments, the only GitHub jobs marked with `environment: upload_anaconda` can have access to the secrets.

CC @lesteve 

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# Set environment for Anaconda upload
376,"bpo-39947: Use _PyInterpreterState_GET_UNSAFE()
Replace _PyInterpreterState_Get() function call with
_PyInterpreterState_GET_UNSAFE() macro which is more efficient but
don't check if tstate or interp is NULL.

_Py_GetConfigsAsDict() now uses _PyThreadState_GET().

<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
bpo-NNNN: Summary of the changes made
```

Where: bpo-NNNN refers to the issue number in the https://bugs.python.org.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `master`),
please ensure that the PR title is in the following format:

```
[X.Y] <title from the original PR> (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `master`.

-->


<!-- issue-number: [bpo-39947](https://bugs.python.org/issue39947) -->
https://bugs.python.org/issue39947
<!-- /issue-number -->
",# bpo-41498: Use _PyInterpreterState_GET_UNSAFE() in Python code
377,"Test that the readme renders in CI.
Resolves #4030.",# Add a test for the README
378,"Fix some unescaped shell colors
### Changes
* Uses printf rather than echo to escape shell colors.

### Examples

Before:
![image](https://user-images.githubusercontent.com/26678747/105424891-38634d80-5c16-11eb-806e-c8a9c640566e.png)

After:
![image](https://user-images.githubusercontent.com/26678747/105425338-2e8e1a00-5c17-11eb-94c4-6d6422353c65.png)

### Notes

I couldn't find any more cases of this mistake:
```console
$ egrep -rnw . --exclude-dir=venv -e ""echo.*033.*""
./tests/results/8:695:        echo ""\033[0;31mstealth:\033[0m selection length is longer than $STEALTH_MAX_SELECTION_LENGTH words; ignoring""
./share/cht.sh.txt:695:        echo ""\033[0;31mstealth:\033[0m selection length is longer than $STEALTH_MAX_SELECTION_LENGTH words; ignoring""
```
",# Fix stealth test
379,"Fixed #4764
### Fixed the issue #4764

I added a check condition `x==y` and if this condition becomes 
true then `return`.


* [ ] Add an algorithm?
* [X] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [X] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [X] This pull request is all my own work -- I have not plagiarized.
* [X] I know that pull requests will not be merged if they fail the automated tests.
* [X] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [X] All new Python files are placed inside an existing directory.
* [X] All filenames are in all lowercase characters with no spaces or dashes.
* [X] All functions and variable names follow Python naming conventions.
* [X] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [X] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [X] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [X] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",# Fix union_set function
380,"[ci] `nv-transformers-v100` - use the same torch version as transformers CI
At HF Transformers we are trying to figure out how to get less breakages on deepspeed transformers CI job.

So one proposal is to sync the pytorch versions, which is what this PR is proposing. 

This change will always use the latest official pytorch version for `nv-transformers-v100`

@jeffra ",# [ci] use the same pytorch version as transformers CI
381,"Pass plugin errors back out to the user.
Closes: #971
",# Add a `problem` property to the Disco pluginFixes #1115
382,"Remove obsolete requirements from prepare_http_tests
##### SUMMARY

Remove obsolete requirements from prepare_http_tests.

##### ISSUE TYPE

Test Pull Request
",# Remove decorator and importlib from kerberos test
383,"Update llama2-chat-format.json
added the missing comma

## Checklist:

- [ ] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
",# fix llama2 chat format
384,"Update pendulum.py
Minor: more consistent docstring",# Fix typo in PendulumEnv docstring
385,"Fix toy_text rendering on headless machines
# Description

Fixes #3032

The pygame code did stuff with the display even in `rgb_array` mode, which makes it impossible to run it on a headless machine. The relevant code has been moved into the `if` condition.

WIP because I need to check if it actually works on colab and on a head...ful? computer, and probably address potential similar problems in other envs.",# Fix display init in cliffwalking and frozen lake
386,"[3.11] gh-106368: Increase Argument Clinic CLI test coverage (GH-107156)
Instead of hacking into the Clinic class, use the Argument Clinic tool
to run the ClinicExternalTest test suite.

(cherry picked from commit 83a2837b328c58b243f7d97bec12c64ec66681c5)

Co-authored-by: Erlend E. Aasland <erlend@python.org>
Co-authored-by: Nikita Sobolev <mail@sobolevn.me>

<!-- gh-issue-number: gh-106368 -->
* Issue: gh-106368
<!-- /gh-issue-number -->
",# bpo-42398: Add tests for clinic CLI
387,"Fixed nits with plugin choice
Changed order of plugins listed - they'll now be reverse alphabetical
Made the descriptions of plugins not mimic their names
Made more_info for standalone work the same way as manual
Made more_info strings not have missing spaces due to stripped \n formatting by adding leading spaces
",# Improve plugin descriptions
388,"Add LAPIS API
<!-- Thank you for taking the time to work on a Pull Request for this project! -->
<!-- To ensure your PR is dealt with swiftly please check the following: -->
- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added LAPIS API
389,"fix(dashboards): widgetQueries undefined check for stats
updates `stats` to optional",# fix: widgetQueries.tsx
390,"Fix pull manager retry
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

#12335 introduced a bug where the object manager's global timer was only firing once.

This PR fixes that issue by reseting the timer each time it goes off.

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# [ObjectManager] Fix pull retry timer
391,"Address #726 review comments
Addresses my review comments from #726.
",# Fix Boulder integration testsFixes #1595
392,"Convert embeds to np array
To remove the warning that appears while training",# Fix speaker embedding in SynthesizerDataset
393,"Add scheme to url_build error handler parameters
`_scheme` is passed to `url_for` but is not forwarded to error handlers if an exception is raised",# Pass _scheme to handle_build_errorFixes #2017
394,"Jinja2 repo reallocated to Pallets project
Yesterday Armin Ronacher aka mitsuhiko announced the creation of Pallets project: ""a Github organization which will be the home of Flask and all the associated projects"". 
## Vote for this pull request

Who agrees that this change should be merged could add your reactions (e.g. :+1:) to this pull request.
",# Update README.md
395,"TST: `test_highlight.py` convert to functional tests not class
- [x] add `pytest.fixture` instead of Class setup method
- [x] no test removed or added, just amended to accept new fixtures ",# TST: refactor test_highlight.py
396,"Luhn Algorithm Program in Python
I am contributing a Python program that uses the Luhn algorithm to calculate the check digit of any 10-digit number.",# Luhn Algorithm
397,"[stable-2.5] Detect the socket path after starting the service. Fixes…
… #47582

(cherry picked from commit 10e129e)

Co-authored-by: Matt Martz <matt@sivel.net>

##### ISSUE TYPE
<!--- Pick one below and delete the rest -->
- Bugfix Pull Request


##### COMPONENT NAME
mysql integration tests

##### ANSIBLE VERSION
<!--- Paste verbatim output from ""ansible --version"" between quotes -->
```paste below
2.5.x
```
",# Detect socket path
398,"Delete dynamic_programming/longest_sub_array.py
### Describe your change:

Fixes #8098. 

Deleted `longest_sub_array.py` since `longest_sub_array.py` solves a similar problem with `max_subarray_sum.py` (maximum sum of a subarray), but it has no doctests and not as completed as the latter.

* [ ] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [ ] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [x] If this pull request resolves one or more open issues then the description above includes the issue number(s) with a [closing keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue): ""Fixes #ISSUE-NUMBER"".
",# delete longest_sub_array.py
399,"Fix typo
Fix typo in wall_clock_breakdown documentation",# Fix typo in features.md
400,"Fix hitbtc2 ohlcv
Hitbtc2 ohlcv api returns volume information different than others. Usually quote volume means the volume of the currency itself, whereas base volume means the volume of currency in base currency such as BTC.

For hitbtc2, however ([example](https://api.hitbtc.com/api/2/public/candles/EMCBTC?limit=100&period=D1))
   - volume => quote volume
   - volumeQuote => base volume

So, i've made the neccesary change to make it consistent with other exchanges.",# hitbtc2: fix volume
401,"Remove preview status from TOML inventory
##### SUMMARY
Remove preview status from TOML inventory

##### ISSUE TYPE
- Feature Pull Request

##### COMPONENT NAME
lib/ansible/plugins/inventory/toml.py

##### ADDITIONAL INFORMATION
<!--- Include additional information to help people understand the change here -->
<!--- A step-by-step reproduction of the problem is helpful if there is no related issue -->

<!--- Paste verbatim command output below, e.g. before and after your change -->
```paste below

```
",# [stable-2.9] tomal: remove preview warning (stable-2.9)##### SUMMARYtomal: remove preview warning##### ISSUE TYPE- Bugfix Pull Request##### COMPONENT NAMEtoml plugin##### ANSIBLE VERSION```ansible 2.9.0  config file = /etc/ansible/ansible.cfg  configured module search path = Default w/o overrides```##### ADDITIONAL INFORMATION``````
402,"Add more patterns to sudo.py
These patterns cover commands like
`reboot`
or
`dpkg-reconfigure something`
",# Add more sudo error messages
403,"Add `git_merge_unrelated` rule for `git merge --allow-unrelated-histories`
From https://git-scm.com/docs/merge-options#merge-options---allow-unrelated-histories

> By default, `git merge` command refuses to merge histories that do not
share a common ancestor. This option can be used to override this safety
when merging histories of two projects that started their lives
independently.",# Add git_merge_unrelated rule
404,"[extractor/ximalaya] use the normal sort order
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible


-->

ADD DESCRIPTION HERE

The `sort=1` reverses the sort order of the playlist so that the last track is downloaded first. I don't know why this was added but the user has to download all tracks to get the first one.

<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


<!-- Do NOT edit/remove anything below this! -->
</details><details><summary>Copilot Summary</summary>  

<!--
copilot:all
-->
### <samp>🤖 Generated by Copilot at 7b3e24d</samp>

### Summary
🐛🚫🎵

<!--
1.  🐛 - This emoji represents a bug fix, which is the main goal of this change. Removing the `sort` parameter solved the problem of missing or duplicated tracks in some albums.
2.  🚫 - This emoji represents a removal or deletion, which is the effect of this change. The `sort` parameter was removed from the query of the tracks list request, simplifying the code and the request.
3.  🎵 - This emoji represents music, which is the domain of this change. The change affects the tracks list request, which is used to fetch the music tracks of an album.
-->
Removed `sort` parameter from `ximalaya.py` extractor to fix missing tracks issue. This parameter caused some tracks to be skipped or duplicated in some albums.

> _`sort` parameter_
> _gone from tracks list query_
> _no more missing songs_

### Walkthrough
* Remove `sort` parameter from tracks list query to fix missing tracks issue ([link](https://github.com/yt-dlp/yt-dlp/pull/7292/files?diff=unified&w=0#diff-0b49e0118c7ef46255bc0d36cc6cf3b6c6472ba0fa3296994444014c5d6fa909L161-R161))



</details>
",# [ximalaya] remove sort parameter
405,"Making changes to the Community Guide index
##### SUMMARY
* Added a link where one was missing (issues & PRs)
* Added anchor to help link to the edit listed above
* Changed one line to match the ""statement, question"" format
* Minor changes to some wording in the table of contents
* Updated one index entry at the very bottom to reflect title case vs. sentence case 

##### ISSUE TYPE

- Docs Pull Request


##### ADDITIONAL INFORMATION
These changes were made per Community Devel meeting/discussion on 12/7/2018",# Fix typos in community docs
406,"Update Ulyssess
Update Ulyssess README",# Fix typos in Ulysses blog
407,"Upgrade langchain to support new openai
# Context
The upgrade of OpenAI, leaving Langchain unupgraded, has resulted in issues with Faiss.

# Amendments details
1. Upgrade Langchain 0.0.231 -> 0.0.352, supporting OpenAI v1.
2. Use Langchain faiss's load/save functions to simplify the code, because after upgrading Langchain, the original code will throw an error ""pickle.dump(store, f)TypeError: cannot pickle '_thread.RLock' object"".
3. Simplify the example/search_kb.py code.",# fix faiss store
408,"correct rmkv in interface to rwkv


## Why are these changes needed?

The changes reflect what the actual model is being loaded


## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).
",# fix model name
409,"Refactoring in |raise_for_status| method.
- Simplified the if statements.
- Remove duplicate code.
",# Simplify the status code checks
410,"[doc] update readme with the new xTrimoMultimer project
Adding experimental results of xTrimoMultimer.",# [doc] add xTrimoMultimer to the real world
411,"Get mypy passing with check_untyped_defs everywhere
This finishes getting mypy to pass with `--check-untyped-defs` for everything in this repo. To make it easy to distribute, `letshelp-certbot` has no dependencies outside of the standard library so rather than adding some so rather than add some, I just copied `acme.magic_typing` to that package as well.",# Fix mypy errors
412,"Documentation: Clarify instructions about changing row_factory for SQLite3
When I was working through the tutorial, this was very confusing to me; so, I've added the code and clarification that would have helped me get through it faster.
",# Add sqlite3.Row example
413,"Remove duplicated WORKDIR in CI Dockerfile
Having it doesn't cause any harm, but it was already set five commands
further up to the same value (on L401)
",# Remove WORKDIR in Dockerfile.ci
414,"[hotfix]: polish code and fix typo
## 📌 Checklist before creating the PR

- [ ] I have created an issue for this PR for traceability
- [ ] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [ ] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`



## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.



## 💥 Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [ ] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# [shardformer] fix mistral policy
415,"Add new exceptions module, to implement JSONHttpException and JSONBadRequest.
This is an update to pull request #423, to move exception classes out of wrappers.py
",# Return JSON formatted error description by defaultFixes #1055
416,"Electric power
### Describe your change: ###
Used code from ohms_law algorithm, but now for power calculation 

* [x] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",# Added electric_power.py
417,"ref(page-filters): Remove environment filter in Alerts History
According @robinrendle, we don't need the environment filter in the History tab.

**Before:**
<img width=""981"" alt=""Screen Shot 2022-03-24 at 11 35 55 AM"" src=""https://user-images.githubusercontent.com/44172267/159986953-640db67d-dafb-4e72-87c6-6774003db28b.png"">

**After:**
<img width=""981"" alt=""Screen Shot 2022-03-24 at 11 36 05 AM"" src=""https://user-images.githubusercontent.com/44172267/159986982-f55b3b03-2b75-4d34-821f-e8c7e9e2ceb0.png"">

",# feat(alerts): Remove environment filter from alerts
418,"Correct bad URL in token_counter
**Features**
<!-- Clear and direct description of the submit features. -->
<!-- If it's a bug fix, please also paste the issue link. -->

Fix bug:
```
2024-03-19 14:52:18.433 | WARNING  | metagpt.provider.openai_api:_calc_usage:250 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt4. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
```

In fact the link `https://github.com/openai/openai-python/blob/main/chatml.md` as been removed long time, that mislead users. The PR is correct the link.

With the changes, the output as following:
```
2024-03-19 15:59:26.193 | WARNING  | metagpt.provider.openai_api:_calc_usage:247 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt4. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.
```
    
**Feature Docs**
<!-- The RFC, tutorial, or use cases about the feature if it's a pretty big update. If not, there is no need to fill. -->

**Influence**
<!-- Tell me the impact of the new feature and I'll focus on it.  -->

**Result**
<!-- The screenshot/log of unittest/running result -->

**Other**
<!-- Something else about this PR. -->",# Update token_counter.py
419,"BUG: take into account adjoin width, closes #3201
",# TST: test to_string line width
420,"Fix run tests fail.
Fix typo changed in upstream.",# Fix typo in test results
421,"[bitrue] withdraw parse
",# bitrue: parseTransaction
422,"[CI] force upgrade HF dependencies & output py env
Fixes an issue with our CI runners using outdated versions of packages (e.g., datasets) that caused transformers integration tests to fail.",# [ci] add python environment check
423,"Delete duplicate function
",# remove create_multi_devices_program
424,"Update Vertex template
",# Add rag-matching-engine template
425,"feat: use consistent file name in gradio
Closes https://github.com/lllyasviel/Fooocus/issues/1421
Adds ability for https://github.com/lllyasviel/Fooocus/pull/1940 to return metadata in images in the browser.

Returns and uses filepaths instead of numpy image by saving to args_manager.args.temp_path (fallback gettempdir()).
Temp images are removed after yielding to gradio. ",# delete Fooocus temp images
426,"Cleanup Unix domain socket file on exit
Subj",# manager.py cleanup
427,"Fixed typo in documentation.
",# Fix typo in advanced.rst
428,"[extractor/owncloud] New Extractor for Owncloud
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information


I'm not sure if we want this extractor in yt-dlp, because in Owncloud there is no download block option, and there is always a download button. Since the extractor has been used in my project for years (https://github.com/C0D3D3V/Moodle-DL/blob/main/moodle_dl/downloader/extractors/owncloud.py)  I thought I make a PR, and if you want it you can review it, or reject it.

Also for now I only added two known OwnCloud servers, since I do not know if you want the extractor I did not search for more.


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [x] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

</details>
",# [owncloud] Add extractor
429,"[Security] Bump urllib3 from 1.26.3 to 1.26.4
Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.3 to 1.26.4. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-5phf-pp7p-vc2r"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Using default SSLContext for HTTPS requests in an HTTPS proxy doesn't verify certificate hostname for proxy connection</strong></p>
<h3>Impact</h3>
<p>Users who are using an HTTPS proxy to issue HTTPS requests and haven't configured their own SSLContext via <code>proxy_config</code>.
Only the default SSLContext is impacted.</p>
<h3>Patches</h3>
<p><a href=""https://github.com/urllib3/urllib3/releases/tag/1.26.4"">urllib3 &gt;=1.26.4 has the issue resolved</a>. urllib3&lt;1.26 is not impacted due to not supporting HTTPS requests via HTTPS proxies.</p>
<h3>Workarounds</h3>
<p>Upgrading is recommended as this is a minor release and not likely to break current usage.</p>
<p>Configuring an <code>SSLContext</code> with <code>check_hostname=True</code> and passing via <code>proxy_config</code> instead of relying on the default <code>SSLContext</code></p>
<h3>For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li>Email us at <a href=""mailto:sethmichaellarson@gmail.com"">sethmichaellarson@gmail.com</a></li>
</ul>
<p>Affected versions: &gt;= 1.26.0, &lt;= 1.26.3</p>
</blockquote>
</details>
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/releases"">urllib3's releases</a>.</em></p>
<blockquote>
<h2>1.26.4</h2>
<p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>
<ul>
<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>
</ul>
<p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a></strong></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/blob/main/CHANGES.rst"">urllib3's changelog</a>.</em></p>
<blockquote>
<h1>1.26.4 (2021-03-15)</h1>
<ul>
<li>Changed behavior of the default <code>SSLContext</code> when connecting to HTTPS proxy during HTTPS requests. The default <code>SSLContext</code> now sets <code>check_hostname=True</code>.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/urllib3/urllib3/commit/a8913042b676c510e94fc2b097f6b514ae11a537""><code>a891304</code></a> Release 1.26.4</li>
<li><a href=""https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0""><code>8d65ea1</code></a> Merge pull request from GHSA-5phf-pp7p-vc2r</li>
<li><a href=""https://github.com/urllib3/urllib3/commit/5e3432646ad63749ff0d655c157fe293cdc6c2aa""><code>5e34326</code></a> Add proper stacklevel to method_allowlist warning</li>
<li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.3...1.26.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)](https://dependabot.com/compatibility-score/?dependency-name=urllib3&package-manager=pip&previous-version=1.26.3&new-version=1.26.4)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
If all status checks pass Dependabot will automatically merge this pull request.

[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Automerge options (never/patch/minor, and dev/runtime dependencies)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",# Update urllib3 to 1.26.4
430,"Update README.md
Insert reply for questions on Prometheus section",# Add more Prometheus questions
431,"fixing bug: AttributeError: DumpMaster instance has no attribute 'unload...
Without this fix, I kept getting this error when using mitmdump -s bla.py -r somefile:

Traceback (most recent call last):
  File ""/usr/local/bin/mitmdump"", line 55, in <module>
    m.run()
  File ""/usr/local/lib/python2.7/dist-packages/libmproxy/dump.py"", line 227, in run
    self.unload_script(script)
AttributeError: DumpMaster instance has no attribute 'unload_script'
",# Fix #1115
432,"Update imports from Transformers
This helps resolve the following warnings:

``` 
  /tmp/actions-runner/_work/DeepSpeed/DeepSpeed/unit-test-venv/lib/python3.8/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
    warnings.warn(
```",# [hotfix] fix transformers import in tests
433,"Subtitles rework
Now the subtitles field in the info dict is just a dictionary with the keys being the language and the values, the subtitles. If the subtitles are not found/are not available for that language it should be set to `{}`.
The error handling logic has been simplified, now each function reports a warning and return None or `{}` if it can't do his work.
The code needed for saving the subtitles have been reduced to a single loop that iterates over the subtitles dictionary.

I think these changes simplify adding subtitles extraction to other IEs (I'm planning to do it for TED).

Note: the test fail quite often, because it gets a lot of 404 errors from youtube.
",# [youtube] fix subtitles extraction
434,"Upgrade psutil to 5.1.1
## 5.1.1

### Enhancements

- [Linux] sensors_battery().percent is a float and is more precise.
### Bug fixes

- [Windows] Process.username() and psutil.users() may return badly decoding character on Python 3.
- [Linux] disk_io_counters() may miscalculate sector size and report the wrong number of bytes read and written.
- [Linux] sensors_battery() may fail with ""no such file error"".
- [Linux] sensors_battery().power_plugged may lie.

## 5.1.0

### Enhancements

- added psutil.Process.cpu_num() (what CPU a process is on).
- added psutil.sensors_temperatures() (Linux only).
- added psutil.cpu_freq() (CPU frequency).
- added psutil.sensors_battery() (Linux, Windows, only).
- cpu_affinity([]) can now be used as an alias to set affinity against all eligible CPUs.
### Bug fixes

- [Linux] pid_exists() no longer returns True if passed a process thread ID.
- cannot install psutil with PYTHONOPTIMIZE=2.
- [Windows] Process.cpu_percent() was calculated incorrectly and showed higher number than real usage.
- [Windows] the uploaded wheels for Python 3.6 64 bit didn't work.
- psutil exception objects could not be pickled.
- Popen.wait() did not return the correct negative exit status if process is ``kill()``ed by a signal.
- [Windows] WindowsService.description() may fail with ERROR_MUI_FILE_NOT_FOUND.

Tested with the following configuration:

``` yaml
sensor:
  - platform: systemmonitor
    resources:
      - type: load_1m
      - type: 'disk_use_percent'
        arg: '/'
      - type: 'disk_use'
        arg: '/home'
      - type: 'disk_free'
        arg: '/'
```
",# Update psutil to 5.1.1
435,"itbit: use string in safeTicker ccxt/ccxt#11379
ccxt/ccxt#11379",# itbit fetchTicker
436,"Cleanup jsonify() function
Cleanup some leftover stuff from #1671. PEP8 spacing, args/kwargs don't need to be converted to list/dict, and Sphinx formatting.
",# Fix #1262
437,"docs:Add Cohere examples in documentation 
- Description: Add cohere examples to documentation 
- Issue:N/A
- Dependencies: N/A",# Add Cohere API docs
438,"STY Changing .format method to f-string formatting
Change in formatting

<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->


#### What does this implement/fix? Explain your changes.
As our old school .format method is quite verbose so I have updated with new and efficient way.

#### Any other comments?


<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# Fix print statements in 20newsgroups benchmark
439,"update_1
",# Update 21_Day/21_class_and_object.md
440,"feat(js-loader): Make latest unselectable
We want to remove the option to select ""latest"" in the JS loader because it makes the maintenance of the JS SDK hell in terms of backwards compatibility.

For this we need to start mapping ""latest"", when selected, to the actual latest value, which at the current time is ""7.x"".

We are starting in the frontend:
- When the backend says ""latest"" is a valid option to select, we remove that option from the list of selectable items.
- Because of the above, we also need to map the ""latest"" value, if the backend says it is selected, to ""7.x"" so that the select knows what selection to show because ""latest"" is not an option anymore.
- Previously, there was never the case where only one item was selectable. After this change, there are situations where only ""7.x"" may be selected. In this case we disable the select (because there are no more valid options) and show a hint explaining that only one option can be selected and why.

In a follow-up, we will update the backend to limit what options are returned. (follow up: https://github.com/getsentry/sentry/pull/65691 - both could in theory be deployed independently but having this PR out first is a tiny bit better because of the disabled state of the select)",# Fix SDK version dropdown
441,"print() function and raw_input() for Python 3
",# fix launcher
442,"Update master from 2.7.4 release
This PR should not be squashed to preserve the signed and tagged commit.",# Update changelog and cli-help.txt
443,"Add missing `await` to GDAX fetchTime
",# gdax: fix fetchTime
444,"Clean up after #117, fixes #123
",# Apache Configurator: Fix #1115
445,"📝 Add external link to article: How-to deploy FastAPI app to Heroku
Related to https://github.com/tiangolo/fastapi/issues/802 & will act as a central place for anyone looking to deploy their FastAPI application to Heroku.",# Add new article to external links
446,"Refs #27996 -- Fixed postgres_tests crash if not running with PostgreSQL.
https://github.com/django/django/pull/13241#pullrequestreview-459038045",# Fix postgres tests
447,"🌐 Add French translation for `docs/fr/docs/tutorial/index.md`
Dear fellow translators 👋

This is a small PR to translate `docs/tutorial/index.md` to french 🇫🇷

Thanks 🍰 ",# 🌐 Add French translation for the tutorial
448,"Added code for Maximum Subarray Sum
### Describe your change:
Added code for Maximum subarray sum

* [X] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [X] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [X] This pull request is all my own work -- I have not plagiarized.
* [X] I know that pull requests will not be merged if they fail the automated tests.
* [X] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [X] All new Python files are placed inside an existing directory.
* [X] All filenames are in all lowercase characters with no spaces or dashes.
* [X] All functions and variable names follow Python naming conventions.
* [X] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [X] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [X] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [X] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",# Added maximum subarray problem
449,"Update Dockerfile
Fix ModuleNotFoundError: No module named 'transformers' in Docker

<!-- Thank you for your contribution! -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number (if applicable)

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've run `format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed.
- [ ] I've made sure the relevant tests are passing (if applicable).
",# Update Dockerfile
450,"Localize some labels that were missing in the tasks view
Translation to English and Spanish included",# Update translations for unchanged warning
451,"Rewrote Getting Help FAQ.
Make it a more useful place to point beginners with questions.",# Fixed #28613 -- Improved the FAQ.
452,"[Serve] Cleanup Router Implementation
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

## Why are these changes needed?
Cleanup some technical debts in router:
- Use deque instead of asyncio.Queue
- remove unnecessary async

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [x] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/latest/.
- [x] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failure rates at https://ray-travis-tracker.herokuapp.com/.
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested (please justify below)
",# [Serve] Use deque instead of asyncio.Queue
453,"Responsive URL input
## Current:
<img width=""200"" alt=""image"" src=""https://github.com/abi/screenshot-to-code/assets/76090263/af745239-ca84-4f06-87bf-fe6c544f195e"">
<img width=""500"" alt=""image"" src=""https://github.com/abi/screenshot-to-code/assets/76090263/3c52b429-d5b8-436a-a595-75bf04bd26fa"">


## Fixed input box:
<img width=""200"" alt=""image"" src=""https://github.com/abi/screenshot-to-code/assets/76090263/360496df-1d99-488e-abd5-eb460689cc51"">
<img width=""600"" alt=""image"" src=""https://github.com/abi/screenshot-to-code/assets/76090263/8cb5d8ae-b218-4861-b96f-755fa41edb44"">

",# Fix responsive issue on UrlInputSection
454,"Fix integration tests with Pebble v2.1.0 +
Since Pebble v2.1.0, new controls have been added on ACME specs compliance on Pebble with strict mode enabled. These controls are described here: https://github.com/letsencrypt/pebble/commit/3a2ce1c2facf20dacf65bb476209c389d4060935

Currently Certbot is not compliant enough to pass these new controls. One part of the work to do is described here: https://github.com/certbot/certbot/issues/7171

As a consequence, our CI is currently broken, both on PR builds and nightly builds.

This PR disables the strict mode during integration tests, fixing temporarily our CI. This will give us some time to fix theses deviations, and add back the strict mode in a future PR once it is merged.
",# Disable strict mode in Pebble v2.1.0+Pebble v2.1.0 added specs in strict mode for which Certbot is not compliant for now.
455,"[kuwo] New extractor for kuwo.cn
Kuwo is a legal Chinese music streaming service (similar to qqmusic).
",# [kuwo] add new extractor
456,"Skip pushing a new history if the new page hash is the same as the current one

## 📚 Context

_Please describe the project or issue background here_

- What kind of change does this PR introduce?

  - [x] Bugfix
  - [ ] Feature
  - [ ] Refactoring
  - [ ] Other, please describe:

## 🧠 Description of Changes

- _Add bullet points summarizing your changes here_

  - [ ] This is a breaking API change
  - [ ] This is a visible (user-facing) change

## 🧪 Testing Done

- [ ] Screenshots included
- [x] Added/Updated unit tests
- [ ] Added/Updated e2e tests

## 🌐 References

_Does this depend on other work, documents, or tickets?_

- **Issue**: Closes #5292

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",# Fix duplicated history when rerunning
457,"FIxed DOcs grmmatical issues
# Description

Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [x] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [ ] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] I have added Google Colab support for the newly added notebooks.
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] I ran `make format; make lint` to appease the lint gods
",# Fix typo in train_questions.txt
458,"[AIRFLOW-5687] Upgrade pip to 19.0.2
Make sure you have checked _all_ steps below.

### Jira

- [x] My PR addresses the following [Airflow Jira](https://issues.apache.org/jira/browse/AIRFLOW/) issues and references them in the PR title. For example, ""\[AIRFLOW-XXX\] My Airflow PR""
  - https://issues.apache.org/jira/browse/AIRFLOW-5687

### Description

- [x] Here are some details about my PR, including screenshots of any UI changes:
Pendulum==1.4.4 errors

Discussion on Slack resulted this PR:
https://apache-airflow.slack.com/archives/CCPRP7943/p1571319320145100
https://apache-airflow.slack.com/archives/CCPRP7943/p1571320302147400

Failed build: https://travis-ci.com/ashb/airflow/jobs/246690984
```
Complete output from command /usr/local/bin/python /usr/local/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmpGuP1ar:
  Traceback (most recent call last):
    File ""/usr/local/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py"", line 207, in <module>
      main()
    File ""/usr/local/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py"", line 197, in main
      json_out['return_val'] = hook(**hook_input['kwargs'])
    File ""/usr/local/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py"", line 54, in get_requires_for_build_wheel
      return hook(config_settings)
    File ""/tmp/pip-build-env-_krb5E/overlay/lib/python2.7/site-packages/setuptools/build_meta.py"", line 115, in get_requires_for_build_wheel
      return _get_build_requires(config_settings, requirements=['wheel'])
    File ""/tmp/pip-build-env-_krb5E/overlay/lib/python2.7/site-packages/setuptools/build_meta.py"", line 101, in _get_build_requires
      _run_setup()
    File ""/tmp/pip-build-env-_krb5E/overlay/lib/python2.7/site-packages/setuptools/build_meta.py"", line 85, in _run_setup
      exec(compile(code, __file__, 'exec'), locals())
    File ""setup.py"", line 47, in <module>
      from build import *
    File ""/usr/local/lib/python2.7/site-packages/pip/_vendor/pep517/build.py"", line 7, in <module>
      from pip._vendor import pytoml
  ImportError: No module named pip._vendor
```
More details: https://github.com/pypa/pip/issues/6190

Here is the comment from the maintainer: https://github.com/pypa/pip/issues/6163#issuecomment-462014864 that says pip==19.0.2 fixes that


### Tests

- [x] My PR adds the following unit tests __OR__ does not need testing for this extremely good reason:

### Commits

- [x] My commits all reference Jira issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)"":
  1. Subject is separated from body by a blank line
  1. Subject is limited to 50 characters (not including Jira issue reference)
  1. Subject does not end with a period
  1. Subject uses the imperative mood (""add"", not ""adding"")
  1. Body wraps at 72 characters
  1. Body explains ""what"" and ""why"", not ""how""

### Documentation

- [x] In case of new functionality, my PR adds documentation that describes how to use it.
  - All the public functions and the classes in the PR contain docstrings that explain what it does
  - If you implement backwards incompatible changes, please leave a note in the [Updating.md](https://github.com/apache/airflow/blob/master/UPDATING.md) so we can assign it to a appropriate release
",# [AIRFLOW-1111] Update pip version to 19.0.2
459,"Readme update
Adding Quick Start guide to README.md. This is based off various issues from the bug bash with people asking how to run the models locally without relying on Hugging Face",# Update README.md
460,"Fix warning for qlora
Hope I didn't make a typo but this warning shouldn't happen when using qlora either. Just QOL fix.",# Fix for 4bit training
461,"DOC: fixup formula for exponentially weighted mean with input vector …
…of times? #40327

- [x] closes #40327 
- [ ] tests added / passed
- [ ] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them
- [ ] whatsnew entry
",# Fix typo in the formula of ExponentialMovingWindow
462,"Update blogs.md
Added nbshare.io as a resource for data science blogs",# Add NBShare Data Science Blog
463,"[3.11] Fix readline.c compiler warning. (GH-98738)
```
Modules/readline.c:1260:37: warning: assigning to 'char *' from 'const char *' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers]
    completer_word_break_characters =
                                    ^
```
(cherry picked from commit 29b391b1378577825a658b14764a8ff3e0b5c958)


Co-authored-by: Benjamin Peterson <benjamin@python.org>",# bpo-38498: Fix readline.c
464,"Correct variable name in YoutubeDL
",# fix #1055
465,"now ANSIBLE_KEEP_REMOTE_FILE acts as boolean
should fix #3507
",# Fix #1115
466,"Move dependency declarations from Pipfile -> setup.py
## 📚 Context

We've been using our `Pipfile` to manage all dependencies. To ensure that `pip` knows
about these dependencies, we convert the content of the `Pipfile` using `pipenv`'s
`convert_deps_to_pip` utility function and pass the output to `setuptools.setup` as the
`install_requires` argument.

This ended up being problematic when trying to get conda builds of Streamlit working without
any dependencies that don't exist in the conda default channel (`pipenv` only exists in conda-forge).
When looking for ways to resolve this, I noticed [some documentation](https://pipenv.pypa.io/en/latest/advanced/#pipfile-vs-setup-py) and [a GitHub issue](https://github.com/pypa/pipenv/issues/1263) that suggest
that a library's `Pipfile` shouldn't be used for managing its non-dev requirements, and that we should
define the dependencies directly in `setup.py`.

- What kind of change does this PR introduce?

  - [x] Refactoring
  - [x] Other, please describe: dependency reorganization
",# Remove Pipfile
467,"Add useful always existing windows file
Adding always existing file in recent Windows machine. Ideal to test path traversal but nothing much interesting inside",# Added license.rtf and eula.txt
468,"Add Phind Provider
Add release_curl in url_cffi requets
Support create image response in Bing",# Add Phind provider
469,"fix Ajenti
fix lint to Ajenti",# Update README.md
470,"Update restapi.py
Fix attempt for https://github.com/ultralytics/yolov5/issues/7288#issuecomment-1089911155

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhancement of image loading for YOLOv5 REST API endpoint.

### 📊 Key Changes
- Removed direct read of the uploaded image file to bytes.
- Added commented-out alternative Method 1 for reading the image using a context manager.
- Implemented Method 2 involving direct read and conversion from bytes to an image.

### 🎯 Purpose & Impact
- 👍 Improves code maintainability by showing alternative approaches (though one is commented out).
- 🏃 Provides potentially more reliable image handling during upload before inference.
- 🛠️ Prepares for more flexibility in future updates due to clearer and more structured code.
- ✅ Should have no direct impact on end-users but may improve stability and backend performance.",# Fix image file read
471,"Fix various item tags (missing colons)
I.2, C.10, A.1, A.2, A.4, NL.5",# Fix broken links
472,"minor refactor loss scaler
A minor refactor of loss scaler. Adding a base class to remove duplicate code.",# [pt] refactor loss scaler
473,"cherry-pick add total text
",# update doc of pgnet
474,"style(replays): adjusted the height for the url copy bar
Closes #35408

Made the height smaller on the url copy bar on the player.

<img width=""958"" alt=""image"" src=""https://user-images.githubusercontent.com/7014871/172272137-78aa8f2c-2a33-4b16-840b-bd5bdf491f23.png"">


<!-- Describe your PR here. -->



<!--

  Sentry employees and contractors can delete or ignore the following.

-->

### Legal Boilerplate

Look, I get it. The entity doing business as ""Sentry"" was incorporated in the State of Delaware in 2015 as Functional Software, Inc. and is gonna need some rights from me in order to utilize my contributions in this here PR. So here's the deal: I retain all rights, title and interest in and to my contributions, and by keeping this boilerplate intact I confirm that Sentry can use, modify, copy, and redistribute my contributions, under Sentry's choice of terms.
",# Fix replayCurrentUrl height
475,"Use Identity instead of Seqence in SQLAlchemy 1.4 for MSSQL
Primary columns in MsSQL use IDENTITY keyword to autoincrement. Using
Sequence for those fields used to be allowed in SQLAlchemy 1.3 (and
essentially ignored if only name was specified).

See https://docs.sqlalchemy.org/en/14/dialects/mssql.html:

  Changed in version 1.4: Removed the ability to use a Sequence
  object to modify IDENTITY characteristics. Sequence objects
  now only manipulate true T-SQL SEQUENCE types.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/main/UPDATING.md).
",# Fix MSSQL compatibility in fab_security/sqla/models.pyFix MSSQL compatibility in fab_security/sqla/models.py
476,"[examples/language/roberta] remove redundant texts & update roberta
## 📝 **What does this PR do?**

> In pull request from [](https://github.com/hpcaitech/ColossalAI/pull/3472)， the PR brings redundant conflict text from **examples/language/roberta/pretraining/run_pretraining.py**, such as ""<<<<<<< HEAD"". In this PR, I remove the redundant texts above.


## 💥 Checklist before requesting a review

- [ ] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [ ] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?
- [x]🌝 Yes, I do.

",# [examples] fix roberta pretraining example
477,"Implement ruling hash to appropriate complexity of Rabin Karp
- Previous solution is based on the hash function of python.
- Implemented ruling hash to get the appropriate complexity of rabin karp.",# Rabin-Karp Algorithm
478,"Remove documentation for configuring ciphersuites (#8027)
Issue #1123 discusses a feature that allows users to set the cipher
security level. That feature wasn't built. It didn't provide enough
user value to justify the corresponding increase in complexity. The
feature request and the associated discussion threads were closed.
However, the proposed API spec and the TODO section remained in the
cipher docs. They're a vestige of that issue from olden days and this PR
removes those last living traces...

Fixes #8027.

## Pull Request Checklist

- [x] If the change being made is to a [distributed component](https://certbot.eff.org/docs/contributing.html#code-components-and-layout), edit the `master` section of `certbot/CHANGELOG.md` to include a description of the change being made.
- [x] Include your name in `AUTHORS.md` if you like.
",# Remove cipher configuration optionsThis PR removes the cipher configuration options that were previously mentioned in the ciphers.rst file.
479,"Print cause of exit in red text
Certbot writes logging messages at the warning level or higher to the terminal in red text. It turns out fatal errors aren't always printed in red though.

I noticed this when testing https://github.com/certbot/certbot/pull/7984. Relevant output looks like:
![Screen Shot 2020-05-18 at 10 22 11 AM](https://user-images.githubusercontent.com/6504915/82241751-8ab6d680-98f1-11ea-8f7d-da725874ac95.png)

The fatal error message here is ""Could not find ssl_module; not installing certificate."" but it's not given any special significance and I think it's harder to see because of the other red text and the important notes section.

While we have plans to remove the important notes section in the future, I personally think another thing we should do here is to display the fatal error in red as well which is done in this PR.

I started to add tests here, but I think we're pretty well covered by the existing tests checking that `SystemExit` is raised and that the error message is written to the terminal in all cases. I'm happy to add more if there's something in particular the reviewer of this PR thinks should be tested.",# Use logger to print error messages
480,"When loading recent messages, filter by the user's stored language.
A simple short term fix.  Applies to #962.  To fully fix a small backend change is needed.",# Show the language in the recent messages title
481,"Add detect.py --hide-conf --hide-labels --line-thickness options
Three minor changes

- command line argument for specifying line thickness of bounding boxes, if not set defaults to 3 (the previous value)
- option to hide class labels (defaults to False)
- option to hide confidence values (defaults to False)

If none of the new parameters are set, nothing changes.

**Use case**
I have small images where only one class is detected. The labels and bounding boxes occlude most of the image making it hard to visually evaluate the results.
See also #2550


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhanced customization for object detection visual outputs in YOLOv5.

### 📊 Key Changes
- Added flexibility to hide labels and confidences on detection outputs.
- Introduced argument to adjust bounding box line thickness.

### 🎯 Purpose & Impact
- **Purpose**: Allows users to control how detection results are visualized, making it easier to produce cleaner images for presentations or to respect privacy constraints.
- **Impact**: Users gain finer control over the visualization aspect of object detection, possibly improving the user experience for both developers presenting results and end users consuming those results. 🎨",# Add bounding box thickness and hide labels/confidence
482,"Use new DeviceClass enums in lutron_caseta
## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Use constants from homeassistant.components.*
483,"More release enhancements
Automatically removes `SIGFILEBALL` after creating signature in `offline-sigrequest.sh`.
",# Remove letsencrypt-auto-source/letsencrypt-auto.sig.lzma.base64
484,"Unit test for string containing multi-byte UTF-8 #6586
There are two tests here. One demonstrating existing, correct behavior for `data=bytes`, and another, failing, test for the case where `data=string` and the string contains multi-byte UTF-8.",# Test for content length for bytes data
485,"Added Heroku to the list of third-party plugins
I published a new plugin for Heroku. Simply adding it to the list of third-party plugins.",# Add heroku plugin to using.rst
486,"Fix modifiers triggering key down checks for undo history
Fixes modifier keys triggering multiple history entries, e.g. previously shift+drag/alt+drag and move node would store each position while it was being dragged rather than just the start/end of the drag events",# Fix undo/redo on mac
487,"Typo
",# Fix README.md
488,"Bump opower to 0.4.0


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
https://github.com/tronikos/opower/compare/v0.3.1...v0.4.0

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [x] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] I have followed the [perfect PR recommendations][perfect-pr]
- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [x] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [x] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
",# Update opower to 0.4.0
489,"Add: Litmus Chaos and Chaos Mess for chaos engineering
Signed-off-by: Nicolas Lamirault <nicolas.lamirault@gmail.com>",# Add k8s.chaos
490,"Update mlx_worker to be async
Generate tokens asynchronously (using run_in_threadpool) to avoid blocking FastAPI thread.

<!-- Thank you for your contribution! -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number (if applicable)

<!-- For example: ""Closes #1234"" -->

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).
",# Fix mlx worker
491,"Upgrade GitHub Actions
",# Update GitHub Actions
492,"fix doc of quant demo
",# fix slim quantization doc
493,"deleted A*.py
Duplicate File",# delete A*.py
494,"Fix misuse of empty cursor in downloader
Fixes https://github.com/oobabooga/text-generation-webui/issues/1371

Maybe they changed their API.  This, however, works.",# Fix download_model.py
495,"cpplint: add filter `whitespace/forcolon`
",# Fix pre-commit
496,"Fix crash when using body filters
They still don't work, but at least the web interface won't crash.",# fix typo
497,"👷 Update build docs, verify README on CI
👷 Update build docs, verify README on CI",# 📝 Fix docs workflow📝 Fix docs workflow
498,"fix format
remove bert from model zoo",# Remove.init files
499,"test car models: fix random hanging
Running locally, I reproduced a similar failure to the one seen in CI recently. It would get stuck downloading the front camera video, which was unnecessary, and was probably only done to make unlogger happy. Not having to download those videos each time should speed up the test a bit. Also added a timeout to the request so it doesn't just wait forever.

Fixes #1043 ",# fix unlogger
500,"Bump the github-actions group with 4 updates
Bumps the github-actions group with 4 updates: [actions/checkout](https://github.com/actions/checkout), [actions/setup-python](https://github.com/actions/setup-python), [actions/upload-artifact](https://github.com/actions/upload-artifact) and [actions/cache](https://github.com/actions/cache).

Updates `actions/checkout` from 3.6.0 to 4.1.1
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/releases"">actions/checkout's releases</a>.</em></p>
<blockquote>
<h2>v4.1.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Update CODEOWNERS to Launch team by <a href=""https://github.com/joshmgross""><code>@​joshmgross</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1510"">actions/checkout#1510</a></li>
<li>Correct link to GitHub Docs by <a href=""https://github.com/peterbe""><code>@​peterbe</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1511"">actions/checkout#1511</a></li>
<li>Link to release page from what's new section by <a href=""https://github.com/cory-miller""><code>@​cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1514"">actions/checkout#1514</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/joshmgross""><code>@​joshmgross</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1510"">actions/checkout#1510</a></li>
<li><a href=""https://github.com/peterbe""><code>@​peterbe</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1511"">actions/checkout#1511</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.0...v4.1.1"">https://github.com/actions/checkout/compare/v4.1.0...v4.1.1</a></p>
<h2>v4.1.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Update README.md for V4 by <a href=""https://github.com/sivapalan""><code>@​sivapalan</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1452"">actions/checkout#1452</a></li>
<li>Add support for partial checkout filters by <a href=""https://github.com/finleygn""><code>@​finleygn</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1396"">actions/checkout#1396</a></li>
<li>Prepare 4.1.0 release by <a href=""https://github.com/cory-miller""><code>@​cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1496"">actions/checkout#1496</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/sivapalan""><code>@​sivapalan</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1452"">actions/checkout#1452</a></li>
<li><a href=""https://github.com/finleygn""><code>@​finleygn</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1396"">actions/checkout#1396</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.0.0...v4.1.0"">https://github.com/actions/checkout/compare/v4.0.0...v4.1.0</a></p>
<h2>v4.0.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Update default runtime to node20 by <a href=""https://github.com/takost""><code>@​takost</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1436"">actions/checkout#1436</a></li>
<li>Support fetching without the --progress option by <a href=""https://github.com/simonbaird""><code>@​simonbaird</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1067"">actions/checkout#1067</a></li>
<li>Release 4.0.0 by <a href=""https://github.com/takost""><code>@​takost</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1447"">actions/checkout#1447</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/takost""><code>@​takost</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1436"">actions/checkout#1436</a></li>
<li><a href=""https://github.com/simonbaird""><code>@​simonbaird</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1067"">actions/checkout#1067</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v3...v4.0.0"">https://github.com/actions/checkout/compare/v3...v4.0.0</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/blob/main/CHANGELOG.md"">actions/checkout's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
<h2>v4.1.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1396"">Add support for partial checkout filters</a></li>
</ul>
<h2>v4.0.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1067"">Support fetching without the --progress option</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1436"">Update to node20</a></li>
</ul>
<h2>v3.6.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1377"">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/579"">Add option to fetch tags even if fetch-depth &gt; 0</a></li>
</ul>
<h2>v3.5.3</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1196"">Fix: Checkout fail in self-hosted runners when faulty submodule are checked-in</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1287"">Fix typos found by codespell</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1369"">Add support for sparse checkouts</a></li>
</ul>
<h2>v3.5.2</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1289"">Fix api endpoint for GHES</a></li>
</ul>
<h2>v3.5.1</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1246"">Fix slow checkout on Windows</a></li>
</ul>
<h2>v3.5.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1237"">Add new public key for known_hosts</a></li>
</ul>
<h2>v3.4.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1209"">Upgrade codeql actions to v2</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1210"">Upgrade dependencies</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1225"">Upgrade <code>@​actions/io</code></a></li>
</ul>
<h2>v3.3.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1045"">Implement branch list using callbacks from exec function</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1050"">Add in explicit reference to private checkout options</a></li>
<li>[Fix comment typos (that got added in <a href=""https://redirect.github.com/actions/checkout/issues/770"">#770</a>)](<a href=""https://redirect.github.com/actions/checkout/pull/1057"">actions/checkout#1057</a>)</li>
</ul>
<h2>v3.2.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/942"">Add GitHub Action to perform release</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/967"">Fix status badge</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1002"">Replace datadog/squid with ubuntu/squid Docker image</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/964"">Wrap pipeline commands for submoduleForeach in quotes</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1029"">Update <code>@​actions/io</code> to 1.1.2</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1039"">Upgrading version to 3.2.0</a></li>
</ul>
<h2>v3.1.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/939"">Use <code>@​actions/core</code> <code>saveState</code> and <code>getState</code></a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/922"">Add <code>github-server-url</code> input</a></li>
</ul>
<h2>v3.0.2</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/checkout/commit/b4ffde65f46336ab88eb53be808477a3936bae11""><code>b4ffde6</code></a> Link to release page from what's new section (<a href=""https://redirect.github.com/actions/checkout/issues/1514"">#1514</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/8530928916aaef40f59e6f221989ccb31f5759e7""><code>8530928</code></a> Correct link to GitHub Docs (<a href=""https://redirect.github.com/actions/checkout/issues/1511"">#1511</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/7cdaf2fbc075e6f3b9ca94cfd6cec5adc8a75622""><code>7cdaf2f</code></a> Update CODEOWNERS to Launch team (<a href=""https://redirect.github.com/actions/checkout/issues/1510"">#1510</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/8ade135a41bc03ea155e62e844d188df1ea18608""><code>8ade135</code></a> Prepare 4.1.0 release (<a href=""https://redirect.github.com/actions/checkout/issues/1496"">#1496</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/c533a0a4cfc4962971818edcfac47a2899e69799""><code>c533a0a</code></a> Add support for partial checkout filters (<a href=""https://redirect.github.com/actions/checkout/issues/1396"">#1396</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/72f2cec99f417b1a1c5e2e88945068983b7965f9""><code>72f2cec</code></a> Update README.md for V4 (<a href=""https://redirect.github.com/actions/checkout/issues/1452"">#1452</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/3df4ab11eba7bda6032a0b82a6bb43b11571feac""><code>3df4ab1</code></a> Release 4.0.0 (<a href=""https://redirect.github.com/actions/checkout/issues/1447"">#1447</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/8b5e8b768746b50394015010d25e690bfab9dfbc""><code>8b5e8b7</code></a> Support fetching without the --progress option (<a href=""https://redirect.github.com/actions/checkout/issues/1067"">#1067</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/97a652b80035363df47baee5031ec8670b8878ac""><code>97a652b</code></a> Update default runtime to node20 (<a href=""https://redirect.github.com/actions/checkout/issues/1436"">#1436</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/checkout/compare/f43a0e5ff2bd294095638e18286ca9a3d1956744...b4ffde65f46336ab88eb53be808477a3936bae11"">compare view</a></li>
</ul>
</details>
<br />

Updates `actions/setup-python` from 4.7.0 to 4.7.1
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v4.7.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Bump word-wrap from 1.2.3 to 1.2.4 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/702"">actions/setup-python#702</a></li>
<li>Add range validation for toml files by <a href=""https://github.com/dmitry-shibanov""><code>@​dmitry-shibanov</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/726"">actions/setup-python#726</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v4...v4.7.1"">https://github.com/actions/setup-python/compare/v4...v4.7.1</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236""><code>65d7f2d</code></a> Add range validation for toml files (<a href=""https://redirect.github.com/actions/setup-python/issues/726"">#726</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/f97b83114c6f41cfaa57698147ad3ce20543a127""><code>f97b831</code></a> Bump word-wrap from 1.2.3 to 1.2.4 (<a href=""https://redirect.github.com/actions/setup-python/issues/702"">#702</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/setup-python/compare/61a6322f88396a6271a6ee3565807d608ecaddd1...65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236"">compare view</a></li>
</ul>
</details>
<br />

Updates `actions/upload-artifact` from 3.1.2 to 3.1.3
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/upload-artifact/releases"">actions/upload-artifact's releases</a>.</em></p>
<blockquote>
<h2>v3.1.3</h2>
<h2>What's Changed</h2>
<ul>
<li>chore(github): remove trailing whitespaces by <a href=""https://github.com/ljmf00""><code>@​ljmf00</code></a> in <a href=""https://redirect.github.com/actions/upload-artifact/pull/313"">actions/upload-artifact#313</a></li>
<li>Bump <code>@​actions/artifact</code> version to v1.1.2 by <a href=""https://github.com/bethanyj28""><code>@​bethanyj28</code></a> in <a href=""https://redirect.github.com/actions/upload-artifact/pull/436"">actions/upload-artifact#436</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/upload-artifact/compare/v3...v3.1.3"">https://github.com/actions/upload-artifact/compare/v3...v3.1.3</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/upload-artifact/commit/a8a3f3ad30e3422c9c7b888a15615d19a852ae32""><code>a8a3f3a</code></a> Merge pull request <a href=""https://redirect.github.com/actions/upload-artifact/issues/436"">#436</a> from bethanyj28/main</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/7b48769c030f7121ecb01c3558dd3cd8b9660a20""><code>7b48769</code></a> update dependency cache</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/66630398dfe3d04deb4c489ac54b9b468f071706""><code>6663039</code></a> update dist/index.js</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/55e76b779da56f582e27a6f7aff54c1e610551e5""><code>55e76b7</code></a> bump <code>@​actions/artifact</code> version</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/65d862660abb392b8c4a3d1195a2108db131dd05""><code>65d8626</code></a> chore(github): remove trailing whitespaces (<a href=""https://redirect.github.com/actions/upload-artifact/issues/313"">#313</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/upload-artifact/compare/0b7f8abb1508181956e8e162db84b466c27e18ce...a8a3f3ad30e3422c9c7b888a15615d19a852ae32"">compare view</a></li>
</ul>
</details>
<br />

Updates `actions/cache` from 3.3.1 to 3.3.2
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/cache/releases"">actions/cache's releases</a>.</em></p>
<blockquote>
<h2>v3.3.2</h2>
<h2>What's Changed</h2>
<ul>
<li>Fixed readme with new segment timeout values by <a href=""https://github.com/kotewar""><code>@​kotewar</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1133"">actions/cache#1133</a></li>
<li>Readme fixes by <a href=""https://github.com/kotewar""><code>@​kotewar</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1134"">actions/cache#1134</a></li>
<li>Updated description of the lookup-only input for main action by <a href=""https://github.com/kotewar""><code>@​kotewar</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1130"">actions/cache#1130</a></li>
<li>Change two new actions mention as quoted text by <a href=""https://github.com/bishal-pdMSFT""><code>@​bishal-pdMSFT</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1131"">actions/cache#1131</a></li>
<li>Update Cross-OS Caching tips by <a href=""https://github.com/pdotl""><code>@​pdotl</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1122"">actions/cache#1122</a></li>
<li>Bazel example (Take <a href=""https://redirect.github.com/actions/cache/issues/2"">#2</a>️⃣) by <a href=""https://github.com/vorburger""><code>@​vorburger</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1132"">actions/cache#1132</a></li>
<li>Remove actions to add new PRs and issues to a project board by <a href=""https://github.com/jorendorff""><code>@​jorendorff</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1187"">actions/cache#1187</a></li>
<li>Consume latest toolkit and fix dangling promise bug by <a href=""https://github.com/chkimes""><code>@​chkimes</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1217"">actions/cache#1217</a></li>
<li>Bump action version to 3.3.2 by <a href=""https://github.com/bethanyj28""><code>@​bethanyj28</code></a> in <a href=""https://redirect.github.com/actions/cache/pull/1236"">actions/cache#1236</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/vorburger""><code>@​vorburger</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/cache/pull/1132"">actions/cache#1132</a></li>
<li><a href=""https://github.com/jorendorff""><code>@​jorendorff</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/cache/pull/1187"">actions/cache#1187</a></li>
<li><a href=""https://github.com/chkimes""><code>@​chkimes</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/cache/pull/1217"">actions/cache#1217</a></li>
<li><a href=""https://github.com/bethanyj28""><code>@​bethanyj28</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/cache/pull/1236"">actions/cache#1236</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/cache/compare/v3...v3.3.2"">https://github.com/actions/cache/compare/v3...v3.3.2</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/actions/cache/blob/main/RELEASES.md"">actions/cache's changelog</a>.</em></p>
<blockquote>
<h1>Releases</h1>
<h3>3.0.0</h3>
<ul>
<li>Updated minimum runner version support from node 12 -&gt; node 16</li>
</ul>
<h3>3.0.1</h3>
<ul>
<li>Added support for caching from GHES 3.5.</li>
<li>Fixed download issue for files &gt; 2GB during restore.</li>
</ul>
<h3>3.0.2</h3>
<ul>
<li>Added support for dynamic cache size cap on GHES.</li>
</ul>
<h3>3.0.3</h3>
<ul>
<li>Fixed avoiding empty cache save when no files are available for caching. (<a href=""https://redirect.github.com/actions/cache/issues/624"">issue</a>)</li>
</ul>
<h3>3.0.4</h3>
<ul>
<li>Fixed tar creation error while trying to create tar with path as <code>~/</code> home folder on <code>ubuntu-latest</code>. (<a href=""https://redirect.github.com/actions/cache/issues/689"">issue</a>)</li>
</ul>
<h3>3.0.5</h3>
<ul>
<li>Removed error handling by consuming actions/cache 3.0 toolkit, Now cache server error handling will be done by toolkit. (<a href=""https://redirect.github.com/actions/cache/pull/834"">PR</a>)</li>
</ul>
<h3>3.0.6</h3>
<ul>
<li>Fixed <a href=""https://redirect.github.com/actions/cache/issues/809"">#809</a> - zstd -d: no such file or directory error</li>
<li>Fixed <a href=""https://redirect.github.com/actions/cache/issues/833"">#833</a> - cache doesn't work with github workspace directory</li>
</ul>
<h3>3.0.7</h3>
<ul>
<li>Fixed <a href=""https://redirect.github.com/actions/cache/issues/810"">#810</a> - download stuck issue. A new timeout is introduced in the download process to abort the download if it gets stuck and doesn't finish within an hour.</li>
</ul>
<h3>3.0.8</h3>
<ul>
<li>Fix zstd not working for windows on gnu tar in issues <a href=""https://redirect.github.com/actions/cache/issues/888"">#888</a> and <a href=""https://redirect.github.com/actions/cache/issues/891"">#891</a>.</li>
<li>Allowing users to provide a custom timeout as input for aborting download of a cache segment using an environment variable <code>SEGMENT_DOWNLOAD_TIMEOUT_MINS</code>. Default is 60 minutes.</li>
</ul>
<h3>3.0.9</h3>
<ul>
<li>Enhanced the warning message for cache unavailablity in case of GHES.</li>
</ul>
<h3>3.0.10</h3>
<ul>
<li>Fix a bug with sorting inputs.</li>
<li>Update definition for restore-keys in README.md</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/cache/commit/704facf57e6136b1bc63b828d79edcd491f0ee84""><code>704facf</code></a> Merge pull request <a href=""https://redirect.github.com/actions/cache/issues/1236"">#1236</a> from actions/bethanyj28/bump-version</li>
<li><a href=""https://github.com/actions/cache/commit/17e2888746ae4cdbac78cbb1a45a157d310c0e53""><code>17e2888</code></a> Add to RELEASES.md</li>
<li><a href=""https://github.com/actions/cache/commit/667d8fdfa213683cee9fcaad43be0f25322bef02""><code>667d8fd</code></a> bump action version to 3.3.2</li>
<li><a href=""https://github.com/actions/cache/commit/f7ebb81a3f195b4fb88dab7c14e2f7aff52045aa""><code>f7ebb81</code></a> Consume latest toolkit and fix dangling promise bug (<a href=""https://redirect.github.com/actions/cache/issues/1217"">#1217</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/67b839edb68371cc5014f6cea11c9aa77238de78""><code>67b839e</code></a> Merge pull request <a href=""https://redirect.github.com/actions/cache/issues/1187"">#1187</a> from jorendorff/jorendorff/rm-add-to-project</li>
<li><a href=""https://github.com/actions/cache/commit/57f0e3f198251983d70fc3c83e71b973822da983""><code>57f0e3f</code></a> Remove actions to add new PRs and issues to a project board</li>
<li><a href=""https://github.com/actions/cache/commit/04f198bf0b2a39f7230a4304bf07747a0bddf146""><code>04f198b</code></a> Merge pull request <a href=""https://redirect.github.com/actions/cache/issues/1132"">#1132</a> from vorburger/bazel-example</li>
<li><a href=""https://github.com/actions/cache/commit/bd9b49b6c3b91fb2f92c80901a466ba260a746eb""><code>bd9b49b</code></a> Merge branch 'main' into bazel-example</li>
<li><a href=""https://github.com/actions/cache/commit/ea0503788c59256f4da17725d04df850ca027df5""><code>ea05037</code></a> Merge pull request <a href=""https://redirect.github.com/actions/cache/issues/1122"">#1122</a> from actions/pdotl-patch-1</li>
<li><a href=""https://github.com/actions/cache/commit/6a1a45d49b4738670d9804cd9a8fee56a01b6bf2""><code>6a1a45d</code></a> Merge branch 'main' into pdotl-patch-1</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/cache/compare/88522ab9f39a2ea568f7027eddc7d8d8bc9d59c8...704facf57e6136b1bc63b828d79edcd491f0ee84"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore <dependency name> major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)
- `@dependabot ignore <dependency name> minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)
- `@dependabot ignore <dependency name>` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)
- `@dependabot unignore <dependency name>` will remove all of the ignore conditions of the specified dependency
- `@dependabot unignore <dependency name> <ignore condition>` will remove the ignore condition of the specified dependency and ignore conditions


</details>",# Update GitHub Actions
501,"Make results column sticky
## Description

Closes https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/7896, per suggestion of @missionfloyd 

Makes results column sticky, with a fix to make it work with Gradio 3.39.0. This will still function properly if the column happens to extend further towards the bottom, and will still always let you scroll to the bottom.

## Screenshots/videos:

https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/122327233/8beeaf90-ff29-4e57-b155-6c08007ec2ef

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Fix img2img results column
502,"start少重命名了一处
",# fix post_update.py
503,"👷 Fix logic for when to install and use MkDocs Insiders
👷 Fix logic for when to install and use MkDocs Insiders",# Update GitHub Actions workflow to use v08 cache key
504,"Update data.json to add Filmo.gs
Just added the site for Filmo.gs and verified tests. ",# Added Filmogs
505,"Fix memory handling and error handling in utils.ssl.get_temp_key_info.
Found in #3892. Tested on xenial with various pyOpenSSL and cryptography combinations.",# Fix #1595
506,"Store birthday dates
This program helps us to store data about our friends’ birthdays. I have created a program with the names as keys 
and the birthdays as values. We can also add new dates in this program very easily",# Added birthdays program
507,"Add `export.py` ONNX inference suggestion


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Improvements to model export feedback in the Ultralytics YOLOv5 repository.

### 📊 Key Changes
- Added additional output message guiding users on how to run ONNX model inference after successful export.
- Improved error visibility in export failure by adding a line break before the error message.

### 🎯 Purpose & Impact
- The new output message provides clear instructions for using the exported ONNX model, making it easier for users to understand the next steps. 🧭
- Formatting the error message with a preceding line break increases its visibility, helping users to quickly identify export issues. 🚨

This PR enhances user experience by streamlining the process and guidance provided after model export, leading to a more intuitive workflow for YOLOv5 users.",# Add export success message
508,"Add problem 23 solution
This PR adds the solution to the Project Euler's problem 23",# Added solution for problem 23
509,"Allow full screen button to show for dataframes, charts, etc in expander
<!--
Before contributing (PLEASE READ!)

⚠️ If your contribution is more than a few lines of code, then prior to starting to code on it please post in the issue saying you want to volunteer, then wait for a positive response. And if there is no issue for it yet, create it first.

This helps make sure:

  1. Two people aren't working on the same thing
  2. This is something Streamlit's maintainers believe should be implemented/fixed
  3. Any API, UI, or deeper architectural changes that need to be implemented have been fully thought through by Streamlit's maintainers
  4. Your time is well spent!

More information in our wiki: https://github.com/streamlit/streamlit/wiki/Contributing
-->

## 📚 Context
https://github.com/streamlit/streamlit/issues/5694
_Please describe the project or issue background here_
Fullscreen button can't be found because the overflow is hidden so just setting the parent div to overflow: visible will solve this.
Solution was found by: @LukasMasuch 

- What kind of change does this PR introduce?

  - [x] Bugfix
  - [ ] Feature
  - [ ] Refactoring
  - [ ] Other, please describe:

## 🧠 Description of Changes
- _Add bullet points summarizing your changes here_

  - [ ] This is a breaking API change
  - [x] This is a visible (user-facing) change

**Revised:**
_Insert screenshot of your updated UI/code here_
![Screenshot 2023-02-08 at 11 07 47 AM](https://user-images.githubusercontent.com/16749069/217629584-a6ce8b9e-ec64-4dab-b338-97b513c9af69.png)


**Current:**
![Screenshot 2023-02-08 at 11 16 51 AM](https://user-images.githubusercontent.com/16749069/217629763-439d27a2-2548-4d30-8540-6ee4ffea632f.png)

_Insert screenshot of existing UI/code here_

## 🧪 Testing Done

- [x] Screenshots included
- [ ] Added/Updated unit tests
- [ ] Added/Updated e2e tests

## 🌐 References

_Does this depend on other work, documents, or tickets?_

- **Issue**: Closes #5694 

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",# Allow fullscreen button to show
510,"Integrate MBPP benchmarks
Solves https://github.com/gpt-engineer-org/gpt-engineer/issues/914

Run with `python3 gpt_engineer/benchmark gpt_engineer/core/default/simple_agent.py mbpp`

Here are my results running for the first 47 tasks using `gpt-4-0125-preview` model

```
--- Results ---
Total time: 465.19s
Completely correct tasks: 40/47
Total correct assertions: 123/142
Average success rate: 86.52482269503545% on 47 tasks
--- Results ---
```",# Add MBPP benchmark
511,"Move Nginx TLS configuration files into a specific folder
Following discussions in #7298.

This PR moves the three Nginx TLS configuration files into a specific folder, `tls_configs`, update the MANIFEST to include this folder and its content into the `certbot-nginx` package, and update tests accordingly.",# Move nginx tls config files to tls_configs
512,"opt cpu speed and fix wrong link of weights
",# [chinese_db_crnn_mobile] fix the inference model
513,"UI: add flag for showing map render
",# Add map render view
514,"Add placebear API
- [x] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added PlaceBear API
515,"Add links for latency based and geolocation based routing
Added Amazon AWS public docs link for better understanding of latency based and geo-location based routing.",# Add links to AWS Route 53 routing policies
516,"Consider hiding the api-key
Some people share screenshots with their API key visible.
Using getpass to hide the key should be considered

### Describe the changes you have made:
Added getpass to hide the key.

### Reference any relevant issue (Fixes #000)

- [x] I have performed a self-review of my code:

### I have tested the code on the following OS:
- [x] Windows
- [ ] MacOS
- [ ] Linux

### AI Language Model (if applicable)
- [ ] GPT4
- [ ] GPT3
- [ ] Llama 7B
- [ ] Llama 13B
- [ ] Llama 34B
- [ ] Huggingface model (Please specify which one)
",# Hide OpenAI API key
517,"init ProxyConfig.certstore with custom certs
It seems, you just forget to initialize custom certs. :-)
",# Add support for multiple cert files
518,"[hotfix] ColoTensor pin_memory
",# [Tensor] Add device to ColoTensor
519,"Copy the mtime from the oldest source file to the file created by ffmpeg
This fixes #4245.

I tested this with Python 2.7.8 and Python 3.4.1 on Windows 7.  The mtime is now correctly set when using `-f bestvideo+bestaudio`.

`--no-mtime` still works as expected.
",# Set the timestamp of the output file to the oldest input fileFixes #1085
520,"Fixes: #3869: Optimize CI runtime of Project Euler's Problem 74's Solution 2


fixes: #3869 

### **Describe your change:**

- Optimize Project Euler's Problem 74's  Solution #2 using caches of factorials and sums of factorials of digits of a number
- Fix typo for Project Euler's Problem 74's  Solution #1 because of which it wasn't running on CI for running solutions


* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### **Checklist:**
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms have a URL in its comments that points to Wikipedia or other similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",# Add new problems to the directory
521,"Fixing the way we generate the backenduser object during jwt creation
",# Fix user display name
522,"Fixed #30388 -- Made inspectdb generate OneToOneFields rather than ForeignKey(unique/primary_key=True).
",# Fixed #28613 -- Added OneToOneField to inspectdb's output.
523,"Slot colors by type
This PR set the color of slots by type, so you can see what connects where without dragging the connection.

![image](https://user-images.githubusercontent.com/5104869/227709219-2a038ea2-822f-44d4-832c-95cdef55a448.png)

P.S.: colors created by chat GPT to be distinguishable, if it was a bad choice of colors blame the chat GPT 😁",# Add slot color setup
524,"Add Scorecard Action to monitor Keras' security posture
Fixes #18906.

This PR adds the Scorecard Action to monitor Keras' security posture.

I can also add a badge to the project's README if you're interested: [![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/keras-team/keras/badge)](https://securityscorecards.dev/viewer/?uri=github.com/keras-team/keras)
",# Add GitHub Actions workflow for Scorecard
525,"DOC fix broken links in faq.rst and glossary.rst
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->


#### What does this implement/fix? Explain your changes.
This PR fixes two broken links:
1. In `glossary.rst` [this](https://contrib.scikit-learn.org/categorical-encoding) broken link was replaced with [this](https://github.com/scikit-learn-contrib/category_encoders) one.
2. In `faq.rst` [this](https://scikits.appspot.com/scikits) broken link was removed completely since no equivalent was found.

",# DOC: Update links to scikit-learn contrib
526,"try fix google 503
基于性能和复杂度考虑，没有检查内容，不知道有没有误检。

试了很多次搜索还是没触发 503，懒得试了。。。",# fix gae proxy
527,"Delete conflicting server_names for random28524
This fixes the same problem in the config under `nginx-roundtrip-testdata` as the one I fixed in https://github.com/certbot/certbot/pull/8248 for the nginx compatibility test.",# Remove duplicate server_name directives
528,"Updated CKA.md
resolved some issues, I hot it was helpful.",# Fix some typos in CKA.md
529,"Fix the wrong link
Fix the wrong link for ""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks""
",# Update babi_memnn.py
530,"Fix stop tokens in `gen_model_answer.py`
## Why are these changes needed?

Some models (e.g. StarChat) have special tokens the stop strings. In such cases the generation is not split properly because with `skip_special_tokens=True` they are removed during decoding. The proposed change keeps them during decoding and removes them after splitting off the proper substring.
",# fix xgen output
531,"Deprecate non-keyword arguments in mask
- [x] xref #41485
- [x] tests added / passed
- [x] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them
- [x] whatsnew entry
",# DEPR: mask positional argumentsCloses #41485
532,"[docs] Fix image segmentation guide
Fixes #30058:

- adds import for Accelerate
- adds code snippet to view image but also keeps viewing the metadata as well since imo its important to see the other fields in there
- reloads the dataset in the Inference section
- adds the `ade_palette` colormap manually so the code snippet just runs (let me know if there is a better way to import the colormap!)",# Update semantic segmentation guide
533,"Corrected tutorial05 method name
The code examples use the method assertIs() while the docs used assertEqual()
",# Fixed typo in tutorial05.txt
534,"Added 1 More Python Program to Extract Tables From docx,txt and PDF
Added 1 More Python Program to Extract Tables From docx,txt and PDF",# Extract-Table-from-pdf-txt-docx
535,"Nissan: use bus 0 to fingerprint
Closes: https://github.com/commaai/openpilot/issues/25755

Follow up to https://github.com/commaai/openpilot/pull/31138

Once we go to release we'll get a lot more data and can merge

- [x] NISSAN X-TRAIL 2017 - everything comes back! fa9224be239005c7|2024-01-31--17-57-19
- [x] NISSAN LEAF 2018 - everything comes back! 289d318fded3221a|2024-01-31--17-35-48
- [x] NISSAN LEAF 2018 Instrument Cluster - probably works
- [ ] NISSAN ROGUE 2019
- [ ] NISSAN ALTIMA 2020",# Fix Nissan RX offset
536,"Mongo index creation
- [ ] Title: Mongodb: MongoDB connection performance improvement. 
- [ ] Message: 
    - **Description:** I made collection index_creation as optional. Index Creation is one time process.
    - **Issue:** MongoDBChatMessageHistory class object is attempting to create an index during connection, causing each request to take longer than usual. This should be optional with a parameter.
    - **Dependencies:** N/A
    - **Branch to be checked:** origin/mongo_index_creation

",# MongoDBChatMessageHistory: add create_index parameter
537,"find: Allow reading whole file for contains regex

##### SUMMARY

Change:
- Add a parameter `read_whole_file` which allows for reading the whole
  file when doing a `contains` regex search.
- This allows for (for example) matching a pattern at the very end of
  a file.

Test Plan:
- New integration tests

Tickets:
- Fixes #63378

Signed-off-by: Rick Elrod <rick@elrod.me>

<!--- Describe the change below, including rationale and design decisions -->

<!--- HINT: Include ""Fixes #nnn"" if you are fixing an existing issue -->

##### ISSUE TYPE
<!--- Pick one below and delete the rest -->
- Feature Pull Request


##### COMPONENT NAME

find module",# find: add read_whole_file parameter##### SUMMARYThis PR adds a read_whole_file parameter to the find module. This allows for the whole file to be read into memory and the regex to be applied to the whole file.##### ISSUE TYPE- Feature Pull Request##### COMPONENT NAMEfind module
538,"removed a pitfall where the code was using a default mutable argument
**The problem**
In Python it usually dangerous to use mutable arguments like dicts or lists as default arguments in method, as is better explained [here](https://docs.python-guide.org/writing/gotchas/)

**the solution**
This PR applies a simple refactoring to remove a case where a method was created using default a mutable argument",# Fixing the default value of file_names in find_tf_idf
539,"Clean up cartpole environment.
Improve legibility and adhere to PEP-8.
I left some long lines (the physics equations) as I am not sure whether breaking them up really improves readability.",# Fix cartpole
540,"Update kens github
His website points to https://github.com/ken-reitz, kennethreitz seems to be trolling account (there is Islamophobic profile picture )


![image](https://user-images.githubusercontent.com/193832/92941329-8722fe80-f450-11ea-9ee6-86e55957b21d.png)
",# Update AUTHORS.rst
541,"FROM nvcr.io/nvidia/pytorch:22.01-py3
Reordered installation may help reduce resource usage in autobuild

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Updated the base Docker image used for YOLOv5 to a newer version.

### 📊 Key Changes
- The Dockerfile has been updated to start from a newer base image, changing from `nvcr.io/nvidia/pytorch:21.10-py3` to `nvcr.io/nvidia/pytorch:22.01-py3`.

### 🎯 Purpose & Impact
- **Improved Compatibility:** Ensures compatibility with the latest PyTorch features and CUDA optimizations.
- **Potential Performance Gains:** Users may experience improved performance and efficiency from the newer software stack.
- **Future-Proofing:** Keeps the project up-to-date with current technologies, which can simplify future updates and maintenance.",# Update Dockerfile to use PyTorch 22.01
542,"F.21: fix variable name in example and text
",# Fix typo in example
543,"Add --video_output_dir flag
Video is currently written to a directory named after the input module, which can lead to collisions if modules with the same name are used in a single project. This option allows specifying a video directory manually rather than using the default.",# Add --video_output_dir
544,"Doc notes for core team members
",# DOC: Add guidelines for merging PRs
545,"Fix error message in OpenSSL >=3.2.0
#### Description

Fix the test cases for OpenSSL v3

Ref:
https://github.com/openssl/openssl/commit/81b741f68984b2620166d0d6271fbd946bab9e7f
https://github.com/openssl/openssl/commit/4030869d24309bfb5292e7bec41cd2b3012ba99d

#### Checklist

 - [x] I have updated tests where applicable.
 - [ ] I have added an entry to the CHANGELOG.
",# Update pyOpenSSL to 24.1
546,"Bump actions/stale from 4 to 5
Bumps [actions/stale](https://github.com/actions/stale) from 4 to 5.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/stale/releases"">actions/stale's releases</a>.</em></p>
<blockquote>
<h2>v5.0.0</h2>
<h2>Features</h2>
<ul>
<li><a href=""https://github-redirect.dependabot.com/actions/stale/pull/670"">Update Runtime to node16</a></li>
</ul>
<h2>v4.1.0</h2>
<h1>Features</h1>
<ul>
<li><a href=""https://github.com/actions/stale/commit/9912fa74d1c01b5d6187793d97441019cbe325d0"">Ability to exempt draft PRs</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/actions/stale/blob/main/CHANGELOG.md"">actions/stale's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/stale/commit/3cc123766321e9f15a6676375c154ccffb12a358""><code>3cc1237</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/actions/stale/issues/670"">#670</a> from actions/thboop/node16upgrade</li>
<li><a href=""https://github.com/actions/stale/commit/76e9fbc6aed3c0c0ae07b80482afa556484462ce""><code>76e9fbc</code></a> update node version</li>
<li><a href=""https://github.com/actions/stale/commit/6467b96231c45da20bd7c8e2d2cf71eb03ea2cc5""><code>6467b96</code></a> Update default runtime to node16</li>
<li><a href=""https://github.com/actions/stale/commit/8af60513daf46d35533e7d765d4553d223d810e0""><code>8af6051</code></a> build(deps-dev): bump jest-circus from 27.2.0 to 27.4.6 (<a href=""https://github-redirect.dependabot.com/actions/stale/issues/665"">#665</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/7a7efcae1f55c298ef504dcb1c6317ae0c4d4b28""><code>7a7efca</code></a> Fix per issue operation count (<a href=""https://github-redirect.dependabot.com/actions/stale/issues/662"">#662</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/04a1828bc18ada028d85a0252a47cd2963a91abe""><code>04a1828</code></a> build(deps-dev): bump ts-jest from 27.0.5 to 27.1.2 (<a href=""https://github-redirect.dependabot.com/actions/stale/issues/641"">#641</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/65ca3956bd95319211c8614e1329c503511f4ca7""><code>65ca395</code></a> build(deps-dev): bump eslint-plugin-jest from 24.4.2 to 25.3.2 (<a href=""https://github-redirect.dependabot.com/actions/stale/issues/639"">#639</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/eee276c280fb6bde3fbc80ee2d8bdef44b0b83a6""><code>eee276c</code></a> build(deps-dev): bump prettier from 2.4.1 to 2.5.1 (<a href=""https://github-redirect.dependabot.com/actions/stale/issues/628"">#628</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/6c2f9f3f54c858dc4c197dc32a11f39cafd7dc03""><code>6c2f9f3</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/actions/stale/issues/640"">#640</a> from dmitry-shibanov/v-dmshib/fix-check-dist</li>
<li><a href=""https://github.com/actions/stale/commit/37323f14dd31b16fa32ff4f6ca4c39fa5cefc60d""><code>37323f1</code></a> fix check-dist.yml</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/stale/compare/v4...v5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/stale&package-manager=github_actions&previous-version=4&new-version=5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update stale.yml
547,"[Test] [Client] Skip `test_delay_in_rewriting_environment` on MacOS
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?
* `test_client_proxy::test_delay_in_rewriting_environment` has been quite Flaky on MacOS
* This test is **fine to skip**, because the ClientServer Proxy is used for remote clusters (which are linux).

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# [python] fix flaky test on MacOS
548,"Print cause of exceptions even when they have no traceback
Exceptions from subprocesses raised by 'multiprocessing' don't include a traceback, so rich doesn't currently print them. They contain important information though, so this PR enables printing the exception without the traceback. This works because `walk_tb` doesn't do anything if the input is `None`.

Minimal example:

```py
import rich.traceback
import multiprocessing


def fail():
    raise ValueError


if __name__ == ""__main__"":
    rich.traceback.install()
    with multiprocessing.Pool() as pool:
        # The traceback printed by rich doesn't point to the function `fail`,
        # but only to code in the `multiprocessing` module. This PR fixes that.
        pool.apply(fail)
```

Note that exceptions from multiprocessing include the traceback formatted as a string in the description of the exception (see this code in multiprocessing.pool: https://github.com/python/cpython/blob/main/Lib/multiprocessing/pool.py#L57). This will be printed by rich after this PR.

## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.
",# Fix #1595
549,"[Snyk] Security upgrade pillow from 9.5.0 to 10.3.0
<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>



#### Changes included in this PR

- Changes to the following files to upgrade the vulnerable dependencies to a fixed version:
    - requirements.txt



#### Vulnerabilities that will be fixed





##### By pinning:
Severity                   | Priority Score (*)                   | Issue                   | Upgrade                   | Breaking Change                   | Exploit Maturity
:-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------
![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"")  |  **651/1000**  <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.3  | Buffer Overflow <br/>[SNYK-PYTHON-PILLOW-6514866](https://snyk.io/vuln/SNYK-PYTHON-PILLOW-6514866) |  `pillow:` <br> `9.5.0 -> 10.3.0` <br>  |  No  | No Known Exploit 

(*) Note that the real score may have changed since the PR was raised.




Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded.


Check the changes in this PR to ensure they won't cause issues with your project.



------------



**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*

For more information:  <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NTMzOGNmMC00M2E5LTRhNTgtOWE3YS05MmE0NGM1OWIxZWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk1MzM4Y2YwLTQzYTktNGE1OC05YTdhLTkyYTQ0YzU5YjFlYSJ9fQ=="" width=""0"" height=""0""/>
🧐 [View latest project report](https://app.snyk.io/org/glenn-jocher/project/b49ff501-40a6-42c7-ab7e-b98a30f3409e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr)

🛠 [Adjust project settings](https://app.snyk.io/org/glenn-jocher/project/b49ff501-40a6-42c7-ab7e-b98a30f3409e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings)

📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities)

[//]: # (snyk:metadata:{""prId"":""95338cf0-43a9-4a58-9a7a-92a44c59b1ea"",""prPublicId"":""95338cf0-43a9-4a58-9a7a-92a44c59b1ea"",""dependencies"":[{""name"":""pillow"",""from"":""9.5.0"",""to"":""10.3.0""}],""packageManager"":""pip"",""projectPublicId"":""b49ff501-40a6-42c7-ab7e-b98a30f3409e"",""projectUrl"":""https://app.snyk.io/org/glenn-jocher/project/b49ff501-40a6-42c7-ab7e-b98a30f3409e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-PILLOW-6514866""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[651],""remediationStrategy"":""vuln""})

---

**Learn how to fix vulnerabilities with free interactive lessons:**

 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Upgraded minimum required version of Pillow in `yolov5` dependencies.

### 📊 Key Changes
- Updated the Pillow library version from `>=9.4.0` to `>=10.3.0`.

### 🎯 Purpose & Impact
- **Purpose**: The update ensures compatibility with the latest improvements and security patches in the Pillow library, which is crucial for image processing tasks in YOLOv5.
- **Impact**: Users must upgrade their Pillow installation to at least version 10.3.0. This change can help in improving performance and security but may require users to update their environments, potentially leading to temporary downtime or adjustment period for those with older versions. 🖼️✨",# Update Pillow to 10.3.0
550,"build(deps): bump xor-cipher from 3.0.1 to 3.1.0
Bumps [xor-cipher](https://github.com/xor-cipher/xor-cipher) from 3.0.1 to 3.1.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/xor-cipher/xor-cipher/blob/main/CHANGELOG.md"">xor-cipher's changelog</a>.</em></p>
<blockquote>
<h2>3.1.0 (2024-01-15)</h2>
<h3>Internal</h3>
<ul>
<li>Dropped Python 3.7 support.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/a2ccbd654b75940cf2ed5b8991cc0c922c88a8bb""><code>a2ccbd6</code></a> Another attempt.</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/6fb898d921e7ae2a4f7bf9fde458815331d3ddec""><code>6fb898d</code></a> Update workflows.</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/0187ab6973684259e49fd8a0827c4b0e7cc301ba""><code>0187ab6</code></a> Do not install poetry with pipx.</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/418cf0203318676cf864b632f3847a01747180ce""><code>418cf02</code></a> Workflows are fun...</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/8ea0d19427509536f1f269796e973b5ada362f1b""><code>8ea0d19</code></a> More workflow updates.</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/c39862a5e07336f4cfdd323067d671f12cf2d0e6""><code>c39862a</code></a> Update build script.</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/6b2e677ce27505dd5a63abed3eb50af64dfee917""><code>6b2e677</code></a> Update infrastructure.</li>
<li><a href=""https://github.com/xor-cipher/xor-cipher/commit/9781a3e29113d19fac19da7f8280e83d8e7add4a""><code>9781a3e</code></a> Update security keys.</li>
<li>See full diff in <a href=""https://github.com/xor-cipher/xor-cipher/compare/v3.0.1...v3.1.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=xor-cipher&package-manager=pip&previous-version=3.0.1&new-version=3.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update xor-cipher
551,"[downloader/http] Reject broken range before request
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Funimation seems to respond with 206 even if the start is before end, while it's supposed to respond 406. It addresses that problem.

I'm not confident with the code, but at least we can download video without corrupting anything.",# Fix #1595
552,"[ie/abc:iview] Extract episode name from title
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

This PR changes the ABC iview extractor to extract the episode name from the video title, rather than using the fallback “Episode \d” name.

Most videos are titled e.g. “Series 1 Ep 1 Episode Name”, although some (usually news programs) are titled with the year and no episode number (“Series 2023 Episode Name”), others have no episode name (“Series 1 Ep 1”), and some are missing both (“Series 2021”). All these cases are handled with a permissive regex, and tests are added for each.


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))


<!-- Do NOT edit/remove anything below this! -->
</details><details><summary>Copilot Summary</summary>  

<!--
copilot:all
-->
### <samp>🤖 Generated by Copilot at 4102bad</samp>

### Summary
🧪🗃️🐛

<!--
1.  🧪 for adding more test cases
2.  🗃️ for extracting more information from the video metadata
3.  🐛 for fixing the episode name extraction
-->
Improve `ABCIViewIE` extractor for ABC Australia videos. Add more tests, extract more metadata, and fix episode name.

> _We are the extractors of the ABCIViewIE_
> _We dig deeper into the video metadata_
> _We fix the episode names with our skill and might_
> _We test our code with fury and rigor_

### Walkthrough
* Extract episode name from title and add it to `info_dict` in `_real_extract` function of `ABCIViewIE` class (`[link](https://github.com/yt-dlp/yt-dlp/pull/8201/files?diff=unified&w=0#diff-65fb45ff5464c45c0963dd9a56a6ea7b3f85fab95e15cbd3fe360391c073051bR341-R342)`)



</details>
",# [abc] Add more tests and fix extraction
553,"add ABINet pretrained model & fix vitstr yml bug
",# fix some config
554,"Bump actions/cache from 1 to 2.1.6
Bumps [actions/cache](https://github.com/actions/cache) from 1 to 2.1.6.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/cache/releases"">actions/cache's releases</a>.</em></p>
<blockquote>
<h2>v2.1.6</h2>
<ul>
<li>Catch unhandled &quot;bad file descriptor&quot; errors that sometimes occurs when the cache server returns non-successful response (<a href=""https://github-redirect.dependabot.com/actions/cache/pull/596"">actions/cache#596</a>)</li>
</ul>
<h2>v2.1.5</h2>
<ul>
<li>Fix permissions error seen when extracting caches with GNU tar that were previously created using BSD tar (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/527"">actions/cache#527</a>)</li>
</ul>
<h2>v2.1.4</h2>
<ul>
<li>Make caching more verbose <a href=""https://github-redirect.dependabot.com/actions/toolkit/pull/650"">#650</a></li>
<li>Use GNU tar on macOS if available <a href=""https://github-redirect.dependabot.com/actions/toolkit/pull/701"">#701</a></li>
</ul>
<h2>v2.1.3</h2>
<ul>
<li>Upgrades <code>@actions/core</code> to v1.2.6 for <a href=""https://github.com/advisories/GHSA-mfwh-5m23-j46w"">CVE-2020-15228</a>. This action was not using the affected methods.</li>
<li>Fix error handling in <code>uploadChunk</code> where 400-level errors were not being detected and handled correctly</li>
</ul>
<h2>v2.1.2</h2>
<ul>
<li>Adds input to limit the chunk upload size, useful for self-hosted runners with slower upload speeds</li>
<li>No-op when executing on GHES</li>
</ul>
<h2>v2.1.1</h2>
<ul>
<li>Update <code>@actions/cache</code> package to <code>v1.0.2</code> which allows cache action to use posix format when taring files.</li>
</ul>
<h2>v2.1.0</h2>
<ul>
<li>Replaces the <code>http-client</code> with the Azure Storage SDK for NodeJS when downloading cache content from Azure.  This should help improve download performance and reliability as the SDK downloads files in 4 MB chunks, which can be parallelized and retried independently</li>
<li>Display download progress and speed</li>
</ul>
<h2>v2.0.0</h2>
<p>Initial v2 release</p>
<h2>What's new in v2</h2>
<ul>
<li>Added support for multiple paths (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/16"">actions/cache#16</a>), glob patterns, and single file caches (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/33"">actions/cache#33</a>)</li>
<li>Increased performance and improved cache sizes using <code>zstd</code> for compression for Linux and macOS runners (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/184"">actions/cache#184</a>)</li>
<li>Allowed caching for all events with a ref (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/63"">actions/cache#63</a>)</li>
<li>Created the <a href=""https://github.com/actions/toolkit/tree/master/packages/cache""><code>@actions/cache</code></a> npm package to allow other actions to utilize caching (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/55"">actions/cache#55</a>)</li>
<li>Added a best-effort step to delete the archive after extraction to reduces storage space (<a href=""https://github-redirect.dependabot.com/actions/cache/pull/209"">actions/cache#209</a>)</li>
</ul>
<h2>v1.2.0</h2>
<h1>Bug Fixes</h1>
<ul>
<li>Fall back to GNU tar on older versions of Windows that do not have BSD tar installed (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/252"">#252</a>)</li>
<li>Fixed chunk upload retry logic (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/305"">#305</a>)</li>
</ul>
<h1>Improvements</h1>
<ul>
<li>Improved reliability of the download cache APIs (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/269"">#269</a>)</li>
<li>Added retries to API calls that failed due to retryable errors (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/306"">#306</a>)</li>
<li>Improved error handling during both cache upload (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/300"">#300</a>) and download (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/284"">#284</a>)</li>
</ul>
<h2>v1.1.2</h2>
<h1>Other</h1>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/cache/commit/c64c572235d810460d0d6876e9c705ad5002b353""><code>c64c572</code></a> Catch and log unhandled exceptions stemming from closed file descriptor (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/596"">#596</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/cc2d767a726ddd654506e76169ec14b20dc75915""><code>cc2d767</code></a> Update Rust directories recommended for caching (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/433"">#433</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/2fa955d825a29821e73ec064792122ea9f70e573""><code>2fa955d</code></a> Update examples.md (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/588"">#588</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/3a696372f2ec10535e4c026a4fdae5fcca629e4a""><code>3a69637</code></a> elixir typo - stray parenthesis (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/569"">#569</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/366e5ba0224e0ebd6fba2a453d108cb20e734946""><code>366e5ba</code></a> Update cache key for Elixir (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/568"">#568</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/8d3f2fc3ce25d6c95a1297ce8d93f9c3c3ac8f00""><code>8d3f2fc</code></a> Update dependencies (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/565"">#565</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/1a9e2138d905efd099035b49d8b7a3888c653ca8""><code>1a9e213</code></a> Update cache module to v1.0.7 (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/562"">#562</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/981fa981ed950efef5277587ee4ba0eead30cadf""><code>981fa98</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/actions/cache/issues/469"">#469</a> from ericmj/patch-1</li>
<li><a href=""https://github.com/actions/cache/commit/4498c5b4d8b0673dbc7d9731bc11d9cc5a2c6087""><code>4498c5b</code></a> Drop the example based on using pip's internals (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/519"">#519</a>)</li>
<li><a href=""https://github.com/actions/cache/commit/4134e6de47156381d31ff74f8aabf86718858f70""><code>4134e6d</code></a> It is not recommended to cache node_modules (<a href=""https://github-redirect.dependabot.com/actions/cache/issues/537"">#537</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/cache/compare/v1...v2.1.6"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/cache&package-manager=github_actions&previous-version=1&new-version=2.1.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Upgrade of GitHub Actions pip caching for better efficiency.

### 📊 Key Changes
- Updated the GitHub Actions cache dependency from `actions/cache@v1` to `actions/cache@v2.1.6`.

### 🎯 Purpose & Impact
- The update aims to enhance the caching mechanism for pip in the CI (Continuous Integration) testing workflow.
- Users can expect more reliable and faster build/test times due to the improved caching strategy. 🚀",# Update actions/cache to v2.1.6
555,"added OpenCorporates
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [ ] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added OpenCorporates API
556,"Don't run tox for temporarily-disabled python versions
Additional tweak for #630 
","# Remove py26, py27, py33, py34 from tox.ini"
557,"Use latest Boulder for integration tests.
I'm open to discussion about whether we want to always run against latest Boulder (with potential flakiness), or just bring the fixed branch up to a more modern commit.",# Travis: Use GOPATH to find BoulderFixes #2045.
558,"bpo-34070: only check for isatty when buffering < 0
https://bugs.python.org/issue34070

Only check for isatty when buffering actually requires the check (buffering < 0)

<!-- issue-number: bpo-34070 -->
https://bugs.python.org/issue34070
<!-- /issue-number -->
",# bpo-34070: Fix #34070
559,"added pre-commit guides and purposely did not run pre-commit
",# Update CONTRIBUTING.md
560,"Backport PR #57089 on branch 2.2.x (BUG: wide_to_long with string columns)
Backport PR #57089: BUG: wide_to_long with string columns",# REGR: Fix regression in wide_to_long for string columnsCloses #57066
561,"Fix typo in doc
a very small diff:
  fix `paeper` -> `paper`",# Fix typo in AdamW docstring
562,"Add cppcheck as a pre-commit hook
",# cppcheck
563,"add Lob.com address verification API
The US address verification API is provided free of charge to all users. Registration is required to obtain an API key, but this can be done freely. Payment methods are required to send LIVE requests but the address verification API also works in TEST mode which you don't need to provide any payment methods for.

Proof API is free: [Lob.com Address Verification Pricing Page](https://lob.com/verification/address/pricing)
",# Added Lob.com
564,"Remove functions deprecated in 2.6.0
~The only deprecated logic that i didn't remove was:~
~- https://github.com/scrapy/scrapy/pull/5090~

~Because seems a little be tricky (should we remove the deprecated parameters?) 😄~

I will commit the removal of #5090 logic later on in this PR.",# Remove deprecated code
565,"Backwards compatibility for Python 2
The following line is not required but supposedly optimizes code.  However, this breaks on some Python 2 installations, where the future module version installed is > 0.16.  This can be a pain to revert.
```python
from builtins import range
```",# Fix for Python 2.7
566,"Add German RAV4H_TSS2 Lounge FP
2f210c724fd9f73b|2020-01-31--14-12-53--0",# Add German Lounge to Toyota values
567,"Bump AWQ to 0.1.6
Changes:
- upgrades to transformers 4.35.0 (4.35.0 is not compatible with AutoAWQ 0.1.5)
- fix performance regression (25% speedup) from previous refactor
- upgrade to torch 2.1.0 and CUDA 12.1.1

NOTE: v0.1.6 is in the process of being released, currently building https://github.com/casper-hansen/AutoAWQ/releases/tag/v0.1.6. When it is available on PyPi, I will mark this PR ready, until then it is a draft.

## Checklist:

- [x] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
",# Update autoawq to 0.1.6
568,"prevent DEFAULT_REGION's deprecation message to always show
Whenever we start localstack we're greeting with this warning message:

```
WARN --- [  MainThread] localstack.deprecations    : DEFAULT_REGION is deprecated (since 0.12.7) and will be removed in upcoming releases of LocalStack! LocalStack now has full multi-region support. Please remove this environment variable.
```

This happens even if we don't have the environment variable `DEFAULT_REGION` set.
This is because in `localstack/config.py` the check for the environment variable has a side effect of creating it if the environment variable is not set!

Later on the detection `log_deprecation_warnings()` checks kick-in and detect that the environment variable is set and issue the warning.

With this commit we're avoiding creating the environment variable.

See https://github.com/localstack/localstack/issues/7257#issuecomment-1351278444

**NOTE**: There's an extra commit to fix a typo in the python doc.
",# Set default region in configFixes #1590
569,"release version 2.2.2
",# Release 2.2.2
570,"Added updatedb (mlocate) to sudo rules
Added the pattern for ```updatedb``` (mlocate), if command is run without ```sudo``` privileges, to ```rules/sudo.py```",# Add updatedb to sudo.py
571,"Corrected link to noexcept anchor
",# Fix broken link
572,"Implement CFG for ExLlama_HF
This is done by creating an additional cache for the negative prompt when the new `--cfg-cache` flag is provided (it can also be set directly in the UI).

For ExLlama_HF + 24GB VRAM + 30b models, you need to reduce `max_seq_len` to less than 2048 for it to fit when this option is set.
",# Add CFG cache for ExLlama_HF
573,"Fixed #30426 -- Changed X_FRAME_OPTIONS setting default to DENY.
",# Fixed #28613 -- Changed default value of X_FRAME_OPTIONS to DENY.https://code.djangoproject.com/ticket/28613
574,"docs: Document target version inference
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

Resolves #4031 

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [ ] Add an entry in `CHANGES.md` if necessary? - Unnecessary, the feature already existed
- [ ] Add / update tests if necessary? - N/A
- [x] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
",# Document the default behavior of `target-version`
575,"⬆ Bump dawidd6/action-download-artifact from 2.24.0 to 2.24.1
Bumps [dawidd6/action-download-artifact](https://github.com/dawidd6/action-download-artifact) from 2.24.0 to 2.24.1.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/dawidd6/action-download-artifact/commit/b12b127cf24433d14b4f93cee62f5465076ba82a""><code>b12b127</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dawidd6/action-download-artifact/issues/205"">#205</a> from robbie-unlikelyai/handle-search-artifacts-with-m...</li>
<li><a href=""https://github.com/dawidd6/action-download-artifact/commit/0d8d56c0de87cd038c776e0443e83aa206c465a2""><code>0d8d56c</code></a> Add pagination to appropriate listWorkflowRunArtifacts call</li>
<li>See full diff in <a href=""https://github.com/dawidd6/action-download-artifact/compare/v2.24.0...v2.24.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=dawidd6/action-download-artifact&package-manager=github_actions&previous-version=2.24.0&new-version=2.24.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update action-download-artifact to v2.24.1
576,"Add missing .mean() back
## Description
as title

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Fix Lora network
577,"Store temporary DVSNI files in IConfig.work_dir.
",# Use work_dir instead of config_dir for dvsni_page
578,"I used recursive functions and made it simpler! just in a few steps
recursion and completed in few steps",# Decimal to Binary using recursion
579,"Deprecate Python 3.7 support
[Python 3.7 has reached its end of life](https://devguide.python.org/versions/).

This PR was based on #9160.",# Deprecate Python 3.7 supportPython 3.7 is no longer supported by the Python community.
580,"DOC: update the docstring of pandas.DataFrame.from_dict
Checklist for the pandas documentation sprint (ignore this if you are doing
an unrelated PR):

- [x] PR title is ""DOC: update the <your-function-or-method> docstring""
- [x] The validation script passes: `scripts/validate_docstrings.py <your-function-or-method>`
- [x] The PEP8 style check passes: `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [x] The html version looks good: `python doc/make.py --single <your-function-or-method>`
- [ ] It has been proofread on language by another sprint participant

Please include the output of the validation script below between the ""```"" ticks:

```
(pandas_dev) david@david-TM1604:~/repos/pandas$ python scripts/validate_docstrings.py pandas.DataFrame.from_dict

################################################################################
#################### Docstring (pandas.DataFrame.from_dict) ####################
################################################################################

Construct DataFrame from dict of array-like or dicts.

Creates DataFrame object from dictionary by columns or by index
allowing dtype specification.

Parameters
----------
data : dict
    Of the form {field : array-like} or {field : dict}.
orient : {'columns', 'index'}, default 'columns'
    The ""orientation"" of the data. If the keys of the passed dict
    should be the columns of the resulting DataFrame, pass 'columns'
    (default). Otherwise if the keys should be rows, pass 'index'.
dtype : dtype, default None
    Data type to force, otherwise infer.
columns : list, default None
    Column labels to use when orient='index'. Raises a ValueError
    if used with orient='columns'.
    .. versionadded:: 0.23.0

See Also
--------
pandas.DataFrame.from_records : DataFrame from ndarray (structured dtype),
                                list of tuples, dict, or DataFrame
pandas.DataFrame: DataFrame object creation using constructor

Returns
-------
pandas.DataFrame

Examples
--------
>>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}
>>> pd.DataFrame.from_dict(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d

>>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}
>>> pd.DataFrame.from_dict(data, orient='index')
       0  1  2  3
row_1  3  2  1  0
row_2  a  b  c  d

################################################################################
################################## Validation ##################################
################################################################################

Errors found:
	Errors in parameters section
		Parameter ""columns"" description should finish with "".""
```

If the validation script still gives errors, but you think there is a good reason
to deviate in this case (and there are certainly such cases), please state this
explicitly.


Checklist for other PRs (remove this part if you are doing a PR for the pandas documentation sprint):

- [ ] closes #xxxx
- [ ] tests added / passed
- [ ] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [ ] whatsnew entry
",# DOC: improve docstring for DataFrame.from_dict
581,"add thirdparty docs
add thirdparty docs
move the javaspringboot demo",# thirdparty
582,"feat(metrics): group by tag warning icon
- closes #68877  

https://github.com/getsentry/sentry/assets/86684834/94bcb2d9-d1b1-4123-96ca-8420dd15c5f0
",# feat(metrics): Show warning when a tag is used in filter conditionsThis PR adds a warning when a tag is used in filter conditions.
583,"Fix Localstack region is always null in getAccepterVpcInfo after vpc …
- Patch function describe_vpc_peering_connections
- Add integration test

Issue fixed:
Localstack region is always null in getAccepterVpcInfo after vpc peering #2147
",# Add region to vpc_peering_connectionsFixes #2147
584,"clean up gamma variable names
",# real_debayer: use gamma apply
585,"The spelling and grammatical errors in the Polish translation of readme.md have been corrected.
The spelling and grammar errors have been corrected.",# Polish translation update
586,"Fix packit CI
Currently, the package in the Fedora repositories doesn't match the master, since we've added a new command. But packit doesn't know that and tries to build from the master with the 2.6.0 release spec file. This patch reconfigures packit to use our own locally hosted specfile.",# Fedora specfile
587,"[ `PreTrainedTokenizerFast`] Keep properties from fast tokenizer
# What does this PR do?
Start a potential fix to #24179, ended up being releated to #24441, calling modifies the values of the underlying tokenizer, but never changes anything on the surface so will probably add some kind of warning in the documentation. 

TLDR; adds the possibility  of initialize a `PreTrainedTokenizerFast` from a `tokenizer.Tokenizer`, keeping the `padding` and `truncation` informations. 

",# [tokenizer] Save and load tokenizer with truncation and padding
588,"Update mailing list information in DOAP
The mailing list link in DOAP is rendered as ""mailto:"" link at the https://projects.apache.org/project.html?airflow page so we should change it to regular email address.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",# Update doap_airflow.rdf
589,"No domains in cli.ini
This is a small set of changes to the example `cli.ini` to mitigate a recurring bug where people list their domains there with `domains =` and then are unable to renew at all (due to the renewer rejecting `-d`). This tries to make clear that this is for systemwide defaults that apply to every cert on the system.",# Update cli.ini example
590,"Clarification of Phases in Extract
When multi-processing, the status bar description lists the current phase as only Detect. This is misleading and there likely should be a reference to the multiple simultaneous phases being run.

![image](https://user-images.githubusercontent.com/3772434/70369121-0e1bc880-187a-11ea-8ad8-a077a48efa14.png)
",# Add phase description to extraction
591,"vmware_guest: doc fix
##### ISSUE TYPE
 - Docs Pull Request

##### COMPONENT NAME
vmware_guest

##### ANSIBLE VERSION
```
ansible 2.2.0.0
```

##### SUMMARY
Fix a wrong documentation key name
",# Fix vmware_guest network configFixes #20811
592,"Create instruction template for Llama-v2
",# Add Llama-v2 to the config
593,"mistral function calling notebook
",# Add example for mistralai function calling
594,"add routing by embedding doc
",# Add example of using embeddings to route to most similar prompt
595,"[beeg] update test cases
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Explanation of your *pull request* in arbitrary form goes here. Please make sure the description explains the purpose and effect of your *pull request* and is worded well enough to be understood. Provide as much context and examples as possible.
",# [beeg] update md5
596,"Cleans up pre-commits a little
Few cleanups of pre-commits:

* moving non-image-dependent pre-commits before image building
* add setuptools as requirement for provider's dependency pre-commit
* force python 3.6 for all image-dependent pre-commits

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/main/UPDATING.md).
",# [ci] fix pre-commit
597,"Bump furo from 2023.7.26 to 2023.8.19 in /docs + sphinx to 7.2.3
Bumps [furo](https://github.com/pradyunsg/furo) from 2023.7.26 to 2023.8.19.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pradyunsg/furo/blob/main/docs/changelog.md"">furo's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
<!-- raw HTML omitted -->
<h2>2023.08.19 -- Xenolithic Xanadu</h2>
<ul>
<li>Fix missing search context with Sphinx 7.2, for dirhtml builds.</li>
<li>Drop support for Python 3.7.</li>
<li>Present configuration errors in a better format -- thanks <a href=""https://github.com/AA-Turner""><code>@​AA-Turner</code></a>!</li>
<li>Bump <code>require_sphinx()</code> to Sphinx 6.0, in line with dependency changes in Unassuming Ultramarine.</li>
</ul>
<h2>2023.08.17 -- Wonderous White</h2>
<ul>
<li>Fix compatiblity with Sphinx 7.2.0 and 7.2.1.</li>
</ul>
<h2>2023.07.26 -- Vigilant Volt</h2>
<ul>
<li>Fix compatiblity with Sphinx 7.1.</li>
<li>Improve how content overflow is handled.</li>
<li>Improve how literal blocks containing inline code are handled.</li>
</ul>
<h2>2023.05.20 -- Unassuming Ultramarine</h2>
<ul>
<li>✨ Add support for Sphinx 7.</li>
<li>Drop support for Sphinx 5.</li>
<li>Improve the screen-reader label for sidebar collapse.</li>
<li>Make it easier to create derived themes from Furo.</li>
<li>Bump all JS dependencies (NodeJS and npm packages).</li>
</ul>
<h2>2023.03.27 -- Tasty Tangerine</h2>
<ul>
<li>Regenerate with newer version of sphinx-theme-builder, to fix RECORD hashes.</li>
<li>Add missing class to Font Awesome examples</li>
</ul>
<h2>2023.03.23 -- Sassy Saffron</h2>
<ul>
<li>Update Python version classifiers.</li>
<li>Increase the icon size in mobile header.</li>
<li>Increase admonition title bg opacity.</li>
<li>Change the default API background to transparent.</li>
<li>Transition the API background change.</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pradyunsg/furo/commit/0766bb2d6d0392bf90d4e4ac447ae721fa673ee9""><code>0766bb2</code></a> Prepare release: 2023.08.19</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/807d73cb1080a1c9b8321a1dcffd84aee73e859a""><code>807d73c</code></a> Update changelog</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/364b2611f27e463cd1f879bf348975c01294ffc0""><code>364b261</code></a> Accomodate for the required <code>data-content_root</code> for search</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/0d38bc6cffc528ce3cf742fe2bd20e83c46d7891""><code>0d38bc6</code></a> Simplify retrieval of <code>pygments_dark_style</code> value (<a href=""https://redirect.github.com/pradyunsg/furo/issues/699"">#699</a>)</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/3631ffc4ea2f241b89bbd9b6c9d76e52a4226c56""><code>3631ffc</code></a> Use <code>sphinx.errors.ConfigError</code> (<a href=""https://redirect.github.com/pradyunsg/furo/issues/697"">#697</a>)</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/d2e2448852752ec570313bc1daea3bda56069816""><code>d2e2448</code></a> Remove duplicate HTML builder check (<a href=""https://redirect.github.com/pradyunsg/furo/issues/698"">#698</a>)</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/7b4f1308832e99d8e49c80f24665e938673c1644""><code>7b4f130</code></a> Drop Python 3.7 (<a href=""https://redirect.github.com/pradyunsg/furo/issues/701"">#701</a>)</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/e322b71b10c959cce0af80d3ac6934725ce728bb""><code>e322b71</code></a> Remove pointless assert (<a href=""https://redirect.github.com/pradyunsg/furo/issues/702"">#702</a>)</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/ee2097a797e92f1155a17287d063b3181f137115""><code>ee2097a</code></a> Bump <code>require_sphinx()</code> to Sphinx 6.0 (<a href=""https://redirect.github.com/pradyunsg/furo/issues/700"">#700</a>)</li>
<li><a href=""https://github.com/pradyunsg/furo/commit/c1ff10b768aaa2a2e479bbf8d58187e12a2731ac""><code>c1ff10b</code></a> Back to development</li>
<li>Additional commits viewable in <a href=""https://github.com/pradyunsg/furo/compare/2023.07.26...2023.08.19"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=furo&package-manager=pip&previous-version=2023.7.26&new-version=2023.8.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update Sphinx to 7.2.3
598,"Iteration on issue and PR templates
## Proposed change
<!-- 
    Describe the big picture of your changes here to communicate to the
    maintainers why we should accept this pull request. If it fixes a bug
    or resolves a feature request, be sure to link to that issue in the 
    additional information section.
-->

Small iteration on the new PR & Issue templates:

- Changed title of issue template, to make it more consistent in the template chooser.
- Adjusted title of the docs bug report, apparently having a `/` in the title doesn't work.
- Improved the PR template on how it looks when editting it, also added more info to the Quality Scale and a friendly footnote 😄 

## Type of change
<!--
    What types of changes does your PR introduce to our documention/website?
    Put an `x` in the boxes that apply. You can also fill these out after
    creating the PR.
-->

- [x] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix or feature that would cause existing functionality not to work as expected)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
    Details are important, and help maintainers processing your PR.
    Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
    Put an `x` in the boxes that apply. You can also fill these out after
    creating the PR. If you're unsure about any of them, don't hesitate to ask.
    We're here to help! This is simply a reminder of what we are going to look
    for before merging your code.
-->

- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]

[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Update PR template
599,"fix: correctly set preset config and loras in meta parser
fixes https://github.com/lllyasviel/Fooocus/issues/2566",# Fix preset loading
600,"Fixing iosxr return documentation in module.
##### SUMMARY
<!--- Describe the change, including rationale and design decisions -->
In the RETURN section it listed updates, but the module does not return anything with that key.

##### ISSUE TYPE
<!--- Pick one below and delete the rest: -->
 - Bugfix Pull Request

##### COMPONENT NAME
<!--- Name of the module/plugin/module/task -->
iosxr_config

##### ANSIBLE VERSION
<!--- Paste verbatim output from ""ansible --version"" between quotes below -->
```
$ ansible --version
ansible 2.5.0 (iosxr_doc 78b69e87f2) last updated 2017/11/27 09:44:12 (GMT -700)
  config file = None
  configured module search path = [u'/Users/james/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /Users/james/Documents/git/ansible/lib/ansible
  executable location = /Users/james/Documents/git/ansible/bin/ansible
  python version = 2.7.13 (default, Jul 18 2017, 09:17:00) [GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]
```
",# Fix iosxr_config docstring
601,"Add python-tgpt to related projects
Addresses the concern discussed #1553",# Add python-tgpt
602,"Add: MLX Framework
",# Add MLX
603,"Fix: warning for mode in render with python 3.6
Previously, the warning for the mode argument of `render` was not showing for a problem with Python 3.6. This should fix this.",# Fix #449
604,"Add Thai translation link
",# Add Thai translation
605,"Keep retrieval score after reranking
# Description
for some reranker, the score will be overwritten by reranker.
this way will keep the original retrieval score for downstream purpose for better ranking

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [ ] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] I have added Google Colab support for the newly added notebooks.
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] I ran `make format; make lint` to appease the lint gods
",# Add keep_retrieval_score to sbert_rerank
606,"Makes semi_supervised_pendulum envs pass determinism tests
These envs now use seeds from their parent.
",# Use np_random instead of numpy.random
607,"Add PrintNightmare exploit using WebDAV
",# Update Active Directory Attack.md
608,"Add playwright to nightly & release workflows
## Describe your changes

This PR adds the playwright e2e test workflow as part of our release(-candidate) and nightly workflows.

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",# Add playwright tests to nightly and release workflows
609,"VMware: restructure docs
##### SUMMARY
Moved `docs/docsite/rst/scenario_guides/guide_vmware.rst` to respective section of `docs/docsite/rst/vmware`.
And some misc. changes.

Signed-off-by: Abhijeet Kasurde <akasurde@redhat.com>

##### ISSUE TYPE
 - Docs Pull Request

##### COMPONENT NAME
docs/docsite/rst/scenario_guides/guide_vmware.rst
docs/docsite/rst/scenario_guides/guides.rst
docs/docsite/rst/vmware/faq.rst
docs/docsite/rst/vmware/vmware_intro.rst
docs/docsite/rst/vmware/vmware_troubleshooting.rst

##### ANSIBLE VERSION
<!--- Paste verbatim output from ""ansible --version"" between quotes below -->
```
2.7-devel
```",# VMware docs cleanup
610,"Redirect cache
When web clients like Firefox get a redirect they will not go after the old version any more even if you type it into the address bar.
This patch makes the requests framework work in the same way.
This helps performance when creating a request proxy that delegates to other servers based on URL.
This patch has me going from 245 requests per second to 470 requests per second against a server returning 308 response codes.

-- example server
https://gist.github.com/ericfrederich/a004862e1da1fb6916ef
-- example client
https://gist.github.com/ericfrederich/e1225e2d07e3ee923b27
-- example server output of 301 vs 302 redireects
https://gist.github.com/ericfrederich/b77bd4852a3cf9b968f0
",# Cache permanent redirects
611,"Add failed and success count stats to feedstorage backends
Resolves https://github.com/scrapy/scrapy/issues/3947

Example:
```
import scrapy
from scrapy.crawler import CrawlerProcess


class QuotesToScrapeSpider(scrapy.Spider):
    name = ""quotes""

    custom_settings = {
        ""DOWNLOAD_DELAY"": 1,
        ""COOKIES_DISABLED"": True,  # mistyped, should be enabled
        ""CONCURRENCY"": 5,
        ""FEEDS"": {
            ""file:///tmp/tmp-%(batch_time)s.json"": {
                ""format"": ""json"",
            },
            ""s3://mybucket/path/to/export-%(batch_time)s.csv"": {
                ""format"": ""csv"",
            },
        },
        ""FEED_EXPORT_BATCH_ITEM_COUNT"": 5,
    }

    def start_requests(self):
        yield scrapy.Request(url='http://quotes.toscrape.com/', callback=self.parse)

    def parse(self, response):
        for quote in response.css(""div.quote""):
            yield {
                ""quote"": quote.css(""span.text::text"").extract(),
                ""author"": quote.css(""small.author::text"").extract(),
                ""tags"": quote.css(""a.tag::text"").extract()
            }
            break
        next = response.css(""li.next a::attr(href)"").extract_first()
        if next:
            yield scrapy.Request(url=response.urljoin(next), callback=self.parse)


process = CrawlerProcess()
process.crawl(QuotesToScrapeSpider)
process.start()
```
if S3 fails to store, stats will be:
```
{'downloader/request_bytes': 2692,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 23026,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'elapsed_time_seconds': 11.61577,
 'feedexport/failed_count/S3FeedStorage': 2,
 'feedexport/success_count/FileFeedStorage': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 10, 17, 20, 41, 6, 16674),
 'item_scraped_count': 10,
 'log_count/DEBUG': 218,
 'log_count/ERROR': 2,
 'log_count/INFO': 16,
 'memusage/max': 70389760,
 'memusage/startup': 70389760,
 'request_depth_max': 9,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2020, 10, 17, 20, 40, 54, 400904)}
```
Ready to review :smile: ",# [MRG+1] Add stats for feed export
612,"docs: use modern tsig-keygen util in certbot-dns-rfc2136
Fixes #7206.

I think it's about time we did this:

- `dnssec-keygen` on new distros doesn't support the HMAC algorithms anymore, so our instructions don't work.
- The oldest distros we support are Debian Buster (`9.11.5.P4+dfsg-5.1+deb10u7`) and CentOS 7 (`9.11.4-26.P2.el7_9.9`), which ship `tsig-keygen` and support `HMAC-SHA512`.

I am not sure why the linked issue suggests that we have to wait for Bind 9.13.

Before:

<img width=""738"" alt=""image"" src=""https://user-images.githubusercontent.com/311534/193734528-b100831c-acf6-4c6c-8285-7925febd0420.png"">

After:

<img width=""739"" alt=""image"" src=""https://user-images.githubusercontent.com/311534/193734562-0a81041e-31bc-4bbb-854a-b5ada48147ee.png"">

",# Update documentation for tsig-keygenThe `tsig-keygen` command was introduced in BIND 9.10.0.
613,"FIX raise error in HDBSCAN with precomputed X and request centers
closes #27893 

Raise a proper `ValueError` when requesting storing center and `metric=""precomputed""`.",# [MRG+1] HDBSCAN: Raise ValueError when store_centers is requested with precomputed metricFixes #27893
614,"Readability
Hey @vinta 

just improving the readability a bit..

Cheers!",# Fix typo in README.md
615,"Encapsulate force_command in _get_raw_command
Using the `force_command` argument will run into issues as the `_get_raw_command` method simply returns the value of `force_command` (which is a string) while it should actually return a list.

To reproduce the issue:

```bash
$ fuck --force-command 'cd foo'
cd d f o o [enter/↑/↓/ctrl+c]
$ cd foo
-bash: cd: foo: No such file or directory
$ fuck
mkdir -p foo && cd foo [enter/↑/↓/ctrl+c]
```

This bug is fixed by splitting the `force_command`:

```bash
$ fuck --force-command 'cd foo'
mkdir -p foo && cd foo [enter/↑/↓/ctrl+c]
```

Fixes #1240",# Fix #111
616,"fix conversational retrieval docs
",# Fix formatting in conversational retrieval template
617,"Fix the numerical_test by using `tf_keras` instead of `tensorflow.keras`
To ensure the `numerical_test`, compares between Keras 3 and Keras 2,
we use `tf_keras` for Keras 2.",# Fix import tensorflow.keras in numerical_test.py
618,"Allow notification interface to not wrap text
This leaves existing prints in place but allows new code to not wrap text.",# Add wrap to notificationFixes #4444
619,"Recursive batch img2img.py
Searches sub directories and performs img2img batch processing, also limits inputs to jpg, webp, and png. Then saves to output directory with relative paths.

Made this for personal use, but don't see why it isn't the default case as far as subdirectories. Can certainly see the image format limiter being an issue but was necessary to filter out directories the way it was written and didn't bother to change to a more generic isfile check.

 - OS: windows
 - Browser: chrome
 - Graphics card: nvidia 4090
",# img2img: fix batch output dir
620,"Added a python function to load the file for easier use in (python) code.
",# Add a naughtystrings module
621,"Remove 'www' subdomain from URLs
",# Fix broken links
622,"Bump moto-ext to 3.0.5
Bump moto-ext to latest version 3.0.5 (should hopefully fix builds on `master`).",# Update moto-ext to 3.0.5
623,"[TubeTuGraz] Add new extractor
### Before submitting a *pull request* make sure you have:
- [X] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [X] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
  - This is a port of [Youtube-DL#29160](https://github.com/ytdl-org/youtube-dl/pull/29160) to yt-dlp
  - [Youtube-DL#26778](https://github.com/ytdl-org/youtube-dl/pull/26778) is similar, but with less features. I have talked to @ruru4143, and he has suggested creating a new PR for this and closing the old one
- [X] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [X] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
  - I have written the bulk of the extractor code from scratch
- [X] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)
  - Some of the code is inspired by @ruru4143's PR, who released it under the Unlicense according to that post. 

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [X] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Add support for extracting videos from [tube.tugraz.at](https://tube.tugraz.at), the lecture video site from Graz University of Technology.

Features:

- extract videos
- extract playlists
- extract restricted videos and playlists if login details are provided
- attempt fallback formats if metadata cannot be downloaded
- formats are assigned human-readable `format_id`s
- ""presentation"" formats are preferred over ""presenter"" formats

Reading the original PR ([Youtube-DL#29160](https://github.com/ytdl-org/youtube-dl/pull/29160)) might be useful, since the comments to that PR contain some discussion about the detailed design.

The original PR got stalled because of coding style issues, although the maintainer of Youtube-DL refused to elaborate on what exactly was the issue. I tried to follow the coding style guidelines as closely as possible, and I can't really see an issue.

I skimmed the YT-DLP coding style guidelines as well, and it appears nothing has changed compared to Youtube-DL's. If I misread that, and the coding style did change, please mention it so I can fix it.",# [tube.tugraz.at] Add extractor
624,"Remove unnecessary parentheses from `with` statements
### Description
Closes #2921 and closes #2952. Aims to remove redundant parentheses from `with` statements:
![Screen-Recording-2022-03-15-at-17 20 39](https://user-images.githubusercontent.com/80432516/158435983-705c0e92-bd9a-434b-95ef-6c15ecc68664.gif)

I currently have one failing test [tests/data/parenthesized_context_managers.py](https://github.com/psf/black/blob/main/tests/data/parenthesized_context_managers.py) since this code now removes unnecessary parentheses around one-line `with` statements, so think I'll just need to update the test to reflect this. 
I tried looking in the contributing docs but couldn't see any info on how the tests work so please could you advise on where I should add this?

This is my first time contributing to black so let me know if there's anything I've missed 😄 

Thanks!

- [X] Add a CHANGELOG entry if necessary?
- [x] Add / update tests if necessary?
- [x] Add new / update outdated documentation?",# Remove unnecessary parentheses from `with` statements
625,"Added: Cross-Site WebSocket Hijacking (CSWSH)
Hi

This adds Cross-Site WebSocket Hijacking (CSWSH).

Cool repo btw :)

Best regards,
Emanuel",# Added CSWSH
626,"Remove redundant SQS ARN helper
This PR removes a redundant SQS ARN helper.

Ext codebase is not impacted.",# Remove get_sqs_queue_url
627,"[myvideoge] Add new extractor
From old PR #26283 (DMCAed repo) by @fonkap:

## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/ytdl-org/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/ytdl-org/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/ytdl-org/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [ ] Improvement
- [x] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

New extractor for the site https://www.myvideo.ge/ 

Supersedes, closes #26283.",# [myvideo.ge] new extractor
628,"update space_video_api arg: page size
error msg: Key: 'SearchArg.Ps' Error:Field validation for 'Ps' failed on the 'lte' tag",# fix bilibili video api
629,"docs: describe how to modify renewal config
This rewrites the ""Modifying the Renewal Configuration File"" section of the User Guide into a ""Modifying the Renewal Configuration of Existing Certificates"" section, in a way which is more in line with how we want users to interact with existing certificates.

It is a (hopefully) a temporary stopgap, as discussed last week, until we can implement `--dry-run-and-save`.

----

- The title has been changed, but the HTML anchor has been preserved, to not break existing links
- This heavily de-emphasizes modification of the renewal configuration files. 
- This removes the previous example of modifying the files, which was to relocate the symlinks. In my judgement, this example is not relevant today.
- ~~Not super happy about describing the steps in an abstract way and then in a practical/example way. Maybe they are mergeable somehow?~~

![image](https://user-images.githubusercontent.com/311534/142389697-3f1f3fa0-cc11-47ab-836c-1af7b0011b47.png)

",# Improve the renewal configuration file documentation
630,"alerts: escalate soft disable alert near disengagement
fixes #23086",# Soft disable timer
631,"Bump aqlm[cpu,gpu] from 1.1.0 to 1.1.2
Bumps [aqlm[cpu,gpu]](https://github.com/Vahe1994/AQLM) from 1.1.0 to 1.1.2.
<details>
<summary>Commits</summary>
<ul>
<li>See full diff in <a href=""https://github.com/Vahe1994/AQLM/commits"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aqlm[cpu,gpu]&package-manager=pip&previous-version=1.1.0&new-version=1.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update aqlm to 1.1.2
632,"fix: issue template
",# [ISSUE_TEMPLATE] Update issue templates
633,"Add standalone Dockerfile for NVIDIA Jetson
[X] Add support for text-generation-webui on NVIDIA Jetson embedded devices",# Add Dockerfile for Jetson
634,"selector.__repr__ test
Some may consider it redundant, I won't argue.
But discussions and pull requests on selector's methods come and go these days (referring to extract_one, join etc) so I thought some extra coverage may prove useful later.
Which means I have a patch in mind and I need some test coverage before working on it and opening a PR
",# Fix #1055: Selector representation
635,"REF: move templated index.pyx code to non-template
Following cleanup of libalgos, we can get a little bit of code out of the tempita file.",# BACKPORT: TST: Add ObjectEngine to index.pyxBackport PR #15915 on branch 0.13.x (see #15916)
636,"fix(types): colorChip
Small change to prevent types from being wrongly merged/narrowed (I'm trying to warm up my fingers after vacation with a few small PR's)",# fix(docs): fix type errors in colorChip
637,"Remove unused import from the `table_movie.py` example
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [x] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [ ] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Removed the unused import of `from rich.measure import Measurement` from the `examples/table_movie.py`.",# Fix table_movie.py
638,"delist all blinktrade exchanges: vtbc, foxbit, surbitcoin
https://github.com/ccxt/ccxt/pull/9007#issuecomment-831783692

^ No REST API docs and it is impossible to find any volume data

Also no REST API for fetchMarkets

Brazilian reals supported on Binance: https://www.binance.com/en/support/faq/2604a5d35bd947d485dc30d865539e3e","# foxbit, surbitcoin, vbtc: remove"
639,"Update data for Julia language
Fixes #605 .
Added Flux and various packages by JuliaText for Natural Language Processing.",# Add Julia NLP packages
640,"[codeowners] change ray-ci to ray-ci-reviewers
using ray-ci for the team, and reviewers for gate keeping reviewers.
",# [ci] Update CODEOWNERS
641,"gh-115317: Rewrite changelog filter to use vanilla JavaScript
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y] <title from the original PR> (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->

Sphinx removed the jQuery library to improve performance, but the changelog filter was still using it. This PR rewrites it to use basic JavaScript. 


<!-- gh-issue-number: gh-115317 -->
* Issue: gh-115317
<!-- /gh-issue-number -->

# Demo

https://cpython-previews--115324.org.readthedocs.build/en/115324/whatsnew/changelog.html

",
642,"Added new external link
I added an external article in which I briefly explain how to build an Apache Kafka producer / consumer with FastAPI and aiokafka. Could not find something similar out there, so I hope it helps somebody else.",# 📝 Add Apache Kafka producer and consumer with FastAPI and aiokafka📝 Add Apache Kafka producer and consumer with FastAPI and aiokafka
643,"Remove tls-sni integration tests
This PR is a part of the tls-sni-01 removal plan described in #6849.

This PR removes the tls-sni-01 challenge tests during the integration tests. The approach I used here is not to remove completely the existing test code, but simply editing it to use a http-01 challenge. Indeed:
* the current integration tests are strongly coupled, and would require more modifications that it is worth, because ...
* the certbot-ci project, that has already no tls-sni tests, will soon replace completely the current integration tests code.",# Remove tls-sni-01 from testsThis PR removes tls-sni-01 from tests.
644,"Add a simple example of custom authentication in the documentation
",# Add example of custom authentication
645,"[qqmusic] Add support for playlists
For example: http://y.qq.com/#type=taoge&id=3462654915
",# [qqmusic] add playlist extractor
646,"huobi.fetchMarkets unified
```
             id |               symbol |           base | quote | settle |    baseId | quoteId | settleId |   type |  spot | margin |  swap | future | option | active | contract | linear | inverse | taker | maker | contractSize |        expiry |           expiryDatetime | strike | optionType |                                        precision |                                                                              limits
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
          gtbtc |               GT/BTC |             GT |   BTC |        |        gt |     btc |          |   spot |  true |  false | false |  false |  false |   true |    false |        |         | 0.002 | 0.002 |              |               |                          |        |            |         {""amount"":0.01,""price"":1e-8,""cost"":1e-8} |                                                                     [object Object]
Waiting for the debugger to disconnect...
...
        ksmusdt |             KSM/USDT |            KSM |  USDT |        |       ksm |    usdt |          |   spot |  true |   true | false |  false |  false |   true |    false |        |         | 0.002 | 0.002 |              |               |                          |        |            |      {""amount"":0.001,""price"":0.0001,""cost"":1e-8} |                                                                     [object Object]
      FIL220211 |   FIL/USD:FIL-220211 |            FIL |   USD |    FIL |       FIL |     USD |      FIL | future | false |  false | false |   true |  false |   true |     true |  false |    true |       |       |           10 | 1644566400000 | 2022-02-11T08:00:00.000Z |        |            |                       {""amount"":1,""price"":0.001} | {""leverage"":{""min"":1,""max"":1,""superMax"":1},""amount"":{},""price"":{},""cost"":{""min"":0}}
       SAND-USD |        SAND/USD:SAND |           SAND |   USD |   SAND |      SAND |     USD |     SAND |   swap | false |  false |  true |  false |  false |   true |     true |  false |    true |       |       |           10 |               |                          |        |            |                      {""amount"":1,""price"":0.0001} | {""leverage"":{""min"":1,""max"":1,""superMax"":1},""amount"":{},""price"":{},""cost"":{""min"":0}}
       MANA-USD |        MANA/USD:MANA |           MANA |   USD |   MANA |      MANA |     USD |     MANA |   swap | false |  false |  true |  false |  false |   true |     true |  false |    true |       |       |           10 |               |                          |        |            |                      {""amount"":1,""price"":0.0001} | {""leverage"":{""min"":1,""max"":1,""superMax"":1},""amount"":{},""price"":{},""cost"":{""min"":0}}
1296 objects
```",# huobi: add leverage info
647,"Render height fix
## Type of changes

- [x] Bug fix
- [ ] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Fixes the following example:

```python
    from rich.console import Console
    from rich.padding import Padding

    console = Console()
    options = console.options.update_height(1)

    padding = Padding(""hello"", pad=(1, 1, 1, 1))
    console.render_lines(padding, options=options)
```

The height is ending up negative when specified as 1, because we subtract the vertical padding from it (1-2 = -1). It gets passed to `itertools.islice` in `render_lines` as the ""stop"" argument, and that bombs out.",# Fix render_lines crash when render height was negativeFixes #389
648,"Allow to enable/disable email signin via env variable
close #911 ",# feat: add env var for email signin
649,"Refs #30451 -- Added HttpRequest._set_content_type_params() hook.
",# Fixed #28613 -- Refactored WSGIRequest._set_content_type_params() to use cgi.parse_header() instead of urlparse.parse_qs() to parse the content type.
650,"Tests for Proxy config
",# Add tests for proxy config
651,"Weights & Biases (W&B) Feature Addition
## What does this PR do?
This is a cleaned-up and updated version of this PR [#1108](https://github.com/ultralytics/yolov5/pull/1108) which adds W&B logging support.
Updates:

- The code no longer typecasts co-ordinates into `float` before passing them to the logging dictionary.
- Reformatted the code
Some of the import statement orders didn't pass through the PEP8 linter but these were not related to the changes I have made to I didn't edit them.


## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhanced YOLOv5 logging with Weights & Biases integration for better experiment tracking and visualization 📈.

### 📊 Key Changes
- Added Weights & Biases (`wandb`) logging as a dependency in `requirements.txt`.
- Included an option in `test.py` to log images with predictions during testing.
- Updated `train.py` function signature to accept a `wandb` parameter for logging.
- Initialized `wandb` logging in `train.py` to track experiments and log model performance metrics and hyperparameters.
- Implemented functionality to save wandb run ID in checkpoints to resume logging from a specific point.
- Provided an option in the argument parser of `train.py` to set the number of images logged to `wandb`.

### 🎯 Purpose & Impact
- **Enhanced Experiment Tracking**: Enabling `wandb` integration supports researchers and developers in tracking experiments, comparing results, and visualizing model performance more effectively.
- **Better Visualization**: Logging images with predictions allows for quick and easy qualitative analysis of the model's performance.
- **Streamlined Workflows**: Saving the `wandb` run ID in checkpoints allows users to continue logging from a specific point without starting a new logging instance, ensuring continuity in metric tracking.
- **Customization**: Users can customize the number of images they want to log via the `--log-imgs` command-line argument, tailoring the verbosity of visual logging to their needs.

In summary, these updates will make it simpler for users to monitor, analyze, and share their YOLOv5 model training and testing processes, promoting more informed and iterative machine learning development. 🚀",# W&B logging
652,"[youku] fix cookie's issue
fix #845 
refer to http://www.cnblogs.com/zhxilin/p/4993074.html

<!-- Reviewable:start -->

[<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/soimort/you-get/847)

<!-- Reviewable:end -->
",# Youku cookie
653,"Fix the training script for syncing lastest ckpt
",# Sync local checkpoint files
654,"TST: Test groupby for columns with string objects
- [ ] closes #24196 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

@phofl 
@noatamir 
@jorisvandenbossche 
@MarcoGorelli 


",# BUG: groupby.sum on nan should return nancloses #24196
655,"Remove CoinDesk API
The [CoinDesk](http://www.coindesk.com/api/) link was present, but pointed to a 404-page. The endpoint seems to still be working ([example](https://api.coindesk.com/v1/bpi/currentprice.json)), but is nowhere documented or mentioned by CoinDesk, hence the removal from this list.

Alternatively, we could update the CoinDesk API link to be this one endpoint, without any further context or documentation available.
```
| [CoinDesk](https://api.coindesk.com/v1/bpi/currentprice.json) | Bitcoin Price Index | No | No | Unknown |
```
",# Remove CoinDesk
656,"add GPT-J ONNX config to Transformers
# What does this PR do?

I'm looking for contributing to `Transformers` repository by adding more OnnxConfig to available models on the hub.
I have created a little organization [ONNXConfig for all](https://huggingface.co/OWG) to track the models that needs support for ONNX.

This is the first contribution since CamemBERT OnnxConfig some months ago.

I took example on `GPT2` and `GPT-Neo` OnnxConfig but I'm not sure if everything is good or if `GPT-J` needs special things to be added.

So this PR is a work in progress. If anyone can send me ressources to read to understand if it lacks anything, it would be awesome! :hugs: 

## Who can review?

Models GPT2 / GPT-Neo
@LysandreJik @michaelbenayoun 
",# Add GPT-J onnx config
657,"Added 2020 RX350 fwdRadar f/w x018821F3301100
@ottopilot#7631 DongleID/route 3a5c5101bd71ad5d|2020-06-18--16-56-51",# Toyota: add missing forward radar value
658,"Add changelog entry about #7054.
",# Add changelog entry for #10415
659,"bpo-1812: Fix newline conversion when doctest.testfile loads from a package whose loader has a get_data method.
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
bpo-NNNN: Summary of the changes made
```

Where: bpo-NNNN refers to the issue number in the https://bugs.python.org.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `master`),
please ensure that the PR title is in the following format:

```
[X.Y] <title from the original PR> (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `master`.

-->

[bpo-1812](https://bugs.python.org/issue1812): Fix newline conversion when doctest.testfile loads from a package whose loader has a get_data method.

This pull request fixes the newline conversion bug originally reported in issue 1812. When that issue was originally submitted, the open builtin did not default to universal newline mode; now it does, which makes the issue fix simpler, since the only code path that needs to be changed is the one in doctest._load_testfile where the file is loaded from a package whose loader has a get_data method. Commit b6ad8ee contains the change that implements the fix.

This pull request also adds a test that verifies that doctest.testfile does the newline conversion correctly when loading from a package whose loader has a get_data method. This test fails (a ValueError is raised for inconsistent whitespace) unless the change in commit b6ad8ee is applied. Commit dd02845 contains the changes that add the test; the test is added to the test_lineendings docstring along with supporting comments.

Also, the test_lineendings docstring is missing a test to check for correct handling of the old-style Mac newline \r. This pull request adds that case to the original test_lineendings docstring. Commit da35562 contains the changes that add this test and edit the surrounding comments accordingly.

Finally, this pull request contains commit 22094c8 that adds my name to the MISC/Acks file.


<!-- issue-number: [bpo-1812](https://bugs.python.org/issue1812) -->
https://bugs.python.org/issue1812
<!-- /issue-number -->
",
660,"Kill current snapcraft build when a ""Chroot problem"" is encountered
It appears that when a ""Chroot problem"" is encountered during a snapcraft remote build, the snapcraft process does not exit and so the entire build in Azure stales until the timeout is reached.

See https://dev.azure.com/certbot/certbot/_build/results?buildId=2975&view=logs&j=ca2aa996-3000-528f-2c15-4e35d6e2aaa9&t=6b8d8f83-a960-5842-1f93-f9b9a106898f for instance

This PR manages this situation by force-exiting the impacted snapcraft call when this error is detected in the output.

Technically this procedure may kill a snapcraft process while other builds are still running, since one snapcraft call handles builds of a given certbot component for _all_ architectures. However, I think it is ok because in this case, the snapcraft remote build will be relaunched as stated by our retry mechanism, and then the snapcraft remote build reconnects to the current builds running on snapcraft servers, which effectively resumes builds.",# Fix remote build on arm64Fixes #10412
661,"Fix centos6 test_sdists
test_sdists.sh now passes on CentOS 6 (and should pass on other distros where certbot-auto uses Python 3 such as Fedora 29+).

Once this lands, we need to update the release instructions to document that a CentOS 6 failure is not expected.",# Use venv3 for testsFixes #4444
662,"Added Cults3D support
",# Added Cults3D
663,"Add ""run_once"" support to the script addon, use it in mitmproxy
Fixes #1418
",# Add scriptloader addon
664,"C.64 Example fix
Minor fixes to get the C.64 example to compile",# Fix typo in example
665,"./base/functions/generic.js: commenting some funcs
",# Add comments to functions
666,"BUG: setitem with boolean mask and tz-aware DTI
closes #16889 

 - [x] closes #xxxx
 - [x] tests added / passed
 - [x] passes ``git diff upstream/master --name-only -- '*.py' | flake8 --diff`` (On Windows, ``git diff upstream/master -u -- ""*.py"" | flake8 --diff`` might work as an alternative.)
 - [x] whatsnew entry
",# BUG: Fix.loc with alignment and tz-aware DatetimeIndexcloses #16889
667,"no-issue: Remove unused variable in getpath.py
Removed an unused variable `program_name_was_set` in `Modules/getpath.py`",# Remove unused variable
668,"Fix a typo in deprecated message (playbook/helpers.py)
##### SUMMARY
Message refer to `import_role` and `include_role` instead of `import_tasks` and `include_tasks`.

##### ISSUE TYPE
 - Bugfix Pull Request

##### COMPONENT NAME
lib/ansible/playbook/helpers.py

##### ANSIBLE VERSION
```
ansible-playbook 2.4.0 (devel 4532c791fd) last updated 2017/07/18 01:15:07 (GMT +200)
```
",# Fix a typo in the deprecation message
669,"add cw tests for lambda Invocations and Errors metrics
<!-- Please refer to the contribution guidelines before raising a PR: https://github.com/localstack/localstack/blob/master/CONTRIBUTING.md -->

<!-- Why am I raising this PR? Add context such as related issues, PRs, or documentation. -->
## Motivation
While testing the pro-samples we found that lambda is not reporting the `Errors` metrics anymore. 
The metric should be reported when a lambda invocation fails.

We didn't have integration tests for lambda metrics yet, so I added those now.
/cc @joe4dev 

<!-- What notable changes does this PR make? -->
## Changes
* added aws-validated tests
* skipping `test_lambda_invoke_error` for LS as it is currently not working -> this should be fixed 🙂 

<!-- The following sections are optional, but can be useful! 

## Testing

Description of how to test the changes

## TODO

What's left to do:

- [ ] ...
- [ ] ...

-->

",# Add CloudWatch Lambda metrics tests
670,"Update the youtube algorithm generator
I updated the generator with the work of @patrickslin.
Commits:
- f9c3c90ca8bee20f99d6172371b749ed7223588e
- 3a7256697e7c97a79f51d6ef6b9a1108bf8d7d3a
- e1842025d0403784d5a9af82e4fbd4b71fb31b11
- 8a9d86a2a79e78bd7bda941c48fb50dba29d1d66

Is there a reason to not maintain this script ?
",# youtube_genalgo.py: update
671,"Fix typo in LRU cache solution
",# Fix typo in lru_cache.ipynb
672,"Enable unsafe legacy renegotiation
Fixes #5491.

I don't know if we can have a test for it: it would require a server configured in a certain way, I need to check if it's even possible when using OpenSSL 3 on the server side. Locally I tested it on https://dorotheum.com/ with ""pyOpenSSL 21.0.0 ('OpenSSL 1.1.1j  16 Feb 2021'), cryptography 3.4.6"" (no error and website is accessible with and without the change) and ""pyOpenSSL 23.0.0 ('OpenSSL 3.0.7 1 Nov 2022'), cryptography 39.0.0"" (website is accessible only with the change).",# Fix #4301
673,"Update huobi.ts
Fix https://github.com/ccxt/ccxt/issues/17736",# fix(huobi): fix bug when fetchMarketsByTypeAndSubType
674,"Update pre-commit config to upgrade to isort v5.12.0
Fixes #987",# Update isort to 5.12.0
675,"[MRG+1] Add flush() method to StreamLogger
Fixes GH-2125

Local tests:

with a pretty simple spider:

```
$ cat stdoutlogging/spiders/example.py 
# -*- coding: utf-8 -*-
import scrapy


class ExampleSpider(scrapy.Spider):
    name = ""example""
    allowed_domains = [""example.com""]
    start_urls = (
        'http://www.example.com/',
    )

    def parse(self, response):
        print(""hello!"")
        return {""somekey"": ""somevalue""}
```

and Python 3.5:

```
$ scrapy version -v
Scrapy    : 1.2.0dev2
lxml      : 3.6.0.0
libxml2   : 2.9.3
Twisted   : 16.4.0
Python    : 3.5.1+ (default, Mar 30 2016, 22:46:26) - [GCC 5.3.1 20160330]
pyOpenSSL : 16.1.0 (OpenSSL 1.0.2g-fips  1 Mar 2016)
Platform  : Linux-4.4.0-36-generic-x86_64-with-Ubuntu-16.04-xenial
```

Before this change:

```
$ scrapy crawl example -s LOG_STDOUT=1
2016-09-14 12:07:35 [scrapy] INFO: Scrapy 1.2.0dev2 started (bot: stdoutlogging)
2016-09-14 12:07:35 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'stdoutlogging.spiders', 'BOT_NAME': 'stdoutlogging', 'LOG_STDOUT': '1', 'SPIDER_MODULES': ['stdoutlogging.spiders'], 'ROBOTSTXT_OBEY': True}
(...)
2016-09-14 12:07:36 [scrapy] INFO: Spider opened
2016-09-14 12:07:36 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-09-14 12:07:36 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-09-14 12:07:36 [scrapy] DEBUG: Crawled (404) <GET http://www.example.com/robots.txt> (referer: None)
2016-09-14 12:07:36 [scrapy] DEBUG: Crawled (200) <GET http://www.example.com/> (referer: None)
2016-09-14 12:07:36 [stdout] INFO: hello!
2016-09-14 12:07:36 [scrapy] DEBUG: Scraped from <200 http://www.example.com/>
{'somekey': 'somevalue'}
2016-09-14 12:07:36 [scrapy] INFO: Closing spider (finished)
(...stats...)
2016-09-14 12:07:36 [scrapy] INFO: Spider closed (finished)
Exception ignored in: <scrapy.utils.log.StreamLogger object at 0x7f298eb66358>
AttributeError: 'StreamLogger' object has no attribute 'flush'
$
```

After the change:

```
$ scrapy crawl example -s LOG_STDOUT=1
2016-09-14 12:11:33 [scrapy] INFO: Scrapy 1.2.0dev2 started (bot: stdoutlogging)
2016-09-14 12:11:33 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'stdoutlogging.spiders', 'SPIDER_MODULES': ['stdoutlogging.spiders'], 'BOT_NAME': 'stdoutlogging', 'ROBOTSTXT_OBEY': True, 'LOG_STDOUT': '1'}
(...)
2016-09-14 12:11:33 [scrapy] INFO: Spider opened
2016-09-14 12:11:33 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-09-14 12:11:33 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-09-14 12:11:39 [scrapy] DEBUG: Crawled (404) <GET http://www.example.com/robots.txt> (referer: None)
2016-09-14 12:11:39 [scrapy] DEBUG: Crawled (200) <GET http://www.example.com/> (referer: None)
2016-09-14 12:11:39 [stdout] INFO: hello!
2016-09-14 12:11:39 [scrapy] DEBUG: Scraped from <200 http://www.example.com/>
{'somekey': 'somevalue'}
2016-09-14 12:11:39 [scrapy] INFO: Closing spider (finished)
(...stats...)
2016-09-14 12:11:39 [scrapy] INFO: Spider closed (finished)
$
```

Note: I was not able to write a failing-then-passing test for this change in `test_utils_log.StreamLoggerTest`.
I tried with [`testfixtures.OutputCapture`](https://pythonhosted.org/testfixtures/api.html#testfixtures.OutputCapture) but could not capture the stderr output
",# Flush logger handlersFixes #1598
676,"Implement a hierarchical rnn mnist example
Hierarchical RNNs can perform multiple levels of modeling. As in [ A Hierarchical Neural Autoencoder for Paragraphs and Documents ](https://web.stanford.edu/~jurafsky/pubs/P15-1107.pdf), a sentence is first encoded into the a sentence vector by the first layer of a rnn, then the second LSTM takes consecutive sentences vectors as input and encodes the sentence vector sequence into a paragraph vector

Hierarchical RNNs can be done elegantly in keras using TimeDistributed Wrappers and reshaping the Data into 4D. The hierarchical mnist model first encodes columns of pixels into a column vector, then encodes the column vector sequence into a image vector. Trained on MNIST, the training and validation accuracy reached 98% in 5 epochs.

![screen shot 2016-08-13 at 02 23 05](https://cloud.githubusercontent.com/assets/9896736/17632809/e82f9670-60fc-11e6-9ee3-2018ede20fb5.png)
",# Added Hierarchical RNN example
677,"add notice in height of style images.
",# [StyleText] add note about height of style images
678,"Feature 487 ii
Hi Max,
I've added detailed timing information to FlowDetailView, as you requested in #487 
They are in the same order that where in the screenshot and then are sorted by timestamp like is done in https://github.com/mitmproxy/mitmproxy/blob/master/libmproxy/web/static/app.js#L1084 
there is no delta for now, but can [easily] be added later.
Regards.
Marcelo
",# Add timing information to flow detail view
679,"fix for locals max length
Fixes https://github.com/Textualize/rich/issues/2649",# Fix issue with `locals_max_length` parameter not being respectedFixes https://github.com/Textualize/rich/issues/2649
680,"Update the DeepSpeed Phi-2 impl. to work with the HF latest changes
The latest changes in Huggingface Phi-2 implementation (https://huggingface.co/microsoft/phi-2/commit/cb2f4533604d8b67de604e7df03bfe6f3ca22869#d2h-025836)  have broken the DeepSpeed implementation. This PR address the related issues. ",# [phi] fix phi model inference
681,"Update files from 1.26.0 release
This PR should not be squashed to preserve the signed commit.",# Bump version to 1.27.0
682,"add missing dependencies to README, fixes #151
",# Update README.md
683,"Drop loguru and use builtin `logging`
* Changed the 2 existing `print` in the `private_gpt` code base into actual python logging, stop using loguru (dependency will be dropped in a later commit).
* Try to use the `key=value` logging convention in logs (to indicate what dynamic values represents, and what is dynamic vs not).
* Using `%s` log style, so that the string formatting is pushed inside the logger, giving the ability to the logger to determine if the string need to be formatted or not (i.e. strings from debug logs might not be formatted if the log level is not debug)
* The (basic) builtin log configuration have been placed in `private_gpt/__init__.py` in order to initialize the logging system even before we start to launch any python code in `private_gpt` package (ensuring we get any initialization log formatted as we want to)
* Disabled `uvicorn` custom logging format, resulting in having uvicorn logs being outputted in our formatted.

Some more concise format could be used if we want to, especially:
```
COMPACT_LOG_FORMAT = '%(asctime)s.%(msecs)03d [%(levelname)s] %(name)s - %(message)s'
```

Python documentation and cookbook on logging for reference:
* https://docs.python.org/3/library/logging.html
* https://docs.python.org/3/howto/logging.html",# Remove loguru
684,"Fix unorderable types error
Seen on 0.9.3 and 0.12.0 with python 3.4

I ran into this issue where the `poll_and_request_issuance()` threw an ""unorderable type"" error because it attempted to compare the AuthenticationResource objects. After inspecting, some elements of the `waiting` heap shows similar datetime.

If I'm not wrong the piece of code that this PR is modifying assumes the datetime of the tuples wouldn't collide. If the datetime collides, the comparator of heapq will move onto the AuthorizationResource value and throws an ""unorderable type"" error.

This adds an index value to the element tuple to ensure that they are always strictly ordered.",# Use heapq's index as a tiebreakerFixes #1595
685,"Fix depth calculation for shared layers
This PR fixes a bug where model serialization and loading is broken when a shared layer is used at several different depths in a model (issue found here: https://github.com/allenai/deep_qa/pull/357).  I first added a test that failed on master, then fixed the test.  Hopefully the test and the comments around the test and the fix are enough to explain what's going on.",# Fix shared layer depthFixes #1118
686,"Update kucoin.js
It seems the order-id here should be orderId to fix this issue https://github.com/ccxt/ccxt/issues/13541",# fix kucoin order id
687,"Bugfix: spaces.MultiDiscrete.contains() can handle different shapes
See also spaces.Box.contains(), it already has this change

Reproduce Error with following lines:

from gym import spaces
import numpy as np
space_Multidiscrete = spaces.MultiDiscrete(np.ones((10,3)))
sample_test = np.ones((9,3))
space_Multidiscrete.contains(sample_test) #errors: ValueError: operands could not be broadcast together with shapes (9,3) (10,3)",# Fix multi_discrete space contains check
688,"Update readme to reflect current commands
auth -> certonly
",# Update README.rst
689,"remove metadata extractors from platform
# Description

just removing metadata extractions from the `ConfigurableTransformation` dynamic enum

## Type of Change

Please delete options that are not relevant.

- [x] New feature (non-breaking change which adds functionality)

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [ ] I stared at the code and made sure it makes sense

# Suggested Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] I have added Google Colab support for the newly added notebooks.
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] I ran `make format; make lint` to appease the lint gods
",# Remove metadata extractors
690,"Fix #2134
I picked the shape of icon and added toggle buttons for error and warn.

![2017-03-18 9 47 10](https://cloud.githubusercontent.com/assets/17471430/24067525/6fc169aa-0bc1-11e7-9a24-e94d21d9a6fa.png)
![2017-03-18 9 47 17](https://cloud.githubusercontent.com/assets/17471430/24067524/6f9fd402-0bc1-11e7-8f1d-e5ee2ec58900.png)
![2017-03-18 9 47 23](https://cloud.githubusercontent.com/assets/17471430/24067526/6fde2c16-0bc1-11e7-9d0b-6722d3570870.png)
",# Add warn and error filters
691,"Add Talon
Mailgun library to extract message quotations and signatures.
",# Added Talon
692,"Fix camera error description
Camera error description was changed incorrectly in #24156 possibly due to the order of road, driver, wideroad.
*At least the eventname doesn't match the error description in the code. I haven't verified it in any way yet.

Changed the order to road, wideroad, driver and so fixed the description.

Should the messages have the detailed description of which camera it is? Since this was removed in https://github.com/commaai/openpilot/pull/22943 and then added back in #24156 
",# fix: wide road camera error event name
693,"command: script.run
Plus the flowlist binding adjustments.",# Add a command to run a script on a flow
694,"Remove leading *. from default cert name.
Part of #5367.

We handle stripping `*.` in `client.py` rather than in `storage` and its utilities so we know whether we're using `domains` or a user provided cert name. If someone runs Certbot with `--cert-name *.example.org`, we should respect their insane wish rather than suddenly changing it on them.",# Don't create files and directories starting with *.Fixes #4445.
695,"Remove autodoc for standalone.authenticator
This cause errors in doc generation.
",# Remove standalone auth doc
696,"docker: fix cl tag
<!-- Please copy and paste the relevant template -->

<!--- ***** Template: Car bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

**Route**
Route: [a route with the bug fix]

-->

<!--- ***** Template: Bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

-->

<!--- ***** Template: Car port *****

**Checklist**
- [ ] added entry to CarInfo in selfdrive/car/*/values.py and ran `selfdrive/car/docs.py` to generate new docs
- [ ] test route added to [routes.py](https://github.com/commaai/openpilot/blob/master/selfdrive/car/tests/routes.py)
- [ ] route with openpilot:
- [ ] route with stock system:

-->

<!--- ***** Template: Refactor *****

**Description** [](A description of the refactor, including the goals it accomplishes.)

**Verification** [](Explain how you tested the refactor for regressions.)

-->
",# Remove TARGET_ARCHITECTURE
697,"Update Low-code video
Update a pre-view available low-code video",# Update README.md
698,"refine deploy slim
",# [slim] fix quant
699,"fix dtype
",# fix ip_adapter
700,"Improve order of paragraphs on line splitting
### Description

These two paragraphs were tucked away at the end of the section, after the diversion on backslashes. I nearly missed the first paragraph and opened a nonsense issue, and I think the second belongs higher up with it too.

### Checklist - did you ...

- [x] Add a CHANGELOG entry if necessary?
A changelog entry is unnecessary, I believe.
- [x] Add / update tests if necessary?
N/A
- [x] Add new / update outdated documentation?
Yes","# Reorder and expand on the ""labels/why-no-backslashes"" section"
701,"Added tests for check command
Added tests for the check command to increase coverage.",# Add tests for check command
702,"Docs fixes
",# Fix #1595
703,"Vendor `imghdr` module
",# Add imghdr
704,"Extract command to start SFN into separate function
Extract command to start SFN into separate function.",# fix step functions
705,"Fix file descriptor leak in lineinfile module.
##### SUMMARY

Fix a minor file descriptor leak in the lineinfile module.

Fixes #57327

##### ISSUE TYPE

- Bugfix Pull Request

##### COMPONENT NAME

- lineinfile

##### ADDITIONAL INFORMATION

This simply restores the prior `os.fdopen()` call so that the unmanaged file descriptor is consumed by a Python file object.",# fix file descriptor leak in lineinfileFixes #57327
706,"fix format
",# [kernel] fix multi_tensor_scale_kernel.cu
707,"Manual backport fix github quota
xref #50811","# [MRG+1] Use cached data for maintainers, releases, pdeps"
708,"Update the link for Applied Numerical Computing
Fix the broken link of the book Applied
Numerical Computing.",# Update books.md
709,"[vshare] extractor rewritten
### Before submitting a *pull request* make sure you have:
- [X] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [X] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [X] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

The VShare extractor is broken, I've rewritten it to depack the code in the page and get the video url from there.
I've also added the `_extract_urls` method.

This should close issue #14473.
",# [vshare] support for vshare embed
710,"Fix miaopai download failed
Miaopai is using https now. Fix url pattern when download miaopai videos

```
./you-get -di ""https://www.miaopai.com/show/i8xTI~lQ~M1z0oXazPj0Zi0cLvoov~HBYf1A~Q__.htm""
you-get: version 0.4.939, a tiny downloader that scrapes the web.
you-get: Namespace(URL=['https://www.miaopai.com/show/i8xTI~lQ~M1z0oXazPj0Zi0cLvoov~HBYf1A~Q__.htm'], cookies=None, debug=True, extractor_proxy=None, force=False, format=None, help=False, http_proxy=None, info=True, input_file=None, itag=None, json=False, no_caption=False, no_merge=False, no_proxy=False, output_dir='.', output_filename=None, password=None, player=None, playlist=False, socks_proxy=None, stream=None, timeout=600, url=False, version=False)
Traceback (most recent call last):
  File ""./you-get"", line 11, in <module>
    you_get.main(repo_path=_filepath)
  File ""/home/mi/wjw/you-get/src/you_get/__main__.py"", line 92, in main
    main(**kwargs)
  File ""/home/mi/wjw/you-get/src/you_get/common.py"", line 1368, in main
    script_main(any_download, any_download_playlist, **kwargs)
  File ""/home/mi/wjw/you-get/src/you_get/common.py"", line 1276, in script_main
    **extra
  File ""/home/mi/wjw/you-get/src/you_get/common.py"", line 1078, in download_main
    download(url, **kwargs)
  File ""/home/mi/wjw/you-get/src/you_get/common.py"", line 1361, in any_download
    m.download(url, **kwargs)
  File ""/home/mi/wjw/you-get/src/you_get/extractors/yixia.py"", line 75, in yixia_download
    yixia_download_by_scid(scid, output_dir, merge, info_only)
UnboundLocalError: local variable 'scid' referenced before assignment
```


",# fix yixia miaopai extractor
711,"Apt-get help is now much more like apt
",# Update apt_invalid_operation.py
712,"Doc changes
Removed some closed issues from todo and added a reference to [requests-oauth](https://github.com/maraujop/requests-oauth) in quickstart. 
",# Add OAuth Support to Todo List
713,"SQLite Injection add extract database structure
I've added a very useful SQLite injection used to extract the database structure, in the normal SQL format.

![image](https://user-images.githubusercontent.com/82521416/144981649-29c9998a-a724-4ba2-a1bf-c08a4b321bed.png)
",# Added SQLite string based - Extract database structure
714,"🔧  Add support for translations to languages with a longer code name, like `zh-hant`
📝 Add support for translations to languages with a longer code name, like `zh-hant`

This is to support https://github.com/tiangolo/fastapi/pull/10505",# Add missing language name for zh-hant
715,"Fixed outdated link and description
",# Update README.md
716,"Include 0.3.0 release in master's history
",# Bump version to 0.4.0.dev0
717,"Fixed #28917 -- Fixed Paginator unordered warning for EmptyQuerySet.
https://code.djangoproject.com/ticket/28917

Credit to @carltongibson for the idea and @weijunji
for the initial patch.",# Fixed #28698 -- Fixed EmptyQuerySet.ordered.https://code.djangoproject.com/ticket/28698
718,"Update det_basic_loss.py
删除重复赋值[self.main_loss_type]",# fix bug in det_basic_loss.py
719,"Fix bug for "".local"" host name
It's necessary to put new list member in square brackets (i.e. create new list) to merge lists properly, otherwise we will get result list with character elements instead of string element.
",# Fix #1051
720,"[3.8] bpo-37760: Mark all generated Unicode data headers as generated. (GH-15171)
This causes them to be collapsed by default in diffs shown on GitHub.




https://bugs.python.org/issue37760



Automerge-Triggered-By: @benjaminp
(cherry picked from commit 4e3dfcc4b987e683476a1b16456e57d3c9f581cb)


Co-authored-by: Greg Price <gnprice@gmail.com>

<!-- issue-number: [bpo-37760](https://bugs.python.org/issue37760) -->
https://bugs.python.org/issue37760
<!-- /issue-number -->
",# bpo-41498: Update.gitattributes
721,"Disable row level locking for Mariadb and MySQL <8
closes https://github.com/apache/airflow/issues/11899 
closes https://github.com/apache/airflow/issues/13668

This PR disable row-level locking for MySQL variants that do not support skip_locked and no_wait -- **MySQL < 8** and **MariaDB**

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
",# [AIRFLOW-2516] Fix row level locking for MySQLFixes #2516
722,".vs/ directory, matrix_multiplication_addition file and binary tree directory
 Added print function into matrix_multiplication_addition.py and removed blank space in data_structures/binary tree directory. Also  removed .vs/ folder per #893 ",# Update matrix_operation.py
723,"Factor out location_directive_for_achall
Part of #5438: ""code could use deduping internally to `certbot-nginx/certbot_nginx/http_01.py` -- for example, `rewrite_directive` is defined identically twice""

Turns out the code actually wasn't that internally duplicative.
",# Move validation path generation to a separate method
724,"Properly style code blocks in links
Closes: #20873

Allow code blocked nested in links to retain the link text coloring.

Before:
![Screen Shot 2022-01-18 at 1 56 12 PM](https://user-images.githubusercontent.com/66968678/150017340-9221ab30-77d7-4126-ad53-24bbb1bf1dd0.png)

After:
![Screen Shot 2022-01-18 at 1 52 04 PM](https://user-images.githubusercontent.com/66968678/150017346-909fb83b-4bda-4f09-bedc-a7d9569dbaaa.png)

",# Fix bootstrap theme
725,"[3.7] Update VSTS to Azure DevOps and simplify dependencies (GH-9168)
",
726,"Stats.jl has moved to JuliaStats/Stats.jl
",# Update README.md
727,"configure strict pytest and filterwarnings=['error', ...
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

fixes https://github.com/psf/black/issues/3171

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [x] Add a CHANGELOG entry if necessary?
- [x] Add / update tests if necessary?
- [x] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
",# [ci] add pytest options to enforce strict config and markers
728,"add function on web : popup notify
popup notify on web homepage, with 
1.text notify
2.a button that can hopefully send command to python
3.close notify button",# Add notify popup
729,"remove undefined YAML anchor
##### SUMMARY
The tests use module_defaults and never should have included these.

##### ISSUE TYPE
- Bugfix Pull Request

##### COMPONENT NAME
test/integration/targets/ec2_launch_template

",# Remove aws_connection_info from ec2_launch_template tests
730,"[gfycat] add support for /gifs/detail path
### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [X] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)

### What is the purpose of your *pull request*?
- [ ] Bug fix
- [X] Improvement
- [ ] New extractor
- [ ] New feature

---

Add support to new path like https://gfycat.com/gifs/detail/UnconsciousLankyIvorygull 

See issue #14322 ",# [gfycat] fix extraction of new urls
731,"Add N2D2
Add N2D2, [CEA LIST](http://www-list.cea.fr/)'s CAD open-source framework for designing and simulating Deep Neural Network (DNN), and building full DNN-based applications on embedded platforms.

Documentation: https://cea-list.github.io/N2D2-docs/
",# Add N2D2
732,"docs: Adds streetlayer.com
Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added StreetLayer API
733,"chore(deps): bump jinja2 from 3.0.1 to 3.1.2
Bumps [jinja2](https://github.com/pallets/jinja) from 3.0.1 to 3.1.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pallets/jinja/releases"">jinja2's releases</a>.</em></p>
<blockquote>
<h2>3.1.2</h2>
<p>This is a fix release for the <a href=""https://github.com/pallets/jinja/releases/tag/3.1.0"">3.1.0</a> feature release.</p>
<ul>
<li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-2"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-2</a></li>
<li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/13?closed=1"">https://github.com/pallets/jinja/milestone/13?closed=1</a></li>
</ul>
<h2>3.1.1</h2>
<ul>
<li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-1"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-1</a></li>
<li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/12?closed=1"">https://github.com/pallets/jinja/milestone/12?closed=1</a></li>
</ul>
<h2>3.1.0</h2>
<p>This is a feature release, which includes new features and removes previously deprecated features. The 3.1.x branch is now the supported bugfix branch, the 3.0.x branch has become a tag marking the end of support for that branch. We encourage everyone to upgrade, and to use a tool such as <a href=""https://pypi.org/project/pip-tools/"">pip-tools</a> to pin all dependencies and control upgrades. We also encourage upgrading to MarkupSafe 2.1.1, the latest version at this time.</p>
<ul>
<li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-0"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-0</a></li>
<li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/8?closed=1"">https://github.com/pallets/jinja/milestone/8?closed=1</a></li>
<li>MarkupSafe changes: <a href=""https://markupsafe.palletsprojects.com/en/2.1.x/changes/#version-2-1-1"">https://markupsafe.palletsprojects.com/en/2.1.x/changes/#version-2-1-1</a></li>
</ul>
<h2>3.0.3</h2>
<ul>
<li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.0.x/changes/#version-3-0-3"">https://jinja.palletsprojects.com/en/3.0.x/changes/#version-3-0-3</a></li>
</ul>
<h2>3.0.2</h2>
<ul>
<li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.0.x/changes/#version-3-0-2"">https://jinja.palletsprojects.com/en/3.0.x/changes/#version-3-0-2</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>
<blockquote>
<h2>Version 3.1.2</h2>
<p>Released 2022-04-28</p>
<ul>
<li>Add parameters to <code>Environment.overlay</code> to match <code>__init__</code>.
:issue:<code>1645</code></li>
<li>Handle race condition in <code>FileSystemBytecodeCache</code>. :issue:<code>1654</code></li>
</ul>
<h2>Version 3.1.1</h2>
<p>Released 2022-03-25</p>
<ul>
<li>The template filename on Windows uses the primary path separator.
:issue:<code>1637</code></li>
</ul>
<h2>Version 3.1.0</h2>
<p>Released 2022-03-24</p>
<ul>
<li>
<p>Drop support for Python 3.6. :pr:<code>1534</code></p>
</li>
<li>
<p>Remove previously deprecated code. :pr:<code>1544</code></p>
<ul>
<li><code>WithExtension</code> and <code>AutoEscapeExtension</code> are built-in now.</li>
<li><code>contextfilter</code> and <code>contextfunction</code> are replaced by
<code>pass_context</code>. <code>evalcontextfilter</code> and
<code>evalcontextfunction</code> are replaced by <code>pass_eval_context</code>.
<code>environmentfilter</code> and <code>environmentfunction</code> are replaced
by <code>pass_environment</code>.</li>
<li><code>Markup</code> and <code>escape</code> should be imported from MarkupSafe.</li>
<li>Compiled templates from very old Jinja versions may need to be
recompiled.</li>
<li>Legacy resolve mode for <code>Context</code> subclasses is no longer
supported. Override <code>resolve_or_missing</code> instead of
<code>resolve</code>.</li>
<li><code>unicode_urlencode</code> is renamed to <code>url_quote</code>.</li>
</ul>
</li>
<li>
<p>Add support for native types in macros. :issue:<code>1510</code></p>
</li>
<li>
<p>The <code>{% trans %}</code> tag can use <code>pgettext</code> and <code>npgettext</code> by
passing a context string as the first token in the tag, like
<code>{% trans &quot;title&quot; %}</code>. :issue:<code>1430</code></p>
</li>
<li>
<p>Update valid identifier characters from Python 3.6 to 3.7.
:pr:<code>1571</code></p>
</li>
<li>
<p>Filters and tests decorated with <code>@async_variant</code> are pickleable.
:pr:<code>1612</code></p>
</li>
<li>
<p>Add <code>items</code> filter. :issue:<code>1561</code></p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pallets/jinja/commit/b08cd4bc64bb980df86ed2876978ae5735572280""><code>b08cd4b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1660"">#1660</a> from pallets/release-3.1.2</li>
<li><a href=""https://github.com/pallets/jinja/commit/1e68ba86177504bb6404288610608b855eab93fa""><code>1e68ba8</code></a> release version 3.1.2</li>
<li><a href=""https://github.com/pallets/jinja/commit/8efee35092404ba67ede8316566be4f430e7b61d""><code>8efee35</code></a> pre-commit updates latest release branch</li>
<li><a href=""https://github.com/pallets/jinja/commit/a24df26d54fa2ccbe9bdaa0bb9419075a00e2699""><code>a24df26</code></a> ignore new mypy finding</li>
<li><a href=""https://github.com/pallets/jinja/commit/9faee281ea75694e28c33e2878879b322359d411""><code>9faee28</code></a> update requirements</li>
<li><a href=""https://github.com/pallets/jinja/commit/b802b5a6ad9deea082c16d9adb6417eda1a184d8""><code>b802b5a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1655"">#1655</a> from dvitek/dvitek/issue1654</li>
<li><a href=""https://github.com/pallets/jinja/commit/746bb95780c17687b27b6d1bf4df1216f0da972c""><code>746bb95</code></a> Fix race conditions in FileSystemBytecodeCache</li>
<li><a href=""https://github.com/pallets/jinja/commit/466a200ea40642b674db77588d13889abbad55f5""><code>466a200</code></a> update requirements</li>
<li><a href=""https://github.com/pallets/jinja/commit/990602f719b4086540287e95f601baefd830d790""><code>990602f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1647"">#1647</a> from Tom-Brouwer/202204/add-missing-overlay-options</li>
<li><a href=""https://github.com/pallets/jinja/commit/5d3d2414710c1439105d84efc58e4aba8e453cb3""><code>5d3d241</code></a> fix flake8-bugbear finding</li>
<li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.0.1...3.1.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.0.1&new-version=3.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update jinja2 to 3.1.2
734,"ftx AMC mapping
https://coinmarketcap.com/ru/currencies/amc-entertainment-holdings-tokenized-stock-ftx/
conflict with https://www.coingecko.com/en/coins/amc-fight-night#markets",# Added AMC Entertainment Holdings
735,"Fix punctuation in ES.77
",# Fix typo in E.12
736,"fixbug: an unexpected UserRequirement type message is thrown when there is nothing to do.
**Features**
- fixbug: an unexpected UserRequirement type message is thrown when there is nothing to do.
",# fix #1115
737,"Fix clearml args logging when training is launch with run()
This PR fixes #10341

My understading is that clearml logs automaticaly the argument from the first `argparse.parse_args` or `argparse.parse_known_args` call.

When calling run(), we :
1. Run the `argparse.parse_known_args` to get all default values 
2. Override values that are provided in kwargs

So clearml logs the values from step 1.

To fix this, we should pass the args to the `parse_known_args` call so the 2 steps are made at once and clearml get correct args values to log.

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Enhanced logging capabilities in YOLOv5's integration with ClearML.

### 📊 Key Changes
- Added connection of `opt` (command-line arguments) to the ClearML task.

### 🎯 Purpose & Impact
- **Purpose**: To ensure that not just hyperparameters (`hyp`) but also command-line arguments (`opt`) are tracked in ClearML, allowing for a more comprehensive logging and tracking of experiment settings.
- **Impact**: This will enable users to have a better overview and control of their experiments by capturing all relevant parameters and configurations. Additionally, it improves reproducibility of experiments by ensuring that all user-defined settings are recorded. 🔄",# ClearML: add args to hyperparameters
738,"added regex check to Intigriti
",# Added regex check for Intigriti
739,"[data] increase default interval for idle detection
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

This idle detection is used to deal with the resource contention issue. Previously, we allow pulling one block per second. This is too aggressive and will cause exceeded memory usage. Change the default interval to 10 seconds. 

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
    - [ ] I've added any new APIs to the API Reference. For example, if I added a 
           method in Tune, I've added it in `doc/source/tune/api/` under the 
           corresponding `.rst` file.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# [data] Increase idle detection interval
740,"Fix layout doc codebloc
## Type of changes

- [ ] Bug fix
- [ ] New feature
- [x] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

~~- [ ] I've run the latest [black](https://github.com/psf/black) with default args on new code.~~
~~- [ ] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.~~
~~- [ ] I've added tests for new code.~~
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

This is a small documentation fix. The code bloc at https://github.com/willmcgugan/rich/blob/master/docs/source/layout.rst is not recognized as one.

![image](https://user-images.githubusercontent.com/29103753/118359166-85cb4800-b582-11eb-8acc-f5ad135b92c8.png) 

This also removed some trailing spaces.",# Fix a typo in the docs
741,"Ignore unavailable entities when creating zwave_js device actions list
## Proposed change
We should not try to generate device actions for unavailable entities since they may no longer be backed by a valid Z-Wave Value. This PR fixes that and fixes #63331 where this issue was originally reported


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [x] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #63331
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Fix unavailable entities in device actionsFix unavailable entities in device actions
742,"fix compute_output_shape in CategoryEncoding layer
Currently the `CategoryEncoding` layer outputs shape and its `compute_output_shape` method not rendering same outputs. The behaviour is same across all backends. Fixed three cases where there is difference.

Please note that the behaviour is different wrt Keras2 but same across all three backends with Keras3. Hence the fix is inline with Keras3 outputs and `compute_output_shape` function changed to match the actual output shapes.

The behaviour in Keras3 across all backends with and without fix replicated in the attached  [tf-gist,](https://colab.sandbox.google.com/gist/SuryanarayanaY/bfd84b3f37080f3ab9db8bf611bb4ac8/64392_keras3_tf_tested.ipynb) [torch-gist](https://colab.sandbox.google.com/gist/SuryanarayanaY/88d4237009aa344315cd5a0628dc707e/64392_keras3_torch_tested.ipynb) & [jax-gist](https://colab.sandbox.google.com/gist/SuryanarayanaY/319eacdfb1d36282cb67337dc33ff4e4/64392_keras3_jax_tested.ipynb#scrollTo=YFxh5gr40hTk) .

Might fix TF ticket #[64392](https://github.com/tensorflow/tensorflow/issues/64392).",# Fix compute_output_shape for CategoryEncodingFixes #11167
743,"Add and update pynsist template comments
This was an afterthought from https://github.com/certbot/certbot/pull/8749. I just wanted to document things a bit more.",# Pin pynsist to a versionPinning pynsist to a version so we can update the NSIS template as needed.
744,"allow_hosts/ignore_hosts option now matches against the full `host:port` string
#### Description

Resolves #6325. Conflict in documentation between [Options](https://docs.mitmproxy.org/stable/concepts-options/#ignore_hosts) and [Ignoring Domains](https://docs.mitmproxy.org/stable/howto-ignoredomains), but matching against the full `host:port` combination makes more sense.

#### Checklist

 - [x] I have updated tests where applicable.
 - [x] I have added an entry to the CHANGELOG.
",# Fix #6594
745,"Added support for authentication in --share mode (via auth.json)
",# Added support for authentication in --share mode
746,"Added YTS API in Video Category
<!-- Thank you for taking the time to work on a Pull Request for this project! -->
<!-- To ensure your PR is dealt with swiftly please check the following: -->
- [x] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added YTS API
747,"Support XML responses in api gateway templating
## Motivation
https://github.com/localstack/localstack/issues/10380

## Changes
Read the Accept header of the HTTP request and use the corresponding template and validate the response (only XML support added)

<!-- The following sections are optional, but can be useful! 

## Testing
Define an API gateway with an XML template as response_template, and make an HTTP request with Accept: application/xml header. The response must be formatted as a valid XML instead of JSON.

## TODO

What's left to do:

- Add support to other media types
- **I can't label this PR as semver: patch**

",# Support XML response templatesFixes #1594
748,"VW MQB: Add FW for 2018 Volkswagen e-Golf
Add firmware for the 2018 Volkswagen e-Golf. Expand supported model-years.

**Dongle ID:** `8fe9ced03c94e256`

Thanks to community e-Golf owner VictoryCoffee!","# VW e-Golf 2014, 2018-20"
749,"🔧 Lint only in Python 3.7 and above
🔧 Lint only in Python 3.7 and above",# Run lint on CI
750,"Add vector make tests
Currently `gym.vector.make` does not have any tests
This PR adds a number of tests for the function parameters",# [vector] Add tests for gym.vector.make
751,"Fixed typos in docs headers.
",# Fixed some broken headings in the docs.
752,"Added UK Bank Holidays API
Added the GOV.UK API for Bank Holidays in England, Wales, Scotland and Northern Ireland

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added UK Bank Holidays API
753,"DOC Fix random_state parameter definition in docstring
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->
Minor fix unrelated to any issue

#### What does this implement/fix? Explain your changes.

Fix erroneous parameter definition (incorrect: `""random state""`; correct: `""random_state""`).

#### Any other comments?


<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# DOC fix typo in _param_validation.py
754,"Added Stock-Span-Problem
",# Added Stock Span Problem
755,"Rewrite sigfox unittest tests to pytest
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->

## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->


## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Example entry for `configuration.yaml`:
<!--
  Supplying a configuration snippet, makes it easier for a maintainer to test
  your PR. Furthermore, for new integrations, it gives an impression of how
  the configuration would look like.
  Note: Remove this section if this PR does not have an example entry.
-->

```yaml
# Example configuration.yaml

```

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #40891
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [x] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-asc+-review%3Aapproved

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Fix sigfox tests
756,"Improve wording of documentation
",# Fix typos and improve documentation
757,"Do not set RPMDIST to '%dist' when dist is not set by the distribution.
",# Fix RPM buildFixes #1118
758,"Update ISSUE_TEMPLATE.md
感觉还是放在上面显眼点。",# Update ISSUE_TEMPLATE.md
759,"seth and noah updated some confusing things [revisions requested]
This is meant to satisfy some of the feedback on #2938 as well as all of the feedback from https://community.letsencrypt.org/t/lets-make-lets-encrypt-easy-and-simple/15724/26
",# Document re-running certbot
760,"Add modules in PYTHONPATH to watched modules
We currently limit the modules we watch to modules contained in the current directory. This PR extends the watched modules to modules contained in the `PYTHONPATH` as well. For consistency, we also enable hashing for the same modules in the `PYTHONPATH`.

**Issue:** https://github.com/streamlit/streamlit/issues/805",# Add file_in_pythonpath
761,"[Tensor] update pytest.mark.parametrize in tensor tests
",# [hotfix] fix pytest mark
762,"Skip tests on docs-only changes
Added missing ignore paths to CI for documentation-only changes",# [ci] ignore docs and blogs in ci
763,"Update DINOv2 license to Apache 2.0
The models were relicensed from CC-BY-NC to the more permissive Apache 2.0 end of August (see [announcement](https://ai.meta.com/blog/dinov2-facet-computer-vision-fairness-evaluation/)).",# Update license for Dinov2 models
764,"cabana: fix crash when no can events in the log
",# Fix crash when merging empty stream
765,"Integration tests: force le3.wtf over DVSNI.
Becuse of https://github.com/letsencrypt/boulder/issues/985, we need to force standalone to one particular type of challenge at a time. #895 didn't fix it properly - it forgot about issuance of le3.wtf (CSR-initiated), which results in Travis builds failing 50% of a time, e.g. https://travis-ci.org/letsencrypt/letsencrypt/jobs/85875483#L3318.

Please merge before anything else to reduce number of failed builds :)
",# Remove standalone-supported-challenges from integration tests
766,"Fix `custom_generate_chat_prompt`
Fix to allow `custom_generate_chat_prompt` to be loaded from extensions again rather than throwing a TypeError.",# Fix custom_generate_chat_prompt
767,"remove redundant space and add mexopencv
as title
1.remove redundant space
2.add mexopencv
Collection and a development kit of matlab mex functions for OpenCV library
",# Update README.md
768,"fixed top-down button issues in git README file
Initially, the top-down button was not showing content, so I made some changes to fix it and added some content that was previously missing, according to community guidelines.",# Fix some minor issues in the git topic
769,"Add Gas Detector (rqbj) device support to Tuya
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->

This PR adds support for the Tuya Gas Detector (`rqbj`) device category to the Tuya integration.

![image](https://user-images.githubusercontent.com/195327/138560938-18327bea-114d-4793-b8ee-5405049d4030.png)

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [x] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [x] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [x] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [x] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Add support for Tuya Gas Detector
770,"Update dev docs to reflect Python 2 EOL
Python 2 is going to get harder and harder to install locally so I don't think we should assume/require devs to have it installed.

This PR builds on https://github.com/certbot/certbot/pull/7905 so our developer guide only has people use Python 3.",# Update contributing.rst
771,"fix ZeRO++ convergence test 
there may be chances where the dataset shard loaded contains example with empty text `''` which will make the test fail (which occurred on my end) so fixing by dropping the empty examples",# [zero-shot] fix test_zeropp.py
772,"Throttle unavailability warnings for tplink light/switch
## Description:

After this change, a disconnected device will only log a single warning and not one for each `update`:

```
2018-07-21 10:56:45 WARNING (SyncWorker_10) [homeassistant.components.switch.tplink] Could not read state for TP-Link Switch: Communication error
2018-07-21 10:57:15 WARNING (SyncWorker_14) [homeassistant.components.switch.tplink] Could not read state for TP-Link Switch: Communication error
2018-07-21 10:57:47 WARNING (SyncWorker_19) [homeassistant.components.switch.tplink] Could not read state for TP-Link Switch: Communication error
```

I only have the switch, so the light change is not tested.

## Checklist:
  - [X] The code change is tested and works locally.
  - [X] Local tests pass with `tox`.

If the code communicates with devices, web services, or third-party tools:
  - [ ] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).
  - [ ] New dependencies are only imported inside functions that use them ([example][ex-import]).
  - [ ] New or updated dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.
  - [ ] New files were added to `.coveragerc`.

[ex-requir]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L14
[ex-import]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L54
",# Set _available to True after successful update
773,"Added Unplugg Automated Forecasting API
Added under Machine Learning",# Added Unplugg API
774,"Adds LiteGraph Theming Support
Adds support to theme LiteGraph Nodes. This is done by setting some of the global `LiteGraph` object's attributes. Node links are now also colored based on the node slot labels.

The image below is the example theme applied. 

![image](https://user-images.githubusercontent.com/23466035/230728293-56e7478f-0c69-4cb1-9e07-1c94a408cfb8.png)

To accomplish this:
- Most of it is relatively simple, just copying properties from the theme object into into the LiteGraph Base object.
- However, `NODE_TITLE_COLOR` and `LINK_COLOR` need to be assigned to the canvas manually. I could not figure out why as they should be being set from LiteGraph, and printing out the LiteGraph objects shows that they have been set correctly.
- `renderLink` is overriden. This allows to set the link colors the same as the node_slot colors.

Themes are loaded in settings via changing the color palette.",# Add Solarized and LiteGraph Base color palettes
775,"Closed #14069
### Description

Fix #14069

### Twitter handle

[lin_bob57617](https://twitter.com/lin_bob57617)","# Azure AD token provider should be a callableAzure AD token provider should be a callable, not a string."
776,"Fix hash caching in `ObjectStoragePath`
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This fix is taken from the https://github.com/apache/airflow/pull/37757#discussion_r1505123675

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",# [AIRFLOW-1111] Fix ObjectStoragePath hashFixes #1111
777,"Bump mcstatus to v11.1.1
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->

## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Bump `mcstatus` from v11.0.0 to v11.1.1, which fixes a problem with newer server versions.

[Diff v11.0.0 <-> v11.1.1](https://github.com/py-mine/mcstatus/compare/v11.0.0...v11.1.1)

[Changelog v11.1.1](https://github.com/py-mine/mcstatus/releases/tag/v11.1.1)
[Changelog v11.1.0](https://github.com/py-mine/mcstatus/releases/tag/v11.1.0)
[Changelog v11.0.1](https://github.com/py-mine/mcstatus/releases/tag/v11.0.1)

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [x] Dependency upgrade
- [x] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [ ] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #106971
- This PR is related to issue: n.a.
- Link to documentation pull request: n.a.

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [x] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] I have followed the [perfect PR recommendations][perfect-pr]
- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [x] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [x] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [x] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
",# Bump mcstatus to 11.1.1Bump mcstatus to 11.1.1
778,"DOC: Fix typo in nth docstring
Correct spelling mistake nth docstring in pandas/core/groupby/groupby.py",# TST: fix typo in docstring
779,"Exclude download_button data from the list of arguments for computing…
<!--
⚠️ BEFORE CONTRIBUTING PLEASE READ OUR CONTRIBUTING GUIDELINES!
https://github.com/streamlit/streamlit/wiki/Contributing
-->

## Describe your changes
Exclude download_button data from the list of arguments for computing widget id.
Since if `data` is different on each rerun (e.g. generated randomly), widget_ids doesn't match, and it leads to a missing ""True"" value when button clicked on frontend.

## GitHub Issue Link (if applicable)  #7308 

## Testing Plan

- Explanation of why no additional tests are needed
- Unit Tests (JS and/or Python)
- E2E Tests
    -  e2e test added for regression verification
- Any manual testing needed?

---

Closes: #7308

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",# fix(st.download_button): set value correctly when user clicks
780,"skip gptj slow generate tests
# What does this PR do?

As discussed offline, this PR skips the slow generations tests for GPT-J due to GPU OOM. These should be re-enabled with a bigger GPU on CI or when model parallelism #13726 is implemented and then run the tests on multi-GPU.

These slow tests should be run manually before merging anything related to GPTJ modeling.",# [MRG] Mark slow tests for GPTJ
781,"Ignore cache on request.get_json(cache=False) call
Removes usage of `_cached_json` property when `get_json` is called with
disabled cache argument. (closes #2087)",# Ignore cached JSON when cache is disabledFixes #1595
782,"Update netdisco to 1.2.0
Updates netdisco dependency to 1.2.0",# Update netdisco to 1.2.0
783,"Expand the Kelly Coinflip game
",# Add Generalized Kelly Coinflip game
784,"Fix squad 2.0 dev data link
A minor typo fix.",# Fix dev-v2.0.json link
785,"[automated] Update generated content
Automated changes by [create-pull-request](https://github.com/peter-evans/create-pull-request) GitHub action",# Fix apt install command
786,"Add Docstring for SReLU; Docstring Style Fix
Add the function definition of SReLU.
Refine the style of function definitions.",# Add SReLU documentation
787,"fix ui: lead two not updated
",# ui: update_leads
788,"adding linux answers
","# Add answers for ""How to create a file"""
789,"route53: autogenerate documentation
Creates documentation boilerplate for certbot-dns-route53 using tools/sphinx-quickstart.sh.

Adds trivial `authenticator.rst` and `dns_route53.rst` files.",# Add documentation for DNS Route53 plugin
790,"fixing and update
hello 😊 , i try to fix on ```Type of angles of a triangle.py``` and ```Type_of_angles_of_triangle.py``` by:
- change to ```input()``` to ```print()```


more:
- adding paramaters on choice in ```magic8ball.py```
- remove double imported in ```binod.py``` and commented
- commented imported module on ```mask_detection.py```
- commented imported module on ```mobilePhoneSpecsScrapper.py```
- commented imported module on ```Face and eye Recognition/gesture_control.py```

thanks ! 😊 
",# import statements
791,":bug: fixing init
# Description

small bug fix on the init method of a previous PR

",# Add auth token to text embeddings inference
792,"Use the right version of tokenizers
# What does this PR do?

Pulls the version of tokenziers from our deps in the `hubconf.py` otherwise it might install a version of tokenizers that is more recent (if available on pypi). When that is the case, the check of our packages fails at import.",# Update tokenizers to 0.9.4
793,"[3.8] Fix MinGW library generation command (GH-17917)
To print the exports to stdout, the gendef command requires the option ""-"". Without this option, no output is generated.
(cherry picked from commit 2545fa87628b4caca519da8aeb0eeef368b9dc0d)


Co-authored-by: Baljak <baljci@hotmail.com>",# bpo-38498: Fix typo in whatsnew.rst
794,"Fixed #21939 -- Deprecated loading ssi/url tags from future.
",# Fixed #23498 -- Removed deprecated'ssi' and 'url' tags from future template tag library.https://code.djangoproject.com/ticket/23498
795,"cleanup mypy usage
",# Remove.landscape.yml
796,"infra: mv SQLDatabase tests to community
",# Move sql tests to community
797,"Let only the _globally_ 0th rank write checkpoints in `train.py`
Hi There,

Thank You for this project. Just today I started using your code to train EfficientNets for my own purposes. I just came across a teeny tiny bug in `train.py`, that crashes trainings on multiple nodes. It seems to happen, that multiple nodes at once write to the tmp path and then try to move it after another, yielding a 
```
FileNotFoundError: [Errno 2] No such file or directory: 'output/timm_confs/effnet_b0.txt/tmp.pth.tar' -> 'output/timm_confs/effnet_b0.txt/last.pth.tar'
```

With this fix in place it works for me, as there is no more concurrency.

Best regards,

Sam",# fix train.py
798,"Updated URL for CPython
CPython source officially moved to GitHub, so this URL should probably be updated.

--

Anyone who agrees with this pull request could vote for it by adding a 👍 to it, and usually, the maintainer will merge it when votes reach 20.
",# Update README.md
799,"prevent highlighting/selecting image
Occasionally when clicking on an image just right, it causes the image to become selected. This small styling change prevents it from being selected.

before 
<img width=""686"" alt=""image"" src=""https://user-images.githubusercontent.com/362590/196154488-88f5a609-0aab-4ba6-aacb-7c238f76dcf7.png"">
after
<img width=""669"" alt=""image"" src=""https://user-images.githubusercontent.com/362590/196154570-2a7794fd-ebcf-44ed-bacd-7fbdb4bcf78e.png"">
",# Add userSelect='none' to image viewer
800,"`CachedStFunctionWarning` should include `experimental_allow_widgets`, not `suppress_st_warning`
## 📚 Context

Fixes #6216.

- What kind of change does this PR introduce?

  - [x] Bugfix
  - [ ] Feature
  - [ ] Refactoring
  - [ ] Other, please describe:

## 🧠 Description of Changes

- Instead of asking users to pass a non-existent param (`suppress_st_warning`) to the new caching decorators when widget replay is disabled and the cache-decorated function contains a Streamlit widget, we now ask them to pass `experimental_allow_widgets=True` to the caching decorator to enable widget replay and suppress the`CachedStFunctionWarning`.

  - [ ] This is a breaking API change
  - [x] This is a visible (user-facing) change

## 🧪 Testing Done

- [ ] Screenshots included
- [ ] Added/Updated unit tests
- [ ] Added/Updated e2e tests

## 🌐 References

_Does this depend on other work, documents, or tickets?_

- **Issue**: Closes #6216 

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",# Fix warning in cache_errors.py
801,"Add SF.12, 3rd try
",# Add SF.12: Prefer the angle bracket form of `#include` where you can and the quoted form everywhere else
802,"[3.11] GH-93521: For dataclasses, filter out `__weakref__` slot if present in bases (GH-93535)
(cherry picked from commit 5849af7a80166e9e82040e082f22772bd7cf3061)


Co-authored-by: Bluenix <bluenixdev@gmail.com>

Automerge-Triggered-By: GH:ericvsmith",# gh-93521: Fix dataclasses adding __weakref__ to __slots__ when it's already present in a base
803,"Enable ad-hoc running of cpu_inference
",# [ci] allow workflow_dispatch
804,"Delete ch_doc2.jpg
",# remove ch_doc2.jpg
805,"Fix SGLang worker
",# fix: add background tasks to streaming response
806,"Editorial changes for PER, CP, E, and T.
As before, hopefully non-controversial stuff, but let me know if anything should be discussed individually and I'll split it out.
",# Fix typos
807,"Provide git based example
I found it difficult to find documentation for how to pull from a git-based scm that wasn't github. The only way I could find this option was to dig through the google-group.
",# Add gitlab support to galaxy.rst
808,"Revert ""Issue 2002"" (logging function was actually calling an interactive iDisplay notification)
Reverts letsencrypt/letsencrypt#2009
",# Remove unused logging imports
809,"Reject empty SNS messages
Currently, empty SNS messages are permitted, this diverges from AWS behavior.

This PR introduces a check if the message is empty, and adds a test to check if an empty message is successfully rejected.
Also a TODO was acted upon to add a sns_create_topic fixture to create multiple topics if necessary.

Test also passes against AWS.

Fixes #5096 ",# Fix empty sns messageFixes #1594
810,"XX-Net fails to start if the install path contains spaces
XX-Net fails to start if the install path contains spaces, so it must be quoted.",# Fix XX-Net install path with spaces
811,"added the py311 to target-version config
<!-- Hello! Thanks for submitting a PR. To help make things go a bit more
     smoothly we would appreciate that you go through this template. -->

### Description

The documentation currently doesn't share that python 3.11 is supported as part of the `-t, --target-version` flag. This PR updates the documentation to support that.

### Checklist - did you ...

<!-- If any of the following items aren't relevant for your contribution
     please still tick them so we know you've gone through the checklist.

    All user-facing changes should get an entry. Otherwise, signal to us
    this should get the magical label to silence the CHANGELOG entry check.
    Tests are required for bugfixes and new features. Documentation changes
    are necessary for formatting and most enhancement changes. -->

- [ ] Add an entry in `CHANGES.md` if necessary?
- [ ] Add / update tests if necessary?
- [x] Add new / update outdated documentation?

<!-- Just as a reminder, everyone in all psf/black spaces including PRs
     must follow the PSF Code of Conduct (link below).

     Finally, once again thanks for your time and effort. If you have any
     feedback in regards to your experience contributing here, please
     let us know!

     Helpful links:

      PSF COC: https://www.python.org/psf/conduct/
      Contributing docs: https://black.readthedocs.io/en/latest/contributing/index.html
      Chat on Python Discord: https://discord.gg/RtVdv86PrH -->
Issue: https://github.com/psf/black/issues/3897",# Update the basics docs to reflect the latest version
812,"Indicate that a final newline was added in --diff
Fixes: #1662

This works around [bpo2142](https://bugs.python.org/issue2142) from 2008.",# Fix #1662: `--diff` incorrectly reports missing final newlineFixes #1662
813,"update pip -> pip3
",# fix whl doc
814,"Allow black's Github action params overriding.
Fix: #1751 ",# Add GitHub Action
815,"[MRG+1] DOC minor improvement in Ensemble user guide
See http://stackoverflow.com/questions/28411976/unconclusive-randomforest-documentation-in-scikitlearn
The previous sentences were slightly self-contradictory.

Ping @glouppe @arjoly @ogrisel 
",# DOC: Update ensemble.rst
816,"Color picker test framework class
Same deal as every single other one",# Add ColorPicker
817,"DeConvolution2D: Make output_shape parameter respect dim_ordering
See #5001 for the issue.

This simply ensures that the `output_shape` parameter to the DeConv2d layer matches the dim_ordering defined.",# Fix deconv2d for tensorflow backend
818,"[ci] move rllib small-gpu tests to civ2
- rllib uses 'gpu' and 'multi-gpu' tag which confuses bazel query tag since it takes the input as a regex. Updated ray_ci to strictly query for an exact match of tag
- we cannot parallelize this job because the machine has only one core

Test:
- CI",# [ci] fix gpu tests
819,"Don't add duplicate remote/branch name
@josephfrazier this should cover all of the corner cases for #745 ",# Fix git push
820,"add the missing improt for east_process.py and format some codes
add the missing improt for east_process.py and format some codes",# fix some bugs in east_process.py
821,"DOC add permalink to summary of collapsed details section
closes #27127
follow-up of #26872

Add permalink to summaries of collapsed details section.",# [MRG+1] Add a permalink to the summary of a details block
822,"Don't turn on sudo for all tasks when setting the sudo_user or ask_sudo_pass
This also relates to to Issue #3297.

If you specify the sudo_user or the ask_sudo_pass values, you shouldn't have sudo be turned on by default for all tasks.  It should still be executed as the currently executing user, and you can then choose to also sudo=true, or do it per playbook or per task within ansible.

Otherwise, you really have no way of specifying the password for a sudo user, and still use the originally executing user to run your tasks/playbooks.
",# Fix #15913 - Remove redundant sudo checkFixes #15913
823,"Answer a `services` related question
",# Add missing `kubectl expose` command
824,"build: disable ascendex
",# ascendex: skip 502 Gateway Time-out
825,"🔧 Update sponsors, add Codacy
🔧 Update sponsors, add Codacy",# 📈 Add Codacy as a sponsor📈 Add Codacy as a sponsor
826,"Add H100 workflow and status badge.
Adds H100 workflow for unit tests and a status badge showing the status from the action on the `master` branch.",# Add H100 workflow
827,"fix bug: value not found
ubuntu scan ip error",# fix bug in proxy_handler.py
828,"multilang.sh
There's a few things that aren't perfect yet, but I think we should start using something like this to test all the languages at once
- [x] only works in bash because of process substitution, and not sh currently
- [x] would like to get rid of the `-a` argument, and just accept the rest of the arguments that aren't next to a letter
- [ ] would make the node, php, and python output match more exactly line by line (but that wouldn't be a part of this script)

for methods that return tables, 
- [x] python and php dont display a table
- [x] `column: line too long` error with `fetchMarkets`

-----------

```
% bash test.bash -a ""binance fetchTicker XRP/USDT""
2022-03-12T02:12:42.951Z                               PHP v8.1.3                                       Python v3.9.5
Node.js: v14.17.0                                      CCXT v1.75.87                                    CCXT v1.75.87
CCXT v1.75.87                                          binance->fetchTicker(XRP/USDT)                   {'ask': 0.8397,
binance.fetchTicker (XRP/USDT)                         Array                                             'askVolume': 11016.0,
2022-03-12T02:12:44.659Z iteration 0 passed in 641 ms  (                                                 'average': 0.7841,
    [symbol] => XRP/USDT                                'baseVolume': 652472355.0,
{                                                          [timestamp] => 1647051167504                  'bid': 0.8396,
  symbol: 'XRP/USDT',                                      [datetime] => 2022-03-12T02:12:47.504Z        'bidVolume': 10160.0,
  timestamp: 1647051164295,                                [high] => 0.849                               'change': 0.1112,
  datetime: '2022-03-12T02:12:44.295Z',                    [low] => 0.725                                'close': 0.8397,
  high: 0.849,                                             [bid] => 0.8399                               'datetime': '2022-03-12T02:12:45.891Z',
  low: 0.725,                                              [bidVolume] => 21263                          'high': 0.849,
  bid: 0.8396,                                             [ask] => 0.84                                 'info': {'askPrice': '0.83970000',
  bidVolume: 12076,                                        [askVolume] => 1598                                    'askQty': '11016.00000000',
  ask: 0.8397,                                             [vwap] => 0.77904089                                   'bidPrice': '0.83960000',
  askVolume: 9047,                                         [open] => 0.7285                                       'bidQty': '10160.00000000',
  vwap: 0.77903801,                                        [close] => 0.8399                                      'closeTime': '1647051165891',
  open: 0.7285,                                            [last] => 0.8399                                       'count': '660132',
  close: 0.8396,                                           [previousClose] => 0.72850000                          'firstId': '428019321',
  last: 0.8396,                                            [change] => 0.1114                                     'highPrice': '0.84900000',
  previousClose: '0.72850000',                             [percentage] => 15.292                                 'lastId': '428679452',
  change: 0.1111,                                          [average] => 0.7842                                    'lastPrice': '0.83970000',
  percentage: 15.251,                                      [baseVolume] => 652493015                              'lastQty': '16.00000000',
  average: 0.78405,                                        [quoteVolume] => 508318740.7644                        'lowPrice': '0.72500000',
  baseVolume: 652475266,                                   [info] => Array                                        'openPrice': '0.72850000',
  quoteVolume: 508303035.8246,                                 (                                                  'openTime': '1646964765891',
  info: {                                                          [symbol] => XRPUSDT                            'prevClosePrice': '0.72860000',
    symbol: 'XRPUSDT',                                             [priceChange] => 0.11140000                    'priceChange': '0.11120000',
    priceChange: '0.11110000',                                     [priceChangePercent] => 15.292                 'priceChangePercent': '15.264',
    priceChangePercent: '15.251',                                  [weightedAvgPrice] => 0.77904089               'quoteVolume': '508301025.68420000',
    weightedAvgPrice: '0.77903801',                                [prevClosePrice] => 0.72850000                 'symbol': 'XRPUSDT',
    prevClosePrice: '0.72850000',                                  [lastPrice] => 0.83990000                      'volume': '652472355.00000000',
    lastPrice: '0.83960000',                                       [lastQty] => 6428.00000000                     'weightedAvgPrice': '0.77903841'},
    lastQty: '51.00000000',                                        [bidPrice] => 0.83990000              'last': 0.8397,
    bidPrice: '0.83960000',                                        [bidQty] => 21263.00000000            'low': 0.725,
    bidQty: '12076.00000000',                                      [askPrice] => 0.84000000              'open': 0.7285,
    askPrice: '0.83970000',                                        [askQty] => 1598.00000000             'percentage': 15.264,
    askQty: '9047.00000000',                                       [openPrice] => 0.72850000             'previousClose': '0.72860000',
    openPrice: '0.72850000',                                       [highPrice] => 0.84900000             'quoteVolume': 508301025.6842,
    highPrice: '0.84900000',                                       [lowPrice] => 0.72500000              'symbol': 'XRP/USDT',
    lowPrice: '0.72500000',                                        [volume] => 652493015.00000000        'timestamp': 1647051165891,
    volume: '652475266.00000000',                                  [quoteVolume] => 508318740.76440000   'vwap': 0.77903841}
    quoteVolume: '508303035.82460000',                             [openTime] => 1646964767504
    openTime: '1646964764295',                                     [closeTime] => 1647051167504
    closeTime: '1647051164295',                                    [firstId] => 428019326
    firstId: '428019313',                                          [lastId] => 428679470
    lastId: '428679448',                                           [count] => 660145
    count: '660136'                                            )
  }
}                                                      )
```",# Add multilang cli
829,"New features for CodeParrot training script
This PR adds some features to CodeParrot training script.

- Add TFLOPS to logging
- Use Accelerate checkpointing and tracking for Wandb and Tensorborad
- Fix gradient accumulation for DDP (https://github.com/huggingface/accelerate/pull/106)
- Scale loss approprietly for the last batch
- Fix typo in the README

cc @lvwerra @LysandreJik ",# [CodeParrot] Add resume from checkpoint
830,"Update improve_query.md
",# Improve query
831,"add now required `-lcurand` to solve `undefined symbol: curandCreateGenerator`
This is needed with pip installed torch>=1.11 and when using pre-building

It fixes:

```
$ python -c ""import deepspeed; deepspeed.ops.op_builder.CPUAdamBuilder().load()""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/mnt/nvme0/code/github/00optimize/deepspeed/deepspeed/ops/op_builder/builder.py"", line 461, in load
    return importlib.import_module(self.absolute_name())
  File ""/home/stas/anaconda3/envs/py38-pt112/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 657, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 556, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 1166, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: /mnt/nvme0/code/github/00optimize/deepspeed/deepspeed/ops/adam/cpu_adam_op.cpython-38-x86_64-linux-gnu.so: undefined symbol: curandCreateGenerator
```
which I think is the cause of:
```
'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'
```

Fixes: https://github.com/microsoft/DeepSpeed/issues/1846 (for real this time)

@jeffra ",# [cpu_adam] add curand to libraries_args
832,"stricter cpplint checks
Now, allowing the [build/c++11] and [build/class] cpplint categories does not find issues anymore, so I see no reason to ignore these categories in the travis checks.
",# Fix Makefile.in
833,"[naver] Support tv.naver.com links
### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Naver switched to `tv.naver.com` links (also redirects from `tvcast.naver.com` to `tv.`).
Example link: http://tv.naver.com/v/1379289",# [naver] fix extraction
834,"manager.py broadcast process states
<!-- Please copy and paste the relevant template -->

<!--- ***** Template: Car bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

**Route**
Route: [a route with the bug fix]

-->

<!--- ***** Template: Bug fix *****

**Description** [](A description of the bug and the fix. Also link any relevant issues.)

**Verification** [](Explain how you tested this bug fix.)

-->

<!--- ***** Template: Car port *****

**Checklist**
- [ ] added to README
- [ ] test route added to [test_car_models](../../selfdrive/test/test_car_models.py)
- [ ] route with openpilot:
- [ ] route with stock system:

-->

<!--- ***** Template: Refactor *****

**Description** [](A description of the refactor, including the goals it accomplishes.)

**Verification** [](Explain how you tested the refactor for regressions.)

-->
",# managerState
835,"Better error message when view return type is not supported
Before, returning a `bool` from a route caused the error

```
[2019-05-31 10:08:42,216] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 2070, in make_response
    rv = self.response_class.force_type(rv, request.environ)
  File ""/Users/johnzeringue/Documents/ts-open/flask/env/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py"", line 269, in force_type
    response = BaseResponse(*_run_wsgi_app(response, environ))
  File ""/Users/johnzeringue/Documents/ts-open/flask/env/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py"", line 26, in _run_wsgi_app
    return _run_wsgi_app(*args)
  File ""/Users/johnzeringue/Documents/ts-open/flask/env/lib/python3.7/site-packages/werkzeug/test.py"", line 1119, in run_wsgi_app
    app_rv = app(environ, start_response)
TypeError: 'bool' object is not callable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 2393, in wsgi_app
    response = self.full_dispatch_request()
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 1906, in full_dispatch_request
    return self.finalize_request(rv)
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 1921, in finalize_request
    response = self.make_response(rv)
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 2078, in make_response
    reraise(TypeError, new_error, sys.exc_info()[2])
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/_compat.py"", line 39, in reraise
    raise value.with_traceback(tb)
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 2070, in make_response
    rv = self.response_class.force_type(rv, request.environ)
  File ""/Users/johnzeringue/Documents/ts-open/flask/env/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py"", line 269, in force_type
    response = BaseResponse(*_run_wsgi_app(response, environ))
  File ""/Users/johnzeringue/Documents/ts-open/flask/env/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py"", line 26, in _run_wsgi_app
    return _run_wsgi_app(*args)
  File ""/Users/johnzeringue/Documents/ts-open/flask/env/lib/python3.7/site-packages/werkzeug/test.py"", line 1119, in run_wsgi_app
    app_rv = app(environ, start_response)
TypeError: 'bool' object is not callable
The view function did not return a valid response. The return type must be a string, tuple, Response instance, or WSGI callable, but it was a bool.
```

Now, it returns the more readable

```
[2019-05-31 10:36:19,500] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 2400, in wsgi_app
    response = self.full_dispatch_request()
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 1907, in full_dispatch_request
    return self.finalize_request(rv)
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 1922, in finalize_request
    response = self.make_response(rv)
  File ""/Users/johnzeringue/Documents/ts-open/flask/flask/app.py"", line 2085, in make_response
    "" {rv.__class__.__name__}."".format(rv=rv))
TypeError: The view function did not return a valid response. The return type must be a string, dict, tuple, Response instance, or WSGI callable, but it was a bool.
```

Fixes #3214

<!--
Commit checklist:

* add tests that fail without the patch
* ensure all tests pass with ``pytest``
* add documentation to the relevant docstrings or pages
* add ``versionadded`` or ``versionchanged`` directives to relevant docstrings
* add a changelog entry if this patch changes code

Tests, coverage, and docs will be run automatically when you submit the pull
request, but running them yourself can save time.
-->
",# Show a better error message when the view return type is not supportedFixes #3214
836,"Feature/button-to-close-flow-details-view
#### Description

Added a button to close the flow details panel, as discussed in issue #6725. It could be useful to have a button to immediately close the section. This is a preliminary idea, as I didn't want to alter the design significantly. What are your thoughts?

https://github.com/mitmproxy/mitmproxy/assets/100372313/732b29ac-6fff-4eff-be7b-98e4460a93a9


#### Checklist

 - [x] I have updated tests where applicable.
 - [x] I have added an entry to the CHANGELOG.
",# Add button to close flow details panel
837,"Fix a serious doc issue
Fix a serious doc issue",# fix doc of detection
838,"Update tox.ini to use py37,py38 instead of ci37,ci38
As defined in the tox documentation
(https://tox.readthedocs.io/en/latest/config.html#tox-environments),
environment with names ""pyNM"" have special meaning and implicitly define
the Python interpreter.

Environment names ci37 and ci38 don't have any special meaning and run
the default version of the interpreter. This results in that that both
environments use the same interpreter locally.

The PR changes the names of environments to make sure that tox creates a
virtual environment with the correct interpreter version.
",# Use tox.ini envlist
839,"don't reuse closed connections, refs #4451
",# Don't reuse closed connectionsFixes #2088
840,"fixed a typo; this was fixed before but seems like it has been lost in the refactor
differnt -> different",# Fix typo in config.py
841,"[pipeline] rewrite bert tests and fix some bugs
## 📌 Checklist before creating the PR

- [x] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`

closes #4372 

## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.
This PR rewrites the bert pipeline test and fix some bugs


## 💥 Checklist before requesting a review

- [x] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [x] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [ ] I have performed a self-review of my code
- [ ] I have added thorough tests.
- [ ] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [x] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# [shardformer] remove pipeline test
842,"🌐 Update Korean translation for `/docs/ko/docs/dependencies/index.md`
- update tip, warning and etc to compatible with mkdocs",# 🌐 Fix Korean translation in docs🌐 Fix Korean translation in docs
843,"Update 'create-pr' action in release workflow to latest
A [warning is shown](https://github.com/microsoft/DeepSpeed/actions/runs/8695213322/job/23845782048#step:10:31) when we do releases:

```
[deploy](https://github.com/microsoft/DeepSpeed/actions/runs/8695213322/job/23845782048)
Node.js 16 actions are deprecated. Please update the following actions to use Node.js 20: peter-evans/create-pull-request@v4. For more information see: https://github.blog/changelog/2023-09-22-github-actions-transitioning-from-node-16-to-node-20/.
```

To resolve this we update the create a pull request to `@v6`, see release notes [here](https://github.com/peter-evans/create-pull-request/releases)",# Update create-pull-request action
844,"Fix grammar selection involving Python 2
Fixes #757.",# Fix #1595
845,"Improvement to the SSTI RCE
Simple improvements to Jinja2 SSTI RCE to clean up the ""0""s in output and facilitate the command input field.",# Update README.md
846,"[extensions/openai] load extension settings via `settings.yaml`
Just utilize the `dotenv` package to load environment variables from the `.env` file. Since the `openai` extension relies on specific environment variables, manually entering them each time the server starts can be cumbersome. Using `.env` will significantly streamline this process and save valuable time.

## Checklist:

- [x] I have read the [Contributing guidelines](https://github.com/oobabooga/text-generation-webui/wiki/Contributing-guidelines).
","# OpenAI: add settings, lazy load embedding model"
847,"Consolidate logging
- Make log event handler work
- Move terminal event log into an addon
- Clean various log related errors and duplications
",# Log: Use controller.LogEntry
848,"Kuba docker
Inherits kuba's docker setup.  Importantly, adds a development container to docker-compose.yml

Adds venv to a discrete directory, rather than it being the parent directory of src/
",# Docker support
849,"Add Statically
Please tell me if the description is not adequate. (I think it is)

<!-- Thank you for taking the time to work on a Pull Request for this project! -->
<!-- To ensure your PR is dealt with swiftly please check the following: -->
- [x] My submission is formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added Statically
850,"Style modals to match rest of UI
![image](https://user-images.githubusercontent.com/4073789/230220910-1f5f6253-0ae5-458a-9dd4-059d037816e9.png)
![image](https://user-images.githubusercontent.com/4073789/230221150-00559ffd-7415-403b-a7f7-84ac65ebad40.png)
![image](https://user-images.githubusercontent.com/4073789/230221021-d6889906-7247-4d7b-b59d-443897087ac8.png)![image](https://user-images.githubusercontent.com/4073789/230221236-fed0ab61-2ca8-4886-8824-dc34b12e7b50.png)

",# Update UI
851,"[embeddings] use cache_ratio instead of cuda_row_num
",# [cache-embedding] use cache ratio to control cache size
852,"Bug fixes for GCP (as of 2019-04-16T06:06:16Z)
##### SUMMARY
Bug fixes for GCP (as of 2019-04-16T06:06:16Z)

##### ISSUE TYPE
- Bugfix Pull Request

##### ADDITIONAL INFORMATION
```
This was generated by [Magic Modules](https://github.com/googlecloudplatform/magic-modules)
```",# Fix #56315 - Fixing the indentation in the gcp_compute_route.py
853,"[ZDF] added current test case
### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [adding new extractor tutorial](https://github.com/rg3/youtube-dl#adding-support-for-a-new-site) and [youtube-dl coding conventions](https://github.com/rg3/youtube-dl#youtube-dl-coding-conventions) sections
- [x] [Searched](https://github.com/rg3/youtube-dl/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [ ] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [x] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Bug fix
- [x] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

Other tests were no longer available (404) so I added a new/current one
",# [zdf] fix extractor test
854,"added option to remove conversations
Also solve a simple bug in line 121",# Add delete conversation button
855,"Fix intersphinx_mapping config for Python standard library
Currently, the [intersphinx_mapping](https://www.sphinx-doc.org/en/master/usage/extensions/intersphinx.html#confval-intersphinx_mapping) for `python` is set to the Requests documentation. This prevents some references from being linked to the Python standard library documentation.

This PR reverts the configuration change made in #5236 and sets the URL for `python` back to https://docs.python.org/3/ as (shown in the example in the intersphinx_mapping documentation).

Some effects of this change can be seen on the Developer Interface page.

Before:

![image](https://user-images.githubusercontent.com/1156625/73128655-84969600-3fa0-11ea-9e43-ffb8e5c7886f.png)

After:

![image](https://user-images.githubusercontent.com/1156625/73128660-a6901880-3fa0-11ea-87a0-012b185b605f.png)
",# Update docs conf.py
856,"fix #1608
",# Fix queue bug
857,"Fix ffmpeg wrong folder format and douyu discard output folder
```
 python3 you-get -o dow http://www.douyu.com/611813
Site:       douyu.com
Title:      台妹髮型師～美髮院直播
Type:       Flash video (video/x-flv)
Size:       inf MiB (inf Bytes)

Downloading streaming content with FFmpeg, press q to stop recording...
ffmpeg -y -re -i http://hdla.douyucdn.cn/live/611813re7VjmtaHO.flv?wsAuth=27185bfe7901f7d65f88834a427ef3dd&token=web-0-611813-260fc67c9f304fe923401dc7d0406014&logo=0&expire=0 -c copy -bsf:a aac_adtstoasc dow/台妹髮型師～美髮院直播.flv
```

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/soimort/you-get/1342)

<!-- Reviewable:end -->
",# fix bug of douyu tv
858,"template: use dashes instead of underscores for neo4j-cypher package and path in readme
Minimal readme template update

underscores didn't work, dashes do

",# Fix typo in README.md
859,"Update onboarding to Laravel 11
Not to be merged before March 12th.",# Update Laravel docs
860,"Fix wheel dependencies for Python 2
Fix issues like #287 where `pathlib` wasn't installed on Python 2
",# Travis CI: Use pip install -r requirements.txt
861,"Style fixes in comments
-make the comment style more consistent by replacing Nothing with N/A
-fix typo in sherlock.py",# Update N/A to Nothing
862,"build(deps): bump beautifulsoup4 from 4.12.2 to 4.12.3
Bumps [beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/bs4/) from 4.12.2 to 4.12.3.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=beautifulsoup4&package-manager=pip&previous-version=4.12.2&new-version=4.12.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update beautifulsoup4 to 4.12.3
863,"Make AMD/ROCm apex install to /blob to save test/compile time.
- Save time on AMD unit tests (despite being only run in CI nightly currently) by pre-compiling and re-using the (AMD/ROCm) apex install.  
- This saves ~15 minutes per build of the AMD unit tests.",# [amd-mi200] Fix apex install
864,"Ignore a domain in allowed_domains with port and issue a warning
Fix for issue #50, see discussion there for a rationale.

Note that this PR is based on PR #4410 and would make PR #3198 obsolete.

Fixes #50, closes #3198",# [MRG+1] Fix #1055
865,"Generate all subsequences using backtracking
",# Added a new problem
866,"recurrent Layers: Fix doc strings on default activations
* The default activation for input is `tanh`, not `linear`, as
  the previous doc string might mislead readers to think.
* Also clarify that the default activation for recurrent is
  `hard_sigmoid`.",# Update recurrent.py
867,"Fix CI by running on Python 3.11
aiohttp doesn't yet support 3.12",# Pin Python version to 3.11
868,"tests - fetchMarketLeverageTiers fix
",# test: skip fetchMarketLeverageTiers for spot markets
869,"📝 Add german blog post (Domain-driven Design mit Python und FastAPI)
I have written a blog post about domain driven design with Python and FastAPI:

https://www.actidoo.com/de/blog/python-fastapi-domain-driven-design

_Domain-driven Design mit Python und FastAPI_

I would be happy about feedback.",# Add German article about FastAPI and Domain-driven Design
870,"Minor docs typo fixes
# What does this PR do?
Just a few typo fixes in the docs.

## Before submitting
- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).

## Who can review?
@sgugger",# Fix typos
871,"docs fix typo in example ondemand_loader_tool
Fixed typo in an example code in docs: `on_demand_loader_tool` -> `ondemand_loader_tool` to make it work",# Fix typo in docs
872,"feat(core): Add stream data return and reception
1. add file: utils/steam_pipe.py
2. add demo: samples/flask_web_api.py
3. Other core code modifications, Add and use the StreamPipe class at night
4. Add flask library to requirements


**Features**
<!-- Clear and direct description of the submit features. -->
<!-- If it's a bug fix, please also paste the issue link. -->

- xx
- yy
    
**Feature Docs**
<!-- The RFC, tutorial, or use cases about the feature if it's a pretty big update. If not, there is no need to fill. -->

**Influence**
Not affecting other functions

**Result**
<!-- The screenshot/log of unittest/running result -->
![4b5a6673dfb9d9fe06dd0272ff89d39](https://github.com/geekan/MetaGPT/assets/50728022/c14a4cd6-990f-47d2-bb44-5d4367f4a416)
Download this MD file here
![e9207c3f6e6c4bf6edb7b95736221a7](https://github.com/geekan/MetaGPT/assets/50728022/c9094d75-57a3-4d1a-927c-cd4dd6c098e0)


**Other**
<!-- Something else about this PR. -->",# [example] Stream output via API
873,"Feat re-commit zhipu-api due to merge mistake
**Features**
<!-- Clear and direct description of the submit features. -->
<!-- If it's a bug fix, please also paste the issue link. -->

- re-commit zhipu-api due to merge mistake
    
**Feature Docs**
<!-- The RFC, tutorial, or use cases about the feature if it's a pretty big update. If not, there is no need to fill. -->

**Influence**
<!-- Tell me the impact of the new feature and I'll focus on it.  -->

**Result**
<!-- The screenshot/log of unittest/running result -->

```
(metagpt_v2) MacBook-Pro:MetaGPT xxx$ pytest tests/metagpt/provider/test_zhipuai_api.py
============================================================================== test session starts ===============================================================================
collected 2 items

tests/metagpt/provider/test_zhipuai_api.py ..                                                                                                                              [100%]

=============================================================================== 2 passed in 0.24s ================================================================================
(metagpt_v2) MacBook-Pro:MetaGPT xxx$ pytest tests/metagpt/provider/zhipuai/test_*
============================================================================== test session starts ===============================================================================
collected 2 items

tests/metagpt/provider/zhipuai/test_async_sse_client.py .                                                                                                                  [ 50%]
tests/metagpt/provider/zhipuai/test_zhipu_model_api.py .                                                                                                                   [100%]

=============================================================================== 2 passed in 0.35s ================================================================================
```

**Other**
<!-- Something else about this PR. -->",# fix zhipuai api
874,"fix get_raw_path parsing
<!-- Please refer to the contribution guidelines before raising a PR: https://github.com/localstack/localstack/blob/master/CONTRIBUTING.md -->

<!-- Why am I raising this PR? Add context such as related issues, PRs, or documentation. -->
## Motivation
This PR would fix #8928 and #8924. We had an issue with parsing the WSGI environ `RAW_URI`, because an HTTP request can also contain a full URL and not only an absolute path. See the RFC: https://www.ietf.org/rfc/rfc2616.txt
```
   To allow for transition to absoluteURIs in all requests in future
   versions of HTTP, all HTTP/1.1 servers MUST accept the absoluteURI
   form in requests, even though HTTP/1.1 clients will only generate
   them in requests to proxies.
```

We would then have more than the path with `get_raw_path`, which lead to issue down the road when trying to match in our router.

<!-- What notable changes does this PR make? -->
## Changes
We now thanks to @dfangl parse the `RAW_URI` variable with `urllib.parse.urlparse` to then only get the `path` part of the `RAW_URI` in case there's more. 
Added a unit test covering this use case.

<!-- The following sections are optional, but can be useful! 

## Testing

Description of how to test the changes

## TODO

What's left to do:

- [ ] ...
- [ ] ...

-->

",# fix get_raw_path for WSGI requests
875,"fix(bybit): parseTicker default type
- fixes https://github.com/ccxt/ccxt/issues/17054

```
Python v3.10.9
CCXT v2.8.93
bybit.fetchTickers()
{'10000NFT/USDT:USDT': {'ask': 0.0045,
                        'askVolume': 1606880.0,
                        'average': 0.0045725,
                        'baseVolume': 69163390.0,
                        'bid': 0.00449,
                        'bidVolume': 808280.0,
                        'change': -0.000145,
                        'close': 0.0045,
                        'datetime': None,
                        'high': 0.0047,
                        'info': {'ask1Price': '0.004500',
                                 'ask1Size': '1606880',
                                 'basisRate': '',
                                 'bid1Price': '0.004490',
                                 'bid1Size': '808280',
                                 'deliveryFeeRate': '',
                                 'deliveryTime': '0',
                                 'fundingRate': '0.0001',
                                 'highPrice24h': '0.004700',
                                 'indexPrice': '0.004488',
                                 'lastPrice': '0.004500',
                                 'lowPrice24h': '0.004455',
                                 'markPrice': '0.004496',
                                 'nextFundingTime': '1677974400000',
                                 'openInterest': '42939560',
                                 'openInterestValue': '193056.26',
                                 'predictedDeliveryPrice': '',
                                 'prevPrice1h': '0.004485',
                                 'prevPrice24h': '0.004645',
                                 'price24hPcnt': '-0.031216',
                                 'symbol': '10000NFTUSDT',
                                 'turnover24h': '316081.51527999',
                                 'volume24h': '69163390'},
                        'last': 0.0045,
                        'low': 0.004455,
                        'open': 0.004645,
                        'percentage': -3.1216,
                        'previousClose': None,
                        'quoteVolume': 316081.51527999,
                        'symbol': '10000NFT/USDT:USDT',
                        'timestamp': None,
                        'vwap': 0.004570069733134682},
```
```
Python v3.10.9
CCXT v2.8.93
bybit.fetchTickers() --spot
{'AAVE/USDT': {'ask': 0.0,
               'askVolume': 0.0,
               'average': 10000.0,
               'baseVolume': 0.0,
               'bid': 10000.0,
               'bidVolume': 0.057,
               'change': 0.0,
               'close': 10000.0,
               'datetime': None,
               'high': 10000.0,
               'info': {'ask1Price': '0',
                        'ask1Size': '0',
                        'bid1Price': '10000',
                        'bid1Size': '0.057',
                        'highPrice24h': '10000',
                        'lastPrice': '10000',
                        'lowPrice24h': '10000',
                        'prevPrice24h': '10000',
                        'price24hPcnt': '0',
                        'symbol': 'AAVEUSDT',
                        'turnover24h': '0',
                        'volume24h': '0'},
               'last': 10000.0,
               'low': 10000.0,
               'open': 10000.0,
               'percentage': 0.0,
               'previousClose': None,
               'quoteVolume': 0.0,
               'symbol': 'AAVE/USDT',
               'timestamp': None,
               'vwap': None},
```
",# bybit: use defaultType from options
876,"Update DS-Chat docs for v0.9.0
",# Update README.md
877,"[pbs] detect errors from http error code
",# [pbs] Add error messages
878,"Fix Taxi (upgrade -> v2)
This fixes the initial state distribution of Taxi such that it no longer produces a start location equal to the goal location (issue #72). At the moment the distribution is not what's expected.

The new reward threshold was calculated using policy iteration.",# Taxi-v1 to Taxi-v2
879,"bitmart.createOrder string math
```
$ bitmart createOrder MATIC/USDT market buy 7 0.795 
2022-09-21T04:55:47.664Z
Node.js: v18.9.0
CCXT v1.93.9
(node:20873) ExperimentalWarning: The Fetch API is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
bitmart.createOrder (MATIC/USDT, market, buy, 7, 0.795)
2022-09-21T04:55:50.338Z iteration 0 passed in 867 ms

{
  id: '54725861463',
  clientOrderId: undefined,
  info: { order_id: '54725861463' },
  timestamp: undefined,
  datetime: undefined,
  lastTradeTimestamp: undefined,
  symbol: 'MATIC/USDT',
  type: 'market',
  timeInForce: undefined,
  postOnly: undefined,
  side: 'buy',
  price: 0.795,
  stopPrice: undefined,
  amount: 7,
  cost: undefined,
  average: undefined,
  filled: undefined,
  remaining: undefined,
  status: undefined,
  fee: undefined,
  trades: [],
  fees: []
}
2022-09-21T04:55:50.338Z iteration 1 passed in 867 ms
```",# bitmart: fix createMarketBuyOrderRequiresPrice
880,"Add Spanish translation
Hello @satwikkansal!

Refer to issue: #252. I've finished the Spanish translation (wrote 1 week on the issue but it turns out I'm a few days late 😅). Nonetheless, the translation is completed.

**Things I did:**
- Translated all content from English to Spanish from the files `README.md`, `CONTRIBUTING.md` and `CONTRIBUTORS.md`.
- Replaced some links with its Spanish translation mirror (most docs.python.org links and some wikipedia links).
- Translate **only** the comments from the code snippets.

The repository: [JoseDeFreitas/wtfpython-es](https://github.com/JoseDeFreitas/wtfpython-es) (on `master` branch).

**This pull request:**
- Added the reference in the [README.md](https://github.com/satwikkansal/wtfpython/blob/master/README.md) file.
- Added myself in the [CONTRIBUTORS.md](https://github.com/satwikkansal/wtfpython/blob/master/CONTRIBUTORS.md) file.

I'll be watching the changes in this repository from time to time so I can update the Spanish translation.",# Add Spanish translation
881,"New snippet: yielding from... return!
","# Add ""Yielding from... return!"""
882,"Update CoinMarketCap Readme
CoinMarketCap does require an `apiKey`

Thank you for taking the time to work on a Pull Request for this project!

To ensure your PR is dealt with swiftly please check the following:

- [x] Your submissions are formatted according to the guidelines in the [contributing guide](CONTRIBUTING.md)
- [x] Your additions are ordered alphabetically
- [x] Your submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column should be padded with one space on either side
- [x] You have searched the repository for any relevant issues or pull requests
- [x] Any category you are creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Update README.md
883,"Refactor chain pattern
Fixes #252 

- aiming for simplification this PR removes second implementation with coroutines, client with delegation method and timing
- rename `_successor` attribute to `successor`: pattern should provide method to add/change successor dynamicly (usually is called ""set_next""). Additional setter would be overkill, but leading underscore discourages changes (wrongly).
- bugfix: add check in handler method if there is a successor (otherwise we do not handle end-of-chain properly)
- add docstring to base `def handle(self, request)`
- rename `_handle` to `compare`
- change intervals from `0 < request <= 10` to `0 <= request < 10: zero-indexing is more natural in such cases (and handles zeroes)
- change numbers in concreate handle names. This way it is easier to understand output e.g. when numbers **2**x belong to ConcreteHanlder**2** (represents number of tens)
- ...

**What's left:**
In case of PR approval - `viz\chain.py.png` should be removed or recreated.
I would also like to rename this file from ""chain.py"" to ""chain_of_responsibility.py"" as it is well known by this name.
",# Update chain.py
884,"corrected version
the version tag should be 1.2.0, afaik 1.1.3 doesn't exist
Btw. https://keras.io/layers/writing-your-own-keras-layers/ shows an older version of this page.",# Update the version number in the writing your own layer template
885,"Edge TPU `tf.lite.experimental.load_delegate` fix
Fix attempt for #6535

## 🛠️ PR Summary

<sub>Made with ❤️ by [Ultralytics Actions](https://github.com/ultralytics/actions)<sub>

### 🌟 Summary
Refinement of TensorFlow Lite model loading in YOLOv5.

### 📊 Key Changes
- Unified import statements for TensorFlow Lite (TFLite) to improve readability and maintainability.
- Adjusted the use of the `tflite_runtime.interpreter` import to better differentiate between the full TensorFlow Lite package and the TensorFlow Lite runtime package.
- Ensured compatibility with Edge TPU by dynamically loading the appropriate delegate based on the underlying operating system.

### 🎯 Purpose & Impact
- **Simplification of Code:** By consolidating import statements and handling TensorFlow Lite in a more straightforward manner, the code is cleaner and easier to understand.
- **Enhanced Flexibility:** This update provides better support for Edge TPU devices by adapting the delegate loading process to the user's operating system.
- **User Experience:** Users will benefit from a smoother experience when running YOLOv5 models with TensorFlow Lite, particularly those using Edge TPU hardware for accelerated inference.",# Fix TensorFlow Lite Edge TPU inference
886,"Hitbtc3 createReduceOnlyOrder
Added createReduceOnlyOrder to Hitbtc3:
```
hitbtc3.createReduceOnlyOrder (BTC/USDT:USDT, market, sell, 0.0001, 31000)
2022-03-18T06:56:52.301Z iteration 0 passed in 218 ms

{
  info: {
    id: '59038431641',
    client_order_id: 'Yt_6r9I071aBzJykD6fHGmrB-9BS03sa',
    symbol: 'BTCUSDT_PERP',
    side: 'sell',
    status: 'filled',
    type: 'market',
    time_in_force: 'GTC',
    quantity: '0.0001',
    quantity_cumulative: '0.0001',
    post_only: false,
    reduce_only: true,
    created_at: '2022-03-18T06:56:53.267Z',
    updated_at: '2022-03-18T06:56:53.267Z',
    trades: [
      {
        id: '4773720',
        position_id: '2386187',
        quantity: '0.0001',
        price: '40745.29',
        fee: '0.002037264500',
        timestamp: '2022-03-18T06:56:53.267Z',
        taker: true
      }
    ]
  },
  id: 'Yt_6r9I071aBzJykD6fHGmrB-9BS03sa',
  clientOrderId: 'Yt_6r9I071aBzJykD6fHGmrB-9BS03sa',
  timestamp: 1647586613267,
  datetime: '2022-03-18T06:56:53.267Z',
  lastTradeTimestamp: 1647586613267,
  symbol: 'BTC/USDT:USDT',
  price: 40745.29,
  amount: 0.0001,
  type: 'market',
  side: 'sell',
  timeInForce: 'IOC',
  postOnly: false,
  filled: 0.0001,
  remaining: 0,
  cost: 4.074529,
  status: 'closed',
  average: 40745.29,
  trades: [
    {
      info: {
        id: '4773720',
        position_id: '2386187',
        quantity: '0.0001',
        price: '40745.29',
        fee: '0.002037264500',
        timestamp: '2022-03-18T06:56:53.267Z',
        taker: true
      },
      id: '4773720',
      order: 'Yt_6r9I071aBzJykD6fHGmrB-9BS03sa',
      timestamp: 1647586613267,
      datetime: '2022-03-18T06:56:53.267Z',
      symbol: 'BTC/USDT:USDT',
      type: 'market',
      side: 'sell',
      takerOrMaker: 'taker',
      price: 40745.29,
      amount: 0.0001,
      cost: 4.074529,
      fee: { cost: 0.0020372645, currency: 'USDT' },
      fees: [ { currency: 'USDT', cost: '0.002037264500' } ]
    }
  ],
  fee: { currency: 'USDT', cost: 0.0020372645 },
  fees: [ { currency: 'USDT', cost: 0.0020372645 } ]
}
```",# hitbtc3: add createReduceOnlyOrder
887,"[twitter] fix twitter video download
fix twitter video download",# [twitter] fix #111
888,"Slow writing to shared memory in VectorEnv
Writing to shared memory was very slow, most likely due to slicing the shared memory. It is now using numpy to copy data over the shared memory (similar to what is done in `baselines`).",# Fix shared memory
889,"Add autoclave cipher
### Describe your change:

I'm adding the autoclave or autokey cipher.
Is similar to the vigenerè cipher, but using the own plaintext as the key.
The code implements an encrypt and a decrypt function.
For more info:
https://en.wikipedia.org/wiki/Autokey_cipher

* [x] Add an algorithm?
* [ ] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [x] All new Python files are placed inside an existing directory.
* [x] All filenames are in all lowercase characters with no spaces or dashes.
* [x] All functions and variable names follow Python naming conventions.
* [x] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [x] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [x] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [x] If this pull request resolves one or more open issues then the commit message contains `Fixes: #{$ISSUE_NO}`.
",# Autokey cipher
890,"Fix SGLang worker
",# fix: add background tasks to streaming response
891,"bingx: update
Changes:
* add new api
* add clientOrderId => test their api but the behavior seems not right, the clientOrderId wasn't set / return for spot order api

When I create order for spot, I found the handleErrors didn't work.
The error response from spot: `'{""code"":100202,""msg"":""Code: 100202, Msg: {\""Code\"":100202,\""Msg\"":\""order PendingManager.PlaceMultiOrdersNormalUser transfer in: dtm DTM.handleTaskEvent withdrawal fail: dtm DTM.withdrawal ret fail, code: 102202, msg: \"",\""RemoteInfo\"":null,\""TextData\"":{\""Format\"":\""用户资产不足\"",\""Args\"":[]}}"",""debugMsg"":""""}'` (not a correct json string).

For swap, they return `{""code"":101204,""msg"":""Insufficient margin"",""data"":{}}`, so it works fine.",# bingx: add clientOrderId to order
892,"bump 324 and 35
",# bump version
893,"[keras/applications/mobilenet.py] Standardise docstring usage of ""Default to""
This is one of many PRs. Discussion + request to split into multiple PRs @ #17748",# Fix docstring of MobileNet
894,"Fix flickering effect when changing tabs
## Describe your changes

I don't know when and why the width == 0 flicker problem returned (could be related to [this](https://github.com/streamlit/streamlit/pull/7835) or [this](https://github.com/streamlit/streamlit/pull/7697) change or some browser changes). It seems to happen a bit more randomly:

https://github.com/streamlit/streamlit/assets/2852129/033623d7-0b61-4baa-ad18-6cddfce80209

The fixes in this PR seem to prevent this flickering fully. 

## Testing Plan

- Not really easy to test since it is just some flickering. 

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.
",# Fix flickering effect on vertical blocks
895,"[extractor/nos.nl] Add extractor
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

</details>

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

ADD DESCRIPTION HERE
This PR add site-support for nos.nl, a site that serve news in Netherland 

Fixes #4649 


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [ ] Fix or improvement to an extractor (Make sure to add/update tests)
- [x] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))
",# [nosnl] Add extractor
896,"Support second turn judgement and singe answer grading
<!-- Thank you for your contribution! -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

Requested by @merrymercy to support second turn judgement for MT-bench. Also added single answer grading as a second tab to the MT-bench judge. 

<!-- Please give a short summary of the change and the problem this solves. -->

You can take a look at the new site at: https://a5070c83f1fe17e8b1.gradio.live/


## Related issue number (if applicable)

<!-- For example: ""Closes #1234"" -->

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [x] I've included any doc changes needed.
- [x] I've made sure the relevant tests are passing (if applicable).
",# Add single answer grading demo
897,"fix wrong path in some doc
# What does this PR do?

The examples use a path this is (likely) moved to the current one some time ago. Let's update those.",# Fix broken links in testing.md
898,"MNT remove deprecated kind='legacy' in partial_dependence
Remove `kind='legacy'` in `partial_dependence` after deprecation cycle.",# DOC: Remove kind='legacy' from partial_dependence
899,"Add param functions, to override types, to make mypy happy
:sparkles: Add param functions, to override types, to make `mypy` happy.

This would solve https://github.com/tiangolo/fastapi/issues/219 and other cases of `mypy` complaining about the default types.

## Simple solution

The simplest approach would be to make `mypy` ignore the types in those parameters, using comments with `# type: ignore` like in:

```Python
from fastapi import FastAPI, Path, Query

app = FastAPI()


@app.get(""/items/{item_id}"")
async def read_items(  # type: ignore
    item_id: int = Path(..., title=""The ID of the item to get""),
    q: str = Query(None, alias=""item-query""),  
):
    results = {""item_id"": item_id}
    if q:
        results.update({""q"": q})
    return results
```

### Drawback

But asking all the users to add comments to ignore type checks each time they use these classes would be difficult and cumbersome (for end users/developers).

## Reason

The issue is that `mypy` is right, from the typing point of view. Putting an instance of `Query` as the ""default value"" of a parameter with type `str` is not really correct (from the typing point of view).

But here in FastAPI we are ""hacking"" the typing system, and extending its use to the extreme (which has proven to work really well for many users/use-cases). The *path operation function* is only called by FastAPI (not by the user or any other code), and FastAPI makes sure to pass the correct type, those classes are only for meta-information, used by FastAPI.

## Alternatives

I tried overriding the type declaration of the parameter classes, but there's no way to achieve that.

Then I tried adding a typing stub (`parameters.pyi`), but although it removed `mypy` errors, there where other errors in places used by FastAPI internally.

And then, by relaxing the type declarations to avoid the internal errors, the type hints of those parameters were also lost for final users.

There's a lot of work (and code) there just to have completion for all those parameters in classes... One of the main objectives is for FastAPI to be as comfortable for final developers as possible, even if that is at the expense of the developers of the library itself (me and the community that submits PRs :grin: ).

## Final solution

Here's the solution. We can't override the type declaration of a class (the class itself).

But we can override the return type declaration of a function.

So, I converted all these parameter classes exposed by FastAPI (`Depends`, `Query`, `File`, etc) to functions. But then, as the function is actually called when the code is run and FastAPI needs to inspect it afterwards when the app is running, each of these functions returns the original class instances.

So, the default values of the parameters are actually those classes, and can be checked by the rest of the FastAPI code (dependencies, etc).",# Add param_functions.py
900,"Support batch-dimension in log_mel_spectogram
`log_mel_spectrogram` makes the assumption in `stft[:, :-1].abs() ** 2` that the input to this function is one dimensional (sequence of audio samples in 16kHz). 

However, all the tensor operating functions can deal with a leading batch dimensions. PyTorch supports the Ellipsis like NumPy to indicate remaining dimensions. This allows us to directly reference the last dimension, instead of assuming that the `stft` frames end up in the second dimension.

By using the ellipsis symbol on the `stft` tensor we can make `log_mel_spectogram` support batched inputs of shape [batch, samples].",# Fix audio processing
901,"[AIRFLOW-XXXX] Add cross-reference between connection and fernet
The `Manage connection` page contains very detailed information. However, it doesn't contain information about fernet.
 
---
Issue link: `Document only change, no JIRA issue`

Make sure to mark the boxes below before creating PR: [x]

- [X] Description above provides context of the change
- [X] Commit message/PR title starts with `[AIRFLOW-NNNN]`. AIRFLOW-NNNN = JIRA ID<sup>*</sup>
- [X] Unit tests coverage for changes (not needed for documentation changes)
- [X] Commits follow ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)""
- [X] Relevant documentation is updated including usage instructions.
- [X] I will engage committers as explained in [Contribution Workflow Example](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#contribution-workflow-example).

<sup>*</sup> For document-only changes commit message can start with `[AIRFLOW-XXXX]`.

---
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
Read the [Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines) for more information.
",# [MRG+1] Add a section on securing connections
902,"Added tests for form.py
Improving code and branch coverage within form.py",# Add tests for invalid formdata
903,"SL_3 'Do not add non-standard entities to namespace `std`' add example
Add simple example","# Add ""My_vector"" to the list of forbidden namesFixes #1115."
904,"Docker fix
",# Update Dockerfile
905,"Update Liaobots.py
Add claude 3 models & update other models",# Update Liaobots
906,"Updated typing for WebsocketMessage.content
#### Description

Fixes https://github.com/mitmproxy/mitmproxy/issues/4131
I have no idea about Python typing, I copied this from StackOverflow like a professional.

#### Checklist

 - [x] I have updated tests where applicable.
 - [x] I have added an entry to the CHANGELOG.
",# Update typing for WebsocketMessage.content
907,"Pendulum updates
See Issue #2156

First change is using the identity that -sin(x + pi) = sin(x)

Second change is the fact that the angular velocity is clipped to the predefined range *before* being applied to the state of the environment. This way, we are guaranteed that the actual change of the angle between two consecutive timesteps will be constrained in the (-max_speed, max_speed) range. The change in the actual dynamics of the environment is minimal, but technically can be non-zero, so I bumped the version to Pendulum-v1.",# Fix Pendulum-v0
908,"perf(group): add type index to improve querying on groups 
Adds a compound index `(""project"", ""type"", ""status"", ""last_seen"", ""id"")` to improve query performance. 

Growth team is currently observing timeouts for large projects so this is required.

Fixes WOR-2122",# feat(group): Add index to group model
909,"add Citi API
Add Citi API to Finance
- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not have more than 100 characters
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

Relates to: #2107 ",# Added Citi API
910,"Refactor item_data update to handle byte keys and convert messages to dict
Closes #1237 ",# fix: handle byte keys in item
911,"ui: fix memory leak in `MapSettings`
",# Fix memory leak in MapSettings
912,"add CVE-2021-34527 + It Was All A Dream scanner
",# Add PrintNightmare scanner
913,"[MRG] Configures Appveyor to fail fast after sklearn installation
This PR configures Appveyor check for a newer build **after** sklearn installation and cancel the current build if a newer build exists.",# [appveyor] cancel if there is a newer build queued for the same PR
914,"Fix installation script for Fedora.
装了Fedora 23发现, Fedora用的不是`yum`, 所以改了一下脚本.
",# Add dnf support
915,"improved XXE SVG payloads to be valid XMLs
Hi,

while testing for XXEs in SVG I needed to make some changes so that the payloads are treated as valid XMLs. I thought it's worth doing a pr so that nobody misses an XXE because of lack of required attribute.

I fixed 2 things actually:
### image tag for XXE inside SVG
I was validating my payloads [here](https://validator.w3.org/#validate_by_input+with_options) and when you use _Validate by Direct Input_, choose _SVG 1.1_ DOCTYPE and paste 
```xml
<svg xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" width=""300"" version=""1.1"" height=""200"">
    <image xlink:href=""expect://ls""></image>
</svg>
```
There are 2 errors:

> Line 2, Column 36: required attribute ""width"" not specified 
> \<image xlink:href=""expect://ls"">\</image>
> The attribute given above is required for an element that you've used, but you have omitted it

and the same for height.

Thus I added them to the XXE SVG payload.

### xml tag in OOB via SVG rasterization
I added XML tag as without it my payload was causing exceptions. On the aforementioned validator it's still not considered valid, but adding it made the payload work in my case.

**Both fixes made my XXE work during the pentest and those payloads didn't work without them.**",# Update README.md
916,"Update README.md
fixed link of cortex",# Update README.md
917,"Added question ""What is an index in a database?""
",# Added a new question
918,"[ci/release] Move ML long running tests to sdk file manager
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

What: Long running tests should use sdk file manager
Why: Job submission server seems to crash under load, using the sdk file manager ensures we can still fetch results after a run.

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# [release] fix file manager in release tests
919,"[2.7] Build docs in parallel (GH-1842).
(cherry picked from commit eba68e2c42e149acecb15bbeb692786e2540157d)",# Travis: Use 4 cores for sphinx
920,"Added plugin support to the cli
This fixes #1776
",# Add support for CLI pluginsThis is a follow-up to #1054.  It adds support for plugins to be loaded from `setup.py` files.
921,"[workflow] added cuda extension build test before release
## 📌 Checklist before creating the PR

- [x] I have created an issue for this PR for traceability
- [x] The title follows the standard format: `[doc/gemini/tensor/...]: A concise description`
- [x] I have added relevant tags if possible for us to better distinguish different PRs


## 🚨 Issue number

> Link this PR to your issue with words like fixed to automatically close the linked issue upon merge
>
> e.g. `fixed #1234`, `closed #1234`, `resolved #1234`

Fixed #2597 

## 📝 What does this PR do?

> Summarize your work here.
> if you have any plots/diagrams/screenshots/tables, please attach them here.

In this PR, I have renamed the `release_bdist.yml` so that it will only be used to check whether CUDA extensions can be built before release.

## 💥 Checklist before requesting a review

- [x] I have linked my PR to an issue ([instruction](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue))
- [x] My issue clearly describes the problem/feature/proposal, with diagrams/charts/table/code if possible
- [x] I have performed a self-review of my code
- [x] I have added thorough tests.
- [x] I have added docstrings for all the functions/methods I implemented

## ⭐️ Do you enjoy contributing to Colossal-AI?

- [x] 🌝 Yes, I do.
- [ ] 🌚 No, I don't.

Tell us more if you don't enjoy contributing to Colossal-AI.
",# [ci] remove bdist workflow
922,"Add regex control over separators in character text splitter
<!-- Thank you for contributing to LangChain!

Replace this comment with:
  - Description: a description of the change, 
  - Issue: the issue # it fixes (if applicable),
  - Dependencies: any dependencies required for this change,
  - Tag maintainer: for a quicker response, tag the relevant maintainer (see below),
  - Twitter handle: we announce bigger features on Twitter. If your PR gets announced and you'd like a mention, we'll gladly shout you out!

Please make sure you're PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.

If you're adding a new integration, please include:
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use.

Maintainer responsibilities:
  - General / Misc / if you don't know who to tag: @baskaryan
  - DataLoaders / VectorStores / Retrievers: @rlancemartin, @eyurtsev
  - Models / Prompts: @hwchase17, @baskaryan
  - Memory: @hwchase17
  - Agents / Tools / Toolkits: @hinthornw
  - Tracing / Callbacks: @agola11
  - Async: @agola11

If no one reviews your PR within a few days, feel free to @-mention the same people again.

See contribution guidelines for more information on how to write/run tests, lint, etc: https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md
 -->
#7854

Added the ability to use the `separator` ase a regex or a simple character.
Fixed a bug where `start_index` was incorrectly counting from -1.

Who can review?
@eyurtsev
@hwchase17 
@mmz-001",# Add is_separator_regex to TextSplitter
923,"Use k-nn for face filtering
The current implementation of face detection uses a threshold for determining if a face matches the reference image. This commit allows the user to add multiple reference images and multiple negative reference images and then uses the old threshold in addition to K-nearest neighbours method to determine if some negative reference is more similar. This is useful if we have a video of multiple actors that look very similar.",# Add support for multiple reference images
924,"[downloader/mhtml] Fix fragments with absolute urls
## Please follow the guide below

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes [ ] relevant to your *pull request* (like that [x])
- Use *Preview* tab to see how your *pull request* will actually look like

---

### Before submitting a *pull request* make sure you have:
- [X] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [X] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [X] Checked the code with [flake8](https://pypi.python.org/pypi/flake8)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [X] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [X] Bug fix
- [ ] Improvement
- [ ] New extractor
- [ ] New feature

---

### Description of your *pull request* and other information

As per [extractor/common.py](https://github.com/yt-dlp/yt-dlp/blob/a825ffbffa0bea322e3ccb44c6f8e01d8d9572fb/yt_dlp/extractor/common.py#L174-L182), a fragment can either have a relative url (`path`) or absolute url (`url`). MhtmlFD currently does not take into account fragments that have an absolute url.

This also fixes the FranceTV extractor which incorrectly uses `path` for the absolute url in fragments.

The fix is copied from the implementation in [DashSegmentsFD](https://github.com/yt-dlp/yt-dlp/blob/a825ffbffa0bea322e3ccb44c6f8e01d8d9572fb/yt_dlp/downloader/dash.py#L71-L74).

",# [mhtml] fix #1591
925,"Fix Python 3.2 compatibility in tests
The FAQ says that requests is compatible with Python 3.2. However, I could not execute the tests using that Python version. This PR fixes this and updated the FAQ to match.
",# Fix #1595
926,"Added passlib for secure password storage
",# Add Passlib
927,"[1.0] Restore _plasma_directory option
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

These are needed for some libraries like Modin, until we have object spilling working.
",# [python] Add plasma_directory to worker init
928,"Fixed #28222 - Allow non-field model property attributes in defaults passed update_or_create()/get_or_create()
Allow the `defaults` argument to `update_or_create()`/`get_or_create()` to contain property attributes. The added tests further demonstrate the issue. 

For context, in 1.11 the `defaults` argument passed to `update_or_create()` and `get_or_create()` is validated and non-fields are reported as `FieldErrors` (introduced by #7255). There is an exception made for `pk` (added in #7338) but I believe it should apply to all `_meta._property_names` for the creation behavior to be consistent with `Model.create` and better backwards compatibility.

One thing to note @francoisfreitag, if `self.model._meta._property_names` always has `pk` then the param test can be made simpler by not checking for `pk` explicitly. 

https://code.djangoproject.com/ticket/28222

",# Fixed #28222 -- Relaxed validation of model properties in QuerySet.get_or_create() and update_or_create()https://code.djangoproject.com/ticket/28222
929,"Warn if the user edits a [server] config option
We can't always automatically apply these without a full server restart,
so we should bug the user to reboot streamlit.
    
Note that warning for all server config options is overly broad, but
it's certainly better to over-warn users than under-warn them in this
case.",# Warn on server config changes
930,"[extractor/trovo] fix extractor
Fixes: https://github.com/yt-dlp/yt-dlp/issues/4878

This is still available? Сould not find it used on platform.

https://github.com/yt-dlp/yt-dlp/blob/ae1035646a6be09c2aed3e22eb8910f341ddacfe/yt_dlp/extractor/trovo.py#L299-L300 and
https://github.com/yt-dlp/yt-dlp/blob/ae1035646a6be09c2aed3e22eb8910f341ddacfe/yt_dlp/extractor/trovo.py#L332-L333

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check one of the following options:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))
",# [trovo] fix #1111
931,"Create Python Program to Display Fibonacci Sequence Using Recursion
",# Create Python Program to Display Fibonacci Sequence Using Recursion
932,"Fix DeprecationWarning in local_weighted_learning.py
### Describe your change:

Recent build logs (e.g., [this one](https://github.com/TheAlgorithms/Python/actions/runs/6367653954/job/17286407238#step:6:750)) show that `machine_learning/local_weighted_learning/local_weighted_learning.py` produces a DeprecationWarning:
```
machine_learning/local_weighted_learning/local_weighted_learning.py::machine_learning.local_weighted_learning.local_weighted_learning.local_weight_regression
machine_learning/local_weighted_learning/local_weighted_learning.py::machine_learning.local_weighted_learning.local_weighted_learning.local_weight_regression
machine_learning/local_weighted_learning/local_weighted_learning.py::machine_learning.local_weighted_learning.local_weighted_learning.local_weight_regression
  /home/runner/work/Python/Python/machine_learning/local_weighted_learning/local_weighted_learning.py:125: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
    y_pred[i] = item @ local_weight(item, x_train, y_train, tau)
```
This warning occurs because the output of `@`, which is an `np.ndarray`, is being implicitly converted to a scalar. This PR replaces `@` with `np.dot()` to resolve this warning.

* [ ] Add an algorithm?
* [x] Fix a bug or typo in an existing algorithm?
* [ ] Documentation change?

### Checklist:
* [x] I have read [CONTRIBUTING.md](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md).
* [x] This pull request is all my own work -- I have not plagiarized.
* [x] I know that pull requests will not be merged if they fail the automated tests.
* [x] This PR only changes one algorithm file.  To ease review, please open separate PRs for separate algorithms.
* [ ] All new Python files are placed inside an existing directory.
* [ ] All filenames are in all lowercase characters with no spaces or dashes.
* [ ] All functions and variable names follow Python naming conventions.
* [ ] All function parameters and return values are annotated with Python [type hints](https://docs.python.org/3/library/typing.html).
* [ ] All functions have [doctests](https://docs.python.org/3/library/doctest.html) that pass the automated testing.
* [ ] All new algorithms include at least one URL that points to Wikipedia or another similar explanation.
* [ ] If this pull request resolves one or more open issues then the description above includes the issue number(s) with a [closing keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue): ""Fixes #ISSUE-NUMBER"".
",# Fix numpy compatibility
933,"Increase MyQ update interval
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Breaking change
<!--
  If your PR contains a breaking change for existing users, it is important
  to tell them what breaks, how to make it work again and why we did this.
  This piece of text is published with the release notes, so it helps if you
  write it towards our users, not us.
  Note: Remove this section if this PR is NOT a breaking change.
-->


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
Regardless of anything else that may be the problem, I think MyQ is being hit too much and that is causing some of the problems people are having (directly or indirectly)

I believe 30 seconds is a more appropriate polling interval.

Also removed some unused constants

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Deprecation (breaking change to happen in the future)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [ ] The code change is tested and works locally.
- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**
- [ ] There is no commented out code in this PR.
- [ ] I have followed the [development checklist][dev-checklist]
- [ ] I have followed the [perfect PR recommendations][perfect-pr]
- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.
- [ ] Untested files have been added to `.coveragerc`.

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/
[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/
[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/
[docs-repository]: https://github.com/home-assistant/home-assistant.io
[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr
",# myq: Update const.py
934,"[wip][dependencies] pip-compile dependencies as a build step
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

It's currently complicated to update dependencies, as it requires a (manual) recompilation of the `requirements_compiled.txt` file.

This PR adds a separate build job that runs pip compile on all input files to generate an updated `requirements_compiled.txt`, that is than exposed as an artifact in the buildkite job.

To update a dependency in the future, the process would be:

1. Open a PR that updates the respective requirements in the input requirements file
2. Wait for the CI job to run through and output the updated compiled requirements file
3. If the compilation was successful, add the contents of the file to the PR

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
    - [ ] I've added any new APIs to the API Reference. For example, if I added a 
           method in Tune, I've added it in `doc/source/tune/api/` under the 
           corresponding `.rst` file.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# [ci] Create var/artifact directory
935,"Updated Musikki entry
Musikki requires AppKey and AppId that can be obtained in the Musikki dashboard",# Added Musikki API
936,"Refs #30400 -- Improved typography in debug and csrf templates.
https://code.djangoproject.com/ticket/30400",# Fixed typos in technical 404 and 500 pages.
937,"fix exception when using Anthropic_API_KEY rather than OPENAI_API_KEY
fix problem in #189 ",# Add Anthropic API Key
938,"[letstest] create and reuse a persistent boulder AMI
Closes #2017 
",# Fix #1115
939,"raise exception instead of print & exit
It's better to raise an exception to handle the error more gracefully than abruptly exiting the script.",# Add exception for unsupported model type
940,"fix: Reduce warnings for k_means and discriminant_analysis
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->

References #5685

#### What does this implement/fix? Explain your changes.

- Reduce the number of warnings for k_means by setting n_init to 1
when proviging initialization centers
- Remove discriminant_analysis test warnings by guarding against zero
division for `predict_log_proba`
- Print `p` parameter ignore warning only when different than `None`

#### Any other comments?

#DataUmbrella

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->
",# [MRG] Fix warnings in DBSCAN and KMeans
941,"Refactor zwave_js disconnect client helper
<!--
  You are amazing! Thanks for contributing to our project!
  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).
-->
## Breaking change
<!--
  If your PR contains a breaking change for existing users, it is important
  to tell them what breaks, how to make it work again and why we did this.
  This piece of text is published with the release notes, so it helps if you
  write it towards our users, not us.
  Note: Remove this section if this PR is NOT a breaking change.
-->


## Proposed change
<!--
  Describe the big picture of your changes here to communicate to the
  maintainers why we should accept this pull request. If it fixes a bug
  or resolves a feature request, be sure to link to that issue in the
  additional information section.
-->
- This refactor prepares for the zwave_js options flow that will use the disconnect client helper.

## Type of change
<!--
  What type of change does your PR introduce to Home Assistant?
  NOTE: Please, check only 1! box!
  If your PR requires multiple boxes to be checked, you'll most likely need to
  split it into multiple PRs. This makes things easier and faster to code review.
-->

- [ ] Dependency upgrade
- [ ] Bugfix (non-breaking change which fixes an issue)
- [ ] New integration (thank you!)
- [ ] New feature (which adds functionality to an existing integration)
- [ ] Breaking change (fix/feature causing existing functionality to break)
- [x] Code quality improvements to existing code or addition of tests

## Additional information
<!--
  Details are important, and help maintainers processing your PR.
  Please be sure to fill out additional details, if applicable.
-->

- This PR fixes or closes issue: fixes #
- This PR is related to issue: 
- Link to documentation pull request: 

## Checklist
<!--
  Put an `x` in the boxes that apply. You can also fill these out after
  creating the PR. If you're unsure about any of them, don't hesitate to ask.
  We're here to help! This is simply a reminder of what we are going to look
  for before merging your code.
-->

- [x] The code change is tested and works locally.
- [x] Local tests pass. **Your PR cannot be merged unless tests pass**
- [x] There is no commented out code in this PR.
- [x] I have followed the [development checklist][dev-checklist]
- [x] The code has been formatted using Black (`black --fast homeassistant tests`)
- [ ] Tests have been added to verify that the new code works.

If user exposed functionality or configuration variables are added/changed:

- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]

If the code communicates with devices, web services, or third-party tools:

- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  
      Updated and included derived files by running: `python3 -m script.hassfest`.
- [ ] New or updated dependencies have been added to `requirements_all.txt`.  
      Updated by running `python3 -m script.gen_requirements_all`.
- [ ] Untested files have been added to `.coveragerc`.

The integration reached or maintains the following [Integration Quality Scale][quality-scale]:
<!--
  The Integration Quality Scale scores an integration on the code quality
  and user experience. Each level of the quality scale consists of a list
  of requirements. We highly recommend getting your integration scored!
-->

- [ ] No score or internal
- [ ] 🥈 Silver
- [ ] 🥇 Gold
- [ ] 🏆 Platinum

<!--
  This project is very active and we have a high turnover of pull requests.

  Unfortunately, the number of incoming pull requests is higher than what our
  reviewers can review and merge so there is a long backlog of pull requests
  waiting for review. You can help here!
  
  By reviewing another pull request, you will help raise the code quality of
  that pull request and the final review will be faster. This way the general
  pace of pull request reviews will go up and your wait time will go down.
  
  When picking a pull request to review, try to choose one that hasn't yet
  been reviewed.

  Thanks for helping out!
-->

To help with the load of incoming pull requests:

- [ ] I have reviewed two other [open pull requests][prs] in this repository.

[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone

<!--
  Thank you for contributing <3

  Below, some useful links you could explore:
-->
[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html
[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html
[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html
[docs-repository]: https://github.com/home-assistant/home-assistant.io
",# Remove unused variables
942,"Correct typo in typing.py
In the docstring of `ParamSpec`, the name of `P = ParamSpec('P')` was mistakenly written as `'T'`.

<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y] <title from the original PR> (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->
",# bpo-39498: Fix typo in typing.py
943,"Set `inputs` as kwarg in `TextClassificationPipeline`
# What does this PR do?

This PR replaces the current `*args` arg within `TextClassificationPipeline` with a kwarg named `inputs` to be able to use it as a keyword arg when e.g. trying to unpack a Python dict as `pipeline(**{""inputs"": ""text""})` which is not possible with the current approach since the `*args` were being used instead.

Additionally, the usage of a kwarg aligns the `TextClassificationPipeline` implementation with the rest of the `Pipeline` subclasses, and not being a breaking change, since before no keyword arg could be specified.

## Before submitting

- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [x] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).
- [x] Did you write any new necessary tests? -> There was no need to write any test, since the unpacking of `*inputs` works the same way as `*args` did, only adding the possibility to use it as a kwarg too.

## Who can review?

Anyone in the community is free to review the PR once the tests have passed. Feel free to tag
members/contributors who may be interested in your PR.

Library:

- pipelines: @Rocketknight1 ",# Fix text classification pipeline
944,"[BildIE] Fix ampersands in xml attributes & update test thumbnails
Currently the BildIE test case fails for the following reasons:

1/ The XML downloaded contains raw ampersands in attributes
2/ The expected thumbnail has changed.

This pull request fixes these 2 issues
",# [bild] fix xml ampersands
945,"feat: expose sfn endpoint
Currently, when attempting to [execute workflow from task](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-nested-workflows.html), I get this error: {""Type"":""TaskFailed"",""PreviousEventId"":6,""TaskFailedEventDetails"":{""ResourceType"":""states"",""Resource"":""startExecution.sync"",""Error"":""StepFunctions-AWSStepFunctionsException"",""Cause"":""The security token included in the request is invalid. (Service: AWSStepFunctions; Status Code: 400; Error Code: UnrecognizedClientException; Request ID: 1a9d805b-55af-4bf3-8515-4bf49e4f81e3)""}}

This PR exposes the `--step-functions-endpoint` flag that was added to the jar but not documented properly in the AWS docs.",# Add stepfunctions endpoint to stepfunctions_starter.py
946,"Allow PNG-RGBA for Extras Tab
## Description

Hello guys!
There's a small issue when we want to swap a face to PNG images (with RGBA) - (in particular via ReActor)
By default SD WebUI cuts Alpha-channel when we postprocess the image via the Extras Tab

E.g.:
I load the image with transparency and want to swap the face
So I get the following result:

![image](https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/85128026/591b0a5e-fa34-450c-8a79-34d0fcefc9cf)
![image](https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/85128026/36611231-83ba-46f2-afae-dc92c69e0cb2)

As we can see the alpha channel is lost

With this little fix we can operate with all 4 channels of the input image - and the result is:

![image](https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/85128026/128162bf-d961-47a9-976c-ff1eea8acd12)
![image](https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/85128026/b87c1c2f-5dbc-4372-bdb3-1477e0c9879f)

## Screenshots/videos:

![image](https://github.com/AUTOMATIC1111/stable-diffusion-webui/assets/85128026/c6770898-0a87-4462-9a96-3649293c5cab)

## Additional information

Related Issue: https://github.com/Gourieff/sd-webui-reactor/issues/382

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Fix for RGBA images
947,"Add UA-SQuAD QA dataset
Resolves https://github.com/LAION-AI/Open-Assistant/issues/1531",# Add UA squad dataset
948,"Add support for three-legged OAuth for Google connections. Useful for…
… developer-mode.
",# [AIRFLOW-1111] Move BigQuery and GCS hooks to use a base class
949,"Afterwords->Afterwards
",# Fix typo in loaders.rst
950,"[3.6] bpo-27385: Clarify docstring for groupby() (GH-3738)
(cherry picked from commit 49392c63a243052c8013bef80d35202bb6d7c404)

<!-- issue-number: bpo-27385 -->
https://bugs.python.org/issue27385
<!-- /issue-number -->
",# bpo-31198: Clarify groupby() docstring
951,"Tested invalid QuerySet.order_by() arguments.
",# Fixed #28614 -- Added test for invalid order_by arguments.
952,"fix(widget-builder): Avoid unnecessary queries for events
The events dataset would re-query in some unnecessary cases. 

Reordering the fields, adding an alias, and adding a new field shouldn't immediately trigger a request when it's blank

There are some unnecessary queries in the release data set but I'm going to handle those separately.",# fix(dashboards): Fix dashboard query when adding a columnFixes https://github.com/getsentry/sentry/issues/24015
953,"remove dead links
",# Remove outdated links
954,"Readme: document cd_parent
",# Fix typo in README.md
955,"Remove __pycache__ and add __pycache__ to .gitignore
**pycache** is python3 bitcode which shouldn't be included.

Signed-off-by: Wang wangwangwar@gmail.com
",# Add.gitignore
956,"Parse escape codes in `Pretty` repr
## Type of changes

- [ ] Bug fix
- [x] New feature
- [ ] Documentation / docstrings
- [ ] Tests
- [ ] Other

## Checklist

- [x] I've run the latest [black](https://github.com/psf/black) with default args on new code.
- [x] I've updated CHANGELOG.md and CONTRIBUTORS.md where appropriate.
- [x] I've added tests for new code.
- [x] I accept that @willmcgugan may be pedantic in the code review.

## Description

Given the class:

```python
    class Thing:
        def __repr__(self) -> str:
            return ""Hello\x1b[38;5;239m World!""
```

Rich outputs:

Old version without ANSI parsing in pretty repr:
<img width=""252"" alt=""image"" src=""https://user-images.githubusercontent.com/5740731/184918637-69bfbe58-d5e5-4cd3-adf9-fd22354eb8b7.png"">

New version with ANSI parsing in pretty repr:
<img width=""297"" alt=""image"" src=""https://user-images.githubusercontent.com/5740731/184918766-d6c58fcc-9cb5-4ef2-8b5a-6328ff060547.png"">

",# Parse ANSI escape sequences in pretty reprFixes #2470
957,"Fix misspelling in CKA.md
",# Fix typo in CKA.md
958,"[xiami] 继续修非数字 URL
继 #1650 之后，又遇到了新的不能解析的 URL： http://www.xiami.com/song/xL4jJGd3829

现在应该都能解析了。顺手修了歌曲名不对的问题。

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/soimort/you-get/1756)
<!-- Reviewable:end -->
",# fix xiami.com
959,"Keras 2 and keras-contrib pull request process
Updated https://github.com/fchollet/keras/pull/5445 for keras-2 release.
Explains the new pull request procedures for Keras 1, Keras 2, and keras-contrib, should resolve #5270.
Based on discussion in #4944 and farizrahman4u/keras-contrib#9.",# Add a note about where to submit PRs
960,"[TNAFlix] Allow dot (and more) in cat_id and display_id
URLs with dots were raising a ""UnsupportedError: Unsupported URL"" error.
",# [empflix] and [tnaflix] tests
961,"Update checkout action on workflows on ubuntu 20.04
- Only workflows running Ubuntu 20.04 or later can be updated as the GLIBC that is needed for node 20+ can be updated now.
- Workflows that aren't updated are running Ubuntu 18.04 or older, those will need to be moved to updated images shortly and will be updated later in the original PR, #5021

Sample warning that is resolved:

```
Node.js 16 actions are deprecated. Please update the following actions to use Node.js 20: actions/checkout@v3. For more information see: https://github.blog/changelog/2023-09-22-github-actions-transitioning-from-node-16-to-node-20/.
```",# Update actions/checkout to v4
962,"Bump torch-rocm to 5.6/5.7
## Description

updated whl and nightly versions for rocm from 5.4.2 to 5.6 and 5.6 nightly to 5.7, running in my linux build and works

## Screenshots/videos:


## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Update torch version for Navi 3
963,"[AIRFLOW-6511] Remove BATS docker containers
The containers were not removed and you have to remove them
with `dockery system prune`. The --rm flag is added.

---
Issue link: [AIRFLOW-6511](https://issues.apache.org/jira/browse/AIRFLOW-6511/)

- [x] Description above provides context of the change
- [x] Commit message/PR title starts with `[AIRFLOW-NNNN]`. AIRFLOW-NNNN = JIRA ID<sup>*</sup>
- [x] Unit tests coverage for changes (not needed for documentation changes)
- [x] Commits follow ""[How to write a good git commit message](http://chris.beams.io/posts/git-commit/)""
- [x] Relevant documentation is updated including usage instructions.
- [x] I will engage committers as explained in [Contribution Workflow Example](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#contribution-workflow-example).

<sup>*</sup> For document-only changes commit message can start with `[AIRFLOW-XXXX]`.

---
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in [UPDATING.md](https://github.com/apache/airflow/blob/master/UPDATING.md).
Read the [Pull Request Guidelines](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst#pull-request-guidelines) for more information.
",# Remove dangling docker container
964,"Add Notebooks - A starter kit for jupyter notebooks and machine learning
There is a great list of software here. What I see missing is a pre-built environment to start quickly to run them. I've built a set of docker images to take care of that.",# Add Notebooks
965,"[requires.io] dependency update on main branch
",# Update ruamel.yaml to 0.17.14
966,"Update llama.cpp integration
<!-- 
  - **Description:** removed redondant link, replaced it with Meta's LLaMA repo, add resources for models' hardware requirements, 
  - **Issue:** None,
  - **Dependencies:** None,
  - **Tag maintainer:** None,
  - **Twitter handle:** @ElliotAlladaye
 -->
",# Update llama.cpp docs
967,"Clarifications/simplifications in S3 and Redis notebooks
# Description

Clarifications and simplifications in S3 and Redis notebooks. Also fixes https://github.com/run-llama/llama_index/issues/8205

## Type of Change

- [x] New feature (non-breaking change which adds functionality)

# How Has This Been Tested?

- [ ] Added new unit/integration tests
- [ ] Added new notebook (that tests end-to-end)
- [x] I stared at the code and made sure it makes sense
",# Fix some minor issues in the docs
968,"TST: Test datetime array assignment with different units (#7492)
 - [x] closes #7492
 - [x] tests added / passed
 - [x] passes ``git diff upstream/master | flake8 --diff``

The example in this issue currently works in master. Added a test to confirm. Based on a quick skim of the recent PRs, doesn't look like it was fixed recently. 
",# TST: Add test for datetime assignment with NaT and diff time unitsCloses #7492
969,"Fix data-sort-name containing spaces
Spaces in extra network filenames cause the card's `data-sort-name` attribute to be truncated to the first word, with the rest added as empty attributes.

Before:
```html
<div class=""card"" ... data-sort-name=""3d"" rendering="""" v12.safetensors="""">
```

After:
```html
<div class=""card"" ... data-sort-name=""3d rendering style v12.safetensors"">
```

## Checklist:
- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Fix sort keys in extra networks
970,"[air] Deprecate some fields/classes that are supposed to be gone in 2.6.
<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?
Deprecate some fields/classes that are supposed to be gone in 2.6.

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number
Closes #38380

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
    - [ ] I've added any new APIs to the API Reference. For example, if I added a 
           method in Tune, I've added it in `doc/source/tune/api/` under the 
           corresponding `.rst` file.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
",# [AIR] Remove deprecated properties
971,"Note about large num of options for multiselect
Ref #1059 

Make a note in the docstring that performance will be degraded on the front-end when a large list of possible values are passed for a multiselect widget. The number of 100+ is just there as a conservatively low value for people to determine ""large"". The actual number is likely higher, but also likely a function of the hardware being used.

![image](https://user-images.githubusercontent.com/2762787/84934790-cfc35980-b0a5-11ea-9e4d-a7f43f5dae32.png)
",# Add note to multiselect docstring
972,"Fix case-insensitive comparison in Session.get_adapter
While trying to get the adapter for an url, the url is lowered before comparing with the prefix, but the prefix is not, so if it contains non-lowercase characters (eg. `https://example.com/sOmE_WeiRD_pReFIX/`), it won't return the correct adapter.

The other solution is to lower the prefix while adding the adapter. I have opted for the first solution to isolate in one place the case-insensitivity feature.

Edit:
Another alternative could be to document that the prefix should be passed lowered to Session.mount() (this is what I am doing for now to work-around the issue).",# Make prefix matching in get_adapter() case-insensitiveFixes #1321
973,"Add unit test to check HF low_cpu_mem_usage_flag 
Re-submitting #2511.  

Context: 
low_cpu_mem_usage flag was breaking before [this fix](https://github.com/microsoft/DeepSpeed/commit/f2710bbe1dc19717b3c99e910cb453ea20ae8b08), and we saw a lot of interest in this feature, so adding this unit test to not regress.

Co-authored-by: Lok Chand Koppaka <lokoppak@microsoft.com>",# [pt] Add test for low cpu mem usage
974,"Minor change in README
Spelling fix of: weigths to weights",# Fix typo in README.md
975,"add best_of and use_beam_search for completions interface
Since vllm's openai interface also support those two parameter. We'd better to also add it for fastchat, to pass those to vllm backend.

<!-- Thank you for your contribution! -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number (if applicable)

<!-- For example: ""Closes #1234"" -->

## Checks

- [x] I've run `format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed.
- [ ] I've made sure the relevant tests are passing (if applicable).
",# support best_of in vllm
976,"Major Update for Bing - Supports latest bundle version and image analysis
Here it is, a much-needed update to this service which offers numerous functionalities that the old code was unable to deliver to us.

As you may know, ChatGPT Plus subscribers now have the opportunity to request image analysis directly from GPT within the chat bar. Bing has also integrated this feature into its chatbot. With this new code, you can now provide an image using a data URI, with all the following supported extensions: jpg, jpeg, png, and gif!

**What is a data URI and how can I provide an image to Bing?**

Just to clarify, a data URI is a method for encoding data directly into a URI (Uniform Resource Identifier). It is typically used for embedding small data objects like images, text, or other resources within web pages or documents. Data URIs are widely used in web applications.

To provide an image from your desktop and retrieve it as a data URI, you can use this code: [GitHub link](https://gist.github.com/3l3gant-cod3s/6d5bab4b8f5c116e7b447538a8095a62).

Now, here is a code snippet you can use to provide images to Bing:

```python
import g4f

user_message = [{""role"": ""user"", ""content"": ""Hi, describe this image.""}]

response = g4f.ChatCompletion.create(
    model = g4f.models.gpt_4,
    provider = g4f.Provider.Bing,
    messages = user_message,
    stream = True,
    image = ""data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/4RiSRXhpZgAASUkqAAg...""  # Insert your full data URI image here
)

for message in response:
    print(message, flush=True, end='')
```

If the image you provided is not valid or if the upload fails, I have ensured that Bing can still respond to your message without causing the entire request to fail. And if you don't want to analyze any image, just do not specify the image parameter.

Regarding the implementation, the image is preprocessed within the Bing.py code, which can be resource-intensive for a server-side implementation. When using the Bing chatbot in your web browser, the image is preprocessed on your computer before being sent to the server. This preprocessing includes tasks like image rotation and compression. Although this implementation works, it would be more efficient to delegate image preprocessing to the client as it happens in reality. I will try to provide a JavaScript code for that at a later time.

As you saw, I did mention in the title that it is in Beta. The way the code is written, Bing can sometimes mess up its answers. Indeed, Bing does not really stream its responses as the other providers do. Bing sends its answers like this on each iteration:

""Hi,""
""Hi, this,""
""Hi, this is""
""Hi, this is Bing.""

Instead of sending each segment one at a time, it already adds them on each iteration. So, to simulate a normal streaming response, other contributors made the code wait for the next iteration to retrieve the newer segments and yield them. However, this method ignores something that Bing does.

Bing processes its responses in a markdown detector, which searches for links while the AI answers. If it finds a link, it saves it and waits until the AI finishes its answer to put all the found links at the very end of the answer. So if the AI is writing a link, but then on the next iteration, it finishes writing this link, it will then be deleted from the answer and appear later at the very end. Example:

""Here is your link reference [""
""Here is your link reference [^""
""Here is your link reference [^1""
""Here is your link reference [^1^""

And then the response would get stuck there because the markdown detector would have deleted this link reference in the next iteration and waited until the AI is finished to put it at the very end.

For this reason, I am working on an update to anticipate the markdown detector. So please, if you guys notice any bugs with this new implementation, I would greatly appreciate it if you could report them on the issue tab of this repo. Thanks in advance, and I hope that all these explanations were clear to you!",# Bing: Add image support
977,"add option: Live preview in full page image viewer
feature request: https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/14213 Option for Full Page Viewer (""ModalView""): LastGeneratedImage or CurrentPreviewImage 

add option to make  #13459 ""show the preview image in the modal view if available"" optional

not sure if I should place this option under live preview or under gallery
I put it under live preview because I guess it's the first place that people look when for stuff for live preview

---
someone is requesting this to get pushed to 1.7.0-RC
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/14213#discussioncomment-7848590
> I hope the PR gets added because the new 1.7 functionality prevents me from using one of my custom extensions effectively.

## Checklist:

- [x] I have read [contributing wiki page](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)
- [x] I have performed a self-review of my own code
- [x] My code follows the [style guidelines](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing#code-style)
- [x] My code passes [tests](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Tests)
",# Add option to show live preview in full page image viewer
978,"build(deps): bump emoji from 2.9.0 to 2.10.0
Bumps [emoji](https://github.com/carpedm20/emoji) from 2.9.0 to 2.10.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/carpedm20/emoji/releases"">emoji's releases</a>.</em></p>
<blockquote>
<h2>v2.10.0</h2>
<ul>
<li>Added Arabic and Turkish translations</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/carpedm20/emoji/blob/master/CHANGES.md"">emoji's changelog</a>.</em></p>
<blockquote>
<h2>v2.10.0 (2024-01-18)</h2>
<ul>
<li>Added Arabic and Turkish translations</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/carpedm20/emoji/commit/ec64b72e8c98897c6b9c0e0d2aa72b5d439a20ee""><code>ec64b72</code></a> v2.10.0 added to changelog</li>
<li><a href=""https://github.com/carpedm20/emoji/commit/3045892e46d34cf684124593f1f4a5cc62cac584""><code>3045892</code></a> Merge pull request <a href=""https://redirect.github.com/carpedm20/emoji/issues/279"">#279</a> from fqa-cyber/master</li>
<li><a href=""https://github.com/carpedm20/emoji/commit/fc1b3fd771fd04c717a697c63f1e8617ef64c9f9""><code>fc1b3fd</code></a> Update generatePages file</li>
<li><a href=""https://github.com/carpedm20/emoji/commit/f14ece8475a1f2323326a4b850a209509310e470""><code>f14ece8</code></a> Adding Arabic Language Support</li>
<li><a href=""https://github.com/carpedm20/emoji/commit/daf8c13d649616818e81d29b894f7759b568007f""><code>daf8c13</code></a> Adding Turkish Language Support</li>
<li><a href=""https://github.com/carpedm20/emoji/commit/f5ffc860b61cb3208b73b2fe43cf842312f94aed""><code>f5ffc86</code></a> Update README.rst</li>
<li>See full diff in <a href=""https://github.com/carpedm20/emoji/compare/v2.9.0...v2.10.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=emoji&package-manager=pip&previous-version=2.9.0&new-version=2.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update emoji to 2.10.0
979,"Add exception handling when attempting to write keras config file
Add exception handling when attempting to write keras config file to disk to match tf.contrib.keras implementation.
Basically trying to match:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/keras/python/keras/backend.py#L3648
My understanding is that writing the config file is only an ""attempt"" and should be treated as such?",# Fix #2085
980,"ZeRO2-Offload: Load balance gradient copying to CPU
During backward in ZeRO-2 Offload, reduced gradients are accumulated into CPU memory for later optimizer step. Due to the previous model partitioning scheme, gradient copying to CPU occurs one rank at a time, which slows down backward and under-utilizes PCIe. This PR introduces a new model partitioning scheme that spreads gradient copying evenly among all (most) ranks at any point in time. This improves backward time and PCIe utilization.   ",# [zero3] Reorder gradients for load balancingReorder gradients for load balancing
981,"Add comment to flake8 configuration explaining line-length mismatch
We noticed this mismatch in configuration when the configuration to our own repo. Could not see a good reason why this would be any different

Updated to match pyproject.toml configuration https://github.com/psf/black/blob/master/pyproject.toml#L9

UPDATE: changed PR so that it explains why flake8 configuration has a different line length",# Flake8 max-line-length
982,"mypy: ignore `git` package entirely
The recent mypy fix for the `git` import (https://github.com/streamlit/streamlit/pull/3819) is causing mypy to fail locally:

```
$ make mypy
./scripts/mypy
lib/streamlit/git_util.py:37:1: error: Skipping analyzing ""git"": found module but no type hints or library stubs  [import]
                import git
    ^
lib/streamlit/git_util.py:37:1: note: See https://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports
lib/streamlit/git_util.py:42: error: unused ""type: ignore"" comment
                self.repo = git.Repo(path, search_parent_directories=True)  # type: ignore[attr-defined]
```

Instead, let's just have mypy ignore the git package altogether. This should work in both CircleCI and local.",# Bypass mypy for GitPython
983,"Switch LGPL'd chardet for MIT licensed charset_normalizer
At least for Python 3 -- charset_normalizer doesn't support Python2, so for that chardet is still used -- this means the ""have chardet"" path is also still tested.

Although using the (non-vendored) chardet library is fine for requests itself, but using a LGPL dependency the story is a lot less clear for downstream projects, particularly ones that might like to bundle requests (and thus chardet) in to a single binary -- think something similar to what docker-compose is doing. By including an LGPL'd module it is no longer clear if the resulting artefact must also be LGPL'd.

By changing out this dependency for one under MIT we remove all license ambiguity.

As an ""escape hatch"" I have made the code so that it will use chardet first if it is installed, but we no longer depend upon it directly, although there is a new extra added, `requests[lgpl]`. This should minimize the impact to users, and give them an escape hatch if charset_normalizer turns out to be not as good. (In my non-exhaustive tests it detects the same encoding as chartdet in every case I threw at it)

I've read https://github.com/psf/requests/pull/4115, https://github.com/psf/requests/issues/3389, and https://github.com/chardet/chardet/issues/36#issuecomment-768281452 so I'm aware of the history, but I hope that the approach in this PR will allow this to be merged, as right now, the Apache Software Foundation doesn't allow projects to depend upon LGPL'd code (this is something I'm trying to get changed, but it is a _very_ slow process)
",# Use charset_normalizer for Python 3
984,"DOC: Add PyArrow user guide
",# DOC: Add PyArrow user guide
985,"Fixed base model class name extraction from PeftModels
# What does this PR do?

<!--
Congratulations! You've made it this far! You're not quite done yet though.

Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.

Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.

Once you're done, someone will review your PR shortly (see the section ""Who can review?"" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.
-->

<!-- Remove if not applicable -->

Fixes #27161


## Before submitting
- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).
- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),
      Pull Request section?
- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link
      to it if that's the case.
- [ ] Did you make sure to update the documentation with your changes? Here are the
      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and
      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).
- [ ] Did you write any new necessary tests?


## Who can review?

@pacman100, @muellerzr 

<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @

 If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.
 Please tag fewer than 3 people.

Models:

- text models: @ArthurZucker and @younesbelkada
- vision models: @amyeroberts
- speech models: @sanchit-gandhi
- graph models: @clefourrier

Library:

- flax: @sanchit-gandhi
- generate: @gante
- pipelines: @Narsil
- tensorflow: @gante and @Rocketknight1
- tokenizers: @ArthurZucker
- trainer: @muellerzr and @pacman100

Integrations:

- deepspeed: HF Trainer/Accelerate: @pacman100
- ray/raytune: @richardliaw, @amogkam
- Big Model Inference: @SunMarc
- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada

Documentation: @stevhliu and @MKhalusova

HF projects:

- accelerate: [different repo](https://github.com/huggingface/accelerate)
- datasets: [different repo](https://github.com/huggingface/datasets)
- diffusers: [different repo](https://github.com/huggingface/diffusers)
- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)

Maintained examples (not research project or legacy):

- Flax: @sanchit-gandhi
- PyTorch: See Models above and tag the person corresponding to the modality of the example.
- TensorFlow: @Rocketknight1

 -->
",# Fix PEFT Trainer
986,"fixbug: #1095
**Features**
fixbug: #1095",# fix bug: add issue to code plan and change
987,"Tie Lambda backend lookup to resource ARNs to avoid region mismatches
Tie Lambda backend lookup to resource ARNs to avoid region mismatches.

The problem is that we're currently accessing `LambdaRegion.get()` in a few places, and the assumption is that the proper region is configured in the context (which is a conceptual flaw in the first place). This may not be the case, e.g., when restoring state from persistence/pods, where we iterate through the regions, and then restore the function code for each function in each region.

This is currently breaking our integration tests upstream (restoring Lambdas from pods/persistence) in platform. Example of an error we're seeing in the logs:
```
localstack_main | 2022-10-04T21:56:21.428  INFO --- [   asgi_gw_1] l.s.awslambda.persistence  : Unable to load user code for Lambda function arn:aws:lambda:us-east-2:000000000000:function:PreSignUpLambda: 'arn:aws:lambda:us-east-1:000000000000:function:PreSignUpLambda'
```

Should be considered more as a quick fix / bandaid for now. Also added a small unit test, to test the lookup with different input parameters.",# Fix LambdaRegion lookup for ARNsFixes #1595
988,"Bump actions/setup-python from 4 to 5
Bumps [actions/setup-python](https://github.com/actions/setup-python) from 4 to 5.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v5.0.0</h2>
<h2>What's Changed</h2>
<p>In scope of this release, we update node version runtime from node16 to node20 (<a href=""https://redirect.github.com/actions/setup-python/pull/772"">actions/setup-python#772</a>). Besides, we update dependencies to the latest versions.</p>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v4.8.0...v5.0.0"">https://github.com/actions/setup-python/compare/v4.8.0...v5.0.0</a></p>
<h2>v4.8.0</h2>
<h2>What's Changed</h2>
<p>In scope of this release we added support for GraalPy (<a href=""https://redirect.github.com/actions/setup-python/pull/694"">actions/setup-python#694</a>). You can use this snippet to set up GraalPy:</p>
<pre lang=""yaml""><code>steps:
- uses: actions/checkout@v4
- uses: actions/setup-python@v4 
  with:
    python-version: 'graalpy-22.3' 
- run: python my_script.py
</code></pre>
<p>Besides, the release contains such changes as:</p>
<ul>
<li>Trim python version when reading from file by <a href=""https://github.com/FerranPares""><code>@​FerranPares</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/628"">actions/setup-python#628</a></li>
<li>Use non-deprecated versions in examples by <a href=""https://github.com/jeffwidman""><code>@​jeffwidman</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/724"">actions/setup-python#724</a></li>
<li>Change deprecation comment to past tense by <a href=""https://github.com/jeffwidman""><code>@​jeffwidman</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/723"">actions/setup-python#723</a></li>
<li>Bump <code>@​babel/traverse</code> from 7.9.0 to 7.23.2 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/743"">actions/setup-python#743</a></li>
<li>advanced-usage.md: Encourage the use actions/checkout@v4 by <a href=""https://github.com/cclauss""><code>@​cclauss</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/729"">actions/setup-python#729</a></li>
<li>Examples now use checkout@v4 by <a href=""https://github.com/simonw""><code>@​simonw</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/738"">actions/setup-python#738</a></li>
<li>Update actions/checkout to v4 by <a href=""https://github.com/dmitry-shibanov""><code>@​dmitry-shibanov</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/761"">actions/setup-python#761</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/FerranPares""><code>@​FerranPares</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/628"">actions/setup-python#628</a></li>
<li><a href=""https://github.com/timfel""><code>@​timfel</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/694"">actions/setup-python#694</a></li>
<li><a href=""https://github.com/jeffwidman""><code>@​jeffwidman</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/724"">actions/setup-python#724</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v4...v4.8.0"">https://github.com/actions/setup-python/compare/v4...v4.8.0</a></p>
<h2>v4.7.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Bump word-wrap from 1.2.3 to 1.2.4 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/702"">actions/setup-python#702</a></li>
<li>Add range validation for toml files by <a href=""https://github.com/dmitry-shibanov""><code>@​dmitry-shibanov</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/726"">actions/setup-python#726</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v4...v4.7.1"">https://github.com/actions/setup-python/compare/v4...v4.7.1</a></p>
<h2>v4.7.0</h2>
<p>In scope of this release, the support for reading python version from pyproject.toml was added (<a href=""https://redirect.github.com/actions/setup-python/pull/669"">actions/setup-python#669</a>).</p>
<pre lang=""yaml""><code>      - name: Setup Python
        uses: actions/setup-python@v4
&lt;/tr&gt;&lt;/table&gt; 
</code></pre>
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/0a5c61591373683505ea898e09a3ea4f39ef2b9c""><code>0a5c615</code></a> Update action to node20 (<a href=""https://redirect.github.com/actions/setup-python/issues/772"">#772</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/0ae58361cdfd39e2950bed97a1e26aa20c3d8955""><code>0ae5836</code></a> Add example of GraalPy to docs (<a href=""https://redirect.github.com/actions/setup-python/issues/773"">#773</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/b64ffcaf5b410884ad320a9cfac8866006a109aa""><code>b64ffca</code></a> update actions/checkout to v4 (<a href=""https://redirect.github.com/actions/setup-python/issues/761"">#761</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/8d2896179abf658742de432b3f203d2c2d86a587""><code>8d28961</code></a> Examples now use checkout@v4 (<a href=""https://redirect.github.com/actions/setup-python/issues/738"">#738</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/7bc6abb01e0555719edc2dbca70a2fde309e5e56""><code>7bc6abb</code></a> advanced-usage.md: Encourage the use actions/checkout@v4 (<a href=""https://redirect.github.com/actions/setup-python/issues/729"">#729</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/e8111cec9d3dc15220d8a3b638f08419f57b906a""><code>e8111ce</code></a> Bump <code>@​babel/traverse</code> from 7.9.0 to 7.23.2 (<a href=""https://redirect.github.com/actions/setup-python/issues/743"">#743</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/a00ea43da65e7c04d2bdae58b3afecd77057eb9e""><code>a00ea43</code></a> add fix for graalpy ci (<a href=""https://redirect.github.com/actions/setup-python/issues/741"">#741</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/8635b1ccc5934e73ed3510980fd2e7790b85839b""><code>8635b1c</code></a> Change deprecation comment to past tense (<a href=""https://redirect.github.com/actions/setup-python/issues/723"">#723</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/f6cc428f535856f9c23558d01765a42a4d6cf758""><code>f6cc428</code></a> Use non-deprecated versions in examples (<a href=""https://redirect.github.com/actions/setup-python/issues/724"">#724</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/5f2af211d616f86005883b44826180b21abb4060""><code>5f2af21</code></a> Add GraalPy support (<a href=""https://redirect.github.com/actions/setup-python/issues/694"">#694</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/setup-python/compare/v4...v5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=4&new-version=5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",# Update GitHub Actions setup-python to v5
989,"Adding Docs for `PromptLayerCallbackHandler`
@baskaryan
Here I am adding documentation for the `PromptLayerCallbackHandler`.
When we created the initial PR for the callback handler the docs were causing issues, so we merged without the docs.",# Add PromptLayer docs
990,"tici loggerd fixes
",# loggerd: fix encoder thread
991,"[YouPornIE] Extract all encrypted links and remove doubles at the end
",# Youporn: fix extraction
992,"fix download redtube.com
**IMPORTANT**: PRs without the template will be CLOSED

### Description of your *pull request* and other information

<!--

Explanation of your *pull request* in arbitrary form goes here. Please **make sure the description explains the purpose and effect** of your *pull request* and is worded well enough to be understood. Provide as much **context and examples** as possible

-->

Reason: because https://www.redtube.com is not added to the beginning of the URL of the videoURL variable. I added it and it worked fine

```
[debug] Command-line config: ['-Fv', 'https://www.redtube.com/103228341']
[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out utf-8, error utf-8, screen utf-8
[debug] yt-dlp version stable@2023.12.30 from yt-dlp/yt-dlp [f10589e34] (linux_exe)
[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-5.15.0-91-generic-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)
[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2
[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2023.11.17, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.1.0, websockets-12.0
[debug] Request Handlers: urllib, requests, websockets
[debug] Loaded 1819 extractors
[RedTube] Extracting URL: https://www.redtube.com/103228341
[RedTube] 103228341: Downloading webpage
[RedTube] 103228341: Downloading JSON metadata
[RedTube] 103228341: Downloading m3u8 information
[RedTube] 103228341: Downloading m3u8 information
[RedTube] 103228341: Downloading m3u8 information
[RedTube] 103228341: Downloading m3u8 information
[RedTube] 103228341: Downloading m3u8 information
[RedTube] 103228341: Downloading JSON metadata
[debug] Formats sorted by: hasvid, ie_pref, lang, quality, res, fps, hdr:12(7), vcodec:vp9.2(10), channels, acodec, size, br, asr, proto, vext, aext, hasaud, source, id
[info] Available formats for 103228341:
ID         EXT RESOLUTION FPS │   FILESIZE   TBR PROTO │ VCODEC      ACODEC
──────────────────────────────────────────────────────────────────────────────
240        mp4 240p           │                  https │ unknown     unknown
hls-377-0  mp4 426x240     30 │ ~ 41.97MiB  378k m3u8  │ avc1.640015 mp4a.40.2
hls-377-1  mp4 426x240     30 │ ~ 41.97MiB  378k m3u8  │ avc1.640015 mp4a.40.2
480        mp4 480p           │                  https │ unknown     unknown
hls-781-0  mp4 854x480     30 │ ~ 86.77MiB  781k m3u8  │ avc1.64001f mp4a.40.2
hls-781-1  mp4 854x480     30 │ ~ 86.77MiB  781k m3u8  │ avc1.64001f mp4a.40.2
720        mp4 720p           │                  https │ unknown     unknown
hls-1411-0 mp4 1280x720    30 │ ~156.82MiB 1412k m3u8  │ avc1.64001f mp4a.40.2
hls-1411-1 mp4 1280x720    30 │ ~156.82MiB 1412k m3u8  │ avc1.64001f mp4a.40.2
1080       mp4 1080p          │                  https │ unknown     unknown
hls-2030-0 mp4 1920x1080   30 │ ~225.61MiB 2031k m3u8  │ avc1.640032 mp4a.40.2
hls-2030-1 mp4 1920x1080   30 │ ~225.61MiB 2031k m3u8  │ avc1.640032 mp4a.40.2
```

Fixes #


<details open><summary>Template</summary> <!-- OPEN is intentional -->

<!--

# PLEASE FOLLOW THE GUIDE BELOW

- You will be asked some questions, please read them **carefully** and answer honestly
- Put an `x` into all the boxes `[ ]` relevant to your *pull request* (like [x])
- Use *Preview* tab to see how your *pull request* will actually look like

-->

### Before submitting a *pull request* make sure you have:
- [x] At least skimmed through [contributing guidelines](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions) including [yt-dlp coding conventions](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#yt-dlp-coding-conventions)
- [x] [Searched](https://github.com/yt-dlp/yt-dlp/search?q=is%3Apr&type=Issues) the bugtracker for similar pull requests
- [x] Checked the code with [flake8](https://pypi.python.org/pypi/flake8) and [ran relevant tests](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions)

### In order to be accepted and merged into yt-dlp each piece of code must be in public domain or released under [Unlicense](http://unlicense.org/). Check all of the following options that apply:
- [x] I am the original author of this code and I am willing to release it under [Unlicense](http://unlicense.org/)
- [ ] I am not the original author of this code but it is in public domain or released under [Unlicense](http://unlicense.org/) (provide reliable evidence)

### What is the purpose of your *pull request*?
- [x] Fix or improvement to an extractor (Make sure to add/update tests)
- [ ] New extractor ([Piracy websites will not be accepted](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#is-the-website-primarily-used-for-piracy))
- [ ] Core bug fix/improvement
- [ ] New feature (It is strongly [recommended to open an issue first](https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#adding-new-feature-or-making-overarching-changes))

</details>
",# [redtube] fix broken video URLs
993,"Fixed logic error in ""Beware of default mutable arguments!""
The example showing how using None as a default argument is used
instead of a mutable default argument had reversed logic.  It would
set default_arg to [] whenever the caller passed a non-None argument.",# Fix typo in README.md
994,"Add Clico API
<!-- Thank you for taking the time to work on a Pull Request for this project! -->
<!-- To ensure your PR is dealt with swiftly please check the following: -->
- [x] My submission is formatted according to the guidelines in the [contributing guide](/CONTRIBUTING.md)
- [x] My addition is ordered alphabetically
- [x] My submission has a useful description
- [x] The description does not end with punctuation
- [x] Each table column is padded with one space on either side
- [x] I have searched the repository for any relevant issues or pull requests
- [x] Any category I am creating has the minimum requirement of 3 items
- [x] All changes have been [squashed][squash-link] into a single commit

[squash-link]: <https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit>
",# Added Clico
995,"Added Google Play
",# Added Google Play
996,"fix forward slash validation in S3 pre-signed url
This PR mostly add a test to verify behaviour raised in a community slack issue. The PHP SDK allows the user to specify a bucket with a slash in the name while generating a pre-signed URL. However, this is not allowed by AWS, and we would not raise the proper exception (and there was a small issue in our calculation, as we were using the sanitized path to create the `CanonicalRequest` used for the signature). 

I just added some proper exceptions in that case for the test to pass like it would against AWS. ",# Fix presigned URL for bucket name with forward slashFixes #1594
997,"Adds import statement to front page of docs for clarity and quicker start up
",# Add a code snippet to the index
998,"ansible_tower modules doc: fix typos, use formatting functions
##### SUMMARY
Improve `ansible_tower` modules documentation:
* fix typo
* use formatting functions
* acronyms: use uppercase
* s/job_template/job template/
* `become_enabled`: improve description

##### ISSUE TYPE
 - Docs Pull Request

##### COMPONENT NAME
ansible_tower modules

##### ANSIBLE VERSION
```
ansible 2.6.0 (devel dd0140dfed) last updated 2018/03/14 17:59:25 (GMT +200)
```",# Fix typos in Ansible Tower modules
999,"Year should be year of original publication
Great project! Thanks for this.

While looking through it I noticed that you've updated the copyright year to 2017 but actually, the aim of the year in a copyright notice is to indicate when the work was originally published, in case of any dispute. So I thought I'd raise a PR.

You're not in the UK but this, from the UK's copyright service is useful: http://www.copyrightservice.co.uk/copyright/p03_copyright_notices, item 4, and the rules will be the same in the US.",# Update LICENSE
